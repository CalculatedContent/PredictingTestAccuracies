{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  pretrained models in PyTorch\n",
    "\n",
    "This notebook only has the default pyTorch models\n",
    "\n",
    "More models are available in the osmr and/or cadene repos\n",
    "\n",
    "https://github.com/Cadene/pretrained-models.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T20:35:35.764969Z",
     "start_time": "2018-11-26T20:35:30.965789Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import powerlaw\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    " \n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T20:35:35.788561Z",
     "start_time": "2018-11-26T20:35:35.775597Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [5,5]\n",
    "matplotlib.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models in Torch\n",
    "\n",
    "Accuracies file is taken from the Cadene website\n",
    "\n",
    "https://github.com/Cadene/pretrained-models.pytorch\n",
    "\n",
    "Although I discovered later that this package does not work consistantly so I just use the prebuilt pytorch models here\n",
    "\n",
    "### <font color='red'> Check this file to ensure the numbers are correct...I am sure the trends are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T20:35:35.839589Z",
     "start_time": "2018-11-26T20:35:35.794851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = pd.read_csv('accuracies', delimiter=\"\\t\")\n",
    "len(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T20:35:35.868979Z",
     "start_time": "2018-11-26T20:35:35.849759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tensorflow', 'ourporting', 'Caffe', 'Torch7', 'Keras', 'Pytorch'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies['platform'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T20:35:35.916085Z",
     "start_time": "2018-11-26T20:35:35.877108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,                   model    platform    acc1    acc5\n",
       " 1       PNASNet-5-Large  ourporting  82.736  95.992\n",
       " 3        NASNet-A-Large  ourporting  82.566  96.086\n",
       " 5              SENet154  ourporting  81.304  95.498\n",
       " 7               PolyNet  ourporting  81.002  95.624\n",
       " 10  SE-ResNeXt101_32x4d  ourporting  80.236  95.028\n",
       " 12    InceptionResNetV2  ourporting  80.170  95.234\n",
       " 13          InceptionV4  ourporting  80.062  94.926\n",
       " 14    DualPathNet107_5k  ourporting  79.746  94.684\n",
       " 16       DualPathNet131  ourporting  79.432  94.574\n",
       " 17     DualPathNet92_5k  ourporting  79.400  94.620\n",
       " 18        DualPathNet98  ourporting  79.224  94.488\n",
       " 19   SE-ResNeXt50_32x4d  ourporting  79.076  94.434\n",
       " 22     ResNeXt101_64x4d  ourporting  78.956  94.252\n",
       " 23             Xception  ourporting  78.888  94.292\n",
       " 26         SE-ResNet152  ourporting  78.658  94.374\n",
       " 28         SE-ResNet101  ourporting  78.396  94.258\n",
       " 30     ResNeXt101_32x4d  ourporting  78.188  93.886\n",
       " 33          SE-ResNet50  ourporting  77.636  93.752\n",
       " 36          FBResNet152  ourporting  77.386  93.594\n",
       " 39    DualPathNet68b_5k  ourporting  77.034  93.590\n",
       " 41       CaffeResnet101  ourporting  76.200  92.766\n",
       " 44        DualPathNet68  ourporting  75.868  92.774\n",
       " 48      NASNet-A-Mobile  ourporting  74.080  91.740\n",
       " 50          BNInception  ourporting  73.522  91.560)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_acc = accuracies[accuracies['platform']=='ourporting']\n",
    "len(our_acc), our_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T20:35:36.618411Z",
     "start_time": "2018-11-26T20:35:36.578869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,             model platform    acc1    acc5\n",
       " 27      ResNet152  Pytorch  78.428  94.110\n",
       " 34    DenseNet161  Pytorch  77.560  93.798\n",
       " 35      ResNet101  Pytorch  77.438  93.672\n",
       " 37    InceptionV3  Pytorch  77.294  93.454\n",
       " 38    DenseNet201  Pytorch  77.152  93.548\n",
       " 42    DenseNet169  Pytorch  76.026  92.992\n",
       " 43       ResNet50  Pytorch  76.002  92.980\n",
       " 45    DenseNet121  Pytorch  74.646  92.136\n",
       " 46       VGG19_BN  Pytorch  74.266  92.066\n",
       " 49       ResNet34  Pytorch  73.554  91.456\n",
       " 51       VGG16_BN  Pytorch  73.518  91.608\n",
       " 52          VGG19  Pytorch  72.080  90.822\n",
       " 53          VGG16  Pytorch  71.636  90.354\n",
       " 54       VGG13_BN  Pytorch  71.508  90.494\n",
       " 55       VGG11_BN  Pytorch  70.452  89.818\n",
       " 56       ResNet18  Pytorch  70.142  89.274\n",
       " 57          VGG13  Pytorch  69.662  89.264\n",
       " 58          VGG11  Pytorch  68.970  88.746\n",
       " 59  SqueezeNet1_1  Pytorch  58.250  80.800\n",
       " 60  SqueezeNet1_0  Pytorch  58.108  80.428\n",
       " 61        Alexnet  Pytorch  56.432  79.194)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_acc = accuracies[accuracies['platform']=='Pytorch']\n",
    "len(py_acc), py_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- merge dataframes\n",
    "- get model names\n",
    "- load pretrained\n",
    "- compute lognorm\n",
    "- store in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T20:35:38.090679Z",
     "start_time": "2018-11-26T20:35:38.051383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>platform</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ResNet152</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>78.428</td>\n",
       "      <td>94.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DenseNet161</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.560</td>\n",
       "      <td>93.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ResNet101</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.438</td>\n",
       "      <td>93.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>InceptionV3</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.294</td>\n",
       "      <td>93.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DenseNet201</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.152</td>\n",
       "      <td>93.548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model platform    acc1    acc5\n",
       "27    ResNet152  Pytorch  78.428  94.110\n",
       "34  DenseNet161  Pytorch  77.560  93.798\n",
       "35    ResNet101  Pytorch  77.438  93.672\n",
       "37  InceptionV3  Pytorch  77.294  93.454\n",
       "38  DenseNet201  Pytorch  77.152  93.548"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.concat([py_acc, our_acc])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum dimension for W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T20:35:39.043020Z",
     "start_time": "2018-11-26T20:35:39.034448Z"
    }
   },
   "outputs": [],
   "source": [
    "MIN_DIM = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T20:35:39.917921Z",
     "start_time": "2018-11-26T20:35:39.905916Z"
    }
   },
   "outputs": [],
   "source": [
    "# Suppress the powerlaw package warnings\n",
    "# \"powerlaw.py:700: RuntimeWarning: divide by zero encountered in true_divide\"\n",
    "# \"powerlaw.py:700: RuntimeWarning: invalid value encountered in true_divide\"\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T20:35:40.479972Z",
     "start_time": "2018-11-26T20:35:40.455337Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_model_weighted_alphas(model):\n",
    "    \"\"\"\n",
    "    Metrics ar:\n",
    "        alpha_weighted\n",
    "        alpha_weighted_compound\n",
    "        alpha\n",
    "        alpha_compound\n",
    "        lognorm\n",
    "        lognorm_compound\n",
    "        \n",
    "    \"\"\"\n",
    "#     try:\n",
    "    w_alphas = {}\n",
    "\n",
    "    import weightwatcher as ww\n",
    "\n",
    "    watcher = ww.WeightWatcher(model=model)\n",
    "\n",
    "    #results = watcher.analyze(compute_power=True)\n",
    "    results = watcher.analyze(compute_power=True, max_size=256) # Faster testing\n",
    "\n",
    "    summary = watcher.get_summary()\n",
    "    \n",
    "    for metric in [\"alpha_weighted\", \"alpha_weighted_compound\", \"alpha\", \"alpha_compound\", \"lognorm\", \"lognorm_compound\"]:\n",
    "        if metric in summary:\n",
    "            w_alphas[metric] = summary[metric]\n",
    "\n",
    "#         for W in tqdm(iter_pytorch_layers(model)):\n",
    "#             M, N = np.min(W.shape), np.max(W.shape)\n",
    "            \n",
    "#             # we do NOT normalize by N here...\n",
    "#             # probably should uses tructaed ZSVD for speed\n",
    "#             #X=np.dot(W.T,W)#/N\n",
    "#             #evals = np.linalg.eigvals(X)\n",
    "            \n",
    "#             # orders of magnitude faster, even if we are missing very small 1 SV\n",
    "#             svd = TruncatedSVD(n_components=M-1, n_iter=7, random_state=42)\n",
    "#             svd.fit(W) \n",
    "#             sv = svd.singular_values_\n",
    "#             evals = sv*sv\n",
    "\n",
    "#             l_max, l_min = np.max(evals), np.min(evals)\n",
    "        \n",
    "#             fit = powerlaw.Fit(evals, xmax=l_max, verbose=False)\n",
    "#             w_alphas.append(fit.alpha*np.log10(l_max))\n",
    "            \n",
    "\n",
    "#     except Exception as e: \n",
    "\n",
    "#         print(\"skipping \", model_name)\n",
    "#         print(e)\n",
    "\n",
    "#         pass\n",
    "    \n",
    "    return w_alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T21:42:25.894341Z",
     "start_time": "2018-11-26T20:35:42.072238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2018-11-26 12:35:55,513 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 12:35:55,516 INFO Analyzing model\n",
      "2018-11-26 12:35:55,519 INFO Layer 0: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU(inplace)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:35:55,522 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 12:35:55,525 INFO Layer 1: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): ReLU(inplace)\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU(inplace)\n",
      "  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): ReLU(inplace)\n",
      "  (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (12): ReLU(inplace)\n",
      "  (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (14): ReLU(inplace)\n",
      "  (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (17): ReLU(inplace)\n",
      "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (19): ReLU(inplace)\n",
      "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "2018-11-26 12:35:55,527 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 12:35:55,530 INFO Layer 2: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:35:55,534 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:35:55,538 INFO Layer 2: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:35:55,542 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:35:55,545 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:35:55,547 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:35:55,551 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:35:55,553 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:35:55,555 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:35:55,561 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:35:55,567 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:35:55,571 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:35:55,574 INFO Layer 3: ReLU(inplace)\n",
      "2018-11-26 12:35:55,576 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:35:55,578 INFO Layer 4: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:35:55,581 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 12:35:55,583 INFO Layer 5: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:35:55,590 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:35:55,593 INFO Layer 5: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:35:55,596 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:35:56,139 INFO     Weight matrix 1/9 (64,128): Alpha: 1.6501382770775943, Alpha Weighted: 1.0766481037887519, D: 0.16948541888647117\n",
      "2018-11-26 12:35:56,142 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.7435316443443298\n",
      "2018-11-26 12:35:56,146 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:35:56,598 INFO     Weight matrix 2/9 (64,128): Alpha: 1.5729750131445848, Alpha Weighted: 1.1663846304163914, D: 0.17973842750311175\n",
      "2018-11-26 12:35:56,602 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.7791202068328857\n",
      "2018-11-26 12:35:56,604 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:35:57,073 INFO     Weight matrix 3/9 (64,128): Alpha: 1.4121039504790391, Alpha Weighted: 0.8954579004653346, D: 0.19428108503595737\n",
      "2018-11-26 12:35:57,075 INFO     Weight matrix 3/9 (64,128): Alpha 1.4121039504790391 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:35:57,081 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.7536869049072266\n",
      "2018-11-26 12:35:57,086 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:35:57,632 INFO     Weight matrix 4/9 (64,128): Alpha: 1.4345913027003299, Alpha Weighted: 0.9448696774806342, D: 0.18133941433239287\n",
      "2018-11-26 12:35:57,635 INFO     Weight matrix 4/9 (64,128): Alpha 1.4345913027003299 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:35:57,639 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.7681989669799805\n",
      "2018-11-26 12:35:57,645 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:35:58,173 INFO     Weight matrix 5/9 (64,128): Alpha: 1.618499097955453, Alpha Weighted: 1.5610026505187182, D: 0.1623259162046009\n",
      "2018-11-26 12:35:58,178 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.8472697138786316\n",
      "2018-11-26 12:35:58,181 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:35:58,636 INFO     Weight matrix 6/9 (64,128): Alpha: 1.3854856815241523, Alpha Weighted: 1.0132790887261636, D: 0.18905124095354037\n",
      "2018-11-26 12:35:58,638 INFO     Weight matrix 6/9 (64,128): Alpha 1.3854856815241523 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:35:58,641 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.7852299809455872\n",
      "2018-11-26 12:35:58,643 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:35:59,150 INFO     Weight matrix 7/9 (64,128): Alpha: 1.569204287744134, Alpha Weighted: 0.9040590765965885, D: 0.18198363054134498\n",
      "2018-11-26 12:35:59,155 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.7200042009353638\n",
      "2018-11-26 12:35:59,157 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:35:59,663 INFO     Weight matrix 8/9 (64,128): Alpha: 1.4466120457359575, Alpha Weighted: 1.0071455523713326, D: 0.1815803043396445\n",
      "2018-11-26 12:35:59,665 INFO     Weight matrix 8/9 (64,128): Alpha 1.4466120457359575 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:35:59,670 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.7804905772209167\n",
      "2018-11-26 12:35:59,672 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:36:00,201 INFO     Weight matrix 9/9 (64,128): Alpha: 1.6136188649159218, Alpha Weighted: 1.0025028039906874, D: 0.17297146920538053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:36:00,205 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.7450646758079529\n",
      "2018-11-26 12:36:00,208 INFO Layer 6: ReLU(inplace)\n",
      "2018-11-26 12:36:00,218 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 12:36:00,221 INFO Layer 7: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:36:00,227 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 12:36:00,231 INFO Layer 8: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:36:00,242 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:36:00,246 INFO Layer 8: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:36:00,253 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:36:01,743 INFO     Weight matrix 1/9 (128,256): Alpha: 2.682211407006033, Alpha Weighted: 1.1110499237387716, D: 0.15839192109291017\n",
      "2018-11-26 12:36:01,748 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.7695422768592834\n",
      "2018-11-26 12:36:01,753 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:36:02,941 INFO     Weight matrix 2/9 (128,256): Alpha: 1.624575541168831, Alpha Weighted: 0.984971913982178, D: 0.15038349531670658\n",
      "2018-11-26 12:36:02,945 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.8349188566207886\n",
      "2018-11-26 12:36:02,950 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:36:04,016 INFO     Weight matrix 3/9 (128,256): Alpha: 1.7481679222487294, Alpha Weighted: 0.7086755610270317, D: 0.15976233422592823\n",
      "2018-11-26 12:36:04,019 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.7710186839103699\n",
      "2018-11-26 12:36:04,023 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:36:05,079 INFO     Weight matrix 4/9 (128,256): Alpha: 2.5760761533690415, Alpha Weighted: 1.6520568886432534, D: 0.1331333429941114\n",
      "2018-11-26 12:36:05,083 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.8396487832069397\n",
      "2018-11-26 12:36:05,087 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:36:06,097 INFO     Weight matrix 5/9 (128,256): Alpha: 2.533727366357981, Alpha Weighted: 2.241522152097174, D: 0.1260398277024164\n",
      "2018-11-26 12:36:06,102 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.9509152770042419\n",
      "2018-11-26 12:36:06,105 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:36:07,289 INFO     Weight matrix 6/9 (128,256): Alpha: 1.6150834846735778, Alpha Weighted: 1.0727976671879713, D: 0.12912547936004531\n",
      "2018-11-26 12:36:07,293 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.8459222912788391\n",
      "2018-11-26 12:36:07,297 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:36:08,605 INFO     Weight matrix 7/9 (128,256): Alpha: 1.6649289890160561, Alpha Weighted: 0.6363945630295984, D: 0.15493782240951948\n",
      "2018-11-26 12:36:08,610 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.769291341304779\n",
      "2018-11-26 12:36:08,615 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:36:09,796 INFO     Weight matrix 8/9 (128,256): Alpha: 1.6911656312843695, Alpha Weighted: 1.020692965175946, D: 0.13113787530768883\n",
      "2018-11-26 12:36:09,801 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.8332030773162842\n",
      "2018-11-26 12:36:09,807 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:36:11,053 INFO     Weight matrix 9/9 (128,256): Alpha: 2.0503678706616313, Alpha Weighted: 0.8569681256199276, D: 0.14425799900587544\n",
      "2018-11-26 12:36:11,057 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.7771602272987366\n",
      "2018-11-26 12:36:11,060 INFO Layer 9: ReLU(inplace)\n",
      "2018-11-26 12:36:11,064 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 12:36:11,067 INFO Layer 10: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:36:11,076 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:36:11,079 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:36:11,083 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:36:14,086 INFO     Weight matrix 1/9 (256,256): Alpha: 2.2103685446241137, Alpha Weighted: 0.8721202008061498, D: 0.12885915651960533\n",
      "2018-11-26 12:36:14,090 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.8579453229904175\n",
      "2018-11-26 12:36:14,095 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:36:16,882 INFO     Weight matrix 2/9 (256,256): Alpha: 2.0252637250206416, Alpha Weighted: 1.0256377100677299, D: 0.12252819174340557\n",
      "2018-11-26 12:36:16,886 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.8855762481689453\n",
      "2018-11-26 12:36:16,888 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:36:19,483 INFO     Weight matrix 3/9 (256,256): Alpha: 2.0484478817871095, Alpha Weighted: 0.8159194240963691, D: 0.12204156291064844\n",
      "2018-11-26 12:36:19,488 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.8663251399993896\n",
      "2018-11-26 12:36:19,492 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:36:22,273 INFO     Weight matrix 4/9 (256,256): Alpha: 2.6582698201793162, Alpha Weighted: 1.3211438834431082, D: 0.12169919267658397\n",
      "2018-11-26 12:36:22,278 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.8791447281837463\n",
      "2018-11-26 12:36:22,282 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:36:24,881 INFO     Weight matrix 5/9 (256,256): Alpha: 1.80045361683568, Alpha Weighted: 1.3681396518985667, D: 0.11590061764212117\n",
      "2018-11-26 12:36:24,885 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.9453065395355225\n",
      "2018-11-26 12:36:24,888 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:36:27,928 INFO     Weight matrix 6/9 (256,256): Alpha: 2.0425176083551984, Alpha Weighted: 1.1107903400938146, D: 0.12374498607648132\n",
      "2018-11-26 12:36:27,932 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.886420488357544\n",
      "2018-11-26 12:36:27,935 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:36:30,388 INFO     Weight matrix 7/9 (256,256): Alpha: 2.604096789214418, Alpha Weighted: 1.0384152774430735, D: 0.12428418827194665\n",
      "2018-11-26 12:36:30,391 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.8589674830436707\n",
      "2018-11-26 12:36:30,394 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:36:33,178 INFO     Weight matrix 8/9 (256,256): Alpha: 1.974426187742051, Alpha Weighted: 0.9784457988600769, D: 0.12141249164484802\n",
      "2018-11-26 12:36:33,182 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.8895105123519897\n",
      "2018-11-26 12:36:33,187 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:36:36,062 INFO     Weight matrix 9/9 (256,256): Alpha: 2.0731958622076387, Alpha Weighted: 0.8033694269240823, D: 0.13215291968367504\n",
      "2018-11-26 12:36:36,066 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.8611611127853394\n",
      "2018-11-26 12:36:36,070 INFO Layer 11: ReLU(inplace)\n",
      "2018-11-26 12:36:36,073 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:36:36,076 INFO Layer 12: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:36:36,078 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 12:36:36,081 INFO Layer 13: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:36:36,115 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:36:36,118 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:36:36,120 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:36:39,020 INFO     Weight matrix 1/9 (256,512): Alpha: 2.6517221926740246, Alpha Weighted: 1.2570211280999037, D: 0.10811361598539998\n",
      "2018-11-26 12:36:39,025 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.9264131188392639\n",
      "2018-11-26 12:36:39,029 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:36:42,006 INFO     Weight matrix 2/9 (256,512): Alpha: 2.168115236956596, Alpha Weighted: 1.2167389540956297, D: 0.12371985885919029\n",
      "2018-11-26 12:36:42,011 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.9532338976860046\n",
      "2018-11-26 12:36:42,014 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:36:44,584 INFO     Weight matrix 3/9 (256,512): Alpha: 2.6890834415941622, Alpha Weighted: 1.2802716588252028, D: 0.09975489509022295\n",
      "2018-11-26 12:36:44,589 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.9262917041778564\n",
      "2018-11-26 12:36:44,592 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:36:47,889 INFO     Weight matrix 4/9 (256,512): Alpha: 2.0557190033109602, Alpha Weighted: 1.2611990454013073, D: 0.1102519664380106\n",
      "2018-11-26 12:36:47,895 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.9493745565414429\n",
      "2018-11-26 12:36:47,899 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:36:51,437 INFO     Weight matrix 5/9 (256,512): Alpha: 3.8241563365024627, Alpha Weighted: 3.263759049479247, D: 0.0990651856076652\n",
      "2018-11-26 12:36:51,440 INFO     Weight matrix 5/9 (256,512): Alpha 3.8241563365024627 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:36:51,444 INFO     Weight matrix 5/9 (256,512): Lognorm: 1.0106232166290283\n",
      "2018-11-26 12:36:51,447 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:36:54,387 INFO     Weight matrix 6/9 (256,512): Alpha: 2.841660949785283, Alpha Weighted: 1.7285448401474826, D: 0.10146026051677032\n",
      "2018-11-26 12:36:54,392 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.9507067203521729\n",
      "2018-11-26 12:36:54,395 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:36:57,597 INFO     Weight matrix 7/9 (256,512): Alpha: 2.5426618067263176, Alpha Weighted: 1.1927627254327484, D: 0.11033037759688885\n",
      "2018-11-26 12:36:57,602 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.9216506481170654\n",
      "2018-11-26 12:36:57,604 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:37:00,484 INFO     Weight matrix 8/9 (256,512): Alpha: 2.8994876906762146, Alpha Weighted: 1.6334750171091756, D: 0.11620842040762192\n",
      "2018-11-26 12:37:00,488 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.9460030794143677\n",
      "2018-11-26 12:37:00,491 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:37:03,040 INFO     Weight matrix 9/9 (256,512): Alpha: 2.2671621440449634, Alpha Weighted: 1.1108181220288662, D: 0.11398776995328902\n",
      "2018-11-26 12:37:03,044 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.922294020652771\n",
      "2018-11-26 12:37:03,048 INFO Layer 14: ReLU(inplace)\n",
      "2018-11-26 12:37:03,051 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:03,054 INFO Layer 15: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:37:03,107 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:37:03,111 INFO Layer 15: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:37:03,116 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,121 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,126 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,128 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,133 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,138 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,141 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,144 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,147 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,149 INFO Layer 16: ReLU(inplace)\n",
      "2018-11-26 12:37:03,152 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:03,155 INFO Layer 17: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:37:03,158 INFO Layer 17: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:03,162 INFO Layer 18: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:37:03,209 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:37:03,212 INFO Layer 18: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:37:03,215 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,219 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,224 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,226 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,229 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,233 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,239 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,242 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,246 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,250 INFO Layer 19: ReLU(inplace)\n",
      "2018-11-26 12:37:03,256 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:03,259 INFO Layer 20: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:37:03,286 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:37:03,290 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:37:03,293 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,297 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,299 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,302 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,305 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,308 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,311 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,315 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,318 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:03,321 INFO Layer 21: ReLU(inplace)\n",
      "2018-11-26 12:37:03,323 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:03,328 INFO Layer 22: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:37:03,331 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:03,335 INFO Layer 23: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 12:37:03,337 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:03,340 INFO Layer 24: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 12:37:05,736 INFO Layer 24: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:37:05,739 INFO     Weight matrix 1/1 (4096,25088): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:05,741 INFO Layer 25: ReLU(inplace)\n",
      "2018-11-26 12:37:05,853 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:05,856 INFO Layer 26: Dropout(p=0.5)\n",
      "2018-11-26 12:37:05,860 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:05,863 INFO Layer 27: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 12:37:06,206 INFO Layer 27: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:37:06,209 INFO     Weight matrix 1/1 (4096,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:06,212 INFO Layer 28: ReLU(inplace)\n",
      "2018-11-26 12:37:06,239 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:06,242 INFO Layer 29: Dropout(p=0.5)\n",
      "2018-11-26 12:37:06,244 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:06,247 INFO Layer 30: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 12:37:06,341 INFO Layer 30: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:37:06,343 INFO     Weight matrix 1/1 (1000,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:37:06,346 INFO ### Printing results ###\n",
      "2018-11-26 12:37:06,348 DEBUG Layer 5: Lognorm compound: 0.7691774302058749\n",
      "2018-11-26 12:37:06,350 DEBUG Layer 8: Lognorm compound: 0.8212912016444736\n",
      "2018-11-26 12:37:06,353 DEBUG Layer 10: Lognorm compound: 0.8811508417129517\n",
      "2018-11-26 12:37:06,357 DEBUG Layer 13: Lognorm compound: 0.9451767736011081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:37:06,360 INFO LogNorm: min: 0.7200042009353638, max: 1.0106232166290283, avg: 0.8541991114616394\n",
      "2018-11-26 12:37:06,363 INFO LogNorm compound: min: 0.7691774302058749, max: 0.9451767736011081, avg: 0.854199061791102\n",
      "2018-11-26 12:37:06,367 DEBUG Layer 5: Alpha compound: 1.5225809468085738\n",
      "2018-11-26 12:37:06,372 DEBUG Layer 8: Alpha compound: 2.020700485087361\n",
      "2018-11-26 12:37:06,375 DEBUG Layer 10: Alpha compound: 2.1596711151073524\n",
      "2018-11-26 12:37:06,383 DEBUG Layer 13: Alpha compound: 2.6599743113634426\n",
      "2018-11-26 12:37:06,387 INFO Alpha: min: 1.3854856815241523, max: 3.8241563365024627, avg: 2.0907317145916817\n",
      "2018-11-26 12:37:06,390 INFO Alpha compound: min: 1.5225809468085738, max: 2.6599743113634426, avg: 2.0907317145916826\n",
      "2018-11-26 12:37:06,393 DEBUG Layer 5: Alpha Weighted compound: 1.0634832760394002\n",
      "2018-11-26 12:37:06,396 DEBUG Layer 8: Alpha Weighted compound: 1.1427921956113167\n",
      "2018-11-26 12:37:06,399 DEBUG Layer 10: Alpha Weighted compound: 1.0371090792925524\n",
      "2018-11-26 12:37:06,402 DEBUG Layer 13: Alpha Weighted compound: 1.5493989489577293\n",
      "2018-11-26 12:37:06,406 INFO Alpha Weighted: min: 0.6363945630295984, max: 3.263759049479247, avg: 1.19819587497525\n",
      "2018-11-26 12:37:06,410 INFO Alpha Weighted compound: min: 1.0371090792925524, max: 1.5493989489577293, avg: 1.1981958749752497\n",
      "2018-11-26 12:37:13,703 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 12:37:13,705 INFO Analyzing model\n",
      "2018-11-26 12:37:13,711 INFO Layer 0: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace)\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (27): ReLU(inplace)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:37:13,715 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:13,719 INFO Layer 1: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): ReLU(inplace)\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (10): ReLU(inplace)\n",
      "  (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (13): ReLU(inplace)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (17): ReLU(inplace)\n",
      "  (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (20): ReLU(inplace)\n",
      "  (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (24): ReLU(inplace)\n",
      "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (27): ReLU(inplace)\n",
      "  (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "2018-11-26 12:37:13,722 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:13,725 INFO Layer 2: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:37:13,730 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:37:13,733 INFO Layer 2: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:37:13,735 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:37:13,738 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:37:13,742 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:37:13,744 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:37:13,747 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:37:13,750 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:37:13,752 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:37:13,755 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:37:13,762 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:37:13,766 INFO Layer 3: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:37:13,768 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:13,771 INFO Layer 4: ReLU(inplace)\n",
      "2018-11-26 12:37:13,774 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:13,777 INFO Layer 5: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:37:13,780 INFO Layer 5: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg11_bn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:37:13,928 INFO Layer 6: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:37:13,932 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:37:13,935 INFO Layer 6: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:37:13,940 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:37:14,350 INFO     Weight matrix 1/9 (64,128): Alpha: 1.6496957456422598, Alpha Weighted: 0.5947317011500954, D: 0.20626953809225157\n",
      "2018-11-26 12:37:14,354 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.5997806191444397\n",
      "2018-11-26 12:37:14,357 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:37:14,706 INFO     Weight matrix 2/9 (64,128): Alpha: 1.5135118063674884, Alpha Weighted: 0.806305749102268, D: 0.23009813034916904\n",
      "2018-11-26 12:37:14,709 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.6721765995025635\n",
      "2018-11-26 12:37:14,714 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:37:15,074 INFO     Weight matrix 3/9 (64,128): Alpha: 1.6653278215299951, Alpha Weighted: 0.5977157526353419, D: 0.2209023954719921\n",
      "2018-11-26 12:37:15,077 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.6062731146812439\n",
      "2018-11-26 12:37:15,080 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:37:15,436 INFO     Weight matrix 4/9 (64,128): Alpha: 1.7353059768279364, Alpha Weighted: 0.9808296413762294, D: 0.22664934316417418\n",
      "2018-11-26 12:37:15,439 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.6845961809158325\n",
      "2018-11-26 12:37:15,445 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:37:15,794 INFO     Weight matrix 5/9 (64,128): Alpha: 1.3312675874883295, Alpha Weighted: 1.0279249103896457, D: 0.2326199294950903\n",
      "2018-11-26 12:37:15,797 INFO     Weight matrix 5/9 (64,128): Alpha 1.3312675874883295 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:37:15,803 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.7663372755050659\n",
      "2018-11-26 12:37:15,806 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:37:16,152 INFO     Weight matrix 6/9 (64,128): Alpha: 1.3956646587397088, Alpha Weighted: 0.6589629825741868, D: 0.24556455827769613\n",
      "2018-11-26 12:37:16,154 INFO     Weight matrix 6/9 (64,128): Alpha 1.3956646587397088 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:37:16,158 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.6790146827697754\n",
      "2018-11-26 12:37:16,163 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:37:16,523 INFO     Weight matrix 7/9 (64,128): Alpha: 1.7195690051012653, Alpha Weighted: 0.6645154375610195, D: 0.18926289983584743\n",
      "2018-11-26 12:37:16,527 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.5993328094482422\n",
      "2018-11-26 12:37:16,529 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:37:16,882 INFO     Weight matrix 8/9 (64,128): Alpha: 1.836242467570802, Alpha Weighted: 1.0274902446687846, D: 0.2227667123707997\n",
      "2018-11-26 12:37:16,885 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.6673287749290466\n",
      "2018-11-26 12:37:16,888 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:37:17,229 INFO     Weight matrix 9/9 (64,128): Alpha: 2.1316326145787774, Alpha Weighted: 0.7780607265814438, D: 0.24408139094546888\n",
      "2018-11-26 12:37:17,233 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.6020925045013428\n",
      "2018-11-26 12:37:17,236 INFO Layer 7: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:37:17,241 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:17,244 INFO Layer 8: ReLU(inplace)\n",
      "2018-11-26 12:37:17,247 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:17,249 INFO Layer 9: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:37:17,252 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:17,254 INFO Layer 10: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:37:17,263 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:37:17,265 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:37:17,268 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:37:18,274 INFO     Weight matrix 1/9 (128,256): Alpha: 2.238046629527916, Alpha Weighted: 1.0142093247706725, D: 0.10909762311508908\n",
      "2018-11-26 12:37:18,279 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.7035576105117798\n",
      "2018-11-26 12:37:18,281 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:37:19,246 INFO     Weight matrix 2/9 (128,256): Alpha: 1.7563880935228895, Alpha Weighted: 0.8394058714084498, D: 0.13504888565738954\n",
      "2018-11-26 12:37:19,250 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.7586631178855896\n",
      "2018-11-26 12:37:19,253 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:37:20,215 INFO     Weight matrix 3/9 (128,256): Alpha: 2.229832394597416, Alpha Weighted: 1.0593367754194072, D: 0.09628677587291234\n",
      "2018-11-26 12:37:20,218 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.6992807388305664\n",
      "2018-11-26 12:37:20,223 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:37:21,190 INFO     Weight matrix 4/9 (128,256): Alpha: 1.9745366689034338, Alpha Weighted: 0.9191998337716678, D: 0.1372015892589844\n",
      "2018-11-26 12:37:21,194 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.7612313032150269\n",
      "2018-11-26 12:37:21,197 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:37:22,158 INFO     Weight matrix 5/9 (128,256): Alpha: 2.8687626770298014, Alpha Weighted: 2.0244380578966132, D: 0.11077787242093917\n",
      "2018-11-26 12:37:22,162 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.8638467788696289\n",
      "2018-11-26 12:37:22,169 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:37:23,122 INFO     Weight matrix 6/9 (128,256): Alpha: 1.6140792143445528, Alpha Weighted: 0.706090195097394, D: 0.14066260650547052\n",
      "2018-11-26 12:37:23,126 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.7619961500167847\n",
      "2018-11-26 12:37:23,129 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:37:24,080 INFO     Weight matrix 7/9 (128,256): Alpha: 2.0247996005104323, Alpha Weighted: 0.8544546718868856, D: 0.11699064901932654\n",
      "2018-11-26 12:37:24,083 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.6964058876037598\n",
      "2018-11-26 12:37:24,086 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:37:25,032 INFO     Weight matrix 8/9 (128,256): Alpha: 1.9798945719813577, Alpha Weighted: 0.9343266776650887, D: 0.12884448311407254\n",
      "2018-11-26 12:37:25,035 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.755610466003418\n",
      "2018-11-26 12:37:25,038 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:37:25,986 INFO     Weight matrix 9/9 (128,256): Alpha: 2.139073704759788, Alpha Weighted: 0.9990548541212684, D: 0.10477107838590394\n",
      "2018-11-26 12:37:25,990 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.6986998915672302\n",
      "2018-11-26 12:37:25,993 INFO Layer 11: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:37:25,995 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:25,998 INFO Layer 12: ReLU(inplace)\n",
      "2018-11-26 12:37:26,000 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:26,003 INFO Layer 13: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:37:26,022 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:37:26,025 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:37:26,027 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:37:28,377 INFO     Weight matrix 1/9 (256,256): Alpha: 2.1099516770625915, Alpha Weighted: 0.3695310119993883, D: 0.14019934786805022\n",
      "2018-11-26 12:37:28,383 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7819792628288269\n",
      "2018-11-26 12:37:28,388 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:37:31,208 INFO     Weight matrix 2/9 (256,256): Alpha: 2.035438832624266, Alpha Weighted: 0.5793953027943746, D: 0.1297485802155534\n",
      "2018-11-26 12:37:31,214 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.8153413534164429\n",
      "2018-11-26 12:37:31,217 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:37:34,058 INFO     Weight matrix 3/9 (256,256): Alpha: 2.2584270196724097, Alpha Weighted: 0.4197145819750078, D: 0.12950270137680098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:37:34,062 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.781470537185669\n",
      "2018-11-26 12:37:34,065 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:37:36,795 INFO     Weight matrix 4/9 (256,256): Alpha: 1.8870318130078412, Alpha Weighted: 0.4640333641964341, D: 0.14037330787297508\n",
      "2018-11-26 12:37:36,800 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.8162485361099243\n",
      "2018-11-26 12:37:36,803 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:37:39,285 INFO     Weight matrix 5/9 (256,256): Alpha: 4.426796167746652, Alpha Weighted: 2.2788759337027216, D: 0.12898363996584916\n",
      "2018-11-26 12:37:39,288 INFO     Weight matrix 5/9 (256,256): Alpha 4.426796167746652 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:37:39,293 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8796184062957764\n",
      "2018-11-26 12:37:39,297 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:37:41,634 INFO     Weight matrix 6/9 (256,256): Alpha: 1.9802216846008944, Alpha Weighted: 0.500991229488712, D: 0.1360063084982408\n",
      "2018-11-26 12:37:41,639 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.8149921298027039\n",
      "2018-11-26 12:37:41,642 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:37:43,946 INFO     Weight matrix 7/9 (256,256): Alpha: 2.2316968955671186, Alpha Weighted: 0.30176647632390513, D: 0.14395217344166256\n",
      "2018-11-26 12:37:43,950 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.7732064127922058\n",
      "2018-11-26 12:37:43,954 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:37:46,188 INFO     Weight matrix 8/9 (256,256): Alpha: 2.0924369897290545, Alpha Weighted: 0.5409067682409202, D: 0.13138489016913835\n",
      "2018-11-26 12:37:46,193 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.8121046423912048\n",
      "2018-11-26 12:37:46,196 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:37:48,436 INFO     Weight matrix 9/9 (256,256): Alpha: 2.29185994252126, Alpha Weighted: 0.34461455256572004, D: 0.12595510499948837\n",
      "2018-11-26 12:37:48,441 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7764164805412292\n",
      "2018-11-26 12:37:48,443 INFO Layer 14: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:37:48,446 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:48,448 INFO Layer 15: ReLU(inplace)\n",
      "2018-11-26 12:37:48,451 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:48,453 INFO Layer 16: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:37:48,455 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 12:37:48,458 INFO Layer 17: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:37:48,486 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:37:48,489 INFO Layer 17: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:37:48,492 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:37:50,885 INFO     Weight matrix 1/9 (256,512): Alpha: 2.6050254445874996, Alpha Weighted: 1.135166020621109, D: 0.09174582315715446\n",
      "2018-11-26 12:37:50,890 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.8869200348854065\n",
      "2018-11-26 12:37:50,892 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:37:53,325 INFO     Weight matrix 2/9 (256,512): Alpha: 3.1158529899615575, Alpha Weighted: 1.4450045111295022, D: 0.11584374022084354\n",
      "2018-11-26 12:37:53,329 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.9086707830429077\n",
      "2018-11-26 12:37:53,332 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:37:55,961 INFO     Weight matrix 3/9 (256,512): Alpha: 2.6308645002318776, Alpha Weighted: 1.1658520365132061, D: 0.08596221528298442\n",
      "2018-11-26 12:37:55,965 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.8812524080276489\n",
      "2018-11-26 12:37:55,969 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:37:58,581 INFO     Weight matrix 4/9 (256,512): Alpha: 3.167499679125847, Alpha Weighted: 1.5579714025333327, D: 0.09014502057935336\n",
      "2018-11-26 12:37:58,585 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.9096864461898804\n",
      "2018-11-26 12:37:58,588 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:38:01,138 INFO     Weight matrix 5/9 (256,512): Alpha: 5.2298727236158875, Alpha Weighted: 3.393250607528101, D: 0.07692307692307654\n",
      "2018-11-26 12:38:01,140 INFO     Weight matrix 5/9 (256,512): Alpha 5.2298727236158875 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:38:01,145 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.9789407253265381\n",
      "2018-11-26 12:38:01,147 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:38:03,515 INFO     Weight matrix 6/9 (256,512): Alpha: 3.115656210624684, Alpha Weighted: 1.5973102800070977, D: 0.10252450956358486\n",
      "2018-11-26 12:38:03,521 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.9049524068832397\n",
      "2018-11-26 12:38:03,525 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:38:05,988 INFO     Weight matrix 7/9 (256,512): Alpha: 2.7417277450789443, Alpha Weighted: 1.0893031544901328, D: 0.09379007935205114\n",
      "2018-11-26 12:38:05,993 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.8766897320747375\n",
      "2018-11-26 12:38:05,997 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:38:08,547 INFO     Weight matrix 8/9 (256,512): Alpha: 1.8605935623604024, Alpha Weighted: 0.8242125406714254, D: 0.12543086141276294\n",
      "2018-11-26 12:38:08,552 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.900371253490448\n",
      "2018-11-26 12:38:08,554 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:38:11,090 INFO     Weight matrix 9/9 (256,512): Alpha: 2.78997825142606, Alpha Weighted: 1.1148498637718536, D: 0.08640552216063468\n",
      "2018-11-26 12:38:11,094 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.8750525712966919\n",
      "2018-11-26 12:38:11,096 INFO Layer 18: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:38:11,099 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:11,103 INFO Layer 19: ReLU(inplace)\n",
      "2018-11-26 12:38:11,105 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:11,108 INFO Layer 20: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:38:11,153 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:38:11,156 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:38:11,159 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,164 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,167 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,172 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,177 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,183 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,191 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,194 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,200 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,202 INFO Layer 21: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:38:11,209 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:11,212 INFO Layer 22: ReLU(inplace)\n",
      "2018-11-26 12:38:11,216 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:11,226 INFO Layer 23: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:38:11,230 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:11,234 INFO Layer 24: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:38:11,269 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:38:11,272 INFO Layer 24: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:38:11,275 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,277 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,285 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:38:11,288 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,292 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,297 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,304 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,309 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,319 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,325 INFO Layer 25: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:38:11,331 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:11,334 INFO Layer 26: ReLU(inplace)\n",
      "2018-11-26 12:38:11,340 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:11,343 INFO Layer 27: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:38:11,363 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:38:11,368 INFO Layer 27: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:38:11,371 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,378 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,385 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,390 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,394 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,397 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,403 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,406 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,410 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:11,417 INFO Layer 28: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:38:11,420 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:11,425 INFO Layer 29: ReLU(inplace)\n",
      "2018-11-26 12:38:11,429 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:11,433 INFO Layer 30: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:38:11,439 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:11,443 INFO Layer 31: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 12:38:11,446 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:11,449 INFO Layer 32: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 12:38:13,748 INFO Layer 32: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:38:13,750 INFO     Weight matrix 1/1 (4096,25088): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:13,753 INFO Layer 33: ReLU(inplace)\n",
      "2018-11-26 12:38:13,852 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:13,855 INFO Layer 34: Dropout(p=0.5)\n",
      "2018-11-26 12:38:13,858 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:13,861 INFO Layer 35: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 12:38:14,204 INFO Layer 35: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:38:14,207 INFO     Weight matrix 1/1 (4096,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:14,209 INFO Layer 36: ReLU(inplace)\n",
      "2018-11-26 12:38:14,236 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:14,240 INFO Layer 37: Dropout(p=0.5)\n",
      "2018-11-26 12:38:14,247 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:14,250 INFO Layer 38: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 12:38:14,335 INFO Layer 38: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:38:14,338 INFO     Weight matrix 1/1 (1000,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:38:14,341 INFO ### Printing results ###\n",
      "2018-11-26 12:38:14,344 DEBUG Layer 6: Lognorm compound: 0.6529925068219503\n",
      "2018-11-26 12:38:14,351 DEBUG Layer 10: Lognorm compound: 0.7443657716115316\n",
      "2018-11-26 12:38:14,354 DEBUG Layer 13: Lognorm compound: 0.8057086401515536\n",
      "2018-11-26 12:38:14,356 DEBUG Layer 17: Lognorm compound: 0.9025040401352776\n",
      "2018-11-26 12:38:14,361 INFO LogNorm: min: 0.5993328094482422, max: 0.9789407253265381, avg: 0.7763927578926086\n",
      "2018-11-26 12:38:14,364 INFO LogNorm compound: min: 0.6529925068219503, max: 0.9025040401352776, avg: 0.7763927396800783\n",
      "2018-11-26 12:38:14,367 DEBUG Layer 6: Alpha compound: 1.6642464093162848\n",
      "2018-11-26 12:38:14,369 DEBUG Layer 10: Alpha compound: 2.0917126172419542\n",
      "2018-11-26 12:38:14,372 DEBUG Layer 13: Alpha compound: 2.368206780281343\n",
      "2018-11-26 12:38:14,375 DEBUG Layer 17: Alpha compound: 3.028563456334751\n",
      "2018-11-26 12:38:14,378 INFO Alpha: min: 1.3312675874883295, max: 5.2298727236158875, avg: 2.288182315793583\n",
      "2018-11-26 12:38:14,381 INFO Alpha compound: min: 1.6642464093162848, max: 3.028563456334751, avg: 2.288182315793583\n",
      "2018-11-26 12:38:14,383 DEBUG Layer 6: Alpha Weighted compound: 0.7929485717821129\n",
      "2018-11-26 12:38:14,386 DEBUG Layer 10: Alpha Weighted compound: 1.038946251337494\n",
      "2018-11-26 12:38:14,389 DEBUG Layer 13: Alpha Weighted compound: 0.6444254690319094\n",
      "2018-11-26 12:38:14,391 DEBUG Layer 17: Alpha Weighted compound: 1.4803244908073063\n",
      "2018-11-26 12:38:14,395 INFO Alpha Weighted: min: 0.30176647632390513, max: 3.393250607528101, avg: 0.9891611957397056\n",
      "2018-11-26 12:38:14,397 INFO Alpha Weighted compound: min: 0.6444254690319094, max: 1.4803244908073063, avg: 0.9891611957397056\n",
      "2018-11-26 12:38:22,097 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 12:38:22,099 INFO Analyzing model\n",
      "2018-11-26 12:38:22,104 INFO Layer 0: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): ReLU(inplace)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): ReLU(inplace)\n",
      "    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:38:22,108 INFO Layer 0: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:38:22,115 INFO Layer 1: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace)\n",
      "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (16): ReLU(inplace)\n",
      "  (17): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace)\n",
      "  (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (21): ReLU(inplace)\n",
      "  (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (23): ReLU(inplace)\n",
      "  (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "2018-11-26 12:38:22,118 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:22,122 INFO Layer 2: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:38:22,126 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:38:22,129 INFO Layer 2: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:38:22,136 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:38:22,139 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:38:22,142 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:38:22,146 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:38:22,149 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:38:22,153 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:38:22,156 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:38:22,159 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:38:22,163 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:38:22,166 INFO Layer 3: ReLU(inplace)\n",
      "2018-11-26 12:38:22,170 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:22,173 INFO Layer 4: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:38:22,179 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:38:22,181 INFO Layer 4: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:38:22,186 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:38:22,899 INFO     Weight matrix 1/9 (64,64): Alpha: 1.998570664005624, Alpha Weighted: 0.530849783720195, D: 0.18598398449575027\n",
      "2018-11-26 12:38:22,901 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.555422306060791\n",
      "2018-11-26 12:38:22,907 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:38:23,441 INFO     Weight matrix 2/9 (64,64): Alpha: 1.5227656643676322, Alpha Weighted: 0.7031174869890701, D: 0.15918352804560132\n",
      "2018-11-26 12:38:23,446 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.5787814259529114\n",
      "2018-11-26 12:38:23,448 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:38:24,014 INFO     Weight matrix 3/9 (64,64): Alpha: 2.1369657470537424, Alpha Weighted: 0.6382029023227483, D: 0.16491792098667757\n",
      "2018-11-26 12:38:24,017 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.53458172082901\n",
      "2018-11-26 12:38:24,021 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:38:24,520 INFO     Weight matrix 4/9 (64,64): Alpha: 1.4775758885544734, Alpha Weighted: 0.6623070046116852, D: 0.16073584637340266\n",
      "2018-11-26 12:38:24,523 INFO     Weight matrix 4/9 (64,64): Alpha 1.4775758885544734 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:38:24,526 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.5797208547592163\n",
      "2018-11-26 12:38:24,529 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:38:25,004 INFO     Weight matrix 5/9 (64,64): Alpha: 1.5488980269177948, Alpha Weighted: 0.8708143972205923, D: 0.1493816582439298\n",
      "2018-11-26 12:38:25,007 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.626145601272583\n",
      "2018-11-26 12:38:25,011 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:38:25,528 INFO     Weight matrix 6/9 (64,64): Alpha: 1.552251767488616, Alpha Weighted: 0.621202706146811, D: 0.16765244910266897\n",
      "2018-11-26 12:38:25,531 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.5915738940238953\n",
      "2018-11-26 12:38:25,537 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:38:26,047 INFO     Weight matrix 7/9 (64,64): Alpha: 1.4229915864997174, Alpha Weighted: 0.4182557101962185, D: 0.19553249696330566\n",
      "2018-11-26 12:38:26,050 INFO     Weight matrix 7/9 (64,64): Alpha 1.4229915864997174 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:38:26,054 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.5425663590431213\n",
      "2018-11-26 12:38:26,058 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:38:26,577 INFO     Weight matrix 8/9 (64,64): Alpha: 1.4870415637488288, Alpha Weighted: 0.6945968402271283, D: 0.16496928966711832\n",
      "2018-11-26 12:38:26,580 INFO     Weight matrix 8/9 (64,64): Alpha 1.4870415637488288 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:38:26,583 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.5852140784263611\n",
      "2018-11-26 12:38:26,586 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:38:27,136 INFO     Weight matrix 9/9 (64,64): Alpha: 1.4267628978821798, Alpha Weighted: 0.3745428047958965, D: 0.20325877753223764\n",
      "2018-11-26 12:38:27,139 INFO     Weight matrix 9/9 (64,64): Alpha 1.4267628978821798 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:38:27,143 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.5504339933395386\n",
      "2018-11-26 12:38:27,146 INFO Layer 5: ReLU(inplace)\n",
      "2018-11-26 12:38:27,152 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:27,156 INFO Layer 6: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:38:27,159 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:27,162 INFO Layer 7: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:38:27,167 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:38:27,170 INFO Layer 7: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:38:27,174 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:38:27,774 INFO     Weight matrix 1/9 (64,128): Alpha: 1.8107391581066166, Alpha Weighted: 0.7929710955117995, D: 0.14500309931430655\n",
      "2018-11-26 12:38:27,777 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.6680006384849548\n",
      "2018-11-26 12:38:27,781 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:38:28,304 INFO     Weight matrix 2/9 (64,128): Alpha: 1.7729935906609484, Alpha Weighted: 1.044640883996178, D: 0.1453438269649604\n",
      "2018-11-26 12:38:28,307 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.7057045102119446\n",
      "2018-11-26 12:38:28,310 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:38:28,812 INFO     Weight matrix 3/9 (64,128): Alpha: 1.811471779196968, Alpha Weighted: 0.805938165828245, D: 0.15762444780382928\n",
      "2018-11-26 12:38:28,816 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.6612639427185059\n",
      "2018-11-26 12:38:28,819 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:38:29,256 INFO     Weight matrix 4/9 (64,128): Alpha: 1.7804243850511114, Alpha Weighted: 0.9158584845391363, D: 0.155751260135927\n",
      "2018-11-26 12:38:29,259 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.6933040618896484\n",
      "2018-11-26 12:38:29,262 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:38:29,785 INFO     Weight matrix 5/9 (64,128): Alpha: 1.7223669803109436, Alpha Weighted: 1.2801292605605652, D: 0.14315049564268978\n",
      "2018-11-26 12:38:29,791 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.7414924502372742\n",
      "2018-11-26 12:38:29,796 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:38:30,298 INFO     Weight matrix 6/9 (64,128): Alpha: 1.7330246689158657, Alpha Weighted: 0.9110644503633423, D: 0.14202299140443875\n",
      "2018-11-26 12:38:30,301 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.6887338161468506\n",
      "2018-11-26 12:38:30,304 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:38:30,842 INFO     Weight matrix 7/9 (64,128): Alpha: 1.812909550734491, Alpha Weighted: 1.0364915677262332, D: 0.1380979955484541\n",
      "2018-11-26 12:38:30,845 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.6727420091629028\n",
      "2018-11-26 12:38:30,850 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:38:31,383 INFO     Weight matrix 8/9 (64,128): Alpha: 1.7591478629806345, Alpha Weighted: 0.9669425938617835, D: 0.13934794038801884\n",
      "2018-11-26 12:38:31,387 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.6912813782691956\n",
      "2018-11-26 12:38:31,392 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:38:31,899 INFO     Weight matrix 9/9 (64,128): Alpha: 1.8891456168166523, Alpha Weighted: 0.8229428761873807, D: 0.16650142557586867\n",
      "2018-11-26 12:38:31,902 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.6467894315719604\n",
      "2018-11-26 12:38:31,905 INFO Layer 8: ReLU(inplace)\n",
      "2018-11-26 12:38:31,908 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:31,910 INFO Layer 9: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:38:31,917 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:38:31,920 INFO Layer 9: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:38:31,923 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:38:32,998 INFO     Weight matrix 1/9 (128,128): Alpha: 1.857021824240698, Alpha Weighted: 0.425034828817708, D: 0.15544370594369072\n",
      "2018-11-26 12:38:33,002 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.7174193859100342\n",
      "2018-11-26 12:38:33,005 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:38:34,129 INFO     Weight matrix 2/9 (128,128): Alpha: 1.9010924680505537, Alpha Weighted: 0.6002309722302438, D: 0.1509027468748837\n",
      "2018-11-26 12:38:34,133 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.7336912751197815\n",
      "2018-11-26 12:38:34,136 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:38:35,234 INFO     Weight matrix 3/9 (128,128): Alpha: 3.6536136233634573, Alpha Weighted: 1.0583687919406108, D: 0.15350961810128722\n",
      "2018-11-26 12:38:35,237 INFO     Weight matrix 3/9 (128,128): Alpha 3.6536136233634573 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:38:35,240 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.7086058855056763\n",
      "2018-11-26 12:38:35,243 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:38:36,385 INFO     Weight matrix 4/9 (128,128): Alpha: 1.726248752520473, Alpha Weighted: 0.42188705731147536, D: 0.17243243344900272\n",
      "2018-11-26 12:38:36,390 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.7316402196884155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:38:36,397 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:38:37,514 INFO     Weight matrix 5/9 (128,128): Alpha: 4.822057822997586, Alpha Weighted: 2.2655184285306964, D: 0.14172972976977982\n",
      "2018-11-26 12:38:37,516 INFO     Weight matrix 5/9 (128,128): Alpha 4.822057822997586 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:38:37,521 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.7713156938552856\n",
      "2018-11-26 12:38:37,524 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:38:38,529 INFO     Weight matrix 6/9 (128,128): Alpha: 2.0045945509134526, Alpha Weighted: 0.5872486110176838, D: 0.16553413858855975\n",
      "2018-11-26 12:38:38,533 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.7348038554191589\n",
      "2018-11-26 12:38:38,537 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:38:39,488 INFO     Weight matrix 7/9 (128,128): Alpha: 1.9531349944986998, Alpha Weighted: 0.509380582994308, D: 0.1566485100885634\n",
      "2018-11-26 12:38:39,493 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.7069422006607056\n",
      "2018-11-26 12:38:39,496 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:38:40,437 INFO     Weight matrix 8/9 (128,128): Alpha: 1.9591050122513294, Alpha Weighted: 0.43972489976150203, D: 0.1639783601965067\n",
      "2018-11-26 12:38:40,441 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.7316706776618958\n",
      "2018-11-26 12:38:40,443 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:38:41,419 INFO     Weight matrix 9/9 (128,128): Alpha: 1.8342968770764423, Alpha Weighted: 0.4627399558526968, D: 0.163558750872412\n",
      "2018-11-26 12:38:41,422 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.7158021926879883\n",
      "2018-11-26 12:38:41,426 INFO Layer 10: ReLU(inplace)\n",
      "2018-11-26 12:38:41,429 INFO Layer 10: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:41,432 INFO Layer 11: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:38:41,437 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:41,440 INFO Layer 12: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:38:41,450 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:38:41,455 INFO Layer 12: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:38:41,458 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:38:42,674 INFO     Weight matrix 1/9 (128,256): Alpha: 2.5156248867302464, Alpha Weighted: 1.0518307454393476, D: 0.10143106752935549\n",
      "2018-11-26 12:38:42,678 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.767629086971283\n",
      "2018-11-26 12:38:42,682 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:38:43,687 INFO     Weight matrix 2/9 (128,256): Alpha: 2.4514543446591115, Alpha Weighted: 1.3212487891031406, D: 0.1168162632430787\n",
      "2018-11-26 12:38:43,691 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.8146148920059204\n",
      "2018-11-26 12:38:43,695 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:38:44,735 INFO     Weight matrix 3/9 (128,256): Alpha: 3.0291402205796247, Alpha Weighted: 1.185343531539956, D: 0.1295865824051723\n",
      "2018-11-26 12:38:44,739 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.7666121125221252\n",
      "2018-11-26 12:38:44,741 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:38:45,787 INFO     Weight matrix 4/9 (128,256): Alpha: 2.839263050930465, Alpha Weighted: 1.5765674557968563, D: 0.10860353360842062\n",
      "2018-11-26 12:38:45,790 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.814735472202301\n",
      "2018-11-26 12:38:45,793 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:38:47,019 INFO     Weight matrix 5/9 (128,256): Alpha: 4.882613555143458, Alpha Weighted: 3.6244372535271627, D: 0.14285714285714257\n",
      "2018-11-26 12:38:47,022 INFO     Weight matrix 5/9 (128,256): Alpha 4.882613555143458 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:38:47,024 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.8988584280014038\n",
      "2018-11-26 12:38:47,029 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:38:48,093 INFO     Weight matrix 6/9 (128,256): Alpha: 2.6335163253046927, Alpha Weighted: 1.3063939958172333, D: 0.10870746680877441\n",
      "2018-11-26 12:38:48,097 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.8094183802604675\n",
      "2018-11-26 12:38:48,100 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:38:49,086 INFO     Weight matrix 7/9 (128,256): Alpha: 2.6176190774645054, Alpha Weighted: 0.9261299306873547, D: 0.11393675945220083\n",
      "2018-11-26 12:38:49,089 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.7631824016571045\n",
      "2018-11-26 12:38:49,092 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:38:50,274 INFO     Weight matrix 8/9 (128,256): Alpha: 2.5869481342025766, Alpha Weighted: 1.432440905112883, D: 0.13113951746313557\n",
      "2018-11-26 12:38:50,278 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.8044846057891846\n",
      "2018-11-26 12:38:50,282 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:38:51,403 INFO     Weight matrix 9/9 (128,256): Alpha: 3.147342412427119, Alpha Weighted: 1.1551266722874272, D: 0.11083793021614208\n",
      "2018-11-26 12:38:51,406 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.7636407613754272\n",
      "2018-11-26 12:38:51,409 INFO Layer 13: ReLU(inplace)\n",
      "2018-11-26 12:38:51,411 INFO Layer 13: Skipping (Layer not supported)\n",
      "2018-11-26 12:38:51,413 INFO Layer 14: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:38:51,437 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:38:51,440 INFO Layer 14: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:38:51,442 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:38:54,037 INFO     Weight matrix 1/9 (256,256): Alpha: 2.4906046251345, Alpha Weighted: 0.8338415997824618, D: 0.11926825491193044\n",
      "2018-11-26 12:38:54,044 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.8347761034965515\n",
      "2018-11-26 12:38:54,047 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:38:56,389 INFO     Weight matrix 2/9 (256,256): Alpha: 2.7464403040382743, Alpha Weighted: 1.3198179882559176, D: 0.09733453678389647\n",
      "2018-11-26 12:38:56,393 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.8510901927947998\n",
      "2018-11-26 12:38:56,396 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:38:59,013 INFO     Weight matrix 3/9 (256,256): Alpha: 3.072085929988806, Alpha Weighted: 1.0791197839053435, D: 0.09978870899758263\n",
      "2018-11-26 12:38:59,020 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.8321912288665771\n",
      "2018-11-26 12:38:59,023 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:39:01,489 INFO     Weight matrix 4/9 (256,256): Alpha: 3.0443380554167154, Alpha Weighted: 1.5885945147063367, D: 0.09122426156495661\n",
      "2018-11-26 12:39:01,493 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.8481708765029907\n",
      "2018-11-26 12:39:01,500 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:39:03,786 INFO     Weight matrix 5/9 (256,256): Alpha: 3.4238350142256535, Alpha Weighted: 2.4744267880806934, D: 0.0695713823413896\n",
      "2018-11-26 12:39:03,791 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.9025205969810486\n",
      "2018-11-26 12:39:03,794 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:39:06,103 INFO     Weight matrix 6/9 (256,256): Alpha: 3.193372791081828, Alpha Weighted: 1.5467966075750401, D: 0.08670600754625446\n",
      "2018-11-26 12:39:06,107 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.8415446281433105\n",
      "2018-11-26 12:39:06,110 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:39:08,569 INFO     Weight matrix 7/9 (256,256): Alpha: 2.579755863321081, Alpha Weighted: 0.8874102145279272, D: 0.1090272209363119\n",
      "2018-11-26 12:39:08,573 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.8381807804107666\n",
      "2018-11-26 12:39:08,576 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:39:11,044 INFO     Weight matrix 8/9 (256,256): Alpha: 3.0865112217989927, Alpha Weighted: 1.5002501371223573, D: 0.10738557243873847\n",
      "2018-11-26 12:39:11,048 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.8552940487861633\n",
      "2018-11-26 12:39:11,051 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:39:13,506 INFO     Weight matrix 9/9 (256,256): Alpha: 2.755471004041125, Alpha Weighted: 1.0248423392573844, D: 0.09561998405218597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:39:13,511 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.835618257522583\n",
      "2018-11-26 12:39:13,514 INFO Layer 15: ReLU(inplace)\n",
      "2018-11-26 12:39:13,517 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:13,524 INFO Layer 16: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:39:13,527 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:13,530 INFO Layer 17: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:39:13,557 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:39:13,560 INFO Layer 17: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:39:13,565 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:39:16,210 INFO     Weight matrix 1/9 (256,512): Alpha: 2.339917930309967, Alpha Weighted: 1.009131880796214, D: 0.11919398522401647\n",
      "2018-11-26 12:39:16,214 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.916579008102417\n",
      "2018-11-26 12:39:16,220 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:39:18,584 INFO     Weight matrix 2/9 (256,512): Alpha: 2.032216579380863, Alpha Weighted: 1.0873141729533315, D: 0.11662816432166045\n",
      "2018-11-26 12:39:18,589 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.9380613565444946\n",
      "2018-11-26 12:39:18,593 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:39:20,970 INFO     Weight matrix 3/9 (256,512): Alpha: 2.7086153301028544, Alpha Weighted: 1.2600772536026814, D: 0.1019246621822858\n",
      "2018-11-26 12:39:20,974 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.9178951382637024\n",
      "2018-11-26 12:39:20,977 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:39:23,358 INFO     Weight matrix 4/9 (256,512): Alpha: 2.174964020570722, Alpha Weighted: 1.161320290849224, D: 0.11920918316382945\n",
      "2018-11-26 12:39:23,363 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.9282858967781067\n",
      "2018-11-26 12:39:23,366 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:39:25,857 INFO     Weight matrix 5/9 (256,512): Alpha: 3.9444760346696213, Alpha Weighted: 3.0363939658899466, D: 0.07692307692307654\n",
      "2018-11-26 12:39:25,860 INFO     Weight matrix 5/9 (256,512): Alpha 3.9444760346696213 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:39:25,866 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.980600893497467\n",
      "2018-11-26 12:39:25,868 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:39:28,633 INFO     Weight matrix 6/9 (256,512): Alpha: 3.02538715817979, Alpha Weighted: 1.620448234078988, D: 0.10638341952272412\n",
      "2018-11-26 12:39:28,638 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.9300090670585632\n",
      "2018-11-26 12:39:28,644 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:39:31,236 INFO     Weight matrix 7/9 (256,512): Alpha: 2.300735751499256, Alpha Weighted: 0.9941742434462486, D: 0.11341556343066883\n",
      "2018-11-26 12:39:31,242 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.912216305732727\n",
      "2018-11-26 12:39:31,245 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:39:33,921 INFO     Weight matrix 8/9 (256,512): Alpha: 1.99463932524016, Alpha Weighted: 1.0130028875335417, D: 0.11187604704230997\n",
      "2018-11-26 12:39:33,927 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.9304941892623901\n",
      "2018-11-26 12:39:33,930 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:39:36,647 INFO     Weight matrix 9/9 (256,512): Alpha: 2.9786914525067956, Alpha Weighted: 1.2181638356411233, D: 0.11800487808964932\n",
      "2018-11-26 12:39:36,655 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.9159024953842163\n",
      "2018-11-26 12:39:36,660 INFO Layer 18: ReLU(inplace)\n",
      "2018-11-26 12:39:36,666 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:36,668 INFO Layer 19: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:39:36,728 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:39:36,731 INFO Layer 19: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:39:36,738 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,741 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,746 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,750 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,754 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,760 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,763 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,767 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,770 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,773 INFO Layer 20: ReLU(inplace)\n",
      "2018-11-26 12:39:36,777 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:36,780 INFO Layer 21: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:39:36,783 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:36,787 INFO Layer 22: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:39:36,823 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:39:36,828 INFO Layer 22: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:39:36,833 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,835 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,841 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,847 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,854 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,860 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,870 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,876 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,880 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,885 INFO Layer 23: ReLU(inplace)\n",
      "2018-11-26 12:39:36,890 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:36,892 INFO Layer 24: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:39:36,916 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:39:36,920 INFO Layer 24: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:39:36,923 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,927 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,933 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,936 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,942 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,947 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,951 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,955 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,959 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:36,966 INFO Layer 25: ReLU(inplace)\n",
      "2018-11-26 12:39:36,976 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:36,980 INFO Layer 26: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:39:36,983 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:36,989 INFO Layer 27: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 12:39:36,993 INFO Layer 27: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:39:36,996 INFO Layer 28: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 12:39:38,737 INFO Layer 28: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:39:38,741 INFO     Weight matrix 1/1 (4096,25088): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:38,747 INFO Layer 29: ReLU(inplace)\n",
      "2018-11-26 12:39:38,850 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:38,852 INFO Layer 30: Dropout(p=0.5)\n",
      "2018-11-26 12:39:38,855 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:38,858 INFO Layer 31: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 12:39:39,224 INFO Layer 31: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:39:39,229 INFO     Weight matrix 1/1 (4096,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:39,231 INFO Layer 32: ReLU(inplace)\n",
      "2018-11-26 12:39:39,260 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:39,263 INFO Layer 33: Dropout(p=0.5)\n",
      "2018-11-26 12:39:39,266 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:39,269 INFO Layer 34: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 12:39:39,360 INFO Layer 34: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:39:39,363 INFO     Weight matrix 1/1 (1000,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:39:39,366 INFO ### Printing results ###\n",
      "2018-11-26 12:39:39,370 DEBUG Layer 4: Lognorm compound: 0.5716044704119364\n",
      "2018-11-26 12:39:39,374 DEBUG Layer 7: Lognorm compound: 0.685479137632582\n",
      "2018-11-26 12:39:39,379 DEBUG Layer 9: Lognorm compound: 0.7279879318343269\n",
      "2018-11-26 12:39:39,386 DEBUG Layer 12: Lognorm compound: 0.8003529045316908\n",
      "2018-11-26 12:39:39,390 DEBUG Layer 14: Lognorm compound: 0.8488207459449768\n",
      "2018-11-26 12:39:39,392 DEBUG Layer 17: Lognorm compound: 0.9300049278471205\n",
      "2018-11-26 12:39:39,396 INFO LogNorm: min: 0.53458172082901, max: 0.980600893497467, avg: 0.7607083320617676\n",
      "2018-11-26 12:39:39,399 INFO LogNorm compound: min: 0.5716044704119364, max: 0.9300049278471205, avg: 0.7607083530337722\n",
      "2018-11-26 12:39:39,401 DEBUG Layer 4: Alpha compound: 1.6193137562798454\n",
      "2018-11-26 12:39:39,404 DEBUG Layer 7: Alpha compound: 1.7880248436415813\n",
      "2018-11-26 12:39:39,407 DEBUG Layer 9: Alpha compound: 2.4123517695458547\n",
      "2018-11-26 12:39:39,410 DEBUG Layer 12: Alpha compound: 2.9670580008268663\n",
      "2018-11-26 12:39:39,413 DEBUG Layer 14: Alpha compound: 2.9324905343385534\n",
      "2018-11-26 12:39:39,415 DEBUG Layer 17: Alpha compound: 2.6110715091622256\n",
      "2018-11-26 12:39:39,424 INFO Alpha: min: 1.4229915864997174, max: 4.882613555143458, avg: 2.3883850689658215\n",
      "2018-11-26 12:39:39,427 INFO Alpha compound: min: 1.6193137562798454, max: 2.9670580008268663, avg: 2.3883850689658215\n",
      "2018-11-26 12:39:39,434 DEBUG Layer 4: Alpha Weighted compound: 0.6126544040255939\n",
      "2018-11-26 12:39:39,437 DEBUG Layer 7: Alpha Weighted compound: 0.9529977087305181\n",
      "2018-11-26 12:39:39,440 DEBUG Layer 9: Alpha Weighted compound: 0.7522371253841027\n",
      "2018-11-26 12:39:39,444 DEBUG Layer 12: Alpha Weighted compound: 1.5088354754790398\n",
      "2018-11-26 12:39:39,452 DEBUG Layer 14: Alpha Weighted compound: 1.3616777748014957\n",
      "2018-11-26 12:39:39,461 DEBUG Layer 17: Alpha Weighted compound: 1.377780751643478\n",
      "2018-11-26 12:39:39,465 INFO Alpha Weighted: min: 0.3745428047958965, max: 3.6244372535271627, avg: 1.0943638733440382\n",
      "2018-11-26 12:39:39,468 INFO Alpha Weighted compound: min: 0.6126544040255939, max: 1.5088354754790398, avg: 1.0943638733440382\n",
      "2018-11-26 12:39:46,670 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 12:39:46,673 INFO Analyzing model\n",
      "2018-11-26 12:39:46,680 INFO Layer 0: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (21): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (23): ReLU(inplace)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (30): ReLU(inplace)\n",
      "    (31): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (33): ReLU(inplace)\n",
      "    (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:39:46,683 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:46,688 INFO Layer 1: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace)\n",
      "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace)\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU(inplace)\n",
      "  (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU(inplace)\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (16): ReLU(inplace)\n",
      "  (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (19): ReLU(inplace)\n",
      "  (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (21): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (23): ReLU(inplace)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (26): ReLU(inplace)\n",
      "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (30): ReLU(inplace)\n",
      "  (31): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (33): ReLU(inplace)\n",
      "  (34): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:39:46,690 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:46,693 INFO Layer 2: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:39:46,696 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:39:46,699 INFO Layer 2: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:39:46,702 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:39:46,704 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:39:46,707 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:39:46,710 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:39:46,712 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:39:46,716 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:39:46,719 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:39:46,721 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:39:46,724 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:39:46,726 INFO Layer 3: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:39:46,729 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:46,731 INFO Layer 4: ReLU(inplace)\n",
      "2018-11-26 12:39:46,733 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:46,736 INFO Layer 5: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:39:46,738 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:39:46,742 INFO Layer 5: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:39:46,746 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg13_bn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:39:47,151 INFO     Weight matrix 1/9 (64,64): Alpha: 1.5857116107935703, Alpha Weighted: 0.14409320123545785, D: 0.21408412654279574\n",
      "2018-11-26 12:39:47,154 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.3236437141895294\n",
      "2018-11-26 12:39:47,157 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:39:47,483 INFO     Weight matrix 2/9 (64,64): Alpha: 2.302359162359691, Alpha Weighted: 0.708629497779994, D: 0.23375388623241322\n",
      "2018-11-26 12:39:47,487 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.42646071314811707\n",
      "2018-11-26 12:39:47,491 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:39:47,819 INFO     Weight matrix 3/9 (64,64): Alpha: 1.539537263296173, Alpha Weighted: 0.09612662556461819, D: 0.23468191132558736\n",
      "2018-11-26 12:39:47,822 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.34800300002098083\n",
      "2018-11-26 12:39:47,826 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:39:48,174 INFO     Weight matrix 4/9 (64,64): Alpha: 3.142630549986738, Alpha Weighted: 0.631012075396832, D: 0.21102727039678454\n",
      "2018-11-26 12:39:48,177 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.3956087827682495\n",
      "2018-11-26 12:39:48,183 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:39:48,500 INFO     Weight matrix 5/9 (64,64): Alpha: 3.798671263192149, Alpha Weighted: 1.6685441343673661, D: 0.2000000000000005\n",
      "2018-11-26 12:39:48,502 INFO     Weight matrix 5/9 (64,64): Alpha 3.798671263192149 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:39:48,505 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.4901217222213745\n",
      "2018-11-26 12:39:48,507 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:39:48,851 INFO     Weight matrix 6/9 (64,64): Alpha: 3.6086532275323564, Alpha Weighted: 0.9686894793658604, D: 0.1666666666666673\n",
      "2018-11-26 12:39:48,854 INFO     Weight matrix 6/9 (64,64): Alpha 3.6086532275323564 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:39:48,858 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.406570702791214\n",
      "2018-11-26 12:39:48,860 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:39:49,207 INFO     Weight matrix 7/9 (64,64): Alpha: 1.5424065897984374, Alpha Weighted: -0.0502193424989187, D: 0.24750514062646833\n",
      "2018-11-26 12:39:49,210 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.343167245388031\n",
      "2018-11-26 12:39:49,214 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:39:49,533 INFO     Weight matrix 8/9 (64,64): Alpha: 1.984170470616145, Alpha Weighted: 0.5012683092356816, D: 0.23682796720431798\n",
      "2018-11-26 12:39:49,537 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.40822649002075195\n",
      "2018-11-26 12:39:49,539 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:39:49,857 INFO     Weight matrix 9/9 (64,64): Alpha: 5.100962350298197, Alpha Weighted: 0.13447541766774113, D: 0.2500000000000009\n",
      "2018-11-26 12:39:49,859 INFO     Weight matrix 9/9 (64,64): Alpha 5.100962350298197 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:39:49,862 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.3379751741886139\n",
      "2018-11-26 12:39:49,865 INFO Layer 6: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:39:49,874 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:49,876 INFO Layer 7: ReLU(inplace)\n",
      "2018-11-26 12:39:49,879 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:49,882 INFO Layer 8: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:39:49,885 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:49,888 INFO Layer 9: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:39:49,892 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:39:49,894 INFO Layer 9: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:39:49,899 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:39:50,339 INFO     Weight matrix 1/9 (64,128): Alpha: 1.9736492211698495, Alpha Weighted: 1.1632016662949192, D: 0.09291567776067666\n",
      "2018-11-26 12:39:50,343 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.5718109607696533\n",
      "2018-11-26 12:39:50,345 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:39:50,740 INFO     Weight matrix 2/9 (64,128): Alpha: 1.7716095654128075, Alpha Weighted: 0.9778279280663574, D: 0.1505953056075966\n",
      "2018-11-26 12:39:50,744 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.6119271516799927\n",
      "2018-11-26 12:39:50,747 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:39:51,174 INFO     Weight matrix 3/9 (64,128): Alpha: 2.0631861062840606, Alpha Weighted: 1.1018443919001504, D: 0.11452220658323653\n",
      "2018-11-26 12:39:51,177 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.5712844729423523\n",
      "2018-11-26 12:39:51,180 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:39:51,586 INFO     Weight matrix 4/9 (64,128): Alpha: 1.6305710964421931, Alpha Weighted: 0.7369311380610115, D: 0.13843417792092283\n",
      "2018-11-26 12:39:51,591 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.6082833409309387\n",
      "2018-11-26 12:39:51,594 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:39:52,024 INFO     Weight matrix 5/9 (64,128): Alpha: 1.877471475074063, Alpha Weighted: 1.0708473970127135, D: 0.1716734073712396\n",
      "2018-11-26 12:39:52,028 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.6536932587623596\n",
      "2018-11-26 12:39:52,030 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:39:52,451 INFO     Weight matrix 6/9 (64,128): Alpha: 1.6791195607959608, Alpha Weighted: 0.8388907233706452, D: 0.13418722844289643\n",
      "2018-11-26 12:39:52,454 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.6041015386581421\n",
      "2018-11-26 12:39:52,457 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:39:52,877 INFO     Weight matrix 7/9 (64,128): Alpha: 1.9568468385160056, Alpha Weighted: 0.9325236056418899, D: 0.14153213485359395\n",
      "2018-11-26 12:39:52,880 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.5662127137184143\n",
      "2018-11-26 12:39:52,883 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:39:53,308 INFO     Weight matrix 8/9 (64,128): Alpha: 1.7056952130264353, Alpha Weighted: 0.7917654515974596, D: 0.15206440231617668\n",
      "2018-11-26 12:39:53,312 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.6104803085327148\n",
      "2018-11-26 12:39:53,314 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:39:53,736 INFO     Weight matrix 9/9 (64,128): Alpha: 2.023740768993087, Alpha Weighted: 1.077871203652848, D: 0.09910398678131704\n",
      "2018-11-26 12:39:53,740 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.5680310130119324\n",
      "2018-11-26 12:39:53,742 INFO Layer 10: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:39:53,745 INFO Layer 10: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:53,749 INFO Layer 11: ReLU(inplace)\n",
      "2018-11-26 12:39:53,753 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:39:53,756 INFO Layer 12: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:39:53,763 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:39:53,768 INFO Layer 12: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:39:53,771 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:39:54,595 INFO     Weight matrix 1/9 (128,128): Alpha: 2.473928873212663, Alpha Weighted: 0.2560973346190226, D: 0.14863717401058663\n",
      "2018-11-26 12:39:54,598 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.5798072814941406\n",
      "2018-11-26 12:39:54,602 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:39:55,355 INFO     Weight matrix 2/9 (128,128): Alpha: 1.816940253133723, Alpha Weighted: 0.2813211801308035, D: 0.17681231303968659\n",
      "2018-11-26 12:39:55,358 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.6210896372795105\n",
      "2018-11-26 12:39:55,362 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:39:56,148 INFO     Weight matrix 3/9 (128,128): Alpha: 3.26209099095639, Alpha Weighted: 0.2768403052636063, D: 0.1437725566491097\n",
      "2018-11-26 12:39:56,152 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.5861191153526306\n",
      "2018-11-26 12:39:56,155 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:39:57,040 INFO     Weight matrix 4/9 (128,128): Alpha: 7.42748716716912, Alpha Weighted: 1.035805465820521, D: 0.1818554118261258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:39:57,042 INFO     Weight matrix 4/9 (128,128): Alpha 7.42748716716912 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:39:57,047 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.6276276707649231\n",
      "2018-11-26 12:39:57,050 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:39:57,886 INFO     Weight matrix 5/9 (128,128): Alpha: 2.347539200837576, Alpha Weighted: 0.747634314845567, D: 0.19465044759456673\n",
      "2018-11-26 12:39:57,891 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.6993218064308167\n",
      "2018-11-26 12:39:57,895 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:39:58,826 INFO     Weight matrix 6/9 (128,128): Alpha: 3.1300679731191647, Alpha Weighted: 0.653084789245094, D: 0.17426578540387883\n",
      "2018-11-26 12:39:58,832 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.6377673745155334\n",
      "2018-11-26 12:39:58,836 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:39:59,692 INFO     Weight matrix 7/9 (128,128): Alpha: 1.9127083315698314, Alpha Weighted: 0.22189975449224628, D: 0.16835904147423042\n",
      "2018-11-26 12:39:59,696 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.5919578075408936\n",
      "2018-11-26 12:39:59,701 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:40:00,728 INFO     Weight matrix 8/9 (128,128): Alpha: 1.8429060993594053, Alpha Weighted: 0.3038894578452014, D: 0.17912364500891137\n",
      "2018-11-26 12:40:00,732 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.6258042454719543\n",
      "2018-11-26 12:40:00,734 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:40:01,734 INFO     Weight matrix 9/9 (128,128): Alpha: 2.3716396254137377, Alpha Weighted: 0.3051554591828908, D: 0.16727410197559517\n",
      "2018-11-26 12:40:01,739 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.5891520380973816\n",
      "2018-11-26 12:40:01,741 INFO Layer 13: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:40:01,746 INFO Layer 13: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:01,750 INFO Layer 14: ReLU(inplace)\n",
      "2018-11-26 12:40:01,754 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:01,757 INFO Layer 15: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:40:01,761 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:01,764 INFO Layer 16: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:40:01,774 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:40:01,777 INFO Layer 16: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:40:01,780 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:40:02,893 INFO     Weight matrix 1/9 (128,256): Alpha: 2.087727243819672, Alpha Weighted: 0.4652111809021847, D: 0.14054883863586498\n",
      "2018-11-26 12:40:02,896 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.6993683576583862\n",
      "2018-11-26 12:40:02,900 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:40:04,115 INFO     Weight matrix 2/9 (128,256): Alpha: 3.031325082547182, Alpha Weighted: 1.2081935250920686, D: 0.1307839338133755\n",
      "2018-11-26 12:40:04,119 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.7449001669883728\n",
      "2018-11-26 12:40:04,122 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:40:05,263 INFO     Weight matrix 3/9 (128,256): Alpha: 2.1675841528267394, Alpha Weighted: 0.4208797140868403, D: 0.1419768991919585\n",
      "2018-11-26 12:40:05,268 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.7071148753166199\n",
      "2018-11-26 12:40:05,271 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:40:06,339 INFO     Weight matrix 4/9 (128,256): Alpha: 2.768618529081694, Alpha Weighted: 1.1451792506560012, D: 0.13621476477274175\n",
      "2018-11-26 12:40:06,344 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.7437664270401001\n",
      "2018-11-26 12:40:06,347 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:40:07,410 INFO     Weight matrix 5/9 (128,256): Alpha: 3.3110006679505677, Alpha Weighted: 1.7307005449352684, D: 0.15055935151974376\n",
      "2018-11-26 12:40:07,414 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.8226166367530823\n",
      "2018-11-26 12:40:07,416 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:40:08,404 INFO     Weight matrix 6/9 (128,256): Alpha: 2.8807213385264303, Alpha Weighted: 1.2807483200306182, D: 0.14892288588928515\n",
      "2018-11-26 12:40:08,407 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.7481269836425781\n",
      "2018-11-26 12:40:08,411 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:40:09,766 INFO     Weight matrix 7/9 (128,256): Alpha: 2.501286868828294, Alpha Weighted: 0.5733141592914353, D: 0.14079436427138792\n",
      "2018-11-26 12:40:09,770 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.7054877281188965\n",
      "2018-11-26 12:40:09,773 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:40:10,809 INFO     Weight matrix 8/9 (128,256): Alpha: 2.573545003746826, Alpha Weighted: 0.9894294128275075, D: 0.1343888749751978\n",
      "2018-11-26 12:40:10,814 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.7367128133773804\n",
      "2018-11-26 12:40:10,817 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:40:11,969 INFO     Weight matrix 9/9 (128,256): Alpha: 2.1019959398028583, Alpha Weighted: 0.5304346714824111, D: 0.12442167989877229\n",
      "2018-11-26 12:40:11,974 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.7037714719772339\n",
      "2018-11-26 12:40:11,978 INFO Layer 17: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:40:11,982 INFO Layer 17: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:11,989 INFO Layer 18: ReLU(inplace)\n",
      "2018-11-26 12:40:11,992 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:11,996 INFO Layer 19: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:40:12,019 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:40:12,024 INFO Layer 19: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:40:12,027 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:40:15,090 INFO     Weight matrix 1/9 (256,256): Alpha: 2.9961451200637876, Alpha Weighted: 0.7166362906078226, D: 0.10329279247062462\n",
      "2018-11-26 12:40:15,095 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7758408188819885\n",
      "2018-11-26 12:40:15,097 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:40:17,539 INFO     Weight matrix 2/9 (256,256): Alpha: 4.0800395075358695, Alpha Weighted: 0.9983813496192699, D: 0.1052433453617242\n",
      "2018-11-26 12:40:17,542 INFO     Weight matrix 2/9 (256,256): Alpha 4.0800395075358695 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:40:17,546 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7917833924293518\n",
      "2018-11-26 12:40:17,548 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:40:20,327 INFO     Weight matrix 3/9 (256,256): Alpha: 3.2035870824615085, Alpha Weighted: 0.6633381602380553, D: 0.12629782440518167\n",
      "2018-11-26 12:40:20,332 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.7754475474357605\n",
      "2018-11-26 12:40:20,337 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:40:22,889 INFO     Weight matrix 4/9 (256,256): Alpha: 2.7691564433377334, Alpha Weighted: 0.6287905071032375, D: 0.13948876683937061\n",
      "2018-11-26 12:40:22,894 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.792868971824646\n",
      "2018-11-26 12:40:22,896 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:40:25,375 INFO     Weight matrix 5/9 (256,256): Alpha: 3.4021814259548084, Alpha Weighted: 1.7649045700683552, D: 0.08972497780733091\n",
      "2018-11-26 12:40:25,379 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8511083126068115\n",
      "2018-11-26 12:40:25,383 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:40:27,765 INFO     Weight matrix 6/9 (256,256): Alpha: 3.7705505631407594, Alpha Weighted: 0.8850616906487632, D: 0.12624830381404184\n",
      "2018-11-26 12:40:27,768 INFO     Weight matrix 6/9 (256,256): Alpha 3.7705505631407594 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:40:27,772 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7916189432144165\n",
      "2018-11-26 12:40:27,775 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:40:30,277 INFO     Weight matrix 7/9 (256,256): Alpha: 2.5777291056027667, Alpha Weighted: 0.5140578958173041, D: 0.11841186708866963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:40:30,282 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.773457944393158\n",
      "2018-11-26 12:40:30,286 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:40:32,866 INFO     Weight matrix 8/9 (256,256): Alpha: 2.9914631198725967, Alpha Weighted: 0.6602291370139831, D: 0.14272879184194542\n",
      "2018-11-26 12:40:32,870 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7922695279121399\n",
      "2018-11-26 12:40:32,873 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:40:35,134 INFO     Weight matrix 9/9 (256,256): Alpha: 2.419798207947503, Alpha Weighted: 0.4274390063006023, D: 0.12143165686640356\n",
      "2018-11-26 12:40:35,139 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7736714482307434\n",
      "2018-11-26 12:40:35,141 INFO Layer 20: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:40:35,143 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:35,146 INFO Layer 21: ReLU(inplace)\n",
      "2018-11-26 12:40:35,149 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:35,152 INFO Layer 22: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:40:35,154 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:35,157 INFO Layer 23: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:40:35,183 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:40:35,188 INFO Layer 23: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:40:35,192 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:40:37,538 INFO     Weight matrix 1/9 (256,512): Alpha: 2.4419669431976114, Alpha Weighted: 0.9690392467448189, D: 0.1037714550392358\n",
      "2018-11-26 12:40:37,543 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.8797587752342224\n",
      "2018-11-26 12:40:37,546 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:40:39,947 INFO     Weight matrix 2/9 (256,512): Alpha: 2.893036362454042, Alpha Weighted: 1.1253398404307005, D: 0.12193898199298692\n",
      "2018-11-26 12:40:39,953 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.8948659896850586\n",
      "2018-11-26 12:40:39,955 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:40:42,317 INFO     Weight matrix 3/9 (256,512): Alpha: 2.7743207700900108, Alpha Weighted: 1.0589984462749031, D: 0.09526811097133203\n",
      "2018-11-26 12:40:42,321 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.8786860704421997\n",
      "2018-11-26 12:40:42,324 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:40:44,702 INFO     Weight matrix 4/9 (256,512): Alpha: 3.781576581304724, Alpha Weighted: 1.6576864091339345, D: 0.094891764418913\n",
      "2018-11-26 12:40:44,704 INFO     Weight matrix 4/9 (256,512): Alpha 3.781576581304724 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:40:44,710 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.8890255093574524\n",
      "2018-11-26 12:40:44,713 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:40:47,045 INFO     Weight matrix 5/9 (256,512): Alpha: 3.041303733674345, Alpha Weighted: 1.6626164006009065, D: 0.12162705494876164\n",
      "2018-11-26 12:40:47,050 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.9578632116317749\n",
      "2018-11-26 12:40:47,053 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:40:49,509 INFO     Weight matrix 6/9 (256,512): Alpha: 3.396272054846913, Alpha Weighted: 1.4660271920811054, D: 0.10486384280081074\n",
      "2018-11-26 12:40:49,514 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.8886378407478333\n",
      "2018-11-26 12:40:49,517 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:40:52,172 INFO     Weight matrix 7/9 (256,512): Alpha: 2.9769499656511296, Alpha Weighted: 0.9939506414467625, D: 0.10574799915773231\n",
      "2018-11-26 12:40:52,178 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.8736560344696045\n",
      "2018-11-26 12:40:52,181 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:40:55,140 INFO     Weight matrix 8/9 (256,512): Alpha: 2.7776513658715722, Alpha Weighted: 1.0348493932810263, D: 0.10627796225324276\n",
      "2018-11-26 12:40:55,146 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.8868027925491333\n",
      "2018-11-26 12:40:55,151 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:40:57,886 INFO     Weight matrix 9/9 (256,512): Alpha: 3.030270462862458, Alpha Weighted: 1.0039286656120239, D: 0.0981756898044911\n",
      "2018-11-26 12:40:57,891 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.870478630065918\n",
      "2018-11-26 12:40:57,894 INFO Layer 24: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:40:57,896 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:58,162 INFO Layer 25: ReLU(inplace)\n",
      "2018-11-26 12:40:58,165 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:58,167 INFO Layer 26: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:40:58,187 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:40:58,189 INFO Layer 26: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:40:58,192 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,195 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,197 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,200 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,203 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,207 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,210 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,212 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,215 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,218 INFO Layer 27: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:40:58,220 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:58,222 INFO Layer 28: ReLU(inplace)\n",
      "2018-11-26 12:40:58,226 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:58,231 INFO Layer 29: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:40:58,234 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:58,237 INFO Layer 30: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:40:58,256 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:40:58,259 INFO Layer 30: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:40:58,262 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,265 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,268 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,270 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,274 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,277 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,279 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,282 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,285 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,288 INFO Layer 31: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:40:58,290 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:58,294 INFO Layer 32: ReLU(inplace)\n",
      "2018-11-26 12:40:58,298 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:58,301 INFO Layer 33: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:40:58,319 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:40:58,322 INFO Layer 33: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:40:58,324 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,327 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:40:58,329 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,334 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,337 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,340 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,342 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,345 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,349 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:58,351 INFO Layer 34: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:40:58,354 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:58,357 INFO Layer 35: ReLU(inplace)\n",
      "2018-11-26 12:40:58,359 INFO Layer 35: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:58,363 INFO Layer 36: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:40:58,366 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:58,370 INFO Layer 37: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 12:40:58,372 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:58,375 INFO Layer 38: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 12:40:59,738 INFO Layer 38: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:40:59,741 INFO     Weight matrix 1/1 (4096,25088): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:59,743 INFO Layer 39: ReLU(inplace)\n",
      "2018-11-26 12:40:59,851 INFO Layer 39: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:59,854 INFO Layer 40: Dropout(p=0.5)\n",
      "2018-11-26 12:40:59,858 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 12:40:59,867 INFO Layer 41: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 12:40:59,991 INFO Layer 41: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:40:59,994 INFO     Weight matrix 1/1 (4096,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:40:59,997 INFO Layer 42: ReLU(inplace)\n",
      "2018-11-26 12:41:00,026 INFO Layer 42: Skipping (Layer not supported)\n",
      "2018-11-26 12:41:00,030 INFO Layer 43: Dropout(p=0.5)\n",
      "2018-11-26 12:41:00,033 INFO Layer 43: Skipping (Layer not supported)\n",
      "2018-11-26 12:41:00,037 INFO Layer 44: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 12:41:00,073 INFO Layer 44: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:41:00,078 INFO     Weight matrix 1/1 (1000,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:41:00,081 INFO ### Printing results ###\n",
      "2018-11-26 12:41:00,086 DEBUG Layer 5: Lognorm compound: 0.3866419494152069\n",
      "2018-11-26 12:41:00,091 DEBUG Layer 9: Lognorm compound: 0.5962027510007223\n",
      "2018-11-26 12:41:00,094 DEBUG Layer 12: Lognorm compound: 0.6176274418830872\n",
      "2018-11-26 12:41:00,097 DEBUG Layer 16: Lognorm compound: 0.7346517178747389\n",
      "2018-11-26 12:41:00,101 DEBUG Layer 19: Lognorm compound: 0.7908963229921129\n",
      "2018-11-26 12:41:00,105 DEBUG Layer 23: Lognorm compound: 0.8910860949092441\n",
      "2018-11-26 12:41:00,109 INFO LogNorm: min: 0.3236437141895294, max: 0.9578632116317749, avg: 0.6695178151130676\n",
      "2018-11-26 12:41:00,112 INFO LogNorm compound: min: 0.3866419494152069, max: 0.8910860949092441, avg: 0.6695177130125188\n",
      "2018-11-26 12:41:00,116 DEBUG Layer 5: Alpha compound: 2.733900276430384\n",
      "2018-11-26 12:41:00,119 DEBUG Layer 9: Alpha compound: 1.8535433161904957\n",
      "2018-11-26 12:41:00,122 DEBUG Layer 12: Alpha compound: 2.9539231683079574\n",
      "2018-11-26 12:41:00,125 DEBUG Layer 16: Alpha compound: 2.6026449807922516\n",
      "2018-11-26 12:41:00,128 DEBUG Layer 19: Alpha compound: 3.1345167306574817\n",
      "2018-11-26 12:41:00,132 DEBUG Layer 23: Alpha compound: 3.0125942488836457\n",
      "2018-11-26 12:41:00,135 INFO Alpha: min: 1.539537263296173, max: 7.42748716716912, avg: 2.71518712021037\n",
      "2018-11-26 12:41:00,138 INFO Alpha compound: min: 1.8535433161904957, max: 3.1345167306574817, avg: 2.7151871202103695\n",
      "2018-11-26 12:41:00,142 DEBUG Layer 5: Alpha Weighted compound: 0.5336243775682926\n",
      "2018-11-26 12:41:00,146 DEBUG Layer 9: Alpha Weighted compound: 0.9657448339553328\n",
      "2018-11-26 12:41:00,149 DEBUG Layer 12: Alpha Weighted compound: 0.45352534016055024\n",
      "2018-11-26 12:41:00,154 DEBUG Layer 16: Alpha Weighted compound: 0.9271211977004816\n",
      "2018-11-26 12:41:00,157 DEBUG Layer 19: Alpha Weighted compound: 0.8065376230463771\n",
      "2018-11-26 12:41:00,160 DEBUG Layer 23: Alpha Weighted compound: 1.2191595817340202\n",
      "2018-11-26 12:41:00,164 INFO Alpha Weighted: min: -0.0502193424989187, max: 1.7649045700683552, avg: 0.8176188256941758\n",
      "2018-11-26 12:41:00,167 INFO Alpha Weighted compound: min: 0.45352534016055024, max: 1.2191595817340202, avg: 0.8176188256941758\n",
      "2018-11-26 12:41:07,643 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 12:41:07,645 INFO Analyzing model\n",
      "2018-11-26 12:41:07,648 INFO Layer 0: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:41:07,651 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 12:41:07,656 INFO Layer 1: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace)\n",
      "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:41:07,659 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 12:41:07,661 INFO Layer 2: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:41:07,664 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:41:07,667 INFO Layer 2: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:41:07,670 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:41:07,673 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:41:07,676 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:41:07,679 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:41:07,682 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:41:07,684 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:41:07,686 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:41:07,689 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:41:07,691 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:41:07,695 INFO Layer 3: ReLU(inplace)\n",
      "2018-11-26 12:41:07,697 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:41:07,699 INFO Layer 4: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:41:07,703 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:41:07,705 INFO Layer 4: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:41:07,708 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:41:08,457 INFO     Weight matrix 1/9 (64,64): Alpha: 3.142422624589125, Alpha Weighted: 1.0356264827948563, D: 0.15201147360962397\n",
      "2018-11-26 12:41:08,461 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.5160806179046631\n",
      "2018-11-26 12:41:08,465 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:41:09,010 INFO     Weight matrix 2/9 (64,64): Alpha: 2.6926874054635874, Alpha Weighted: 1.4322326965670529, D: 0.1534784109075178\n",
      "2018-11-26 12:41:09,013 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.5779937505722046\n",
      "2018-11-26 12:41:09,016 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:41:09,487 INFO     Weight matrix 3/9 (64,64): Alpha: 1.7915681803151364, Alpha Weighted: 0.6032889084882009, D: 0.1834562240245426\n",
      "2018-11-26 12:41:09,492 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.5458888411521912\n",
      "2018-11-26 12:41:09,499 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:41:10,075 INFO     Weight matrix 4/9 (64,64): Alpha: 2.6447149023681438, Alpha Weighted: 1.3996292025787689, D: 0.13734371437252257\n",
      "2018-11-26 12:41:10,078 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.5552008152008057\n",
      "2018-11-26 12:41:10,081 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:41:10,568 INFO     Weight matrix 5/9 (64,64): Alpha: 2.8553866197707762, Alpha Weighted: 1.8627007634019093, D: 0.14285714285714324\n",
      "2018-11-26 12:41:10,572 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.6158302426338196\n",
      "2018-11-26 12:41:10,574 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:41:11,119 INFO     Weight matrix 6/9 (64,64): Alpha: 1.5722768658271273, Alpha Weighted: 0.7493920300952568, D: 0.15895596376900445\n",
      "2018-11-26 12:41:11,122 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.575312614440918\n",
      "2018-11-26 12:41:11,125 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:41:11,581 INFO     Weight matrix 7/9 (64,64): Alpha: 1.5593464674916802, Alpha Weighted: 0.3687302460809226, D: 0.17842349473647579\n",
      "2018-11-26 12:41:11,584 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.5055575966835022\n",
      "2018-11-26 12:41:11,586 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:41:12,041 INFO     Weight matrix 8/9 (64,64): Alpha: 2.3832925684368904, Alpha Weighted: 1.296885259312267, D: 0.1385260217761305\n",
      "2018-11-26 12:41:12,044 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.5518020987510681\n",
      "2018-11-26 12:41:12,047 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:41:12,481 INFO     Weight matrix 9/9 (64,64): Alpha: 3.1091440125202143, Alpha Weighted: 0.8731617486323695, D: 0.17602399279348685\n",
      "2018-11-26 12:41:12,483 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.5120531916618347\n",
      "2018-11-26 12:41:12,486 INFO Layer 5: ReLU(inplace)\n",
      "2018-11-26 12:41:12,489 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 12:41:12,491 INFO Layer 6: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:41:12,493 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 12:41:12,497 INFO Layer 7: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:41:12,500 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:41:12,503 INFO Layer 7: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:41:12,506 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:41:13,077 INFO     Weight matrix 1/9 (64,128): Alpha: 1.7198477231421028, Alpha Weighted: 0.6326232372122542, D: 0.154902604293305\n",
      "2018-11-26 12:41:13,082 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.6252495050430298\n",
      "2018-11-26 12:41:13,088 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:41:13,565 INFO     Weight matrix 2/9 (64,128): Alpha: 1.6920180724926328, Alpha Weighted: 0.6797983621627005, D: 0.15375686234752517\n",
      "2018-11-26 12:41:13,569 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.6631074547767639\n",
      "2018-11-26 12:41:13,572 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:41:14,062 INFO     Weight matrix 3/9 (64,128): Alpha: 1.8732094995243895, Alpha Weighted: 0.706494638506219, D: 0.14726965575147122\n",
      "2018-11-26 12:41:14,065 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.6152138710021973\n",
      "2018-11-26 12:41:14,072 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:41:14,535 INFO     Weight matrix 4/9 (64,128): Alpha: 1.6454380004242601, Alpha Weighted: 0.8071385888861151, D: 0.1565297620922238\n",
      "2018-11-26 12:41:14,540 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.6701611280441284\n",
      "2018-11-26 12:41:14,542 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:41:15,048 INFO     Weight matrix 5/9 (64,128): Alpha: 1.6638427065256067, Alpha Weighted: 1.1859452734694642, D: 0.14086583702426608\n",
      "2018-11-26 12:41:15,052 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.7314475178718567\n",
      "2018-11-26 12:41:15,055 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:41:15,495 INFO     Weight matrix 6/9 (64,128): Alpha: 1.7355904518383798, Alpha Weighted: 0.7603759016040842, D: 0.14747526157127516\n",
      "2018-11-26 12:41:15,501 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.6492814421653748\n",
      "2018-11-26 12:41:15,504 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:41:16,020 INFO     Weight matrix 7/9 (64,128): Alpha: 1.9029354721563823, Alpha Weighted: 0.6787662569347408, D: 0.15153538903052177\n",
      "2018-11-26 12:41:16,025 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.6226702332496643\n",
      "2018-11-26 12:41:16,028 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:41:16,527 INFO     Weight matrix 8/9 (64,128): Alpha: 1.6830602152924485, Alpha Weighted: 0.8073421143819843, D: 0.15261492211878785\n",
      "2018-11-26 12:41:16,530 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.6656328439712524\n",
      "2018-11-26 12:41:16,534 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:41:16,973 INFO     Weight matrix 9/9 (64,128): Alpha: 1.8657863757867528, Alpha Weighted: 0.728350662964443, D: 0.1452661793912876\n",
      "2018-11-26 12:41:16,976 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.6046348810195923\n",
      "2018-11-26 12:41:16,979 INFO Layer 8: ReLU(inplace)\n",
      "2018-11-26 12:41:16,982 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 12:41:16,985 INFO Layer 9: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:41:16,990 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:41:16,993 INFO Layer 9: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:41:16,996 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:41:17,973 INFO     Weight matrix 1/9 (128,128): Alpha: 1.9708087310767561, Alpha Weighted: 0.3627348820499047, D: 0.1533051789541121\n",
      "2018-11-26 12:41:17,976 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.6705517768859863\n",
      "2018-11-26 12:41:17,980 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:41:18,940 INFO     Weight matrix 2/9 (128,128): Alpha: 1.771790579992397, Alpha Weighted: 0.44331843099300766, D: 0.16173600512563208\n",
      "2018-11-26 12:41:18,944 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.707156240940094\n",
      "2018-11-26 12:41:18,948 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:41:19,892 INFO     Weight matrix 3/9 (128,128): Alpha: 1.9148813379867815, Alpha Weighted: 0.4394516766873766, D: 0.15214607900339866\n",
      "2018-11-26 12:41:19,896 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.6703708171844482\n",
      "2018-11-26 12:41:19,899 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:41:20,851 INFO     Weight matrix 4/9 (128,128): Alpha: 1.9932234483973792, Alpha Weighted: 0.5333418049744489, D: 0.16250371307627492\n",
      "2018-11-26 12:41:20,855 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.708335816860199\n",
      "2018-11-26 12:41:20,857 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:41:21,960 INFO     Weight matrix 5/9 (128,128): Alpha: 1.8607002357124875, Alpha Weighted: 0.6109738015544449, D: 0.18034601869099343\n",
      "2018-11-26 12:41:21,964 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.7527784705162048\n",
      "2018-11-26 12:41:21,967 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:41:23,113 INFO     Weight matrix 6/9 (128,128): Alpha: 1.9678267515713992, Alpha Weighted: 0.5040800078140927, D: 0.1560897772885056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:41:23,116 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.6959487795829773\n",
      "2018-11-26 12:41:23,121 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:41:24,299 INFO     Weight matrix 7/9 (128,128): Alpha: 1.8584877197254208, Alpha Weighted: 0.3537002379603508, D: 0.16694163259821815\n",
      "2018-11-26 12:41:24,303 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.6658181548118591\n",
      "2018-11-26 12:41:24,308 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:41:25,561 INFO     Weight matrix 8/9 (128,128): Alpha: 1.950535876129496, Alpha Weighted: 0.5586787397014297, D: 0.1492966083512549\n",
      "2018-11-26 12:41:25,566 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.6898443102836609\n",
      "2018-11-26 12:41:25,570 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:41:26,777 INFO     Weight matrix 9/9 (128,128): Alpha: 1.8140198633768492, Alpha Weighted: 0.35767533193553785, D: 0.1445975545077023\n",
      "2018-11-26 12:41:26,782 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.6580457091331482\n",
      "2018-11-26 12:41:26,784 INFO Layer 10: ReLU(inplace)\n",
      "2018-11-26 12:41:26,787 INFO Layer 10: Skipping (Layer not supported)\n",
      "2018-11-26 12:41:26,789 INFO Layer 11: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:41:26,791 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:41:26,795 INFO Layer 12: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:41:26,803 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:41:26,806 INFO Layer 12: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:41:26,808 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:41:27,988 INFO     Weight matrix 1/9 (128,256): Alpha: 2.980997546533984, Alpha Weighted: 0.5434271948919844, D: 0.13899253471883644\n",
      "2018-11-26 12:41:27,992 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.7062947750091553\n",
      "2018-11-26 12:41:27,996 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:41:29,201 INFO     Weight matrix 2/9 (128,256): Alpha: 3.6120507555843804, Alpha Weighted: 1.491393153933572, D: 0.14968121912236987\n",
      "2018-11-26 12:41:29,203 INFO     Weight matrix 2/9 (128,256): Alpha 3.6120507555843804 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:41:29,208 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.7732203006744385\n",
      "2018-11-26 12:41:29,211 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:41:30,450 INFO     Weight matrix 3/9 (128,256): Alpha: 2.773223980860115, Alpha Weighted: 0.5484073623242045, D: 0.12591375018658202\n",
      "2018-11-26 12:41:30,456 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.7141814231872559\n",
      "2018-11-26 12:41:30,460 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:41:31,618 INFO     Weight matrix 4/9 (128,256): Alpha: 3.4532214418482057, Alpha Weighted: 1.2880493197046632, D: 0.1537974151804365\n",
      "2018-11-26 12:41:31,622 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.7659935355186462\n",
      "2018-11-26 12:41:31,624 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:41:32,600 INFO     Weight matrix 5/9 (128,256): Alpha: 1.5250535090545694, Alpha Weighted: 0.8890992939029106, D: 0.15304425542819206\n",
      "2018-11-26 12:41:32,604 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.8792248964309692\n",
      "2018-11-26 12:41:32,608 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:41:33,573 INFO     Weight matrix 6/9 (128,256): Alpha: 1.7512999313915545, Alpha Weighted: 0.6956801963661614, D: 0.15087960449310134\n",
      "2018-11-26 12:41:33,580 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.7701500058174133\n",
      "2018-11-26 12:41:33,583 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:41:34,647 INFO     Weight matrix 7/9 (128,256): Alpha: 2.406611467877192, Alpha Weighted: 0.39244152559311724, D: 0.16482891553491757\n",
      "2018-11-26 12:41:34,651 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.7016052007675171\n",
      "2018-11-26 12:41:34,656 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:41:35,679 INFO     Weight matrix 8/9 (128,256): Alpha: 2.9214692080444844, Alpha Weighted: 1.0782930534023316, D: 0.1478455640629449\n",
      "2018-11-26 12:41:35,683 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.7585638165473938\n",
      "2018-11-26 12:41:35,686 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:41:36,658 INFO     Weight matrix 9/9 (128,256): Alpha: 2.8104434366811226, Alpha Weighted: 0.46751912819604763, D: 0.1446305880748452\n",
      "2018-11-26 12:41:36,661 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.7090867161750793\n",
      "2018-11-26 12:41:36,666 INFO Layer 13: ReLU(inplace)\n",
      "2018-11-26 12:41:36,669 INFO Layer 13: Skipping (Layer not supported)\n",
      "2018-11-26 12:41:36,672 INFO Layer 14: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:41:36,689 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:41:36,691 INFO Layer 14: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:41:36,693 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:41:39,046 INFO     Weight matrix 1/9 (256,256): Alpha: 3.1610547409054557, Alpha Weighted: 0.7746760442393343, D: 0.12169468325696764\n",
      "2018-11-26 12:41:39,050 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7806764245033264\n",
      "2018-11-26 12:41:39,053 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:41:41,399 INFO     Weight matrix 2/9 (256,256): Alpha: 2.170991823320292, Alpha Weighted: 0.7334356293221443, D: 0.11154511438662629\n",
      "2018-11-26 12:41:41,403 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.8059756755828857\n",
      "2018-11-26 12:41:41,407 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:41:44,149 INFO     Weight matrix 3/9 (256,256): Alpha: 2.257073441068872, Alpha Weighted: 0.44293941054821034, D: 0.1307043057071664\n",
      "2018-11-26 12:41:44,155 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.7829821705818176\n",
      "2018-11-26 12:41:44,158 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:41:46,714 INFO     Weight matrix 4/9 (256,256): Alpha: 2.5386169417966666, Alpha Weighted: 0.720960425973891, D: 0.12819916217808447\n",
      "2018-11-26 12:41:46,718 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.7989984750747681\n",
      "2018-11-26 12:41:46,721 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:41:49,194 INFO     Weight matrix 5/9 (256,256): Alpha: 1.7526517640884887, Alpha Weighted: 0.8924835625378258, D: 0.12736088420662117\n",
      "2018-11-26 12:41:49,198 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8561845421791077\n",
      "2018-11-26 12:41:49,200 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:41:51,780 INFO     Weight matrix 6/9 (256,256): Alpha: 3.326342635167146, Alpha Weighted: 1.0367021933184533, D: 0.11796503875528197\n",
      "2018-11-26 12:41:51,784 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.799529492855072\n",
      "2018-11-26 12:41:51,787 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:41:54,167 INFO     Weight matrix 7/9 (256,256): Alpha: 2.971281054225308, Alpha Weighted: 0.6230906637843997, D: 0.11973031610787849\n",
      "2018-11-26 12:41:54,172 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.7790930867195129\n",
      "2018-11-26 12:41:54,175 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:41:56,658 INFO     Weight matrix 8/9 (256,256): Alpha: 3.3636060440376245, Alpha Weighted: 1.0094460371147171, D: 0.11377352310797523\n",
      "2018-11-26 12:41:56,662 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7961214780807495\n",
      "2018-11-26 12:41:56,666 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:41:59,394 INFO     Weight matrix 9/9 (256,256): Alpha: 2.512983060411856, Alpha Weighted: 0.5481955083929518, D: 0.13451817112546982\n",
      "2018-11-26 12:41:59,399 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7766077518463135\n",
      "2018-11-26 12:41:59,404 INFO Layer 15: ReLU(inplace)\n",
      "2018-11-26 12:41:59,407 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 12:41:59,410 INFO Layer 16: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:41:59,420 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:41:59,422 INFO Layer 16: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:41:59,426 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:42:02,055 INFO     Weight matrix 1/9 (256,256): Alpha: 3.324629202913658, Alpha Weighted: 1.0493379152723756, D: 0.10513497292233537\n",
      "2018-11-26 12:42:02,060 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7941233515739441\n",
      "2018-11-26 12:42:02,063 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:42:04,683 INFO     Weight matrix 2/9 (256,256): Alpha: 2.553583721655549, Alpha Weighted: 1.0952654760815128, D: 0.09881861386088847\n",
      "2018-11-26 12:42:04,691 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.8185930848121643\n",
      "2018-11-26 12:42:04,694 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:42:07,095 INFO     Weight matrix 3/9 (256,256): Alpha: 3.1631154497668703, Alpha Weighted: 0.7856250321557615, D: 0.11637832556125666\n",
      "2018-11-26 12:42:07,098 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.7924150824546814\n",
      "2018-11-26 12:42:07,101 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:42:09,429 INFO     Weight matrix 4/9 (256,256): Alpha: 3.6272610123651083, Alpha Weighted: 1.4692685908226746, D: 0.07678727808310559\n",
      "2018-11-26 12:42:09,431 INFO     Weight matrix 4/9 (256,256): Alpha 3.6272610123651083 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:42:09,436 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.8125602006912231\n",
      "2018-11-26 12:42:09,442 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:42:11,741 INFO     Weight matrix 5/9 (256,256): Alpha: 3.557917175215558, Alpha Weighted: 2.1850252309560063, D: 0.09332130912051628\n",
      "2018-11-26 12:42:11,744 INFO     Weight matrix 5/9 (256,256): Alpha 3.557917175215558 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:42:11,750 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8733867406845093\n",
      "2018-11-26 12:42:11,753 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:42:14,102 INFO     Weight matrix 6/9 (256,256): Alpha: 3.380911122517312, Alpha Weighted: 1.3060749769994353, D: 0.09701445032185818\n",
      "2018-11-26 12:42:14,106 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.8054749369621277\n",
      "2018-11-26 12:42:14,109 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:42:16,514 INFO     Weight matrix 7/9 (256,256): Alpha: 2.5100763846878937, Alpha Weighted: 0.7078849411891285, D: 0.11533549488105344\n",
      "2018-11-26 12:42:16,518 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.7954062223434448\n",
      "2018-11-26 12:42:16,521 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:42:19,040 INFO     Weight matrix 8/9 (256,256): Alpha: 3.817706946103756, Alpha Weighted: 1.4716270949314345, D: 0.09791833617147094\n",
      "2018-11-26 12:42:19,043 INFO     Weight matrix 8/9 (256,256): Alpha 3.817706946103756 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:42:19,047 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.8186802864074707\n",
      "2018-11-26 12:42:19,050 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:42:21,777 INFO     Weight matrix 9/9 (256,256): Alpha: 3.600901106362161, Alpha Weighted: 0.9486591016669621, D: 0.09744259110076736\n",
      "2018-11-26 12:42:21,779 INFO     Weight matrix 9/9 (256,256): Alpha 3.600901106362161 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:42:21,784 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7906112670898438\n",
      "2018-11-26 12:42:21,788 INFO Layer 17: ReLU(inplace)\n",
      "2018-11-26 12:42:21,792 INFO Layer 17: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:21,796 INFO Layer 18: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:42:21,799 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:21,802 INFO Layer 19: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:42:21,833 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:42:21,836 INFO Layer 19: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:42:21,840 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:42:25,050 INFO     Weight matrix 1/9 (256,512): Alpha: 2.7172858924723293, Alpha Weighted: 0.9502842047837508, D: 0.11392934427299783\n",
      "2018-11-26 12:42:25,056 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.873299241065979\n",
      "2018-11-26 12:42:25,059 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:42:27,922 INFO     Weight matrix 2/9 (256,512): Alpha: 3.396348607440043, Alpha Weighted: 1.4291680089496752, D: 0.11273020795838296\n",
      "2018-11-26 12:42:27,927 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.8999274373054504\n",
      "2018-11-26 12:42:27,931 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:42:30,796 INFO     Weight matrix 3/9 (256,512): Alpha: 2.8379214093640366, Alpha Weighted: 0.9623290099194338, D: 0.10389450224285579\n",
      "2018-11-26 12:42:30,801 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.8732175230979919\n",
      "2018-11-26 12:42:30,804 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:42:33,513 INFO     Weight matrix 4/9 (256,512): Alpha: 3.103763042631277, Alpha Weighted: 1.4523455641934817, D: 0.08322523963989126\n",
      "2018-11-26 12:42:33,518 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.893368124961853\n",
      "2018-11-26 12:42:33,521 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:42:36,640 INFO     Weight matrix 5/9 (256,512): Alpha: 1.7970234387322581, Alpha Weighted: 1.1138169268882743, D: 0.12000329068080728\n",
      "2018-11-26 12:42:36,645 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.9529684782028198\n",
      "2018-11-26 12:42:36,647 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:42:39,363 INFO     Weight matrix 6/9 (256,512): Alpha: 2.9390042246586283, Alpha Weighted: 1.2124720103073794, D: 0.09788329470457019\n",
      "2018-11-26 12:42:39,368 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.8931679725646973\n",
      "2018-11-26 12:42:39,370 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:42:42,187 INFO     Weight matrix 7/9 (256,512): Alpha: 2.333041192891962, Alpha Weighted: 0.7612649332403806, D: 0.12725536434945328\n",
      "2018-11-26 12:42:42,192 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.8703255653381348\n",
      "2018-11-26 12:42:42,195 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:42:44,756 INFO     Weight matrix 8/9 (256,512): Alpha: 3.62428575866909, Alpha Weighted: 1.4318543029195625, D: 0.12512611707304333\n",
      "2018-11-26 12:42:44,759 INFO     Weight matrix 8/9 (256,512): Alpha 3.62428575866909 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:42:44,764 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.895790159702301\n",
      "2018-11-26 12:42:44,766 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:42:47,185 INFO     Weight matrix 9/9 (256,512): Alpha: 3.3357225016247662, Alpha Weighted: 1.1499509222271882, D: 0.1074301526091831\n",
      "2018-11-26 12:42:47,190 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.8725559115409851\n",
      "2018-11-26 12:42:47,192 INFO Layer 20: ReLU(inplace)\n",
      "2018-11-26 12:42:47,195 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:47,198 INFO Layer 21: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:42:47,247 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:42:47,249 INFO Layer 21: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:42:47,253 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,256 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,259 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,262 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,264 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,267 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,271 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,275 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,279 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,282 INFO Layer 22: ReLU(inplace)\n",
      "2018-11-26 12:42:47,288 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:47,291 INFO Layer 23: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:42:47,326 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:42:47,329 INFO Layer 23: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:42:47,332 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,334 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,338 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,340 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,343 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,345 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,348 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,350 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,353 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,356 INFO Layer 24: ReLU(inplace)\n",
      "2018-11-26 12:42:47,359 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:47,362 INFO Layer 25: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:42:47,365 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:47,367 INFO Layer 26: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:42:47,395 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:42:47,399 INFO Layer 26: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:42:47,403 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,406 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,409 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,411 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,414 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,416 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,419 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,422 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,425 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,428 INFO Layer 27: ReLU(inplace)\n",
      "2018-11-26 12:42:47,431 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:47,434 INFO Layer 28: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:42:47,451 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:42:47,454 INFO Layer 28: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:42:47,457 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,459 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,462 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,465 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,467 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,470 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,473 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,476 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,479 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,482 INFO Layer 29: ReLU(inplace)\n",
      "2018-11-26 12:42:47,484 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:47,488 INFO Layer 30: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:42:47,510 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:42:47,512 INFO Layer 30: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:42:47,517 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,520 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,523 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,526 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,529 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,532 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,535 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,539 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,542 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:47,544 INFO Layer 31: ReLU(inplace)\n",
      "2018-11-26 12:42:47,546 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:47,549 INFO Layer 32: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:42:47,552 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:47,555 INFO Layer 33: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 12:42:47,558 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:47,562 INFO Layer 34: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 12:42:49,734 INFO Layer 34: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:42:49,737 INFO     Weight matrix 1/1 (4096,25088): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:49,739 INFO Layer 35: ReLU(inplace)\n",
      "2018-11-26 12:42:49,856 INFO Layer 35: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:49,859 INFO Layer 36: Dropout(p=0.5)\n",
      "2018-11-26 12:42:49,862 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:49,864 INFO Layer 37: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 12:42:50,120 INFO Layer 37: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:42:50,123 INFO     Weight matrix 1/1 (4096,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:50,125 INFO Layer 38: ReLU(inplace)\n",
      "2018-11-26 12:42:50,155 INFO Layer 38: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:50,158 INFO Layer 39: Dropout(p=0.5)\n",
      "2018-11-26 12:42:50,160 INFO Layer 39: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:50,163 INFO Layer 40: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 12:42:50,231 INFO Layer 40: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:42:50,235 INFO     Weight matrix 1/1 (1000,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:42:50,239 INFO ### Printing results ###\n",
      "2018-11-26 12:42:50,243 DEBUG Layer 4: Lognorm compound: 0.5506355298890008\n",
      "2018-11-26 12:42:50,249 DEBUG Layer 7: Lognorm compound: 0.6497109863493178\n",
      "2018-11-26 12:42:50,254 DEBUG Layer 9: Lognorm compound: 0.690983341799842\n",
      "2018-11-26 12:42:50,260 DEBUG Layer 12: Lognorm compound: 0.7531467411253188\n",
      "2018-11-26 12:42:50,266 DEBUG Layer 14: Lognorm compound: 0.7973521219359504\n",
      "2018-11-26 12:42:50,270 DEBUG Layer 16: Lognorm compound: 0.8112501303354899\n",
      "2018-11-26 12:42:50,272 DEBUG Layer 19: Lognorm compound: 0.8916244904200236\n",
      "2018-11-26 12:42:50,276 INFO LogNorm: min: 0.5055575966835022, max: 0.9529684782028198, avg: 0.7349576354026794\n",
      "2018-11-26 12:42:50,280 INFO LogNorm compound: min: 0.5506355298890008, max: 0.8916244904200236, avg: 0.7349576202649919\n",
      "2018-11-26 12:42:50,282 DEBUG Layer 4: Alpha compound: 2.416759960753631\n",
      "2018-11-26 12:42:50,286 DEBUG Layer 7: Alpha compound: 1.753525390798106\n",
      "2018-11-26 12:42:50,289 DEBUG Layer 9: Alpha compound: 1.900252727107663\n",
      "2018-11-26 12:42:50,291 DEBUG Layer 12: Alpha compound: 2.692707919763956\n",
      "2018-11-26 12:42:50,294 DEBUG Layer 14: Alpha compound: 2.6727335005579675\n",
      "2018-11-26 12:42:50,297 DEBUG Layer 16: Alpha compound: 3.2817891246208735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:42:50,299 DEBUG Layer 19: Alpha compound: 2.8982662298315987\n",
      "2018-11-26 12:42:50,304 INFO Alpha: min: 1.5250535090545694, max: 3.817706946103756, avg: 2.516576407633399\n",
      "2018-11-26 12:42:50,307 INFO Alpha compound: min: 1.753525390798106, max: 3.2817891246208735, avg: 2.516576407633399\n",
      "2018-11-26 12:42:50,321 DEBUG Layer 4: Alpha Weighted compound: 1.0690719264390671\n",
      "2018-11-26 12:42:50,326 DEBUG Layer 7: Alpha Weighted compound: 0.7763150040135561\n",
      "2018-11-26 12:42:50,334 DEBUG Layer 9: Alpha Weighted compound: 0.4626616570745104\n",
      "2018-11-26 12:42:50,337 DEBUG Layer 12: Alpha Weighted compound: 0.8215900253683326\n",
      "2018-11-26 12:42:50,340 DEBUG Layer 14: Alpha Weighted compound: 0.7535477194702142\n",
      "2018-11-26 12:42:50,346 DEBUG Layer 16: Alpha Weighted compound: 1.2243075955639213\n",
      "2018-11-26 12:42:50,349 DEBUG Layer 19: Alpha Weighted compound: 1.1626095426032361\n",
      "2018-11-26 12:42:50,353 INFO Alpha Weighted: min: 0.3537002379603508, max: 2.1850252309560063, avg: 0.8957290672189769\n",
      "2018-11-26 12:42:50,356 INFO Alpha Weighted compound: min: 0.4626616570745104, max: 1.2243075955639213, avg: 0.8957290672189769\n",
      "2018-11-26 12:42:58,155 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 12:42:58,157 INFO Analyzing model\n",
      "2018-11-26 12:42:58,162 INFO Layer 0: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:42:58,165 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:58,168 INFO Layer 1: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace)\n",
      "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace)\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU(inplace)\n",
      "  (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU(inplace)\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (16): ReLU(inplace)\n",
      "  (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (19): ReLU(inplace)\n",
      "  (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (22): ReLU(inplace)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (26): ReLU(inplace)\n",
      "  (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (29): ReLU(inplace)\n",
      "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (32): ReLU(inplace)\n",
      "  (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (36): ReLU(inplace)\n",
      "  (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (39): ReLU(inplace)\n",
      "  (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (42): ReLU(inplace)\n",
      "  (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "2018-11-26 12:42:58,171 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:58,176 INFO Layer 2: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:42:58,179 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:42:58,182 INFO Layer 2: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:42:58,184 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:42:58,187 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:42:58,191 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:42:58,194 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:42:58,197 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:42:58,200 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:42:58,203 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:42:58,207 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:42:58,209 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:42:58,211 INFO Layer 3: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:42:58,214 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:58,217 INFO Layer 4: ReLU(inplace)\n",
      "2018-11-26 12:42:58,219 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 12:42:58,223 INFO Layer 5: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:42:58,226 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:42:58,231 INFO Layer 5: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:42:58,233 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16_bn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:42:58,766 INFO     Weight matrix 1/9 (64,64): Alpha: 3.067246042114857, Alpha Weighted: 0.08128032805170292, D: 0.16145711304065385\n",
      "2018-11-26 12:42:58,769 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.3020470440387726\n",
      "2018-11-26 12:42:58,773 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:42:59,281 INFO     Weight matrix 2/9 (64,64): Alpha: 2.487019328167813, Alpha Weighted: 0.7152870197005471, D: 0.1747309716215718\n",
      "2018-11-26 12:42:59,283 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.3800029456615448\n",
      "2018-11-26 12:42:59,286 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:42:59,718 INFO     Weight matrix 3/9 (64,64): Alpha: 3.209205464233937, Alpha Weighted: 0.4183594121167781, D: 0.216731296136003\n",
      "2018-11-26 12:42:59,720 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.3312205374240875\n",
      "2018-11-26 12:42:59,724 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:43:00,251 INFO     Weight matrix 4/9 (64,64): Alpha: 3.569984582151885, Alpha Weighted: 0.7476807885271962, D: 0.2000000000000005\n",
      "2018-11-26 12:43:00,253 INFO     Weight matrix 4/9 (64,64): Alpha 3.569984582151885 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:43:00,257 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.3538437783718109\n",
      "2018-11-26 12:43:00,264 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:43:00,845 INFO     Weight matrix 5/9 (64,64): Alpha: 2.3669408592474968, Alpha Weighted: 1.1595246665733747, D: 0.18520392153504528\n",
      "2018-11-26 12:43:00,850 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.457820862531662\n",
      "2018-11-26 12:43:00,854 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:43:01,403 INFO     Weight matrix 6/9 (64,64): Alpha: 1.6742878859009784, Alpha Weighted: 0.477696715466196, D: 0.19945472040909074\n",
      "2018-11-26 12:43:01,407 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.37926769256591797\n",
      "2018-11-26 12:43:01,411 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:43:01,961 INFO     Weight matrix 7/9 (64,64): Alpha: 3.451343039404728, Alpha Weighted: -0.03604443294544874, D: 0.2000000000000005\n",
      "2018-11-26 12:43:01,965 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.28816333413124084\n",
      "2018-11-26 12:43:01,968 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:43:02,517 INFO     Weight matrix 8/9 (64,64): Alpha: 3.057496794551882, Alpha Weighted: 0.7702203080087046, D: 0.2000000000000005\n",
      "2018-11-26 12:43:02,519 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.35348039865493774\n",
      "2018-11-26 12:43:02,522 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:43:03,034 INFO     Weight matrix 9/9 (64,64): Alpha: 1.6693840579058814, Alpha Weighted: -9.317455544004709e-05, D: 0.22794544073491085\n",
      "2018-11-26 12:43:03,038 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.30707016587257385\n",
      "2018-11-26 12:43:03,041 INFO Layer 6: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:43:03,044 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 12:43:03,049 INFO Layer 7: ReLU(inplace)\n",
      "2018-11-26 12:43:03,054 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 12:43:03,057 INFO Layer 8: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:43:03,060 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 12:43:03,063 INFO Layer 9: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:43:03,071 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:43:03,075 INFO Layer 9: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:43:03,078 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:43:03,631 INFO     Weight matrix 1/9 (64,128): Alpha: 1.6570815437526, Alpha Weighted: 0.7180292170262772, D: 0.13282842775433334\n",
      "2018-11-26 12:43:03,635 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.5191804766654968\n",
      "2018-11-26 12:43:03,639 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:43:04,230 INFO     Weight matrix 2/9 (64,128): Alpha: 1.650524668741735, Alpha Weighted: 0.7264309038787279, D: 0.14066529617951778\n",
      "2018-11-26 12:43:04,233 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.5679644346237183\n",
      "2018-11-26 12:43:04,239 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:43:04,796 INFO     Weight matrix 3/9 (64,128): Alpha: 1.6339926739048214, Alpha Weighted: 0.6516254929132805, D: 0.1426634616163974\n",
      "2018-11-26 12:43:04,801 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.5102850794792175\n",
      "2018-11-26 12:43:04,805 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:43:05,354 INFO     Weight matrix 4/9 (64,128): Alpha: 1.5416898601966809, Alpha Weighted: 0.5503489022365248, D: 0.1406639198236922\n",
      "2018-11-26 12:43:05,358 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.5551800727844238\n",
      "2018-11-26 12:43:05,362 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:43:05,929 INFO     Weight matrix 5/9 (64,128): Alpha: 1.6504219631527637, Alpha Weighted: 0.9037237023221661, D: 0.15082607895515537\n",
      "2018-11-26 12:43:05,936 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.6409451961517334\n",
      "2018-11-26 12:43:05,940 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:43:06,571 INFO     Weight matrix 6/9 (64,128): Alpha: 1.6502861409549583, Alpha Weighted: 0.7007279800386546, D: 0.13379044762881986\n",
      "2018-11-26 12:43:06,576 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.5546641945838928\n",
      "2018-11-26 12:43:06,581 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:43:07,147 INFO     Weight matrix 7/9 (64,128): Alpha: 2.0074288220498815, Alpha Weighted: 0.7569141042227409, D: 0.13481680465573376\n",
      "2018-11-26 12:43:07,151 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.5064899325370789\n",
      "2018-11-26 12:43:07,159 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:43:07,710 INFO     Weight matrix 8/9 (64,128): Alpha: 1.5606137536171267, Alpha Weighted: 0.6558398815099636, D: 0.1382113726962113\n",
      "2018-11-26 12:43:07,713 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.5696483850479126\n",
      "2018-11-26 12:43:07,717 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:43:08,333 INFO     Weight matrix 9/9 (64,128): Alpha: 1.631992782801147, Alpha Weighted: 0.7257330900887972, D: 0.12051402892114732\n",
      "2018-11-26 12:43:08,338 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.5200129151344299\n",
      "2018-11-26 12:43:08,345 INFO Layer 10: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:43:08,349 INFO Layer 10: Skipping (Layer not supported)\n",
      "2018-11-26 12:43:08,353 INFO Layer 11: ReLU(inplace)\n",
      "2018-11-26 12:43:08,359 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:43:08,362 INFO Layer 12: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:43:08,373 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:43:08,376 INFO Layer 12: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:43:08,381 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:43:09,719 INFO     Weight matrix 1/9 (128,128): Alpha: 2.8200343174995615, Alpha Weighted: -0.14159613714904265, D: 0.1747607359950326\n",
      "2018-11-26 12:43:09,722 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.515646755695343\n",
      "2018-11-26 12:43:09,728 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:43:10,808 INFO     Weight matrix 2/9 (128,128): Alpha: 3.480179520181706, Alpha Weighted: 0.24791370342671656, D: 0.18667768512429572\n",
      "2018-11-26 12:43:10,812 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.5774545669555664\n",
      "2018-11-26 12:43:10,817 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:43:11,812 INFO     Weight matrix 3/9 (128,128): Alpha: 2.472455377842222, Alpha Weighted: -0.1008075824026836, D: 0.15535180907618745\n",
      "2018-11-26 12:43:11,815 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.5236763954162598\n",
      "2018-11-26 12:43:11,819 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:43:12,773 INFO     Weight matrix 4/9 (128,128): Alpha: 3.025870917962053, Alpha Weighted: 0.2934039794621025, D: 0.1427496861970553\n",
      "2018-11-26 12:43:12,776 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.5768951177597046\n",
      "2018-11-26 12:43:12,779 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:43:13,718 INFO     Weight matrix 5/9 (128,128): Alpha: 2.5531063639022538, Alpha Weighted: 0.5312905689512801, D: 0.1866319588834774\n",
      "2018-11-26 12:43:13,722 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.6633272767066956\n",
      "2018-11-26 12:43:13,725 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:43:14,704 INFO     Weight matrix 6/9 (128,128): Alpha: 2.9347511255896004, Alpha Weighted: 0.2728914972548323, D: 0.17412482270150087\n",
      "2018-11-26 12:43:14,708 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.5866610407829285\n",
      "2018-11-26 12:43:14,712 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:43:15,876 INFO     Weight matrix 7/9 (128,128): Alpha: 3.0368064390563916, Alpha Weighted: -0.03731662954558613, D: 0.17720243041572364\n",
      "2018-11-26 12:43:15,881 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.5274824500083923\n",
      "2018-11-26 12:43:15,887 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:43:17,064 INFO     Weight matrix 8/9 (128,128): Alpha: 1.8448496342726686, Alpha Weighted: 0.13346930944544755, D: 0.18721042418969347\n",
      "2018-11-26 12:43:17,069 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.5817798972129822\n",
      "2018-11-26 12:43:17,072 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:43:18,252 INFO     Weight matrix 9/9 (128,128): Alpha: 4.452908689662523, Alpha Weighted: 0.05057070156187614, D: 0.13292287650566703\n",
      "2018-11-26 12:43:18,255 INFO     Weight matrix 9/9 (128,128): Alpha 4.452908689662523 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:43:18,260 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.5293200016021729\n",
      "2018-11-26 12:43:18,263 INFO Layer 13: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:43:18,266 INFO Layer 13: Skipping (Layer not supported)\n",
      "2018-11-26 12:43:18,268 INFO Layer 14: ReLU(inplace)\n",
      "2018-11-26 12:43:18,270 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 12:43:18,273 INFO Layer 15: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:43:18,277 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 12:43:18,281 INFO Layer 16: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:43:18,289 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:43:18,292 INFO Layer 16: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:43:18,296 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:43:19,547 INFO     Weight matrix 1/9 (128,256): Alpha: 2.9493918786184037, Alpha Weighted: 0.2692261554931024, D: 0.1409193343017755\n",
      "2018-11-26 12:43:19,552 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.621558427810669\n",
      "2018-11-26 12:43:19,556 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:43:20,583 INFO     Weight matrix 2/9 (128,256): Alpha: 1.773718504207585, Alpha Weighted: 0.3463540156658837, D: 0.17773781800974925\n",
      "2018-11-26 12:43:20,588 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.681553304195404\n",
      "2018-11-26 12:43:20,590 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:43:21,605 INFO     Weight matrix 3/9 (128,256): Alpha: 2.130429007778414, Alpha Weighted: 0.18684154863991828, D: 0.16321053452307932\n",
      "2018-11-26 12:43:21,609 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.618149995803833\n",
      "2018-11-26 12:43:21,612 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:43:22,562 INFO     Weight matrix 4/9 (128,256): Alpha: 3.457186013821321, Alpha Weighted: 0.667588768311356, D: 0.15311777254863923\n",
      "2018-11-26 12:43:22,566 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.679372251033783\n",
      "2018-11-26 12:43:22,568 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:43:23,531 INFO     Weight matrix 5/9 (128,256): Alpha: 2.932223775602317, Alpha Weighted: 1.2654459886069689, D: 0.15869351132659926\n",
      "2018-11-26 12:43:23,535 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.7932197451591492\n",
      "2018-11-26 12:43:23,538 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:43:24,675 INFO     Weight matrix 6/9 (128,256): Alpha: 3.153117730982223, Alpha Weighted: 0.7266894638484406, D: 0.15079086251847074\n",
      "2018-11-26 12:43:24,679 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.6813148260116577\n",
      "2018-11-26 12:43:24,681 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:43:25,834 INFO     Weight matrix 7/9 (128,256): Alpha: 3.21546311694809, Alpha Weighted: 0.2274303554637589, D: 0.148474108260635\n",
      "2018-11-26 12:43:25,838 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.6089982390403748\n",
      "2018-11-26 12:43:25,846 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:43:27,040 INFO     Weight matrix 8/9 (128,256): Alpha: 3.107690903116211, Alpha Weighted: 0.7722381879546718, D: 0.1519495317159218\n",
      "2018-11-26 12:43:27,044 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.6769558191299438\n",
      "2018-11-26 12:43:27,049 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:43:28,232 INFO     Weight matrix 9/9 (128,256): Alpha: 3.216832021151838, Alpha Weighted: 0.40418589525868215, D: 0.12119178947542164\n",
      "2018-11-26 12:43:28,236 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.6168607473373413\n",
      "2018-11-26 12:43:28,239 INFO Layer 17: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:43:28,242 INFO Layer 17: Skipping (Layer not supported)\n",
      "2018-11-26 12:43:28,244 INFO Layer 18: ReLU(inplace)\n",
      "2018-11-26 12:43:28,247 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 12:43:28,251 INFO Layer 19: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:43:28,270 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:43:28,272 INFO Layer 19: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:43:28,276 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:43:31,134 INFO     Weight matrix 1/9 (256,256): Alpha: 2.14720973114321, Alpha Weighted: 0.03712016462707825, D: 0.13660292187858386\n",
      "2018-11-26 12:43:31,140 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.6896229386329651\n",
      "2018-11-26 12:43:31,144 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:43:33,488 INFO     Weight matrix 2/9 (256,256): Alpha: 2.830266614264951, Alpha Weighted: 0.3383744340643511, D: 0.11647464149816622\n",
      "2018-11-26 12:43:33,493 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7224852442741394\n",
      "2018-11-26 12:43:33,496 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:43:36,182 INFO     Weight matrix 3/9 (256,256): Alpha: 2.690419818470598, Alpha Weighted: 0.0036342226466584016, D: 0.1341964741913101\n",
      "2018-11-26 12:43:36,187 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.689423143863678\n",
      "2018-11-26 12:43:36,190 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:43:38,803 INFO     Weight matrix 4/9 (256,256): Alpha: 2.313093736305263, Alpha Weighted: 0.3948951106170237, D: 0.1265620980276636\n",
      "2018-11-26 12:43:38,808 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.724673330783844\n",
      "2018-11-26 12:43:38,811 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:43:41,755 INFO     Weight matrix 5/9 (256,256): Alpha: 2.7179380239175748, Alpha Weighted: 1.4220980082772603, D: 0.10259248313635605\n",
      "2018-11-26 12:43:41,760 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.7996470332145691\n",
      "2018-11-26 12:43:41,763 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:43:44,409 INFO     Weight matrix 6/9 (256,256): Alpha: 2.5088690505814117, Alpha Weighted: 0.3771235714045967, D: 0.1231615565511569\n",
      "2018-11-26 12:43:44,414 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7196282148361206\n",
      "2018-11-26 12:43:44,417 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:43:46,912 INFO     Weight matrix 7/9 (256,256): Alpha: 2.4933689757019364, Alpha Weighted: -0.030651290776612522, D: 0.1287192928157166\n",
      "2018-11-26 12:43:46,917 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.6880820989608765\n",
      "2018-11-26 12:43:46,921 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:43:49,933 INFO     Weight matrix 8/9 (256,256): Alpha: 2.2733615650007213, Alpha Weighted: 0.29750053138161164, D: 0.13540365631252604\n",
      "2018-11-26 12:43:49,937 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7206573486328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:43:49,941 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:43:52,530 INFO     Weight matrix 9/9 (256,256): Alpha: 2.620186784562488, Alpha Weighted: -0.02583837412378613, D: 0.13129343697231521\n",
      "2018-11-26 12:43:52,535 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6866093277931213\n",
      "2018-11-26 12:43:52,537 INFO Layer 20: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:43:52,540 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 12:43:52,543 INFO Layer 21: ReLU(inplace)\n",
      "2018-11-26 12:43:52,545 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 12:43:52,548 INFO Layer 22: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:43:52,556 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:43:52,559 INFO Layer 22: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:43:52,562 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:43:55,208 INFO     Weight matrix 1/9 (256,256): Alpha: 2.89342357441784, Alpha Weighted: 0.15611208172846805, D: 0.11476736789623154\n",
      "2018-11-26 12:43:55,213 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7132302522659302\n",
      "2018-11-26 12:43:55,216 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:43:58,030 INFO     Weight matrix 2/9 (256,256): Alpha: 3.085923036379448, Alpha Weighted: 0.41249216624522533, D: 0.1328224936301456\n",
      "2018-11-26 12:43:58,035 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7523155808448792\n",
      "2018-11-26 12:43:58,038 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:44:00,538 INFO     Weight matrix 3/9 (256,256): Alpha: 2.9376569635868037, Alpha Weighted: 0.16314705789436304, D: 0.1181213424725508\n",
      "2018-11-26 12:44:00,543 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.713317334651947\n",
      "2018-11-26 12:44:00,546 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:44:03,088 INFO     Weight matrix 4/9 (256,256): Alpha: 2.9171232135917764, Alpha Weighted: 0.27537168192266614, D: 0.13221127667914812\n",
      "2018-11-26 12:44:03,093 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.74599289894104\n",
      "2018-11-26 12:44:03,096 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:44:05,433 INFO     Weight matrix 5/9 (256,256): Alpha: 4.579021559804192, Alpha Weighted: 1.6711741052027487, D: 0.1343512326699875\n",
      "2018-11-26 12:44:05,435 INFO     Weight matrix 5/9 (256,256): Alpha 4.579021559804192 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:44:05,440 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8240542411804199\n",
      "2018-11-26 12:44:05,443 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:44:07,868 INFO     Weight matrix 6/9 (256,256): Alpha: 2.493813340916816, Alpha Weighted: 0.37118927356823606, D: 0.12856092024617838\n",
      "2018-11-26 12:44:07,873 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7495875358581543\n",
      "2018-11-26 12:44:07,875 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:44:10,182 INFO     Weight matrix 7/9 (256,256): Alpha: 2.8328184260101286, Alpha Weighted: 0.04963803683239948, D: 0.1319641703701041\n",
      "2018-11-26 12:44:10,187 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.7099129557609558\n",
      "2018-11-26 12:44:10,191 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:44:12,675 INFO     Weight matrix 8/9 (256,256): Alpha: 3.1678926372577587, Alpha Weighted: 0.25123088403792765, D: 0.14974330900800775\n",
      "2018-11-26 12:44:12,679 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7456675171852112\n",
      "2018-11-26 12:44:12,682 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:44:15,176 INFO     Weight matrix 9/9 (256,256): Alpha: 2.6584012648714963, Alpha Weighted: 0.15033903822304445, D: 0.10004136801283514\n",
      "2018-11-26 12:44:15,181 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7092029452323914\n",
      "2018-11-26 12:44:15,184 INFO Layer 23: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:44:15,188 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:15,193 INFO Layer 24: ReLU(inplace)\n",
      "2018-11-26 12:44:15,196 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:15,200 INFO Layer 25: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:44:15,204 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:15,207 INFO Layer 26: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:44:15,230 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:44:15,232 INFO Layer 26: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:44:15,235 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:44:17,953 INFO     Weight matrix 1/9 (256,512): Alpha: 2.729421713507916, Alpha Weighted: 0.5437397805220295, D: 0.11244652634147356\n",
      "2018-11-26 12:44:17,958 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.8181129693984985\n",
      "2018-11-26 12:44:17,961 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:44:21,287 INFO     Weight matrix 2/9 (256,512): Alpha: 3.5810027037238243, Alpha Weighted: 0.9061112603135036, D: 0.12682630161648034\n",
      "2018-11-26 12:44:21,292 INFO     Weight matrix 2/9 (256,512): Alpha 3.5810027037238243 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:44:21,298 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.8462375998497009\n",
      "2018-11-26 12:44:21,304 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:44:23,944 INFO     Weight matrix 3/9 (256,512): Alpha: 2.6295552925456036, Alpha Weighted: 0.5023896467824799, D: 0.10358085872439232\n",
      "2018-11-26 12:44:23,948 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.8175792098045349\n",
      "2018-11-26 12:44:23,950 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:44:26,350 INFO     Weight matrix 4/9 (256,512): Alpha: 2.9705314324119807, Alpha Weighted: 0.8891787232089909, D: 0.11521446880031605\n",
      "2018-11-26 12:44:26,354 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.8492370843887329\n",
      "2018-11-26 12:44:26,357 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:44:28,736 INFO     Weight matrix 5/9 (256,512): Alpha: 3.715436189373441, Alpha Weighted: 1.3837737708146771, D: 0.15296704869891076\n",
      "2018-11-26 12:44:28,739 INFO     Weight matrix 5/9 (256,512): Alpha 3.715436189373441 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:44:28,746 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.920875608921051\n",
      "2018-11-26 12:44:28,749 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:44:31,154 INFO     Weight matrix 6/9 (256,512): Alpha: 2.875922977371062, Alpha Weighted: 0.8820273815799694, D: 0.11646511404293519\n",
      "2018-11-26 12:44:31,159 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.8457630276679993\n",
      "2018-11-26 12:44:31,161 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:44:33,662 INFO     Weight matrix 7/9 (256,512): Alpha: 2.991136061282754, Alpha Weighted: 0.5633856681775207, D: 0.10495291974896725\n",
      "2018-11-26 12:44:33,667 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.8130205869674683\n",
      "2018-11-26 12:44:33,670 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:44:36,079 INFO     Weight matrix 8/9 (256,512): Alpha: 2.409543418343933, Alpha Weighted: 0.600023700877802, D: 0.13512513334222342\n",
      "2018-11-26 12:44:36,083 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.8386633992195129\n",
      "2018-11-26 12:44:36,087 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:44:38,477 INFO     Weight matrix 9/9 (256,512): Alpha: 2.8159580854543, Alpha Weighted: 0.5228267363405303, D: 0.10759159711652161\n",
      "2018-11-26 12:44:38,482 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.8117393851280212\n",
      "2018-11-26 12:44:38,484 INFO Layer 27: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:44:38,489 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,492 INFO Layer 28: ReLU(inplace)\n",
      "2018-11-26 12:44:38,495 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,497 INFO Layer 29: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:44:38,540 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:44:38,544 INFO Layer 29: Analyzing 9 weight matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:44:38,546 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,548 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,551 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,554 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,558 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,560 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,563 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,565 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,568 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,571 INFO Layer 30: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:44:38,574 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,576 INFO Layer 31: ReLU(inplace)\n",
      "2018-11-26 12:44:38,579 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,582 INFO Layer 32: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:44:38,620 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:44:38,623 INFO Layer 32: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:44:38,626 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,630 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,633 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,636 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,639 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,642 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,645 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,648 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,652 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,655 INFO Layer 33: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:44:38,657 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,659 INFO Layer 34: ReLU(inplace)\n",
      "2018-11-26 12:44:38,661 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,665 INFO Layer 35: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:44:38,669 INFO Layer 35: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,671 INFO Layer 36: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:44:38,693 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:44:38,697 INFO Layer 36: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:44:38,701 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,704 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,707 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,709 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,712 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,715 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,718 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,721 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,723 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,726 INFO Layer 37: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:44:38,732 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,736 INFO Layer 38: ReLU(inplace)\n",
      "2018-11-26 12:44:38,739 INFO Layer 38: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,742 INFO Layer 39: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:44:38,764 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:44:38,767 INFO Layer 39: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:44:38,771 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,775 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,779 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,782 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,786 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,790 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,793 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,798 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,802 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,808 INFO Layer 40: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:44:38,810 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,813 INFO Layer 41: ReLU(inplace)\n",
      "2018-11-26 12:44:38,816 INFO Layer 41: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,819 INFO Layer 42: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:44:38,838 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:44:38,842 INFO Layer 42: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:44:38,845 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,848 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,851 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,854 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,857 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,860 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,862 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,865 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,867 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:38,869 INFO Layer 43: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:44:38,872 INFO Layer 43: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,874 INFO Layer 44: ReLU(inplace)\n",
      "2018-11-26 12:44:38,877 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,880 INFO Layer 45: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:44:38,883 INFO Layer 45: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,886 INFO Layer 46: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 12:44:38,889 INFO Layer 46: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:38,892 INFO Layer 47: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 12:44:40,454 INFO Layer 47: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:44:40,457 INFO     Weight matrix 1/1 (4096,25088): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:40,459 INFO Layer 48: ReLU(inplace)\n",
      "2018-11-26 12:44:40,552 INFO Layer 48: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:40,555 INFO Layer 49: Dropout(p=0.5)\n",
      "2018-11-26 12:44:40,557 INFO Layer 49: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:44:40,559 INFO Layer 50: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 12:44:40,824 INFO Layer 50: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:44:40,827 INFO     Weight matrix 1/1 (4096,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:40,830 INFO Layer 51: ReLU(inplace)\n",
      "2018-11-26 12:44:40,857 INFO Layer 51: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:40,859 INFO Layer 52: Dropout(p=0.5)\n",
      "2018-11-26 12:44:40,862 INFO Layer 52: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:40,865 INFO Layer 53: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 12:44:40,936 INFO Layer 53: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:44:40,939 INFO     Weight matrix 1/1 (1000,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:44:40,942 INFO ### Printing results ###\n",
      "2018-11-26 12:44:40,944 DEBUG Layer 5: Lognorm compound: 0.35032408436139423\n",
      "2018-11-26 12:44:40,947 DEBUG Layer 9: Lognorm compound: 0.549374520778656\n",
      "2018-11-26 12:44:40,950 DEBUG Layer 12: Lognorm compound: 0.564693722460005\n",
      "2018-11-26 12:44:40,955 DEBUG Layer 16: Lognorm compound: 0.664220372835795\n",
      "2018-11-26 12:44:40,958 DEBUG Layer 19: Lognorm compound: 0.7156476312213473\n",
      "2018-11-26 12:44:40,961 DEBUG Layer 22: Lognorm compound: 0.740364584657881\n",
      "2018-11-26 12:44:40,964 DEBUG Layer 26: Lognorm compound: 0.8401365412606133\n",
      "2018-11-26 12:44:40,967 INFO LogNorm: min: 0.28816333413124084, max: 0.920875608921051, avg: 0.6321088075637817\n",
      "2018-11-26 12:44:40,970 INFO LogNorm compound: min: 0.35032408436139423, max: 0.8401365412606133, avg: 0.6321087796536703\n",
      "2018-11-26 12:44:40,974 DEBUG Layer 5: Alpha compound: 2.7281008948532723\n",
      "2018-11-26 12:44:40,977 DEBUG Layer 9: Alpha compound: 1.664892467685746\n",
      "2018-11-26 12:44:40,979 DEBUG Layer 12: Alpha compound: 2.957884709552109\n",
      "2018-11-26 12:44:40,982 DEBUG Layer 16: Alpha compound: 2.8817836613584893\n",
      "2018-11-26 12:44:40,985 DEBUG Layer 19: Alpha compound: 2.5105238111053505\n",
      "2018-11-26 12:44:40,988 DEBUG Layer 22: Alpha compound: 3.0628971129818066\n",
      "2018-11-26 12:44:40,994 DEBUG Layer 26: Alpha compound: 2.9687230971127576\n",
      "2018-11-26 12:44:40,998 INFO Alpha: min: 1.5416898601966809, max: 4.579021559804192, avg: 2.6821151078070757\n",
      "2018-11-26 12:44:41,002 INFO Alpha compound: min: 1.664892467685746, max: 3.0628971129818066, avg: 2.682115107807076\n",
      "2018-11-26 12:44:41,004 DEBUG Layer 5: Alpha Weighted compound: 0.4815457367715123\n",
      "2018-11-26 12:44:41,008 DEBUG Layer 9: Alpha Weighted compound: 0.7099303638041259\n",
      "2018-11-26 12:44:41,011 DEBUG Layer 12: Alpha Weighted compound: 0.13886882344499363\n",
      "2018-11-26 12:44:41,014 DEBUG Layer 16: Alpha Weighted compound: 0.5406667088047536\n",
      "2018-11-26 12:44:41,017 DEBUG Layer 19: Alpha Weighted compound: 0.3126951531242424\n",
      "2018-11-26 12:44:41,020 DEBUG Layer 22: Alpha Weighted compound: 0.3889660361838977\n",
      "2018-11-26 12:44:41,022 DEBUG Layer 26: Alpha Weighted compound: 0.7548285187352781\n",
      "2018-11-26 12:44:41,025 INFO Alpha Weighted: min: -0.14159613714904265, max: 1.6711741052027487, avg: 0.47535733440982914\n",
      "2018-11-26 12:44:41,028 INFO Alpha Weighted compound: min: 0.13886882344499363, max: 0.7548285187352781, avg: 0.4753573344098291\n",
      "2018-11-26 12:44:48,820 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 12:44:48,822 INFO Analyzing model\n",
      "2018-11-26 12:44:48,826 INFO Layer 0: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:44:48,829 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:48,834 INFO Layer 1: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace)\n",
      "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (17): ReLU(inplace)\n",
      "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace)\n",
      "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (24): ReLU(inplace)\n",
      "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (26): ReLU(inplace)\n",
      "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace)\n",
      "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (31): ReLU(inplace)\n",
      "  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (33): ReLU(inplace)\n",
      "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (35): ReLU(inplace)\n",
      "  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "2018-11-26 12:44:48,837 INFO Layer 1: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:44:48,839 INFO Layer 2: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:44:48,845 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:44:48,852 INFO Layer 2: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:44:48,855 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:44:48,858 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:44:48,860 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:44:48,863 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:44:48,866 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:44:48,868 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:44:48,871 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:44:48,873 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:44:48,876 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:44:48,879 INFO Layer 3: ReLU(inplace)\n",
      "2018-11-26 12:44:48,882 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:48,885 INFO Layer 4: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:44:48,891 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:44:48,894 INFO Layer 4: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:44:48,898 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:44:49,440 INFO     Weight matrix 1/9 (64,64): Alpha: 1.4433520467685375, Alpha Weighted: 0.37400046097904044, D: 0.18909774048615235\n",
      "2018-11-26 12:44:49,442 INFO     Weight matrix 1/9 (64,64): Alpha 1.4433520467685375 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:44:49,446 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.5246809124946594\n",
      "2018-11-26 12:44:49,451 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:44:49,980 INFO     Weight matrix 2/9 (64,64): Alpha: 1.528030971311867, Alpha Weighted: 0.6058797957651845, D: 0.1710957801181321\n",
      "2018-11-26 12:44:49,983 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.5623267889022827\n",
      "2018-11-26 12:44:49,988 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:44:50,504 INFO     Weight matrix 3/9 (64,64): Alpha: 2.133732906777966, Alpha Weighted: 0.5358820851415669, D: 0.19530522401359107\n",
      "2018-11-26 12:44:50,509 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.5185110569000244\n",
      "2018-11-26 12:44:50,514 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:44:51,024 INFO     Weight matrix 4/9 (64,64): Alpha: 1.5175890200169748, Alpha Weighted: 0.5657870708681467, D: 0.17687644162917693\n",
      "2018-11-26 12:44:51,027 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.5506455898284912\n",
      "2018-11-26 12:44:51,030 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:44:51,470 INFO     Weight matrix 5/9 (64,64): Alpha: 1.5564280586527477, Alpha Weighted: 0.8959314289689114, D: 0.16548952750192214\n",
      "2018-11-26 12:44:51,473 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.6257965564727783\n",
      "2018-11-26 12:44:51,476 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:44:51,904 INFO     Weight matrix 6/9 (64,64): Alpha: 1.4913516068204231, Alpha Weighted: 0.6635928748809717, D: 0.15060942849528175\n",
      "2018-11-26 12:44:51,907 INFO     Weight matrix 6/9 (64,64): Alpha 1.4913516068204231 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:44:51,910 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.5667096376419067\n",
      "2018-11-26 12:44:51,913 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:44:52,400 INFO     Weight matrix 7/9 (64,64): Alpha: 1.4596253723291455, Alpha Weighted: 0.25546234120250005, D: 0.19951913082225503\n",
      "2018-11-26 12:44:52,403 INFO     Weight matrix 7/9 (64,64): Alpha 1.4596253723291455 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:44:52,407 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.507559061050415\n",
      "2018-11-26 12:44:52,410 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:44:52,867 INFO     Weight matrix 8/9 (64,64): Alpha: 1.5392098605451305, Alpha Weighted: 0.6788768928589369, D: 0.1715947135981234\n",
      "2018-11-26 12:44:52,870 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.5649570226669312\n",
      "2018-11-26 12:44:52,873 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:44:53,343 INFO     Weight matrix 9/9 (64,64): Alpha: 1.457900585050167, Alpha Weighted: 0.4323591532121015, D: 0.17514105297038107\n",
      "2018-11-26 12:44:53,345 INFO     Weight matrix 9/9 (64,64): Alpha 1.457900585050167 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:44:53,348 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.5289150476455688\n",
      "2018-11-26 12:44:53,352 INFO Layer 5: ReLU(inplace)\n",
      "2018-11-26 12:44:53,355 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:53,358 INFO Layer 6: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:44:53,360 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:53,363 INFO Layer 7: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:44:53,367 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:44:53,369 INFO Layer 7: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:44:53,371 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:44:53,849 INFO     Weight matrix 1/9 (64,128): Alpha: 1.9480238595203367, Alpha Weighted: 0.7090820057472119, D: 0.13217526934154944\n",
      "2018-11-26 12:44:53,852 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.6073034405708313\n",
      "2018-11-26 12:44:53,855 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:44:54,323 INFO     Weight matrix 2/9 (64,128): Alpha: 1.765584529493544, Alpha Weighted: 0.8100626315891267, D: 0.15214294998587352\n",
      "2018-11-26 12:44:54,327 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.6629356145858765\n",
      "2018-11-26 12:44:54,329 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:44:54,787 INFO     Weight matrix 3/9 (64,128): Alpha: 1.746850741844208, Alpha Weighted: 0.6559594660058287, D: 0.16942885104780525\n",
      "2018-11-26 12:44:54,792 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.6105842590332031\n",
      "2018-11-26 12:44:54,794 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:44:55,280 INFO     Weight matrix 4/9 (64,128): Alpha: 1.786098677865872, Alpha Weighted: 0.7348436691556204, D: 0.15315527775835747\n",
      "2018-11-26 12:44:55,283 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.6461232900619507\n",
      "2018-11-26 12:44:55,288 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:44:55,731 INFO     Weight matrix 5/9 (64,128): Alpha: 1.7878029346166038, Alpha Weighted: 1.305773586927941, D: 0.14205524666188896\n",
      "2018-11-26 12:44:55,734 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.7240925431251526\n",
      "2018-11-26 12:44:55,737 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:44:56,254 INFO     Weight matrix 6/9 (64,128): Alpha: 1.7338403310129236, Alpha Weighted: 0.8239731100260388, D: 0.14496527821084326\n",
      "2018-11-26 12:44:56,258 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.6685253977775574\n",
      "2018-11-26 12:44:56,260 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:44:56,731 INFO     Weight matrix 7/9 (64,128): Alpha: 1.6244490084241638, Alpha Weighted: 0.5587766376407718, D: 0.1685806107245783\n",
      "2018-11-26 12:44:56,734 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.5926670432090759\n",
      "2018-11-26 12:44:56,737 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:44:57,224 INFO     Weight matrix 8/9 (64,128): Alpha: 1.730681122506987, Alpha Weighted: 0.6888092332393896, D: 0.15668146375170877\n",
      "2018-11-26 12:44:57,228 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.649208664894104\n",
      "2018-11-26 12:44:57,231 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:44:57,721 INFO     Weight matrix 9/9 (64,128): Alpha: 1.8133168218198183, Alpha Weighted: 0.6154359885607584, D: 0.15667685600902193\n",
      "2018-11-26 12:44:57,725 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.6012813448905945\n",
      "2018-11-26 12:44:57,729 INFO Layer 8: ReLU(inplace)\n",
      "2018-11-26 12:44:57,732 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 12:44:57,734 INFO Layer 9: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:44:57,740 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:44:57,742 INFO Layer 9: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:44:57,745 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:44:58,802 INFO     Weight matrix 1/9 (128,128): Alpha: 1.9967976232077218, Alpha Weighted: 0.42513046854519476, D: 0.1570835828457816\n",
      "2018-11-26 12:44:58,806 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.6642192006111145\n",
      "2018-11-26 12:44:58,811 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:44:59,847 INFO     Weight matrix 2/9 (128,128): Alpha: 1.7991023066099974, Alpha Weighted: 0.388447481150204, D: 0.16085117514023872\n",
      "2018-11-26 12:44:59,851 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.6979942321777344\n",
      "2018-11-26 12:44:59,854 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:45:00,868 INFO     Weight matrix 3/9 (128,128): Alpha: 1.8967231858183513, Alpha Weighted: 0.30716291496935466, D: 0.16055939647687534\n",
      "2018-11-26 12:45:00,871 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.6634766459465027\n",
      "2018-11-26 12:45:00,873 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:45:01,825 INFO     Weight matrix 4/9 (128,128): Alpha: 1.9960528166726113, Alpha Weighted: 0.4027891590599473, D: 0.17263021780907317\n",
      "2018-11-26 12:45:01,828 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.6933497190475464\n",
      "2018-11-26 12:45:01,831 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:45:02,787 INFO     Weight matrix 5/9 (128,128): Alpha: 1.7180822780212075, Alpha Weighted: 0.5963777794684845, D: 0.1695526553681827\n",
      "2018-11-26 12:45:02,790 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.7525110840797424\n",
      "2018-11-26 12:45:02,793 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:45:03,748 INFO     Weight matrix 6/9 (128,128): Alpha: 1.7889895686649337, Alpha Weighted: 0.36810295065656373, D: 0.16148107757776398\n",
      "2018-11-26 12:45:03,753 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.7028340697288513\n",
      "2018-11-26 12:45:03,755 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:45:04,839 INFO     Weight matrix 7/9 (128,128): Alpha: 1.8609072216895077, Alpha Weighted: 0.3281176042996576, D: 0.1453232371770954\n",
      "2018-11-26 12:45:04,843 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.6529442071914673\n",
      "2018-11-26 12:45:04,850 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:45:05,985 INFO     Weight matrix 8/9 (128,128): Alpha: 1.8108250870122573, Alpha Weighted: 0.4065406484887754, D: 0.15396073810596123\n",
      "2018-11-26 12:45:05,988 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.6940262317657471\n",
      "2018-11-26 12:45:05,991 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:45:07,120 INFO     Weight matrix 9/9 (128,128): Alpha: 1.7760511594593924, Alpha Weighted: 0.25016470582760847, D: 0.16772248207261398\n",
      "2018-11-26 12:45:07,123 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.6647165417671204\n",
      "2018-11-26 12:45:07,126 INFO Layer 10: ReLU(inplace)\n",
      "2018-11-26 12:45:07,128 INFO Layer 10: Skipping (Layer not supported)\n",
      "2018-11-26 12:45:07,131 INFO Layer 11: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:45:07,133 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:45:07,136 INFO Layer 12: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:45:07,148 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:45:07,150 INFO Layer 12: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:45:07,153 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:45:08,264 INFO     Weight matrix 1/9 (128,256): Alpha: 2.5707363461657433, Alpha Weighted: 0.32426930767246076, D: 0.14223853799907737\n",
      "2018-11-26 12:45:08,267 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.6945570111274719\n",
      "2018-11-26 12:45:08,271 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:45:09,439 INFO     Weight matrix 2/9 (128,256): Alpha: 2.5491702661830926, Alpha Weighted: 0.7963044542000137, D: 0.13031268111253336\n",
      "2018-11-26 12:45:09,443 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.7480389475822449\n",
      "2018-11-26 12:45:09,446 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:45:10,604 INFO     Weight matrix 3/9 (128,256): Alpha: 2.4131950481170166, Alpha Weighted: 0.3821806918922534, D: 0.15405428349131323\n",
      "2018-11-26 12:45:10,610 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.6934777498245239\n",
      "2018-11-26 12:45:10,614 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:45:11,728 INFO     Weight matrix 4/9 (128,256): Alpha: 2.7601963050366907, Alpha Weighted: 0.8824271158865566, D: 0.14516743130890247\n",
      "2018-11-26 12:45:11,732 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.7548373341560364\n",
      "2018-11-26 12:45:11,735 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:45:12,880 INFO     Weight matrix 5/9 (128,256): Alpha: 2.4433348902883036, Alpha Weighted: 1.5407389604152986, D: 0.1387892627908851\n",
      "2018-11-26 12:45:12,885 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.8705501556396484\n",
      "2018-11-26 12:45:12,889 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:45:13,893 INFO     Weight matrix 6/9 (128,256): Alpha: 2.7487807084132676, Alpha Weighted: 0.9089878930282542, D: 0.1515414312332441\n",
      "2018-11-26 12:45:13,897 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.7529991865158081\n",
      "2018-11-26 12:45:13,902 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:45:15,040 INFO     Weight matrix 7/9 (128,256): Alpha: 2.201394312006327, Alpha Weighted: 0.2533078506532587, D: 0.16475251591713713\n",
      "2018-11-26 12:45:15,048 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.6863210797309875\n",
      "2018-11-26 12:45:15,052 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:45:16,289 INFO     Weight matrix 8/9 (128,256): Alpha: 1.6794959107464806, Alpha Weighted: 0.5156157244706753, D: 0.1546351039048967\n",
      "2018-11-26 12:45:16,294 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.7482692003250122\n",
      "2018-11-26 12:45:16,297 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:45:17,468 INFO     Weight matrix 9/9 (128,256): Alpha: 2.911590883994233, Alpha Weighted: 0.27837043675169776, D: 0.1547366977097251\n",
      "2018-11-26 12:45:17,471 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.6904885172843933\n",
      "2018-11-26 12:45:17,475 INFO Layer 13: ReLU(inplace)\n",
      "2018-11-26 12:45:17,478 INFO Layer 13: Skipping (Layer not supported)\n",
      "2018-11-26 12:45:17,481 INFO Layer 14: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:45:17,503 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:45:17,506 INFO Layer 14: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:45:17,509 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:45:20,183 INFO     Weight matrix 1/9 (256,256): Alpha: 2.526270694874791, Alpha Weighted: 0.3412763385752823, D: 0.12212625360518536\n",
      "2018-11-26 12:45:20,187 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7491937875747681\n",
      "2018-11-26 12:45:20,190 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:45:22,541 INFO     Weight matrix 2/9 (256,256): Alpha: 2.0091979479373023, Alpha Weighted: 0.4320524144482032, D: 0.13071110944395747\n",
      "2018-11-26 12:45:22,545 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7718471884727478\n",
      "2018-11-26 12:45:22,549 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:45:25,396 INFO     Weight matrix 3/9 (256,256): Alpha: 2.228523990110248, Alpha Weighted: 0.21452579708070746, D: 0.13738267627581835\n",
      "2018-11-26 12:45:25,399 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.748981773853302\n",
      "2018-11-26 12:45:25,403 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:45:28,229 INFO     Weight matrix 4/9 (256,256): Alpha: 3.3502169095283456, Alpha Weighted: 0.7665525889227784, D: 0.12089214399853665\n",
      "2018-11-26 12:45:28,234 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.771720290184021\n",
      "2018-11-26 12:45:28,237 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:45:31,227 INFO     Weight matrix 5/9 (256,256): Alpha: 1.771555075463516, Alpha Weighted: 0.6821758210233995, D: 0.13084503221978094\n",
      "2018-11-26 12:45:31,231 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8354664444923401\n",
      "2018-11-26 12:45:31,236 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:45:33,985 INFO     Weight matrix 6/9 (256,256): Alpha: 3.1868460831034957, Alpha Weighted: 0.7046538935997849, D: 0.11027405886223629\n",
      "2018-11-26 12:45:33,990 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7708715200424194\n",
      "2018-11-26 12:45:33,992 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:45:36,760 INFO     Weight matrix 7/9 (256,256): Alpha: 2.419534317702996, Alpha Weighted: 0.30642743697728225, D: 0.13187810104330777\n",
      "2018-11-26 12:45:36,765 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.7443217039108276\n",
      "2018-11-26 12:45:36,770 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:45:39,448 INFO     Weight matrix 8/9 (256,256): Alpha: 5.027316766089016, Alpha Weighted: 1.2311623235456524, D: 0.12833373828128591\n",
      "2018-11-26 12:45:39,451 INFO     Weight matrix 8/9 (256,256): Alpha 5.027316766089016 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:45:39,458 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7676737904548645\n",
      "2018-11-26 12:45:39,462 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:45:42,387 INFO     Weight matrix 9/9 (256,256): Alpha: 2.609570119110967, Alpha Weighted: 0.34635605053822494, D: 0.13480240593702472\n",
      "2018-11-26 12:45:42,392 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7488450407981873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:45:42,395 INFO Layer 15: ReLU(inplace)\n",
      "2018-11-26 12:45:42,398 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 12:45:42,401 INFO Layer 16: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:45:42,412 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:45:42,414 INFO Layer 16: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:45:42,417 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:45:45,301 INFO     Weight matrix 1/9 (256,256): Alpha: 3.1605873828336217, Alpha Weighted: 0.5854494529822111, D: 0.09937325826179755\n",
      "2018-11-26 12:45:45,306 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7488040924072266\n",
      "2018-11-26 12:45:45,312 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:45:47,786 INFO     Weight matrix 2/9 (256,256): Alpha: 2.1304272274382496, Alpha Weighted: 0.6128599717274943, D: 0.1109695681537804\n",
      "2018-11-26 12:45:47,791 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7721681594848633\n",
      "2018-11-26 12:45:47,794 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:45:50,632 INFO     Weight matrix 3/9 (256,256): Alpha: 2.997803423840402, Alpha Weighted: 0.4648181601094382, D: 0.11903691210051137\n",
      "2018-11-26 12:45:50,638 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.7476074695587158\n",
      "2018-11-26 12:45:50,641 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:45:54,166 INFO     Weight matrix 4/9 (256,256): Alpha: 2.548678416289066, Alpha Weighted: 0.6731126166072445, D: 0.11099494812097677\n",
      "2018-11-26 12:45:54,172 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.7677842378616333\n",
      "2018-11-26 12:45:54,175 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:45:57,198 INFO     Weight matrix 5/9 (256,256): Alpha: 1.853957853173247, Alpha Weighted: 0.8362905913984802, D: 0.1172212057922507\n",
      "2018-11-26 12:45:57,203 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8333234786987305\n",
      "2018-11-26 12:45:57,207 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:46:00,060 INFO     Weight matrix 6/9 (256,256): Alpha: 3.0765007504769124, Alpha Weighted: 0.8659677907268513, D: 0.09849018588794978\n",
      "2018-11-26 12:46:00,065 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7665061354637146\n",
      "2018-11-26 12:46:00,069 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:46:03,499 INFO     Weight matrix 7/9 (256,256): Alpha: 3.2528872690153965, Alpha Weighted: 0.4013482043884029, D: 0.12544440419495329\n",
      "2018-11-26 12:46:03,503 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.745129406452179\n",
      "2018-11-26 12:46:03,506 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:46:06,383 INFO     Weight matrix 8/9 (256,256): Alpha: 2.0663080375391183, Alpha Weighted: 0.4603133002373895, D: 0.12337815016154924\n",
      "2018-11-26 12:46:06,386 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7673397064208984\n",
      "2018-11-26 12:46:06,390 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:46:08,900 INFO     Weight matrix 9/9 (256,256): Alpha: 2.703128162639186, Alpha Weighted: 0.3411089694358948, D: 0.11069928874980572\n",
      "2018-11-26 12:46:08,905 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7425023317337036\n",
      "2018-11-26 12:46:08,908 INFO Layer 17: ReLU(inplace)\n",
      "2018-11-26 12:46:08,912 INFO Layer 17: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:08,915 INFO Layer 18: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:46:08,920 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:46:08,922 INFO Layer 18: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:46:08,925 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:46:11,469 INFO     Weight matrix 1/9 (256,256): Alpha: 3.081294715606633, Alpha Weighted: 0.6864334936902786, D: 0.10610647761734338\n",
      "2018-11-26 12:46:11,473 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7562655806541443\n",
      "2018-11-26 12:46:11,476 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:46:14,392 INFO     Weight matrix 2/9 (256,256): Alpha: 3.9235997119205126, Alpha Weighted: 1.5028524115535689, D: 0.08333333333333293\n",
      "2018-11-26 12:46:14,395 INFO     Weight matrix 2/9 (256,256): Alpha 3.9235997119205126 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:46:14,401 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7882983088493347\n",
      "2018-11-26 12:46:14,406 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:46:17,287 INFO     Weight matrix 3/9 (256,256): Alpha: 2.9175623147491256, Alpha Weighted: 0.5092043230718079, D: 0.0909994642022422\n",
      "2018-11-26 12:46:17,292 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.7557727098464966\n",
      "2018-11-26 12:46:17,295 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:46:20,121 INFO     Weight matrix 4/9 (256,256): Alpha: 3.7035066503060525, Alpha Weighted: 1.5531059038260473, D: 0.05555555555555536\n",
      "2018-11-26 12:46:20,124 INFO     Weight matrix 4/9 (256,256): Alpha 3.7035066503060525 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:46:20,128 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.7799181938171387\n",
      "2018-11-26 12:46:20,131 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:46:23,069 INFO     Weight matrix 5/9 (256,256): Alpha: 3.394850907422555, Alpha Weighted: 2.071731023425762, D: 0.07243287629900536\n",
      "2018-11-26 12:46:23,073 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.8419984579086304\n",
      "2018-11-26 12:46:23,076 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:46:25,766 INFO     Weight matrix 6/9 (256,256): Alpha: 3.6898566417596284, Alpha Weighted: 1.3446518271078778, D: 0.08396180729870817\n",
      "2018-11-26 12:46:25,769 INFO     Weight matrix 6/9 (256,256): Alpha 3.6898566417596284 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:46:25,775 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7775861024856567\n",
      "2018-11-26 12:46:25,778 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:46:28,786 INFO     Weight matrix 7/9 (256,256): Alpha: 3.688093538198817, Alpha Weighted: 0.8919342199852207, D: 0.071525413257024\n",
      "2018-11-26 12:46:28,789 INFO     Weight matrix 7/9 (256,256): Alpha 3.688093538198817 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:46:28,796 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.7540994882583618\n",
      "2018-11-26 12:46:28,801 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:46:31,738 INFO     Weight matrix 8/9 (256,256): Alpha: 3.7897442845199087, Alpha Weighted: 1.458702970741984, D: 0.10176661660121007\n",
      "2018-11-26 12:46:31,741 INFO     Weight matrix 8/9 (256,256): Alpha 3.7897442845199087 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:46:31,745 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7831012606620789\n",
      "2018-11-26 12:46:31,750 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:46:34,337 INFO     Weight matrix 9/9 (256,256): Alpha: 3.8115022968894507, Alpha Weighted: 0.890731984216727, D: 0.0676730219557099\n",
      "2018-11-26 12:46:34,340 INFO     Weight matrix 9/9 (256,256): Alpha 3.8115022968894507 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:46:34,346 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7492718696594238\n",
      "2018-11-26 12:46:34,349 INFO Layer 19: ReLU(inplace)\n",
      "2018-11-26 12:46:34,352 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:34,355 INFO Layer 20: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:46:34,358 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:34,360 INFO Layer 21: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:46:34,385 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:46:34,388 INFO Layer 21: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:46:34,391 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:46:36,936 INFO     Weight matrix 1/9 (256,512): Alpha: 4.004994370886633, Alpha Weighted: 1.193932485649153, D: 0.11210818715919763\n",
      "2018-11-26 12:46:36,939 INFO     Weight matrix 1/9 (256,512): Alpha 4.004994370886633 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:46:36,946 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.8389447331428528\n",
      "2018-11-26 12:46:36,949 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:46:39,556 INFO     Weight matrix 2/9 (256,512): Alpha: 3.507828589206325, Alpha Weighted: 1.1740432163032473, D: 0.1276738047680409\n",
      "2018-11-26 12:46:39,558 INFO     Weight matrix 2/9 (256,512): Alpha 3.507828589206325 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:46:39,563 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.865201473236084\n",
      "2018-11-26 12:46:39,566 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:46:42,105 INFO     Weight matrix 3/9 (256,512): Alpha: 2.2675362783831474, Alpha Weighted: 0.5747423595567609, D: 0.12880285666085572\n",
      "2018-11-26 12:46:42,110 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.8419089317321777\n",
      "2018-11-26 12:46:42,113 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:46:44,709 INFO     Weight matrix 4/9 (256,512): Alpha: 2.841487823786245, Alpha Weighted: 0.9288110817386377, D: 0.11040072445899313\n",
      "2018-11-26 12:46:44,714 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.8585543632507324\n",
      "2018-11-26 12:46:44,720 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:46:47,195 INFO     Weight matrix 5/9 (256,512): Alpha: 1.8316907753568223, Alpha Weighted: 0.8795039292698581, D: 0.1255956011392073\n",
      "2018-11-26 12:46:47,201 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.9144951105117798\n",
      "2018-11-26 12:46:47,206 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:46:49,708 INFO     Weight matrix 6/9 (256,512): Alpha: 3.1579973637379415, Alpha Weighted: 1.0899711945936337, D: 0.10946747952787272\n",
      "2018-11-26 12:46:49,713 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.8618883490562439\n",
      "2018-11-26 12:46:49,716 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:46:52,190 INFO     Weight matrix 7/9 (256,512): Alpha: 2.9757631156276645, Alpha Weighted: 0.6984061322461743, D: 0.12183839435515242\n",
      "2018-11-26 12:46:52,195 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.8374895453453064\n",
      "2018-11-26 12:46:52,198 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:46:54,683 INFO     Weight matrix 8/9 (256,512): Alpha: 2.083680842765892, Alpha Weighted: 0.671274098717872, D: 0.13390608671706372\n",
      "2018-11-26 12:46:54,688 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.8614062070846558\n",
      "2018-11-26 12:46:54,692 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:46:57,130 INFO     Weight matrix 9/9 (256,512): Alpha: 2.8620470065389307, Alpha Weighted: 0.7635480426636064, D: 0.11329950747807682\n",
      "2018-11-26 12:46:57,135 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.8379868268966675\n",
      "2018-11-26 12:46:57,139 INFO Layer 22: ReLU(inplace)\n",
      "2018-11-26 12:46:57,142 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:57,145 INFO Layer 23: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:46:57,188 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:46:57,191 INFO Layer 23: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:46:57,195 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,198 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,202 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,206 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,209 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,213 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,216 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,218 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,221 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,224 INFO Layer 24: ReLU(inplace)\n",
      "2018-11-26 12:46:57,226 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:57,229 INFO Layer 25: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:46:57,265 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:46:57,267 INFO Layer 25: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:46:57,270 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,273 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,276 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,278 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,282 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,285 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,288 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,291 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,295 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,297 INFO Layer 26: ReLU(inplace)\n",
      "2018-11-26 12:46:57,300 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:57,302 INFO Layer 27: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:46:57,323 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:46:57,326 INFO Layer 27: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:46:57,329 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,331 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,334 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,337 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,342 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,346 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,349 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,353 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,356 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,361 INFO Layer 28: ReLU(inplace)\n",
      "2018-11-26 12:46:57,364 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:57,366 INFO Layer 29: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:46:57,369 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:57,373 INFO Layer 30: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:46:57,391 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:46:57,398 INFO Layer 30: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:46:57,403 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,406 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,410 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,414 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,417 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,420 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,424 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,426 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,429 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,432 INFO Layer 31: ReLU(inplace)\n",
      "2018-11-26 12:46:57,435 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:57,439 INFO Layer 32: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:46:57,458 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:46:57,464 INFO Layer 32: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:46:57,466 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:46:57,469 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,472 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,475 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,477 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,480 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,483 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,486 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,489 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,493 INFO Layer 33: ReLU(inplace)\n",
      "2018-11-26 12:46:57,496 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:57,499 INFO Layer 34: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:46:57,519 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:46:57,522 INFO Layer 34: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:46:57,524 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,527 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,529 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,533 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,536 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,539 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,543 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,546 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,549 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,552 INFO Layer 35: ReLU(inplace)\n",
      "2018-11-26 12:46:57,555 INFO Layer 35: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:57,559 INFO Layer 36: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:46:57,576 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:46:57,579 INFO Layer 36: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:46:57,582 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,595 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,598 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,601 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,605 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,610 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,619 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,622 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,625 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:57,629 INFO Layer 37: ReLU(inplace)\n",
      "2018-11-26 12:46:57,631 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:57,637 INFO Layer 38: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:46:57,641 INFO Layer 38: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:57,644 INFO Layer 39: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 12:46:57,647 INFO Layer 39: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:57,649 INFO Layer 40: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 12:46:59,268 INFO Layer 40: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:46:59,271 INFO     Weight matrix 1/1 (4096,25088): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:59,274 INFO Layer 41: ReLU(inplace)\n",
      "2018-11-26 12:46:59,372 INFO Layer 41: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:59,374 INFO Layer 42: Dropout(p=0.5)\n",
      "2018-11-26 12:46:59,376 INFO Layer 42: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:59,379 INFO Layer 43: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 12:46:59,639 INFO Layer 43: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:46:59,642 INFO     Weight matrix 1/1 (4096,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:59,646 INFO Layer 44: ReLU(inplace)\n",
      "2018-11-26 12:46:59,678 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:59,682 INFO Layer 45: Dropout(p=0.5)\n",
      "2018-11-26 12:46:59,684 INFO Layer 45: Skipping (Layer not supported)\n",
      "2018-11-26 12:46:59,687 INFO Layer 46: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 12:46:59,778 INFO Layer 46: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:46:59,781 INFO     Weight matrix 1/1 (1000,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:46:59,784 INFO ### Printing results ###\n",
      "2018-11-26 12:46:59,788 DEBUG Layer 4: Lognorm compound: 0.5500112970670065\n",
      "2018-11-26 12:46:59,791 DEBUG Layer 7: Lognorm compound: 0.6403023997942606\n",
      "2018-11-26 12:46:59,794 DEBUG Layer 9: Lognorm compound: 0.6873413258128696\n",
      "2018-11-26 12:46:59,797 DEBUG Layer 12: Lognorm compound: 0.7377265757984586\n",
      "2018-11-26 12:46:59,800 DEBUG Layer 14: Lognorm compound: 0.7676579488648309\n",
      "2018-11-26 12:46:59,803 DEBUG Layer 16: Lognorm compound: 0.7656850020090739\n",
      "2018-11-26 12:46:59,807 DEBUG Layer 18: Lognorm compound: 0.776256885793474\n",
      "2018-11-26 12:46:59,810 DEBUG Layer 21: Lognorm compound: 0.8575417266951667\n",
      "2018-11-26 12:46:59,815 INFO LogNorm: min: 0.507559061050415, max: 0.9144951105117798, avg: 0.7228153944015503\n",
      "2018-11-26 12:46:59,817 INFO LogNorm compound: min: 0.5500112970670065, max: 0.8575417266951667, avg: 0.7228153952293925\n",
      "2018-11-26 12:46:59,820 DEBUG Layer 4: Alpha compound: 1.5696911586969953\n",
      "2018-11-26 12:46:59,823 DEBUG Layer 7: Alpha compound: 1.770738669678273\n",
      "2018-11-26 12:46:59,826 DEBUG Layer 9: Alpha compound: 1.8492812496839979\n",
      "2018-11-26 12:46:59,829 DEBUG Layer 12: Alpha compound: 2.475321630105684\n",
      "2018-11-26 12:46:59,831 DEBUG Layer 14: Alpha compound: 2.7921146559911865\n",
      "2018-11-26 12:46:59,833 DEBUG Layer 16: Alpha compound: 2.6433642803605775\n",
      "2018-11-26 12:46:59,836 DEBUG Layer 18: Alpha compound: 3.5555567845969653\n",
      "2018-11-26 12:46:59,839 DEBUG Layer 21: Alpha compound: 2.837002907365511\n",
      "2018-11-26 12:46:59,842 INFO Alpha: min: 1.4433520467685375, max: 5.027316766089016, avg: 2.4366339170598987\n",
      "2018-11-26 12:46:59,846 INFO Alpha compound: min: 1.5696911586969953, max: 3.5555567845969653, avg: 2.4366339170598987\n",
      "2018-11-26 12:46:59,848 DEBUG Layer 4: Alpha Weighted compound: 0.55641912265304\n",
      "2018-11-26 12:46:59,853 DEBUG Layer 7: Alpha Weighted compound: 0.7669684809880764\n",
      "2018-11-26 12:46:59,855 DEBUG Layer 9: Alpha Weighted compound: 0.3858704124961989\n",
      "2018-11-26 12:46:59,859 DEBUG Layer 12: Alpha Weighted compound: 0.6535780483300521\n",
      "2018-11-26 12:46:59,861 DEBUG Layer 14: Alpha Weighted compound: 0.5583536294123683\n",
      "2018-11-26 12:46:59,865 DEBUG Layer 16: Alpha Weighted compound: 0.5823632286237118\n",
      "2018-11-26 12:46:59,867 DEBUG Layer 18: Alpha Weighted compound: 1.2121497952910305\n",
      "2018-11-26 12:46:59,870 DEBUG Layer 21: Alpha Weighted compound: 0.8860258378598826\n",
      "2018-11-26 12:46:59,872 INFO Alpha Weighted: min: 0.21452579708070746, max: 2.071731023425762, avg: 0.7002160694567952\n",
      "2018-11-26 12:46:59,876 INFO Alpha Weighted compound: min: 0.3858704124961989, max: 1.2121497952910305, avg: 0.7002160694567952\n",
      "2018-11-26 12:47:07,761 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:47:07,763 INFO Analyzing model\n",
      "2018-11-26 12:47:07,769 INFO Layer 0: VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace)\n",
      "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace)\n",
      "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace)\n",
      "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace)\n",
      "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:47:07,772 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 12:47:07,775 INFO Layer 1: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace)\n",
      "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU(inplace)\n",
      "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU(inplace)\n",
      "  (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (12): ReLU(inplace)\n",
      "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (16): ReLU(inplace)\n",
      "  (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (19): ReLU(inplace)\n",
      "  (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (22): ReLU(inplace)\n",
      "  (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (25): ReLU(inplace)\n",
      "  (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (29): ReLU(inplace)\n",
      "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (32): ReLU(inplace)\n",
      "  (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (35): ReLU(inplace)\n",
      "  (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (38): ReLU(inplace)\n",
      "  (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (42): ReLU(inplace)\n",
      "  (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (45): ReLU(inplace)\n",
      "  (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (48): ReLU(inplace)\n",
      "  (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (51): ReLU(inplace)\n",
      "  (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "2018-11-26 12:47:07,777 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 12:47:07,780 INFO Layer 2: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:47:07,783 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:47:07,786 INFO Layer 2: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:47:07,789 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:47:07,791 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:47:07,794 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:47:07,797 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:47:07,801 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:47:07,803 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:47:07,807 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:47:07,812 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:47:07,815 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:47:07,818 INFO Layer 3: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:47:07,820 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:47:07,823 INFO Layer 4: ReLU(inplace)\n",
      "2018-11-26 12:47:07,825 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 12:47:07,828 INFO Layer 5: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:47:07,832 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:47:07,835 INFO Layer 5: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:47:07,839 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19_bn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:47:08,512 INFO     Weight matrix 1/9 (64,64): Alpha: 3.0726811832942302, Alpha Weighted: -0.06224750327449201, D: 0.2000000000000005\n",
      "2018-11-26 12:47:08,518 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.21840748190879822\n",
      "2018-11-26 12:47:08,522 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:47:08,923 INFO     Weight matrix 2/9 (64,64): Alpha: 2.4106269178904016, Alpha Weighted: 0.45840411143333326, D: 0.16889785261789775\n",
      "2018-11-26 12:47:08,926 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.300492525100708\n",
      "2018-11-26 12:47:08,929 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:47:09,419 INFO     Weight matrix 3/9 (64,64): Alpha: 1.690531407476214, Alpha Weighted: -0.17032384687729846, D: 0.21886507099897806\n",
      "2018-11-26 12:47:09,422 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.22294633090496063\n",
      "2018-11-26 12:47:09,425 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:47:09,929 INFO     Weight matrix 4/9 (64,64): Alpha: 1.5286226714306121, Alpha Weighted: 0.38563668601187734, D: 0.22748990755495269\n",
      "2018-11-26 12:47:09,932 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.335318922996521\n",
      "2018-11-26 12:47:09,935 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:47:10,338 INFO     Weight matrix 5/9 (64,64): Alpha: 2.1879396535560645, Alpha Weighted: 1.057168260983391, D: 0.18750991043857057\n",
      "2018-11-26 12:47:10,342 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.4457348585128784\n",
      "2018-11-26 12:47:10,349 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:47:10,812 INFO     Weight matrix 6/9 (64,64): Alpha: 2.199505546666523, Alpha Weighted: 0.40058705001821604, D: 0.184022835482071\n",
      "2018-11-26 12:47:10,815 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.3114398717880249\n",
      "2018-11-26 12:47:10,818 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:47:11,307 INFO     Weight matrix 7/9 (64,64): Alpha: 2.896216425452018, Alpha Weighted: -0.036014910922478105, D: 0.21519382219987288\n",
      "2018-11-26 12:47:11,310 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.2702086865901947\n",
      "2018-11-26 12:47:11,314 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:47:11,688 INFO     Weight matrix 8/9 (64,64): Alpha: 1.6809749128571834, Alpha Weighted: 0.3197788161721111, D: 0.19724395769196257\n",
      "2018-11-26 12:47:11,690 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.31995895504951477\n",
      "2018-11-26 12:47:11,694 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:47:12,166 INFO     Weight matrix 9/9 (64,64): Alpha: 4.079719042799393, Alpha Weighted: -0.3700095154954038, D: 0.2500000000000009\n",
      "2018-11-26 12:47:12,168 INFO     Weight matrix 9/9 (64,64): Alpha 4.079719042799393 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:47:12,171 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.21745115518569946\n",
      "2018-11-26 12:47:12,174 INFO Layer 6: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:47:12,176 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 12:47:12,179 INFO Layer 7: ReLU(inplace)\n",
      "2018-11-26 12:47:12,181 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 12:47:12,184 INFO Layer 8: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:47:12,187 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 12:47:12,189 INFO Layer 9: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:47:12,197 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:47:12,201 INFO Layer 9: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:47:12,204 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:47:12,724 INFO     Weight matrix 1/9 (64,128): Alpha: 1.6261398978887343, Alpha Weighted: 0.3712727539165708, D: 0.15856147620677402\n",
      "2018-11-26 12:47:12,728 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.4144156277179718\n",
      "2018-11-26 12:47:12,731 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:47:13,226 INFO     Weight matrix 2/9 (64,128): Alpha: 1.5927197056439097, Alpha Weighted: 0.7466424234461061, D: 0.1322532036932924\n",
      "2018-11-26 12:47:13,230 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.5095121264457703\n",
      "2018-11-26 12:47:13,232 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:47:13,705 INFO     Weight matrix 3/9 (64,128): Alpha: 1.9455480010941124, Alpha Weighted: 0.4809817583875681, D: 0.1354197420419856\n",
      "2018-11-26 12:47:13,708 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.41107144951820374\n",
      "2018-11-26 12:47:13,712 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:47:14,164 INFO     Weight matrix 4/9 (64,128): Alpha: 1.5105249374631677, Alpha Weighted: 0.6122906976735378, D: 0.15923695084095318\n",
      "2018-11-26 12:47:14,169 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.5117618441581726\n",
      "2018-11-26 12:47:14,172 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:47:14,622 INFO     Weight matrix 5/9 (64,128): Alpha: 1.5297252314397343, Alpha Weighted: 0.9042716099631922, D: 0.1522474155790567\n",
      "2018-11-26 12:47:14,625 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.639792263507843\n",
      "2018-11-26 12:47:14,628 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:47:15,048 INFO     Weight matrix 6/9 (64,128): Alpha: 1.5678715524531706, Alpha Weighted: 0.6327102646108371, D: 0.15257219684436873\n",
      "2018-11-26 12:47:15,051 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.5174331665039062\n",
      "2018-11-26 12:47:15,054 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:47:15,476 INFO     Weight matrix 7/9 (64,128): Alpha: 1.7362179081071523, Alpha Weighted: 0.4833022739979021, D: 0.136575722520052\n",
      "2018-11-26 12:47:15,481 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.43038251996040344\n",
      "2018-11-26 12:47:15,483 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:47:15,923 INFO     Weight matrix 8/9 (64,128): Alpha: 1.5917231919070334, Alpha Weighted: 0.6962408546504701, D: 0.1542117015844543\n",
      "2018-11-26 12:47:15,926 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.5156136155128479\n",
      "2018-11-26 12:47:15,930 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:47:16,357 INFO     Weight matrix 9/9 (64,128): Alpha: 1.8819877872605435, Alpha Weighted: 0.6364257374441226, D: 0.12140758040134259\n",
      "2018-11-26 12:47:16,364 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.43336403369903564\n",
      "2018-11-26 12:47:16,367 INFO Layer 10: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:47:16,370 INFO Layer 10: Skipping (Layer not supported)\n",
      "2018-11-26 12:47:16,372 INFO Layer 11: ReLU(inplace)\n",
      "2018-11-26 12:47:16,374 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:47:16,377 INFO Layer 12: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:47:16,385 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:47:16,389 INFO Layer 12: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:47:16,392 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:47:17,291 INFO     Weight matrix 1/9 (128,128): Alpha: 2.0280690877636642, Alpha Weighted: -0.06711883754213469, D: 0.18823260159793875\n",
      "2018-11-26 12:47:17,294 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.45874765515327454\n",
      "2018-11-26 12:47:17,297 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:47:18,131 INFO     Weight matrix 2/9 (128,128): Alpha: 2.0005068502827275, Alpha Weighted: 0.18779182404494077, D: 0.18921697605667082\n",
      "2018-11-26 12:47:18,135 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.5332913398742676\n",
      "2018-11-26 12:47:18,137 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:47:19,177 INFO     Weight matrix 3/9 (128,128): Alpha: 2.908118711346095, Alpha Weighted: -0.37484469026724104, D: 0.17740990008854812\n",
      "2018-11-26 12:47:19,181 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.4506426155567169\n",
      "2018-11-26 12:47:19,184 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:47:20,416 INFO     Weight matrix 4/9 (128,128): Alpha: 1.920100498508883, Alpha Weighted: 0.17963705441368907, D: 0.20997714733918899\n",
      "2018-11-26 12:47:20,421 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.5402300357818604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:47:20,424 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:47:21,700 INFO     Weight matrix 5/9 (128,128): Alpha: 2.8944534337115178, Alpha Weighted: 0.8052209021499531, D: 0.18607418558660138\n",
      "2018-11-26 12:47:21,704 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.6339673399925232\n",
      "2018-11-26 12:47:21,709 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:47:23,023 INFO     Weight matrix 6/9 (128,128): Alpha: 3.226443888659024, Alpha Weighted: 0.4108499924882686, D: 0.19342375040419368\n",
      "2018-11-26 12:47:23,028 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.5432183146476746\n",
      "2018-11-26 12:47:23,031 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:47:24,496 INFO     Weight matrix 7/9 (128,128): Alpha: 2.4050142360040967, Alpha Weighted: -0.2789080331140063, D: 0.2010500464187217\n",
      "2018-11-26 12:47:24,502 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.46046313643455505\n",
      "2018-11-26 12:47:24,511 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:47:26,075 INFO     Weight matrix 8/9 (128,128): Alpha: 2.9707552960741346, Alpha Weighted: 0.22039101174493883, D: 0.17739032238054753\n",
      "2018-11-26 12:47:26,082 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.5355432629585266\n",
      "2018-11-26 12:47:26,088 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:47:27,481 INFO     Weight matrix 9/9 (128,128): Alpha: 3.123710461044143, Alpha Weighted: -0.13521228926962495, D: 0.1909689724053213\n",
      "2018-11-26 12:47:27,485 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.4679080545902252\n",
      "2018-11-26 12:47:27,488 INFO Layer 13: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:47:27,491 INFO Layer 13: Skipping (Layer not supported)\n",
      "2018-11-26 12:47:27,493 INFO Layer 14: ReLU(inplace)\n",
      "2018-11-26 12:47:27,497 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 12:47:27,500 INFO Layer 15: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:47:27,503 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 12:47:27,506 INFO Layer 16: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:47:27,519 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:47:27,521 INFO Layer 16: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:47:27,524 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:47:29,687 INFO     Weight matrix 1/9 (128,256): Alpha: 4.879371548361345, Alpha Weighted: -0.26649973867723964, D: 0.14285714285714257\n",
      "2018-11-26 12:47:29,690 INFO     Weight matrix 1/9 (128,256): Alpha 4.879371548361345 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:47:29,695 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.5310695767402649\n",
      "2018-11-26 12:47:29,700 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:47:31,382 INFO     Weight matrix 2/9 (128,256): Alpha: 2.2738080833253393, Alpha Weighted: 0.15917117451420656, D: 0.18006494264819495\n",
      "2018-11-26 12:47:31,388 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.613785445690155\n",
      "2018-11-26 12:47:31,393 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:47:32,895 INFO     Weight matrix 3/9 (128,256): Alpha: 4.211889917190117, Alpha Weighted: 0.039601853650084264, D: 0.12103488717612165\n",
      "2018-11-26 12:47:32,898 INFO     Weight matrix 3/9 (128,256): Alpha 4.211889917190117 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:47:32,901 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.5367623567581177\n",
      "2018-11-26 12:47:32,904 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:47:34,697 INFO     Weight matrix 4/9 (128,256): Alpha: 2.3361061758675383, Alpha Weighted: 0.16317520099269506, D: 0.16859311398649285\n",
      "2018-11-26 12:47:34,705 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.6148995161056519\n",
      "2018-11-26 12:47:34,712 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:47:36,034 INFO     Weight matrix 5/9 (128,256): Alpha: 2.0687028957652736, Alpha Weighted: 0.9418127411869414, D: 0.19603400581629116\n",
      "2018-11-26 12:47:36,040 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.7892506718635559\n",
      "2018-11-26 12:47:36,044 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:47:37,246 INFO     Weight matrix 6/9 (128,256): Alpha: 3.218462664803351, Alpha Weighted: 0.2476569092420628, D: 0.17744769624787748\n",
      "2018-11-26 12:47:37,249 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.6199840307235718\n",
      "2018-11-26 12:47:37,252 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:47:38,466 INFO     Weight matrix 7/9 (128,256): Alpha: 3.2866170492523517, Alpha Weighted: -0.25703440622821655, D: 0.13841426595803163\n",
      "2018-11-26 12:47:38,471 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.5239893794059753\n",
      "2018-11-26 12:47:38,473 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:47:39,592 INFO     Weight matrix 8/9 (128,256): Alpha: 2.4878967518122272, Alpha Weighted: 0.25729356589235325, D: 0.18531854375394763\n",
      "2018-11-26 12:47:39,595 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.6102331280708313\n",
      "2018-11-26 12:47:39,598 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:47:40,699 INFO     Weight matrix 9/9 (128,256): Alpha: 3.5914272917865686, Alpha Weighted: 0.002905132465350387, D: 0.14778910907156606\n",
      "2018-11-26 12:47:40,701 INFO     Weight matrix 9/9 (128,256): Alpha 3.5914272917865686 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:47:40,704 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.5336019992828369\n",
      "2018-11-26 12:47:40,708 INFO Layer 17: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:47:40,711 INFO Layer 17: Skipping (Layer not supported)\n",
      "2018-11-26 12:47:40,713 INFO Layer 18: ReLU(inplace)\n",
      "2018-11-26 12:47:40,716 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 12:47:40,719 INFO Layer 19: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:47:40,745 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:47:40,748 INFO Layer 19: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:47:40,942 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:47:43,211 INFO     Weight matrix 1/9 (256,256): Alpha: 2.1753589310529673, Alpha Weighted: -0.28533902086891266, D: 0.15537247203315058\n",
      "2018-11-26 12:47:43,215 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.597944974899292\n",
      "2018-11-26 12:47:43,218 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:47:46,344 INFO     Weight matrix 2/9 (256,256): Alpha: 2.065528863671304, Alpha Weighted: -0.03335699371197215, D: 0.15570404036802488\n",
      "2018-11-26 12:47:46,351 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6460882425308228\n",
      "2018-11-26 12:47:46,353 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:47:49,131 INFO     Weight matrix 3/9 (256,256): Alpha: 2.8274106070070135, Alpha Weighted: -0.2770162725501652, D: 0.15462008052557974\n",
      "2018-11-26 12:47:49,135 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.6013931632041931\n",
      "2018-11-26 12:47:49,138 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:47:51,414 INFO     Weight matrix 4/9 (256,256): Alpha: 1.9950514846548504, Alpha Weighted: 0.008495457486345642, D: 0.1584042288384152\n",
      "2018-11-26 12:47:51,419 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.639593243598938\n",
      "2018-11-26 12:47:51,421 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:47:53,593 INFO     Weight matrix 5/9 (256,256): Alpha: 1.8127482278781142, Alpha Weighted: 0.805199224822532, D: 0.14076541701559198\n",
      "2018-11-26 12:47:53,598 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.7612729668617249\n",
      "2018-11-26 12:47:53,601 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:47:56,145 INFO     Weight matrix 6/9 (256,256): Alpha: 1.934771609630292, Alpha Weighted: 0.06834563064542279, D: 0.14552122026067582\n",
      "2018-11-26 12:47:56,151 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6452199816703796\n",
      "2018-11-26 12:47:56,154 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:47:58,815 INFO     Weight matrix 7/9 (256,256): Alpha: 2.4688747354246363, Alpha Weighted: -0.18469714011017446, D: 0.14323128958137887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:47:58,819 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.5974608659744263\n",
      "2018-11-26 12:47:58,823 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:01,505 INFO     Weight matrix 8/9 (256,256): Alpha: 1.9071004229931385, Alpha Weighted: 0.10631959341516575, D: 0.15084525274411753\n",
      "2018-11-26 12:48:01,509 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6414697170257568\n",
      "2018-11-26 12:48:01,512 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:03,782 INFO     Weight matrix 9/9 (256,256): Alpha: 2.387269182157083, Alpha Weighted: -0.3389131915749118, D: 0.15729890636929234\n",
      "2018-11-26 12:48:03,786 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6011737585067749\n",
      "2018-11-26 12:48:03,790 INFO Layer 20: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:48:03,794 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 12:48:03,798 INFO Layer 21: ReLU(inplace)\n",
      "2018-11-26 12:48:03,804 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 12:48:03,807 INFO Layer 22: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:48:03,826 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:48:03,828 INFO Layer 22: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:48:03,832 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:06,189 INFO     Weight matrix 1/9 (256,256): Alpha: 3.0976123956492603, Alpha Weighted: -0.35742173248721837, D: 0.1391014872248436\n",
      "2018-11-26 12:48:06,193 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.6036368012428284\n",
      "2018-11-26 12:48:06,196 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:08,567 INFO     Weight matrix 2/9 (256,256): Alpha: 2.3385546099427397, Alpha Weighted: 0.08320584685875375, D: 0.15100292602964943\n",
      "2018-11-26 12:48:08,572 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6581083536148071\n",
      "2018-11-26 12:48:08,575 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:11,300 INFO     Weight matrix 3/9 (256,256): Alpha: 3.2951314401876868, Alpha Weighted: -0.37013002627779545, D: 0.12911878836197221\n",
      "2018-11-26 12:48:11,305 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.603336751461029\n",
      "2018-11-26 12:48:11,309 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:14,030 INFO     Weight matrix 4/9 (256,256): Alpha: 2.493147123485361, Alpha Weighted: 0.04393431193055538, D: 0.14900053595505108\n",
      "2018-11-26 12:48:14,036 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.6571877002716064\n",
      "2018-11-26 12:48:14,039 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:16,744 INFO     Weight matrix 5/9 (256,256): Alpha: 1.7927104704077554, Alpha Weighted: 0.7036966376600489, D: 0.14470529398248583\n",
      "2018-11-26 12:48:16,748 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.7762420177459717\n",
      "2018-11-26 12:48:16,753 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:19,497 INFO     Weight matrix 6/9 (256,256): Alpha: 2.7426655406127027, Alpha Weighted: 0.12223075094118732, D: 0.13964383592878715\n",
      "2018-11-26 12:48:19,501 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6580830216407776\n",
      "2018-11-26 12:48:19,506 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:22,357 INFO     Weight matrix 7/9 (256,256): Alpha: 2.7449075154286704, Alpha Weighted: -0.3184837661840888, D: 0.13655223129751148\n",
      "2018-11-26 12:48:22,360 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.6029641628265381\n",
      "2018-11-26 12:48:22,364 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:24,995 INFO     Weight matrix 8/9 (256,256): Alpha: 2.020290298625512, Alpha Weighted: -0.002743663313588393, D: 0.15423687696021537\n",
      "2018-11-26 12:48:25,000 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6529862880706787\n",
      "2018-11-26 12:48:25,005 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:27,889 INFO     Weight matrix 9/9 (256,256): Alpha: 2.991734635747582, Alpha Weighted: -0.2976553075234264, D: 0.11579951729591931\n",
      "2018-11-26 12:48:27,895 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6026991009712219\n",
      "2018-11-26 12:48:27,900 INFO Layer 23: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:48:27,903 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 12:48:27,907 INFO Layer 24: ReLU(inplace)\n",
      "2018-11-26 12:48:27,910 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 12:48:27,914 INFO Layer 25: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:48:27,920 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:48:27,923 INFO Layer 25: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:48:27,925 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:30,699 INFO     Weight matrix 1/9 (256,256): Alpha: 3.781784780751175, Alpha Weighted: -0.2693006572481955, D: 0.11779380128729411\n",
      "2018-11-26 12:48:30,702 INFO     Weight matrix 1/9 (256,256): Alpha 3.781784780751175 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:48:30,707 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.6345688104629517\n",
      "2018-11-26 12:48:30,714 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:33,385 INFO     Weight matrix 2/9 (256,256): Alpha: 2.3977764744132117, Alpha Weighted: 0.09533273665711861, D: 0.15997465834460323\n",
      "2018-11-26 12:48:33,390 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6998108625411987\n",
      "2018-11-26 12:48:33,393 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:36,139 INFO     Weight matrix 3/9 (256,256): Alpha: 2.488175161959539, Alpha Weighted: -0.14061810886956308, D: 0.12806699912250763\n",
      "2018-11-26 12:48:36,144 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.6464446783065796\n",
      "2018-11-26 12:48:36,148 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:38,707 INFO     Weight matrix 4/9 (256,256): Alpha: 2.8447022448369625, Alpha Weighted: 0.2283188997888463, D: 0.12997276948698588\n",
      "2018-11-26 12:48:38,711 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.6928083896636963\n",
      "2018-11-26 12:48:38,713 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:41,140 INFO     Weight matrix 5/9 (256,256): Alpha: 2.2064579004292035, Alpha Weighted: 0.6326877061033156, D: 0.14800023092000997\n",
      "2018-11-26 12:48:41,145 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.7969152331352234\n",
      "2018-11-26 12:48:41,148 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:43,477 INFO     Weight matrix 6/9 (256,256): Alpha: 2.820409415514228, Alpha Weighted: 0.2205375593493299, D: 0.13970908328045895\n",
      "2018-11-26 12:48:43,481 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6999793648719788\n",
      "2018-11-26 12:48:43,484 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:46,124 INFO     Weight matrix 7/9 (256,256): Alpha: 2.648178199509183, Alpha Weighted: -0.12286412187713475, D: 0.1096947191544917\n",
      "2018-11-26 12:48:46,130 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.6383600831031799\n",
      "2018-11-26 12:48:46,133 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:48,954 INFO     Weight matrix 8/9 (256,256): Alpha: 1.9999577073860686, Alpha Weighted: 0.08865452091839444, D: 0.15522692403715888\n",
      "2018-11-26 12:48:48,960 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6982215642929077\n",
      "2018-11-26 12:48:48,963 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:48:51,586 INFO     Weight matrix 9/9 (256,256): Alpha: 2.329495120652312, Alpha Weighted: -0.10964510986791628, D: 0.12943892634354648\n",
      "2018-11-26 12:48:51,591 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6461830735206604\n",
      "2018-11-26 12:48:51,593 INFO Layer 26: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:48:51,596 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 12:48:51,604 INFO Layer 27: ReLU(inplace)\n",
      "2018-11-26 12:48:51,607 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 12:48:51,609 INFO Layer 28: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:48:51,612 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 12:48:51,614 INFO Layer 29: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:48:51,647 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:48:51,649 INFO Layer 29: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:48:51,652 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:48:54,515 INFO     Weight matrix 1/9 (256,512): Alpha: 2.302846600449656, Alpha Weighted: 0.09335473844941328, D: 0.1301431775807872\n",
      "2018-11-26 12:48:54,520 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.7397401332855225\n",
      "2018-11-26 12:48:54,523 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:48:57,299 INFO     Weight matrix 2/9 (256,512): Alpha: 2.2331443488271168, Alpha Weighted: 0.45282674720491206, D: 0.12796933226489166\n",
      "2018-11-26 12:48:57,305 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.7917366027832031\n",
      "2018-11-26 12:48:57,308 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:49:00,513 INFO     Weight matrix 3/9 (256,512): Alpha: 2.424992813012353, Alpha Weighted: 0.04407312497277425, D: 0.12910020964885094\n",
      "2018-11-26 12:49:00,518 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.7406051158905029\n",
      "2018-11-26 12:49:00,521 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:49:03,481 INFO     Weight matrix 4/9 (256,512): Alpha: 2.052070648639626, Alpha Weighted: 0.5544321516223304, D: 0.12930236037743476\n",
      "2018-11-26 12:49:03,485 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.7971042394638062\n",
      "2018-11-26 12:49:03,487 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:49:06,393 INFO     Weight matrix 5/9 (256,512): Alpha: 3.0827593238367146, Alpha Weighted: 0.948442050615638, D: 0.1708034828084316\n",
      "2018-11-26 12:49:06,398 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.8910054564476013\n",
      "2018-11-26 12:49:06,401 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:49:09,245 INFO     Weight matrix 6/9 (256,512): Alpha: 2.3252567568220943, Alpha Weighted: 0.6203781245190889, D: 0.11709074644704764\n",
      "2018-11-26 12:49:09,250 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.7986612319946289\n",
      "2018-11-26 12:49:09,253 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:49:11,836 INFO     Weight matrix 7/9 (256,512): Alpha: 2.631724847363615, Alpha Weighted: 0.04113394095973285, D: 0.12543403246722173\n",
      "2018-11-26 12:49:11,842 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.7354503273963928\n",
      "2018-11-26 12:49:11,845 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:49:14,447 INFO     Weight matrix 8/9 (256,512): Alpha: 4.775273661278758, Alpha Weighted: 0.8879701595118581, D: 0.13325739643939566\n",
      "2018-11-26 12:49:14,450 INFO     Weight matrix 8/9 (256,512): Alpha 4.775273661278758 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:14,459 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.7900216579437256\n",
      "2018-11-26 12:49:14,462 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 12:49:17,039 INFO     Weight matrix 9/9 (256,512): Alpha: 2.435159190252935, Alpha Weighted: 0.03212384181917728, D: 0.13049610791857297\n",
      "2018-11-26 12:49:17,043 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.7358574867248535\n",
      "2018-11-26 12:49:17,046 INFO Layer 30: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:17,049 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,051 INFO Layer 31: ReLU(inplace)\n",
      "2018-11-26 12:49:17,054 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,057 INFO Layer 32: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:17,109 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:17,112 INFO Layer 32: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:17,115 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,119 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,122 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,126 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,129 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,133 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,136 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,139 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,143 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,147 INFO Layer 33: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:17,152 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,155 INFO Layer 34: ReLU(inplace)\n",
      "2018-11-26 12:49:17,159 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,162 INFO Layer 35: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:17,201 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:17,205 INFO Layer 35: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:17,210 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,214 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,217 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,221 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,223 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,226 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,228 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,230 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,233 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,236 INFO Layer 36: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:17,239 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,242 INFO Layer 37: ReLU(inplace)\n",
      "2018-11-26 12:49:17,245 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,248 INFO Layer 38: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:17,272 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:17,274 INFO Layer 38: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:17,277 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,280 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,283 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,286 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,289 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,293 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,296 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,299 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,313 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,318 INFO Layer 39: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:17,323 INFO Layer 39: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,328 INFO Layer 40: ReLU(inplace)\n",
      "2018-11-26 12:49:17,332 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,335 INFO Layer 41: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:49:17,339 INFO Layer 41: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,342 INFO Layer 42: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:17,361 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:17,366 INFO Layer 42: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:17,372 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,375 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,378 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,381 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,384 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,387 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,391 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,399 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,406 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,408 INFO Layer 43: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:17,411 INFO Layer 43: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,413 INFO Layer 44: ReLU(inplace)\n",
      "2018-11-26 12:49:17,417 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,420 INFO Layer 45: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:17,440 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:17,443 INFO Layer 45: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:17,446 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,449 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,452 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,456 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,459 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,462 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,466 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,469 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,472 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,475 INFO Layer 46: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:17,477 INFO Layer 46: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,480 INFO Layer 47: ReLU(inplace)\n",
      "2018-11-26 12:49:17,483 INFO Layer 47: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,487 INFO Layer 48: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:17,507 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:17,513 INFO Layer 48: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:17,516 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,522 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,524 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,528 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,531 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,533 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,536 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,539 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,542 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,545 INFO Layer 49: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:17,548 INFO Layer 49: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,550 INFO Layer 50: ReLU(inplace)\n",
      "2018-11-26 12:49:17,552 INFO Layer 50: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,555 INFO Layer 51: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:17,572 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:17,577 INFO Layer 51: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:17,581 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,583 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,586 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,589 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,592 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,595 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,599 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,603 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,608 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:17,611 INFO Layer 52: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:17,614 INFO Layer 52: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,617 INFO Layer 53: ReLU(inplace)\n",
      "2018-11-26 12:49:17,619 INFO Layer 53: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,622 INFO Layer 54: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:49:17,624 INFO Layer 54: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,627 INFO Layer 55: Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 12:49:17,629 INFO Layer 55: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:17,632 INFO Layer 56: Linear(in_features=25088, out_features=4096, bias=True)\n",
      "2018-11-26 12:49:19,215 INFO Layer 56: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:19,219 INFO     Weight matrix 1/1 (4096,25088): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:19,223 INFO Layer 57: ReLU(inplace)\n",
      "2018-11-26 12:49:19,351 INFO Layer 57: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:19,359 INFO Layer 58: Dropout(p=0.5)\n",
      "2018-11-26 12:49:19,361 INFO Layer 58: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:19,364 INFO Layer 59: Linear(in_features=4096, out_features=4096, bias=True)\n",
      "2018-11-26 12:49:19,726 INFO Layer 59: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:19,732 INFO     Weight matrix 1/1 (4096,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:19,736 INFO Layer 60: ReLU(inplace)\n",
      "2018-11-26 12:49:19,763 INFO Layer 60: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:19,771 INFO Layer 61: Dropout(p=0.5)\n",
      "2018-11-26 12:49:19,775 INFO Layer 61: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:19,777 INFO Layer 62: Linear(in_features=4096, out_features=1000, bias=True)\n",
      "2018-11-26 12:49:19,872 INFO Layer 62: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:19,875 INFO     Weight matrix 1/1 (1000,4096): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:19,879 INFO ### Printing results ###\n",
      "2018-11-26 12:49:19,882 DEBUG Layer 5: Lognorm compound: 0.2935509764485889\n",
      "2018-11-26 12:49:19,885 DEBUG Layer 9: Lognorm compound: 0.4870385163360172\n",
      "2018-11-26 12:49:19,888 DEBUG Layer 12: Lognorm compound: 0.513779083887736\n",
      "2018-11-26 12:49:19,892 DEBUG Layer 16: Lognorm compound: 0.5970640116267734\n",
      "2018-11-26 12:49:19,896 DEBUG Layer 19: Lognorm compound: 0.6368463238080343\n",
      "2018-11-26 12:49:19,900 DEBUG Layer 22: Lognorm compound: 0.646138244205051\n",
      "2018-11-26 12:49:19,903 DEBUG Layer 25: Lognorm compound: 0.6836991177664863\n",
      "2018-11-26 12:49:19,907 DEBUG Layer 29: Lognorm compound: 0.7800202502144707\n",
      "2018-11-26 12:49:19,911 INFO LogNorm: min: 0.21745115518569946, max: 0.8910054564476013, avg: 0.5797669887542725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:19,915 INFO LogNorm compound: min: 0.2935509764485889, max: 0.7800202502144707, avg: 0.5797670655366447\n",
      "2018-11-26 12:49:19,918 DEBUG Layer 5: Alpha compound: 2.416313084602516\n",
      "2018-11-26 12:49:19,923 DEBUG Layer 9: Alpha compound: 1.66471757925084\n",
      "2018-11-26 12:49:19,925 DEBUG Layer 12: Alpha compound: 2.608574718154921\n",
      "2018-11-26 12:49:19,928 DEBUG Layer 16: Alpha compound: 3.1504758197960125\n",
      "2018-11-26 12:49:19,932 DEBUG Layer 19: Alpha compound: 2.174901562718822\n",
      "2018-11-26 12:49:19,935 DEBUG Layer 22: Alpha compound: 2.6129726700096967\n",
      "2018-11-26 12:49:19,939 DEBUG Layer 25: Alpha compound: 2.6129930006057647\n",
      "2018-11-26 12:49:19,943 DEBUG Layer 29: Alpha compound: 2.695914243386986\n",
      "2018-11-26 12:49:19,948 INFO Alpha: min: 1.5105249374631677, max: 4.879371548361345, avg: 2.4921078348156946\n",
      "2018-11-26 12:49:19,952 INFO Alpha compound: min: 1.66471757925084, max: 3.1504758197960125, avg: 2.4921078348156946\n",
      "2018-11-26 12:49:19,960 DEBUG Layer 5: Alpha Weighted compound: 0.22033101644991737\n",
      "2018-11-26 12:49:19,962 DEBUG Layer 9: Alpha Weighted compound: 0.6182375971211452\n",
      "2018-11-26 12:49:19,965 DEBUG Layer 12: Alpha Weighted compound: 0.10531188162764259\n",
      "2018-11-26 12:49:19,971 DEBUG Layer 16: Alpha Weighted compound: 0.14312027033758193\n",
      "2018-11-26 12:49:19,975 DEBUG Layer 19: Alpha Weighted compound: -0.014551412494074462\n",
      "2018-11-26 12:49:19,979 DEBUG Layer 22: Alpha Weighted compound: -0.04370743871061911\n",
      "2018-11-26 12:49:19,983 DEBUG Layer 25: Alpha Weighted compound: 0.06923371388379948\n",
      "2018-11-26 12:49:19,986 DEBUG Layer 29: Alpha Weighted compound: 0.4083038755194361\n",
      "2018-11-26 12:49:19,989 INFO Alpha Weighted: min: -0.37484469026724104, max: 1.057168260983391, avg: 0.18828493796685364\n",
      "2018-11-26 12:49:19,992 INFO Alpha Weighted compound: min: -0.04370743871061911, max: 0.6182375971211452, avg: 0.1882849379668536\n",
      "/Users/charlesmartin14/anaconda3/envs/py3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "/Users/charlesmartin14/anaconda3/envs/py3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "2018-11-26 12:49:20,512 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 12:49:20,514 INFO Analyzing model\n",
      "2018-11-26 12:49:20,518 INFO Layer 0: SqueezeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (3): Fire(\n",
      "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (4): Fire(\n",
      "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (5): Fire(\n",
      "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (7): Fire(\n",
      "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (8): Fire(\n",
      "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (9): Fire(\n",
      "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (10): Fire(\n",
      "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (12): Fire(\n",
      "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(inplace)\n",
      "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:49:20,521 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:20,525 INFO Layer 1: Sequential(\n",
      "  (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (3): Fire(\n",
      "    (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      "  (4): Fire(\n",
      "    (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      "  (5): Fire(\n",
      "    (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      "  (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (7): Fire(\n",
      "    (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      "  (8): Fire(\n",
      "    (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      "  (9): Fire(\n",
      "    (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      "  (10): Fire(\n",
      "    (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      "  (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (12): Fire(\n",
      "    (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:20,529 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:20,531 INFO Layer 2: Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
      "2018-11-26 12:49:20,534 INFO Pytorch tensor shape detected: 96x3 (NxM), 7x7 (i,j)\n",
      "2018-11-26 12:49:20,538 INFO Layer 2: Analyzing 49 weight matrices...\n",
      "2018-11-26 12:49:20,541 INFO     Weight matrix 1/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,545 INFO     Weight matrix 2/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,552 INFO     Weight matrix 3/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,558 INFO     Weight matrix 4/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,565 INFO     Weight matrix 5/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,569 INFO     Weight matrix 6/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,571 INFO     Weight matrix 7/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,573 INFO     Weight matrix 8/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,575 INFO     Weight matrix 9/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,578 INFO     Weight matrix 10/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,581 INFO     Weight matrix 11/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,583 INFO     Weight matrix 12/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,586 INFO     Weight matrix 13/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,589 INFO     Weight matrix 14/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,593 INFO     Weight matrix 15/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,596 INFO     Weight matrix 16/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,599 INFO     Weight matrix 17/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,601 INFO     Weight matrix 18/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,605 INFO     Weight matrix 19/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,609 INFO     Weight matrix 20/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,614 INFO     Weight matrix 21/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,622 INFO     Weight matrix 22/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,626 INFO     Weight matrix 23/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,629 INFO     Weight matrix 24/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,632 INFO     Weight matrix 25/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,634 INFO     Weight matrix 26/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,637 INFO     Weight matrix 27/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,640 INFO     Weight matrix 28/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,644 INFO     Weight matrix 29/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,648 INFO     Weight matrix 30/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,654 INFO     Weight matrix 31/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,666 INFO     Weight matrix 32/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,675 INFO     Weight matrix 33/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,678 INFO     Weight matrix 34/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,681 INFO     Weight matrix 35/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,684 INFO     Weight matrix 36/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,686 INFO     Weight matrix 37/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,688 INFO     Weight matrix 38/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,692 INFO     Weight matrix 39/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,707 INFO     Weight matrix 40/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,711 INFO     Weight matrix 41/49 (3,96): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squeezenet1_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:20,713 INFO     Weight matrix 42/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,719 INFO     Weight matrix 43/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,724 INFO     Weight matrix 44/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,727 INFO     Weight matrix 45/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,730 INFO     Weight matrix 46/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,732 INFO     Weight matrix 47/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,735 INFO     Weight matrix 48/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,738 INFO     Weight matrix 49/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,740 INFO Layer 3: ReLU(inplace)\n",
      "2018-11-26 12:49:20,756 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:20,760 INFO Layer 4: MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "2018-11-26 12:49:20,762 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:20,771 INFO Layer 5: Fire(\n",
      "  (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:20,773 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:20,777 INFO Layer 6: Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:20,779 INFO Pytorch tensor shape detected: 16x96 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:20,781 INFO Layer 6: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:20,785 INFO     Weight matrix 1/1 (16,96): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,791 INFO Layer 7: ReLU(inplace)\n",
      "2018-11-26 12:49:20,794 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:20,798 INFO Layer 8: Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:20,807 INFO Pytorch tensor shape detected: 64x16 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:20,810 INFO Layer 8: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:20,814 INFO     Weight matrix 1/1 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,816 INFO Layer 9: ReLU(inplace)\n",
      "2018-11-26 12:49:20,823 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:20,825 INFO Layer 10: Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:20,835 INFO Pytorch tensor shape detected: 64x16 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:20,837 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:20,840 INFO     Weight matrix 1/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,849 INFO     Weight matrix 2/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,853 INFO     Weight matrix 3/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,862 INFO     Weight matrix 4/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,868 INFO     Weight matrix 5/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,871 INFO     Weight matrix 6/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,876 INFO     Weight matrix 7/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,881 INFO     Weight matrix 8/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,886 INFO     Weight matrix 9/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,892 INFO Layer 11: ReLU(inplace)\n",
      "2018-11-26 12:49:20,897 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:20,901 INFO Layer 12: Fire(\n",
      "  (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:20,904 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:20,907 INFO Layer 13: Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:20,912 INFO Pytorch tensor shape detected: 16x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:20,914 INFO Layer 13: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:20,920 INFO     Weight matrix 1/1 (16,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,922 INFO Layer 14: ReLU(inplace)\n",
      "2018-11-26 12:49:20,925 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:20,927 INFO Layer 15: Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:20,931 INFO Pytorch tensor shape detected: 64x16 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:20,937 INFO Layer 15: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:20,940 INFO     Weight matrix 1/1 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,943 INFO Layer 16: ReLU(inplace)\n",
      "2018-11-26 12:49:20,946 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:20,949 INFO Layer 17: Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:20,953 INFO Pytorch tensor shape detected: 64x16 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:20,957 INFO Layer 17: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:20,961 INFO     Weight matrix 1/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,967 INFO     Weight matrix 2/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,970 INFO     Weight matrix 3/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,976 INFO     Weight matrix 4/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,979 INFO     Weight matrix 5/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,981 INFO     Weight matrix 6/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,984 INFO     Weight matrix 7/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,986 INFO     Weight matrix 8/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,989 INFO     Weight matrix 9/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:20,993 INFO Layer 18: ReLU(inplace)\n",
      "2018-11-26 12:49:20,996 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:20,998 INFO Layer 19: Fire(\n",
      "  (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:21,002 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,007 INFO Layer 20: Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:21,012 INFO Pytorch tensor shape detected: 32x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:21,014 INFO Layer 20: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:21,018 INFO     Weight matrix 1/1 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,021 INFO Layer 21: ReLU(inplace)\n",
      "2018-11-26 12:49:21,024 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,027 INFO Layer 22: Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:21,029 INFO Pytorch tensor shape detected: 128x32 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:21,032 INFO Layer 22: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:21,034 INFO     Weight matrix 1/1 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,037 INFO Layer 23: ReLU(inplace)\n",
      "2018-11-26 12:49:21,039 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,042 INFO Layer 24: Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:21,048 INFO Pytorch tensor shape detected: 128x32 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:21,052 INFO Layer 24: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:21,055 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,057 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,060 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,062 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,068 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,073 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,086 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:21,089 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,092 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,103 INFO Layer 25: ReLU(inplace)\n",
      "2018-11-26 12:49:21,109 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,111 INFO Layer 26: MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "2018-11-26 12:49:21,116 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,125 INFO Layer 27: Fire(\n",
      "  (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:21,128 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,132 INFO Layer 28: Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:21,142 INFO Pytorch tensor shape detected: 32x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:21,146 INFO Layer 28: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:21,149 INFO     Weight matrix 1/1 (32,256): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,153 INFO Layer 29: ReLU(inplace)\n",
      "2018-11-26 12:49:21,156 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,159 INFO Layer 30: Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:21,179 INFO Pytorch tensor shape detected: 128x32 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:21,183 INFO Layer 30: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:21,186 INFO     Weight matrix 1/1 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,189 INFO Layer 31: ReLU(inplace)\n",
      "2018-11-26 12:49:21,192 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,195 INFO Layer 32: Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:21,202 INFO Pytorch tensor shape detected: 128x32 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:21,205 INFO Layer 32: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:21,209 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,213 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,216 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,219 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,222 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,225 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,227 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,230 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,233 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,235 INFO Layer 33: ReLU(inplace)\n",
      "2018-11-26 12:49:21,238 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,241 INFO Layer 34: Fire(\n",
      "  (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:21,244 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,249 INFO Layer 35: Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:21,265 INFO Pytorch tensor shape detected: 48x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:21,269 INFO Layer 35: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:21,272 INFO     Weight matrix 1/1 (48,256): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,282 INFO Layer 36: ReLU(inplace)\n",
      "2018-11-26 12:49:21,286 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,292 INFO Layer 37: Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:21,295 INFO Pytorch tensor shape detected: 192x48 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:21,303 INFO Layer 37: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:21,307 INFO     Weight matrix 1/1 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,312 INFO Layer 38: ReLU(inplace)\n",
      "2018-11-26 12:49:21,315 INFO Layer 38: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,318 INFO Layer 39: Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:21,323 INFO Pytorch tensor shape detected: 192x48 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:21,325 INFO Layer 39: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:21,329 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,333 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,337 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,341 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,348 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,350 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,362 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,367 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,372 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,375 INFO Layer 40: ReLU(inplace)\n",
      "2018-11-26 12:49:21,381 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,383 INFO Layer 41: Fire(\n",
      "  (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:21,385 INFO Layer 41: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,388 INFO Layer 42: Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:21,390 INFO Pytorch tensor shape detected: 48x384 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:21,397 INFO Layer 42: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:21,399 INFO     Weight matrix 1/1 (48,384): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,403 INFO Layer 43: ReLU(inplace)\n",
      "2018-11-26 12:49:21,405 INFO Layer 43: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,408 INFO Layer 44: Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:21,415 INFO Pytorch tensor shape detected: 192x48 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:21,417 INFO Layer 44: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:21,420 INFO     Weight matrix 1/1 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,422 INFO Layer 45: ReLU(inplace)\n",
      "2018-11-26 12:49:21,424 INFO Layer 45: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,427 INFO Layer 46: Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:21,434 INFO Pytorch tensor shape detected: 192x48 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:21,436 INFO Layer 46: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:21,439 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,448 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,459 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,464 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,468 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,478 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,484 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,486 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,488 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:21,491 INFO Layer 47: ReLU(inplace)\n",
      "2018-11-26 12:49:21,494 INFO Layer 47: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,498 INFO Layer 48: Fire(\n",
      "  (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:21,503 INFO Layer 48: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:21,514 INFO Layer 49: Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:21,518 INFO Pytorch tensor shape detected: 64x384 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:21,521 INFO Layer 49: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:21,524 INFO     Weight matrix 1/1 (64,384): Analyzing ...\n",
      "2018-11-26 12:49:22,075 INFO     Weight matrix 1/1 (64,384): Alpha: 4.3512116111058265, Alpha Weighted: 3.993374255907116, D: 0.1151639558070589\n",
      "2018-11-26 12:49:22,078 INFO     Weight matrix 1/1 (64,384): Alpha 4.3512116111058265 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:22,081 INFO     Weight matrix 1/1 (64,384): Lognorm: 1.0789355039596558\n",
      "2018-11-26 12:49:22,083 INFO Layer 50: ReLU(inplace)\n",
      "2018-11-26 12:49:22,086 INFO Layer 50: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:22,088 INFO Layer 51: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:22,091 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:22,094 INFO Layer 51: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:22,097 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:22,612 INFO     Weight matrix 1/1 (64,256): Alpha: 6.953507636336353, Alpha Weighted: 5.032899116354051, D: 0.1666666666666673\n",
      "2018-11-26 12:49:22,614 INFO     Weight matrix 1/1 (64,256): Alpha 6.953507636336353 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:22,617 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.9558996558189392\n",
      "2018-11-26 12:49:22,619 INFO Layer 52: ReLU(inplace)\n",
      "2018-11-26 12:49:22,621 INFO Layer 52: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:22,624 INFO Layer 53: Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:22,629 INFO Pytorch tensor shape detected: 256x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:22,631 INFO Layer 53: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:22,634 INFO     Weight matrix 1/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:23,116 INFO     Weight matrix 1/9 (64,256): Alpha: 2.3668934250693745, Alpha Weighted: 0.758395046380797, D: 0.17453938747657943\n",
      "2018-11-26 12:49:23,120 INFO     Weight matrix 1/9 (64,256): Lognorm: 0.7357532978057861\n",
      "2018-11-26 12:49:23,123 INFO     Weight matrix 2/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:23,620 INFO     Weight matrix 2/9 (64,256): Alpha: 3.399202199528893, Alpha Weighted: 0.9292836609820675, D: 0.15246747004506733\n",
      "2018-11-26 12:49:23,625 INFO     Weight matrix 2/9 (64,256): Lognorm: 0.7087920308113098\n",
      "2018-11-26 12:49:23,628 INFO     Weight matrix 3/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:24,227 INFO     Weight matrix 3/9 (64,256): Alpha: 2.549320810026239, Alpha Weighted: 0.7196806226415657, D: 0.17754761622605492\n",
      "2018-11-26 12:49:24,230 INFO     Weight matrix 3/9 (64,256): Lognorm: 0.7281966805458069\n",
      "2018-11-26 12:49:24,235 INFO     Weight matrix 4/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:24,719 INFO     Weight matrix 4/9 (64,256): Alpha: 3.5571767560669585, Alpha Weighted: 0.7100415143494241, D: 0.13689098167722857\n",
      "2018-11-26 12:49:24,722 INFO     Weight matrix 4/9 (64,256): Alpha 3.5571767560669585 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:24,727 INFO     Weight matrix 4/9 (64,256): Lognorm: 0.6512458920478821\n",
      "2018-11-26 12:49:24,730 INFO     Weight matrix 5/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:25,242 INFO     Weight matrix 5/9 (64,256): Alpha: 3.128562833343767, Alpha Weighted: 1.1808589453947635, D: 0.10041094898356451\n",
      "2018-11-26 12:49:25,246 INFO     Weight matrix 5/9 (64,256): Lognorm: 0.6585813164710999\n",
      "2018-11-26 12:49:25,249 INFO     Weight matrix 6/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:25,886 INFO     Weight matrix 6/9 (64,256): Alpha: 3.7620430102081164, Alpha Weighted: 0.7800608542409747, D: 0.10948375819049772\n",
      "2018-11-26 12:49:25,888 INFO     Weight matrix 6/9 (64,256): Alpha 3.7620430102081164 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:25,893 INFO     Weight matrix 6/9 (64,256): Lognorm: 0.6497798562049866\n",
      "2018-11-26 12:49:25,897 INFO     Weight matrix 7/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:26,435 INFO     Weight matrix 7/9 (64,256): Alpha: 3.101578480609098, Alpha Weighted: 0.7788281824978003, D: 0.1462243836480423\n",
      "2018-11-26 12:49:26,441 INFO     Weight matrix 7/9 (64,256): Lognorm: 0.7194444537162781\n",
      "2018-11-26 12:49:26,445 INFO     Weight matrix 8/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:27,069 INFO     Weight matrix 8/9 (64,256): Alpha: 3.9079767428301464, Alpha Weighted: 0.6643314787779666, D: 0.18018177481148379\n",
      "2018-11-26 12:49:27,072 INFO     Weight matrix 8/9 (64,256): Alpha 3.9079767428301464 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:27,076 INFO     Weight matrix 8/9 (64,256): Lognorm: 0.6897745132446289\n",
      "2018-11-26 12:49:27,079 INFO     Weight matrix 9/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:27,716 INFO     Weight matrix 9/9 (64,256): Alpha: 3.0856590668494728, Alpha Weighted: 0.7841164390765847, D: 0.15201579946575872\n",
      "2018-11-26 12:49:27,719 INFO     Weight matrix 9/9 (64,256): Lognorm: 0.7178037762641907\n",
      "2018-11-26 12:49:27,721 INFO Layer 54: ReLU(inplace)\n",
      "2018-11-26 12:49:27,726 INFO Layer 54: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:27,730 INFO Layer 55: MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "2018-11-26 12:49:27,732 INFO Layer 55: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:27,736 INFO Layer 56: Fire(\n",
      "  (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:27,739 INFO Layer 56: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:27,741 INFO Layer 57: Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:27,745 INFO Pytorch tensor shape detected: 64x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:27,747 INFO Layer 57: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:27,749 INFO     Weight matrix 1/1 (64,512): Analyzing ...\n",
      "2018-11-26 12:49:28,330 INFO     Weight matrix 1/1 (64,512): Alpha: 4.267894367762898, Alpha Weighted: 4.3275962950177105, D: 0.08642325206714335\n",
      "2018-11-26 12:49:28,333 INFO     Weight matrix 1/1 (64,512): Alpha 4.267894367762898 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:28,336 INFO     Weight matrix 1/1 (64,512): Lognorm: 1.1490002870559692\n",
      "2018-11-26 12:49:28,340 INFO Layer 58: ReLU(inplace)\n",
      "2018-11-26 12:49:28,343 INFO Layer 58: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:28,347 INFO Layer 59: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:28,358 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:28,362 INFO Layer 59: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:28,365 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:28,986 INFO     Weight matrix 1/1 (64,256): Alpha: 4.696318787508934, Alpha Weighted: 5.947592128396817, D: 0.10000000000000031\n",
      "2018-11-26 12:49:28,989 INFO     Weight matrix 1/1 (64,256): Alpha 4.696318787508934 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:28,992 INFO     Weight matrix 1/1 (64,256): Lognorm: 1.1289067268371582\n",
      "2018-11-26 12:49:28,999 INFO Layer 60: ReLU(inplace)\n",
      "2018-11-26 12:49:29,002 INFO Layer 60: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:29,006 INFO Layer 61: Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:29,009 INFO Pytorch tensor shape detected: 256x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:29,012 INFO Layer 61: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:29,014 INFO     Weight matrix 1/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:29,657 INFO     Weight matrix 1/9 (64,256): Alpha: 3.2892594862770643, Alpha Weighted: 1.6389448301771783, D: 0.10364012463536443\n",
      "2018-11-26 12:49:29,661 INFO     Weight matrix 1/9 (64,256): Lognorm: 0.741067111492157\n",
      "2018-11-26 12:49:29,664 INFO     Weight matrix 2/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:30,266 INFO     Weight matrix 2/9 (64,256): Alpha: 3.59070416979266, Alpha Weighted: 1.5780128364203103, D: 0.12408204212618745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:30,269 INFO     Weight matrix 2/9 (64,256): Alpha 3.59070416979266 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:30,273 INFO     Weight matrix 2/9 (64,256): Lognorm: 0.7514724135398865\n",
      "2018-11-26 12:49:30,278 INFO     Weight matrix 3/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:30,815 INFO     Weight matrix 3/9 (64,256): Alpha: 3.46441917736413, Alpha Weighted: 1.7596311552076476, D: 0.11518736347393155\n",
      "2018-11-26 12:49:30,820 INFO     Weight matrix 3/9 (64,256): Lognorm: 0.7421873807907104\n",
      "2018-11-26 12:49:30,822 INFO     Weight matrix 4/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:31,386 INFO     Weight matrix 4/9 (64,256): Alpha: 4.136324593973027, Alpha Weighted: 1.7975379244213057, D: 0.09090909090909116\n",
      "2018-11-26 12:49:31,389 INFO     Weight matrix 4/9 (64,256): Alpha 4.136324593973027 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:31,395 INFO     Weight matrix 4/9 (64,256): Lognorm: 0.6863933801651001\n",
      "2018-11-26 12:49:31,398 INFO     Weight matrix 5/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:31,907 INFO     Weight matrix 5/9 (64,256): Alpha: 4.232248080565396, Alpha Weighted: 1.9268060914571647, D: 0.0964723538836495\n",
      "2018-11-26 12:49:31,910 INFO     Weight matrix 5/9 (64,256): Alpha 4.232248080565396 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:31,914 INFO     Weight matrix 5/9 (64,256): Lognorm: 0.7414332032203674\n",
      "2018-11-26 12:49:31,916 INFO     Weight matrix 6/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:32,475 INFO     Weight matrix 6/9 (64,256): Alpha: 3.9429896052294753, Alpha Weighted: 1.5546079283309822, D: 0.08412205915152016\n",
      "2018-11-26 12:49:32,478 INFO     Weight matrix 6/9 (64,256): Alpha 3.9429896052294753 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:32,481 INFO     Weight matrix 6/9 (64,256): Lognorm: 0.6882777810096741\n",
      "2018-11-26 12:49:32,486 INFO     Weight matrix 7/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:32,965 INFO     Weight matrix 7/9 (64,256): Alpha: 2.827544732228142, Alpha Weighted: 1.2273969785081884, D: 0.11914075857763456\n",
      "2018-11-26 12:49:32,969 INFO     Weight matrix 7/9 (64,256): Lognorm: 0.7378664612770081\n",
      "2018-11-26 12:49:32,971 INFO     Weight matrix 8/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:33,468 INFO     Weight matrix 8/9 (64,256): Alpha: 2.419647011466699, Alpha Weighted: 0.9349219297246038, D: 0.13358730251771594\n",
      "2018-11-26 12:49:33,472 INFO     Weight matrix 8/9 (64,256): Lognorm: 0.7514867782592773\n",
      "2018-11-26 12:49:33,474 INFO     Weight matrix 9/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:33,973 INFO     Weight matrix 9/9 (64,256): Alpha: 3.186753795493832, Alpha Weighted: 1.4130305519013566, D: 0.11939854156259341\n",
      "2018-11-26 12:49:33,977 INFO     Weight matrix 9/9 (64,256): Lognorm: 0.7384089827537537\n",
      "2018-11-26 12:49:33,979 INFO Layer 62: ReLU(inplace)\n",
      "2018-11-26 12:49:33,982 INFO Layer 62: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:33,985 INFO Layer 63: Sequential(\n",
      "  (0): Dropout(p=0.5)\n",
      "  (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (2): ReLU(inplace)\n",
      "  (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
      ")\n",
      "2018-11-26 12:49:33,987 INFO Layer 63: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:33,990 INFO Layer 64: Dropout(p=0.5)\n",
      "2018-11-26 12:49:33,992 INFO Layer 64: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:33,996 INFO Layer 65: Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:34,008 INFO Pytorch tensor shape detected: 1000x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:34,011 INFO Layer 65: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:34,014 INFO     Weight matrix 1/1 (512,1000): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:34,016 INFO Layer 66: ReLU(inplace)\n",
      "2018-11-26 12:49:34,019 INFO Layer 66: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,022 INFO Layer 67: AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
      "2018-11-26 12:49:34,025 INFO Layer 67: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,028 INFO ### Printing results ###\n",
      "2018-11-26 12:49:34,033 DEBUG Layer 49: Lognorm: 1.0789355039596558\n",
      "2018-11-26 12:49:34,036 DEBUG Layer 51: Lognorm: 0.9558996558189392\n",
      "2018-11-26 12:49:34,039 DEBUG Layer 53: Lognorm compound: 0.6954857574568855\n",
      "2018-11-26 12:49:34,042 DEBUG Layer 57: Lognorm: 1.1490002870559692\n",
      "2018-11-26 12:49:34,048 DEBUG Layer 59: Lognorm: 1.1289067268371582\n",
      "2018-11-26 12:49:34,051 DEBUG Layer 61: Lognorm compound: 0.7309548325008817\n",
      "2018-11-26 12:49:34,055 INFO LogNorm: min: 0.6497798562049866, max: 1.1490002870559692, avg: 0.7795776724815369\n",
      "2018-11-26 12:49:34,059 INFO LogNorm compound: min: 0.6954857574568855, max: 1.1490002870559692, avg: 0.956530460604915\n",
      "2018-11-26 12:49:34,063 DEBUG Layer 49: Alpha: 4.3512116111058265\n",
      "2018-11-26 12:49:34,067 DEBUG Layer 51: Alpha: 6.953507636336353\n",
      "2018-11-26 12:49:34,070 DEBUG Layer 53: Alpha compound: 3.2064903693924522\n",
      "2018-11-26 12:49:34,073 DEBUG Layer 57: Alpha: 4.267894367762898\n",
      "2018-11-26 12:49:34,077 DEBUG Layer 59: Alpha: 4.696318787508934\n",
      "2018-11-26 12:49:34,081 DEBUG Layer 61: Alpha compound: 3.454432294710047\n",
      "2018-11-26 12:49:34,084 INFO Alpha: min: 2.3668934250693745, max: 6.953507636336353, avg: 3.646238017256204\n",
      "2018-11-26 12:49:34,088 INFO Alpha compound: min: 3.2064903693924522, max: 6.953507636336353, avg: 4.488309177802751\n",
      "2018-11-26 12:49:34,091 DEBUG Layer 49: Alpha Weigthed: 3.993374255907116\n",
      "2018-11-26 12:49:34,094 DEBUG Layer 51: Alpha Weigthed: 5.032899116354051\n",
      "2018-11-26 12:49:34,098 DEBUG Layer 53: Alpha Weighted compound: 0.8117329715935493\n",
      "2018-11-26 12:49:34,101 DEBUG Layer 57: Alpha Weigthed: 4.3275962950177105\n",
      "2018-11-26 12:49:34,104 DEBUG Layer 59: Alpha Weigthed: 5.947592128396817\n",
      "2018-11-26 12:49:34,107 DEBUG Layer 61: Alpha Weighted compound: 1.5367655806831932\n",
      "2018-11-26 12:49:34,109 INFO Alpha Weighted: min: 0.6643314787779666, max: 5.947592128396817, avg: 1.8380885802802895\n",
      "2018-11-26 12:49:34,111 INFO Alpha Weighted compound: min: 0.8117329715935493, max: 5.947592128396817, avg: 3.60832672465874\n",
      "/Users/charlesmartin14/anaconda3/envs/py3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/squeezenet.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "/Users/charlesmartin14/anaconda3/envs/py3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/squeezenet.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "2018-11-26 12:49:34,375 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 12:49:34,378 INFO Analyzing model\n",
      "2018-11-26 12:49:34,383 INFO Layer 0: SqueezeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (3): Fire(\n",
      "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (4): Fire(\n",
      "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (6): Fire(\n",
      "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (7): Fire(\n",
      "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (9): Fire(\n",
      "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (10): Fire(\n",
      "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (11): Fire(\n",
      "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (12): Fire(\n",
      "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(inplace)\n",
      "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:34,386 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,391 INFO Layer 1: Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (3): Fire(\n",
      "    (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      "  (4): Fire(\n",
      "    (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      "  (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (6): Fire(\n",
      "    (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      "  (7): Fire(\n",
      "    (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      "  (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (9): Fire(\n",
      "    (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      "  (10): Fire(\n",
      "    (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      "  (11): Fire(\n",
      "    (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      "  (12): Fire(\n",
      "    (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (squeeze_activation): ReLU(inplace)\n",
      "    (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (expand1x1_activation): ReLU(inplace)\n",
      "    (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (expand3x3_activation): ReLU(inplace)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:49:34,394 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,397 INFO Layer 2: Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "2018-11-26 12:49:34,400 INFO Pytorch tensor shape detected: 64x3 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:34,404 INFO Layer 2: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:34,407 INFO     Weight matrix 1/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,410 INFO     Weight matrix 2/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,414 INFO     Weight matrix 3/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,416 INFO     Weight matrix 4/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,419 INFO     Weight matrix 5/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,423 INFO     Weight matrix 6/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,425 INFO     Weight matrix 7/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,428 INFO     Weight matrix 8/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,430 INFO     Weight matrix 9/9 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,433 INFO Layer 3: ReLU(inplace)\n",
      "2018-11-26 12:49:34,436 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,438 INFO Layer 4: MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "2018-11-26 12:49:34,441 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,444 INFO Layer 5: Fire(\n",
      "  (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:34,446 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,449 INFO Layer 6: Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:34,453 INFO Pytorch tensor shape detected: 16x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:34,455 INFO Layer 6: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:34,458 INFO     Weight matrix 1/1 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,461 INFO Layer 7: ReLU(inplace)\n",
      "2018-11-26 12:49:34,463 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,466 INFO Layer 8: Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:34,471 INFO Pytorch tensor shape detected: 64x16 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:34,475 INFO Layer 8: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:34,478 INFO     Weight matrix 1/1 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,481 INFO Layer 9: ReLU(inplace)\n",
      "2018-11-26 12:49:34,483 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,486 INFO Layer 10: Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:34,489 INFO Pytorch tensor shape detected: 64x16 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:34,492 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:34,497 INFO     Weight matrix 1/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,500 INFO     Weight matrix 2/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,504 INFO     Weight matrix 3/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,507 INFO     Weight matrix 4/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,511 INFO     Weight matrix 5/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,513 INFO     Weight matrix 6/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,516 INFO     Weight matrix 7/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,520 INFO     Weight matrix 8/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,522 INFO     Weight matrix 9/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,525 INFO Layer 11: ReLU(inplace)\n",
      "2018-11-26 12:49:34,528 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,531 INFO Layer 12: Fire(\n",
      "  (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:34,534 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,536 INFO Layer 13: Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:34,539 INFO Pytorch tensor shape detected: 16x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:34,545 INFO Layer 13: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:34,547 INFO     Weight matrix 1/1 (16,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,549 INFO Layer 14: ReLU(inplace)\n",
      "2018-11-26 12:49:34,553 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,557 INFO Layer 15: Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:34,561 INFO Pytorch tensor shape detected: 64x16 (NxM), 1x1 (i,j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:34,564 INFO Layer 15: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:34,569 INFO     Weight matrix 1/1 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,573 INFO Layer 16: ReLU(inplace)\n",
      "2018-11-26 12:49:34,575 INFO Layer 16: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squeezenet1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:34,579 INFO Layer 17: Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:34,582 INFO Pytorch tensor shape detected: 64x16 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:34,584 INFO Layer 17: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:34,587 INFO     Weight matrix 1/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,590 INFO     Weight matrix 2/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,594 INFO     Weight matrix 3/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,598 INFO     Weight matrix 4/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,601 INFO     Weight matrix 5/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,604 INFO     Weight matrix 6/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,607 INFO     Weight matrix 7/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,610 INFO     Weight matrix 8/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,613 INFO     Weight matrix 9/9 (16,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,616 INFO Layer 18: ReLU(inplace)\n",
      "2018-11-26 12:49:34,618 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,621 INFO Layer 19: MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "2018-11-26 12:49:34,625 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,628 INFO Layer 20: Fire(\n",
      "  (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:34,630 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,632 INFO Layer 21: Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:34,636 INFO Pytorch tensor shape detected: 32x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:34,639 INFO Layer 21: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:34,643 INFO     Weight matrix 1/1 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,645 INFO Layer 22: ReLU(inplace)\n",
      "2018-11-26 12:49:34,648 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,651 INFO Layer 23: Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:34,654 INFO Pytorch tensor shape detected: 128x32 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:34,658 INFO Layer 23: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:34,660 INFO     Weight matrix 1/1 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,664 INFO Layer 24: ReLU(inplace)\n",
      "2018-11-26 12:49:34,667 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,671 INFO Layer 25: Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:34,674 INFO Pytorch tensor shape detected: 128x32 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:34,677 INFO Layer 25: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:34,680 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,684 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,687 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,690 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,694 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,697 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,700 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,704 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,709 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,712 INFO Layer 26: ReLU(inplace)\n",
      "2018-11-26 12:49:34,716 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,720 INFO Layer 27: Fire(\n",
      "  (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:34,723 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,726 INFO Layer 28: Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:34,730 INFO Pytorch tensor shape detected: 32x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:34,733 INFO Layer 28: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:34,736 INFO     Weight matrix 1/1 (32,256): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,739 INFO Layer 29: ReLU(inplace)\n",
      "2018-11-26 12:49:34,743 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,747 INFO Layer 30: Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:34,752 INFO Pytorch tensor shape detected: 128x32 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:34,756 INFO Layer 30: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:34,759 INFO     Weight matrix 1/1 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,762 INFO Layer 31: ReLU(inplace)\n",
      "2018-11-26 12:49:34,767 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,770 INFO Layer 32: Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:34,775 INFO Pytorch tensor shape detected: 128x32 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:34,779 INFO Layer 32: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:34,782 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,786 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,790 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,793 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,797 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,801 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,805 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,809 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,812 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,815 INFO Layer 33: ReLU(inplace)\n",
      "2018-11-26 12:49:34,820 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,823 INFO Layer 34: MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "2018-11-26 12:49:34,826 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,829 INFO Layer 35: Fire(\n",
      "  (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:34,831 INFO Layer 35: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,835 INFO Layer 36: Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:34,838 INFO Pytorch tensor shape detected: 48x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:34,841 INFO Layer 36: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:34,844 INFO     Weight matrix 1/1 (48,256): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,846 INFO Layer 37: ReLU(inplace)\n",
      "2018-11-26 12:49:34,849 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,851 INFO Layer 38: Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:34,856 INFO Pytorch tensor shape detected: 192x48 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:34,858 INFO Layer 38: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:34,864 INFO     Weight matrix 1/1 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,868 INFO Layer 39: ReLU(inplace)\n",
      "2018-11-26 12:49:34,871 INFO Layer 39: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,874 INFO Layer 40: Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:34,877 INFO Pytorch tensor shape detected: 192x48 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:34,879 INFO Layer 40: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:34,882 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:34,885 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,888 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,890 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,893 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,896 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,900 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,903 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,905 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,908 INFO Layer 41: ReLU(inplace)\n",
      "2018-11-26 12:49:34,912 INFO Layer 41: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,915 INFO Layer 42: Fire(\n",
      "  (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:34,917 INFO Layer 42: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,920 INFO Layer 43: Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:34,924 INFO Pytorch tensor shape detected: 48x384 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:34,926 INFO Layer 43: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:34,930 INFO     Weight matrix 1/1 (48,384): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,932 INFO Layer 44: ReLU(inplace)\n",
      "2018-11-26 12:49:34,934 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,937 INFO Layer 45: Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:34,940 INFO Pytorch tensor shape detected: 192x48 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:34,943 INFO Layer 45: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:34,947 INFO     Weight matrix 1/1 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,951 INFO Layer 46: ReLU(inplace)\n",
      "2018-11-26 12:49:34,954 INFO Layer 46: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:34,958 INFO Layer 47: Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:34,963 INFO Pytorch tensor shape detected: 192x48 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:34,968 INFO Layer 47: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:34,972 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,975 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,981 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,985 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,988 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,992 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,995 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:34,998 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:35,003 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:49:35,006 INFO Layer 48: ReLU(inplace)\n",
      "2018-11-26 12:49:35,010 INFO Layer 48: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:35,013 INFO Layer 49: Fire(\n",
      "  (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:35,019 INFO Layer 49: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:35,021 INFO Layer 50: Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:35,026 INFO Pytorch tensor shape detected: 64x384 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:35,029 INFO Layer 50: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:35,032 INFO     Weight matrix 1/1 (64,384): Analyzing ...\n",
      "2018-11-26 12:49:35,957 INFO     Weight matrix 1/1 (64,384): Alpha: 3.920453869127374, Alpha Weighted: 3.557017262036142, D: 0.10816786352941571\n",
      "2018-11-26 12:49:35,960 INFO     Weight matrix 1/1 (64,384): Alpha 3.920453869127374 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:35,967 INFO     Weight matrix 1/1 (64,384): Lognorm: 1.0911318063735962\n",
      "2018-11-26 12:49:35,970 INFO Layer 51: ReLU(inplace)\n",
      "2018-11-26 12:49:35,972 INFO Layer 51: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:35,976 INFO Layer 52: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:35,980 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:35,983 INFO Layer 52: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:35,986 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:36,799 INFO     Weight matrix 1/1 (64,256): Alpha: 6.7272500865650935, Alpha Weighted: 4.115787439259423, D: 0.20734689320063182\n",
      "2018-11-26 12:49:36,802 INFO     Weight matrix 1/1 (64,256): Alpha 6.7272500865650935 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:36,806 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.9464679956436157\n",
      "2018-11-26 12:49:36,812 INFO Layer 53: ReLU(inplace)\n",
      "2018-11-26 12:49:36,815 INFO Layer 53: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:36,818 INFO Layer 54: Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:36,823 INFO Pytorch tensor shape detected: 256x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:36,826 INFO Layer 54: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:36,829 INFO     Weight matrix 1/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:37,669 INFO     Weight matrix 1/9 (64,256): Alpha: 2.3476081698416, Alpha Weighted: 0.5012730629548399, D: 0.14962739051877716\n",
      "2018-11-26 12:49:37,673 INFO     Weight matrix 1/9 (64,256): Lognorm: 0.66090327501297\n",
      "2018-11-26 12:49:37,677 INFO     Weight matrix 2/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:38,643 INFO     Weight matrix 2/9 (64,256): Alpha: 3.2248356289338354, Alpha Weighted: 0.6595051384821131, D: 0.1539106730051102\n",
      "2018-11-26 12:49:38,650 INFO     Weight matrix 2/9 (64,256): Lognorm: 0.7027187943458557\n",
      "2018-11-26 12:49:38,655 INFO     Weight matrix 3/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:39,305 INFO     Weight matrix 3/9 (64,256): Alpha: 2.800707576314693, Alpha Weighted: 0.537373526517969, D: 0.1342151830047903\n",
      "2018-11-26 12:49:39,309 INFO     Weight matrix 3/9 (64,256): Lognorm: 0.6629696488380432\n",
      "2018-11-26 12:49:39,311 INFO     Weight matrix 4/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:39,796 INFO     Weight matrix 4/9 (64,256): Alpha: 2.80938243875732, Alpha Weighted: 0.4131801189901214, D: 0.15075509379449065\n",
      "2018-11-26 12:49:39,799 INFO     Weight matrix 4/9 (64,256): Lognorm: 0.6497271656990051\n",
      "2018-11-26 12:49:39,802 INFO     Weight matrix 5/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:40,339 INFO     Weight matrix 5/9 (64,256): Alpha: 2.465252854594415, Alpha Weighted: 0.4896672727772608, D: 0.1744942113583943\n",
      "2018-11-26 12:49:40,343 INFO     Weight matrix 5/9 (64,256): Lognorm: 0.7095744609832764\n",
      "2018-11-26 12:49:40,345 INFO     Weight matrix 6/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:40,885 INFO     Weight matrix 6/9 (64,256): Alpha: 3.851078833145951, Alpha Weighted: 0.48634313751427977, D: 0.12863712800633137\n",
      "2018-11-26 12:49:40,889 INFO     Weight matrix 6/9 (64,256): Alpha 3.851078833145951 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:40,892 INFO     Weight matrix 6/9 (64,256): Lognorm: 0.6454957127571106\n",
      "2018-11-26 12:49:40,897 INFO     Weight matrix 7/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:41,440 INFO     Weight matrix 7/9 (64,256): Alpha: 2.858483441979468, Alpha Weighted: 0.43514035916492677, D: 0.15018193451134398\n",
      "2018-11-26 12:49:41,444 INFO     Weight matrix 7/9 (64,256): Lognorm: 0.6552037000656128\n",
      "2018-11-26 12:49:41,447 INFO     Weight matrix 8/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:41,910 INFO     Weight matrix 8/9 (64,256): Alpha: 2.5891015319026405, Alpha Weighted: 0.46712703933708816, D: 0.16067335288421997\n",
      "2018-11-26 12:49:41,913 INFO     Weight matrix 8/9 (64,256): Lognorm: 0.6933382749557495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:41,916 INFO     Weight matrix 9/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:42,470 INFO     Weight matrix 9/9 (64,256): Alpha: 2.251870562240039, Alpha Weighted: 0.3742856112339304, D: 0.15168520132374286\n",
      "2018-11-26 12:49:42,473 INFO     Weight matrix 9/9 (64,256): Lognorm: 0.6546844244003296\n",
      "2018-11-26 12:49:42,476 INFO Layer 55: ReLU(inplace)\n",
      "2018-11-26 12:49:42,479 INFO Layer 55: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:42,483 INFO Layer 56: Fire(\n",
      "  (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (squeeze_activation): ReLU(inplace)\n",
      "  (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (expand1x1_activation): ReLU(inplace)\n",
      "  (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (expand3x3_activation): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 12:49:42,485 INFO Layer 56: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:42,488 INFO Layer 57: Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:42,493 INFO Pytorch tensor shape detected: 64x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:42,496 INFO Layer 57: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:42,502 INFO     Weight matrix 1/1 (64,512): Analyzing ...\n",
      "2018-11-26 12:49:43,054 INFO     Weight matrix 1/1 (64,512): Alpha: 4.962622937083005, Alpha Weighted: 5.11099212357397, D: 0.06059960638543904\n",
      "2018-11-26 12:49:43,057 INFO     Weight matrix 1/1 (64,512): Alpha 4.962622937083005 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:43,063 INFO     Weight matrix 1/1 (64,512): Lognorm: 1.1211203336715698\n",
      "2018-11-26 12:49:43,066 INFO Layer 58: ReLU(inplace)\n",
      "2018-11-26 12:49:43,071 INFO Layer 58: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:43,074 INFO Layer 59: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:43,083 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:43,086 INFO Layer 59: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:43,089 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:43,768 INFO     Weight matrix 1/1 (64,256): Alpha: 5.072642551657799, Alpha Weighted: 6.007007833066747, D: 0.1250045022127267\n",
      "2018-11-26 12:49:43,772 INFO     Weight matrix 1/1 (64,256): Alpha 5.072642551657799 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:43,775 INFO     Weight matrix 1/1 (64,256): Lognorm: 1.1059237718582153\n",
      "2018-11-26 12:49:43,778 INFO Layer 60: ReLU(inplace)\n",
      "2018-11-26 12:49:43,782 INFO Layer 60: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:43,786 INFO Layer 61: Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "2018-11-26 12:49:43,791 INFO Pytorch tensor shape detected: 256x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:43,800 INFO Layer 61: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:43,807 INFO     Weight matrix 1/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:44,328 INFO     Weight matrix 1/9 (64,256): Alpha: 3.0302374974463024, Alpha Weighted: 0.7564753157513943, D: 0.10681263359368554\n",
      "2018-11-26 12:49:44,331 INFO     Weight matrix 1/9 (64,256): Lognorm: 0.6650629043579102\n",
      "2018-11-26 12:49:44,334 INFO     Weight matrix 2/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:44,869 INFO     Weight matrix 2/9 (64,256): Alpha: 4.074891975561651, Alpha Weighted: 1.3659368700260026, D: 0.09815614714067128\n",
      "2018-11-26 12:49:44,872 INFO     Weight matrix 2/9 (64,256): Alpha 4.074891975561651 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:44,876 INFO     Weight matrix 2/9 (64,256): Lognorm: 0.7095051407814026\n",
      "2018-11-26 12:49:44,879 INFO     Weight matrix 3/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:45,419 INFO     Weight matrix 3/9 (64,256): Alpha: 3.2782678412794373, Alpha Weighted: 0.7707544795784578, D: 0.09696217657025907\n",
      "2018-11-26 12:49:45,423 INFO     Weight matrix 3/9 (64,256): Lognorm: 0.6631506085395813\n",
      "2018-11-26 12:49:45,427 INFO     Weight matrix 4/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:45,986 INFO     Weight matrix 4/9 (64,256): Alpha: 4.436369897375291, Alpha Weighted: 1.1544096592851374, D: 0.09491340139602165\n",
      "2018-11-26 12:49:45,989 INFO     Weight matrix 4/9 (64,256): Alpha 4.436369897375291 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:45,997 INFO     Weight matrix 4/9 (64,256): Lognorm: 0.6487345099449158\n",
      "2018-11-26 12:49:46,003 INFO     Weight matrix 5/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:46,564 INFO     Weight matrix 5/9 (64,256): Alpha: 4.204806941786584, Alpha Weighted: 1.7083874061675601, D: 0.09090909090909116\n",
      "2018-11-26 12:49:46,568 INFO     Weight matrix 5/9 (64,256): Alpha 4.204806941786584 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:46,572 INFO     Weight matrix 5/9 (64,256): Lognorm: 0.7154712080955505\n",
      "2018-11-26 12:49:46,576 INFO     Weight matrix 6/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:47,190 INFO     Weight matrix 6/9 (64,256): Alpha: 4.3533511903908835, Alpha Weighted: 1.0815107503394166, D: 0.06250000000000022\n",
      "2018-11-26 12:49:47,193 INFO     Weight matrix 6/9 (64,256): Alpha 4.3533511903908835 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:47,196 INFO     Weight matrix 6/9 (64,256): Lognorm: 0.6425753235816956\n",
      "2018-11-26 12:49:47,200 INFO     Weight matrix 7/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:47,679 INFO     Weight matrix 7/9 (64,256): Alpha: 2.6216701415653674, Alpha Weighted: 0.5383460864772568, D: 0.1240101947292741\n",
      "2018-11-26 12:49:47,683 INFO     Weight matrix 7/9 (64,256): Lognorm: 0.6522693634033203\n",
      "2018-11-26 12:49:47,685 INFO     Weight matrix 8/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:48,182 INFO     Weight matrix 8/9 (64,256): Alpha: 2.5634572520114722, Alpha Weighted: 0.6317816289098356, D: 0.13989631737367808\n",
      "2018-11-26 12:49:48,186 INFO     Weight matrix 8/9 (64,256): Lognorm: 0.6915013790130615\n",
      "2018-11-26 12:49:48,189 INFO     Weight matrix 9/9 (64,256): Analyzing ...\n",
      "2018-11-26 12:49:48,746 INFO     Weight matrix 9/9 (64,256): Alpha: 2.7026986355025615, Alpha Weighted: 0.5954927185366804, D: 0.10063765922118251\n",
      "2018-11-26 12:49:48,750 INFO     Weight matrix 9/9 (64,256): Lognorm: 0.6506377458572388\n",
      "2018-11-26 12:49:48,753 INFO Layer 62: ReLU(inplace)\n",
      "2018-11-26 12:49:48,756 INFO Layer 62: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:48,759 INFO Layer 63: Sequential(\n",
      "  (0): Dropout(p=0.5)\n",
      "  (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (2): ReLU(inplace)\n",
      "  (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
      ")\n",
      "2018-11-26 12:49:48,762 INFO Layer 63: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:48,765 INFO Layer 64: Dropout(p=0.5)\n",
      "2018-11-26 12:49:48,769 INFO Layer 64: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:48,773 INFO Layer 65: Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
      "2018-11-26 12:49:48,782 INFO Pytorch tensor shape detected: 1000x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:48,785 INFO Layer 65: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:48,787 INFO     Weight matrix 1/1 (512,1000): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:49:48,790 INFO Layer 66: ReLU(inplace)\n",
      "2018-11-26 12:49:48,792 INFO Layer 66: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:48,795 INFO Layer 67: AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
      "2018-11-26 12:49:48,798 INFO Layer 67: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:48,800 INFO ### Printing results ###\n",
      "2018-11-26 12:49:48,803 DEBUG Layer 50: Lognorm: 1.0911318063735962\n",
      "2018-11-26 12:49:48,805 DEBUG Layer 52: Lognorm: 0.9464679956436157\n",
      "2018-11-26 12:49:48,815 DEBUG Layer 54: Lognorm compound: 0.6705128285619948\n",
      "2018-11-26 12:49:48,819 DEBUG Layer 57: Lognorm: 1.1211203336715698\n",
      "2018-11-26 12:49:48,823 DEBUG Layer 59: Lognorm: 1.1059237718582153\n",
      "2018-11-26 12:49:48,826 DEBUG Layer 61: Lognorm compound: 0.6709897981749641\n",
      "2018-11-26 12:49:48,829 INFO LogNorm: min: 0.6425753235816956, max: 1.1211203336715698, avg: 0.7426440715789795\n",
      "2018-11-26 12:49:48,832 INFO LogNorm compound: min: 0.6705128285619948, max: 1.1211203336715698, avg: 0.9343577557139926\n",
      "2018-11-26 12:49:48,835 DEBUG Layer 50: Alpha: 3.920453869127374\n",
      "2018-11-26 12:49:48,838 DEBUG Layer 52: Alpha: 6.7272500865650935\n",
      "2018-11-26 12:49:48,840 DEBUG Layer 54: Alpha compound: 2.79981344863444\n",
      "2018-11-26 12:49:48,845 DEBUG Layer 57: Alpha: 4.962622937083005\n",
      "2018-11-26 12:49:48,848 DEBUG Layer 59: Alpha: 5.072642551657799\n",
      "2018-11-26 12:49:48,851 DEBUG Layer 61: Alpha compound: 3.4739723747688385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:48,855 INFO Alpha: min: 2.251870562240039, max: 6.7272500865650935, avg: 3.5066837206846717\n",
      "2018-11-26 12:49:48,860 INFO Alpha compound: min: 2.79981344863444, max: 6.7272500865650935, avg: 4.492792544639426\n",
      "2018-11-26 12:49:48,864 DEBUG Layer 50: Alpha Weigthed: 3.557017262036142\n",
      "2018-11-26 12:49:48,868 DEBUG Layer 52: Alpha Weigthed: 4.115787439259423\n",
      "2018-11-26 12:49:48,872 DEBUG Layer 54: Alpha Weighted compound: 0.4848772518858365\n",
      "2018-11-26 12:49:48,875 DEBUG Layer 57: Alpha Weigthed: 5.11099212357397\n",
      "2018-11-26 12:49:48,878 DEBUG Layer 59: Alpha Weigthed: 6.007007833066747\n",
      "2018-11-26 12:49:48,881 DEBUG Layer 61: Alpha Weighted compound: 0.9558994350079715\n",
      "2018-11-26 12:49:48,884 INFO Alpha Weighted: min: 0.3742856112339304, max: 6.007007833066747, avg: 1.4435361290900248\n",
      "2018-11-26 12:49:48,886 INFO Alpha Weighted compound: min: 0.4848772518858365, max: 6.007007833066747, avg: 3.371930224138348\n",
      "/Users/charlesmartin14/anaconda3/envs/py3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "2018-11-26 12:49:50,327 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 12:49:50,331 INFO Analyzing model\n",
      "2018-11-26 12:49:50,353 INFO Layer 0: DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:50,361 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:50,380 INFO Layer 1: Sequential(\n",
      "  (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu0): ReLU(inplace)\n",
      "  (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (denseblock1): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition1): _Transition(\n",
      "    (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock2): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition2): _Transition(\n",
      "    (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock3): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer13): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer14): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer15): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer16): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer17): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer18): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer19): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer20): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer21): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer22): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer23): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer24): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition3): _Transition(\n",
      "    (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock4): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer13): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer14): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer15): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer16): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:50,384 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:50,388 INFO Layer 2: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "2018-11-26 12:49:50,396 INFO Pytorch tensor shape detected: 64x3 (NxM), 7x7 (i,j)\n",
      "2018-11-26 12:49:50,398 INFO Layer 2: Analyzing 49 weight matrices...\n",
      "2018-11-26 12:49:50,406 INFO     Weight matrix 1/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,412 INFO     Weight matrix 2/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,418 INFO     Weight matrix 3/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,421 INFO     Weight matrix 4/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,427 INFO     Weight matrix 5/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,432 INFO     Weight matrix 6/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,440 INFO     Weight matrix 7/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,448 INFO     Weight matrix 8/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,451 INFO     Weight matrix 9/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,456 INFO     Weight matrix 10/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,465 INFO     Weight matrix 11/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,471 INFO     Weight matrix 12/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,475 INFO     Weight matrix 13/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,479 INFO     Weight matrix 14/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,484 INFO     Weight matrix 15/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,488 INFO     Weight matrix 16/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,496 INFO     Weight matrix 17/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,507 INFO     Weight matrix 18/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,510 INFO     Weight matrix 19/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,518 INFO     Weight matrix 20/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,524 INFO     Weight matrix 21/49 (3,64): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:50,529 INFO     Weight matrix 22/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,536 INFO     Weight matrix 23/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,545 INFO     Weight matrix 24/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,550 INFO     Weight matrix 25/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,555 INFO     Weight matrix 26/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,562 INFO     Weight matrix 27/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,570 INFO     Weight matrix 28/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,575 INFO     Weight matrix 29/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,581 INFO     Weight matrix 30/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,589 INFO     Weight matrix 31/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,598 INFO     Weight matrix 32/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,605 INFO     Weight matrix 33/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,608 INFO     Weight matrix 34/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,620 INFO     Weight matrix 35/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,624 INFO     Weight matrix 36/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,629 INFO     Weight matrix 37/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,635 INFO     Weight matrix 38/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,640 INFO     Weight matrix 39/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,647 INFO     Weight matrix 40/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,661 INFO     Weight matrix 41/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,664 INFO     Weight matrix 42/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,671 INFO     Weight matrix 43/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,673 INFO     Weight matrix 44/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,675 INFO     Weight matrix 45/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,679 INFO     Weight matrix 46/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,682 INFO     Weight matrix 47/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,684 INFO     Weight matrix 48/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,687 INFO     Weight matrix 49/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:49:50,690 INFO Layer 3: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:50,696 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:50,709 INFO Layer 4: ReLU(inplace)\n",
      "2018-11-26 12:49:50,711 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:50,721 INFO Layer 5: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:49:50,724 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:50,728 INFO Layer 6: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:49:50,735 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:50,738 INFO Layer 7: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:49:50,741 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:50,745 INFO Layer 8: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:50,748 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:50,751 INFO Layer 9: ReLU(inplace)\n",
      "2018-11-26 12:49:50,756 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:50,759 INFO Layer 10: Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:49:50,762 INFO Pytorch tensor shape detected: 128x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:50,764 INFO Layer 10: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:50,767 INFO     Weight matrix 1/1 (64,128): Analyzing ...\n",
      "2018-11-26 12:49:51,390 INFO     Weight matrix 1/1 (64,128): Alpha: 1.3668460840132695, Alpha Weighted: 0.4280255137910998, D: 0.24409723403796124\n",
      "2018-11-26 12:49:51,393 INFO     Weight matrix 1/1 (64,128): Alpha 1.3668460840132695 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:51,399 INFO     Weight matrix 1/1 (64,128): Lognorm: 0.709526777267456\n",
      "2018-11-26 12:49:51,402 INFO Layer 11: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:51,408 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:51,412 INFO Layer 12: ReLU(inplace)\n",
      "2018-11-26 12:49:51,416 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:51,419 INFO Layer 13: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:49:51,425 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:51,429 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:51,432 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:51,435 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:51,437 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:51,441 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:51,443 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:51,448 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:51,455 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:51,459 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:51,464 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:51,468 INFO Layer 14: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:49:51,471 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:51,475 INFO Layer 15: BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:51,478 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:51,481 INFO Layer 16: ReLU(inplace)\n",
      "2018-11-26 12:49:51,483 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:51,486 INFO Layer 17: Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:49:51,490 INFO Pytorch tensor shape detected: 128x96 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:51,491 INFO Layer 17: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:51,495 INFO     Weight matrix 1/1 (96,128): Analyzing ...\n",
      "2018-11-26 12:49:52,540 INFO     Weight matrix 1/1 (96,128): Alpha: 1.4743413466988615, Alpha Weighted: 0.5642373262187819, D: 0.2076524033920324\n",
      "2018-11-26 12:49:52,544 INFO     Weight matrix 1/1 (96,128): Alpha 1.4743413466988615 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:52,547 INFO     Weight matrix 1/1 (96,128): Lognorm: 0.7301000952720642\n",
      "2018-11-26 12:49:52,550 INFO Layer 18: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:52,553 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:52,556 INFO Layer 19: ReLU(inplace)\n",
      "2018-11-26 12:49:52,560 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:52,564 INFO Layer 20: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:49:52,568 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:52,574 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:52,577 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:52,581 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:52,583 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:52,587 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:52,591 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:52,594 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:52,598 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:52,602 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:52,606 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:52,609 INFO Layer 21: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:49:52,613 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:52,616 INFO Layer 22: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:52,620 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:52,623 INFO Layer 23: ReLU(inplace)\n",
      "2018-11-26 12:49:52,626 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:52,630 INFO Layer 24: Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:49:52,633 INFO Pytorch tensor shape detected: 128x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:52,636 INFO Layer 24: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:52,639 INFO     Weight matrix 1/1 (128,128): Analyzing ...\n",
      "2018-11-26 12:49:53,751 INFO     Weight matrix 1/1 (128,128): Alpha: 2.652969717491138, Alpha Weighted: 0.6473188070893642, D: 0.2169893400636953\n",
      "2018-11-26 12:49:53,754 INFO     Weight matrix 1/1 (128,128): Lognorm: 0.7291272878646851\n",
      "2018-11-26 12:49:53,757 INFO Layer 25: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:53,759 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:53,762 INFO Layer 26: ReLU(inplace)\n",
      "2018-11-26 12:49:53,765 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:53,768 INFO Layer 27: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:49:53,773 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:53,775 INFO Layer 27: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:53,777 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:53,781 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:53,783 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:53,786 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:53,788 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:53,791 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:53,794 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:53,797 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:53,800 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:53,803 INFO Layer 28: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:49:53,806 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:53,809 INFO Layer 29: BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:53,815 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:53,819 INFO Layer 30: ReLU(inplace)\n",
      "2018-11-26 12:49:53,822 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:53,826 INFO Layer 31: Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:49:53,829 INFO Pytorch tensor shape detected: 128x160 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:53,832 INFO Layer 31: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:53,835 INFO     Weight matrix 1/1 (128,160): Analyzing ...\n",
      "2018-11-26 12:49:55,182 INFO     Weight matrix 1/1 (128,160): Alpha: 3.681430475331508, Alpha Weighted: 0.7929452181953638, D: 0.17178379880235506\n",
      "2018-11-26 12:49:55,185 INFO     Weight matrix 1/1 (128,160): Alpha 3.681430475331508 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:55,188 INFO     Weight matrix 1/1 (128,160): Lognorm: 0.7076682448387146\n",
      "2018-11-26 12:49:55,191 INFO Layer 32: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:55,195 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:55,200 INFO Layer 33: ReLU(inplace)\n",
      "2018-11-26 12:49:55,211 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:55,214 INFO Layer 34: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:49:55,219 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:55,223 INFO Layer 34: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:55,228 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:55,232 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:55,236 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:55,242 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:55,244 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:55,248 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:55,253 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:55,257 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:55,261 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:55,264 INFO Layer 35: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:49:55,268 INFO Layer 35: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:55,271 INFO Layer 36: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:55,275 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:55,278 INFO Layer 37: ReLU(inplace)\n",
      "2018-11-26 12:49:55,281 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:55,283 INFO Layer 38: Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:49:55,287 INFO Pytorch tensor shape detected: 128x192 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:55,290 INFO Layer 38: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:55,293 INFO     Weight matrix 1/1 (128,192): Analyzing ...\n",
      "2018-11-26 12:49:56,788 INFO     Weight matrix 1/1 (128,192): Alpha: 4.541338909120677, Alpha Weighted: 0.5665688905107779, D: 0.15980343013440435\n",
      "2018-11-26 12:49:56,791 INFO     Weight matrix 1/1 (128,192): Alpha 4.541338909120677 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:56,797 INFO     Weight matrix 1/1 (128,192): Lognorm: 0.6634426712989807\n",
      "2018-11-26 12:49:56,799 INFO Layer 39: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:56,802 INFO Layer 39: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:56,805 INFO Layer 40: ReLU(inplace)\n",
      "2018-11-26 12:49:56,808 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:56,815 INFO Layer 41: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:49:56,822 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:56,826 INFO Layer 41: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:56,829 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:56,832 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:56,835 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:56,840 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:56,844 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:56,847 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:56,853 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:56,857 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:56,861 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:56,866 INFO Layer 42: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:49:56,870 INFO Layer 42: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:56,873 INFO Layer 43: BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:56,876 INFO Layer 43: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:56,880 INFO Layer 44: ReLU(inplace)\n",
      "2018-11-26 12:49:56,887 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:56,891 INFO Layer 45: Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:49:56,895 INFO Pytorch tensor shape detected: 128x224 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:56,899 INFO Layer 45: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:56,902 INFO     Weight matrix 1/1 (128,224): Analyzing ...\n",
      "2018-11-26 12:49:58,229 INFO     Weight matrix 1/1 (128,224): Alpha: 6.899438229738612, Alpha Weighted: 2.2829355810852054, D: 0.15605159656182632\n",
      "2018-11-26 12:49:58,231 INFO     Weight matrix 1/1 (128,224): Alpha 6.899438229738612 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:58,234 INFO     Weight matrix 1/1 (128,224): Lognorm: 0.766674816608429\n",
      "2018-11-26 12:49:58,238 INFO Layer 46: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:58,241 INFO Layer 46: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:58,244 INFO Layer 47: ReLU(inplace)\n",
      "2018-11-26 12:49:58,248 INFO Layer 47: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:58,250 INFO Layer 48: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:49:58,254 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:49:58,256 INFO Layer 48: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:49:58,259 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:58,262 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:58,265 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:58,269 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:58,272 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:58,275 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:58,277 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:58,283 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:58,286 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:49:58,289 INFO Layer 49: _Transition(\n",
      "  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "2018-11-26 12:49:58,291 INFO Layer 49: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:58,294 INFO Layer 50: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:58,297 INFO Layer 50: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:58,301 INFO Layer 51: ReLU(inplace)\n",
      "2018-11-26 12:49:58,305 INFO Layer 51: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:58,308 INFO Layer 52: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:49:58,311 INFO Pytorch tensor shape detected: 128x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:58,314 INFO Layer 52: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:58,319 INFO     Weight matrix 1/1 (128,256): Analyzing ...\n",
      "2018-11-26 12:49:59,604 INFO     Weight matrix 1/1 (128,256): Alpha: 4.728791683628474, Alpha Weighted: 3.6784390190162175, D: 0.10991520091695506\n",
      "2018-11-26 12:49:59,607 INFO     Weight matrix 1/1 (128,256): Alpha 4.728791683628474 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:49:59,614 INFO     Weight matrix 1/1 (128,256): Lognorm: 1.033071756362915\n",
      "2018-11-26 12:49:59,619 INFO Layer 53: AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "2018-11-26 12:49:59,621 INFO Layer 53: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:59,627 INFO Layer 54: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer7): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer8): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer9): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer10): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer11): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer12): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:49:59,631 INFO Layer 54: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:59,635 INFO Layer 55: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:49:59,638 INFO Layer 55: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:59,641 INFO Layer 56: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:49:59,643 INFO Layer 56: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:59,646 INFO Layer 57: ReLU(inplace)\n",
      "2018-11-26 12:49:59,649 INFO Layer 57: Skipping (Layer not supported)\n",
      "2018-11-26 12:49:59,652 INFO Layer 58: Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:49:59,655 INFO Pytorch tensor shape detected: 128x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:49:59,658 INFO Layer 58: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:49:59,661 INFO     Weight matrix 1/1 (128,128): Analyzing ...\n",
      "2018-11-26 12:50:00,792 INFO     Weight matrix 1/1 (128,128): Alpha: 1.4750179780911636, Alpha Weighted: 0.02715868976033257, D: 0.2114952836097097\n",
      "2018-11-26 12:50:00,795 INFO     Weight matrix 1/1 (128,128): Alpha 1.4750179780911636 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:00,798 INFO     Weight matrix 1/1 (128,128): Lognorm: 0.4764324724674225\n",
      "2018-11-26 12:50:00,802 INFO Layer 59: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:00,805 INFO Layer 59: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:00,809 INFO Layer 60: ReLU(inplace)\n",
      "2018-11-26 12:50:00,813 INFO Layer 60: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:00,820 INFO Layer 61: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:00,824 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:00,827 INFO Layer 61: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:00,830 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:00,833 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:00,835 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:00,838 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:00,841 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:00,844 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:00,847 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:00,850 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:00,853 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:00,856 INFO Layer 62: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:00,859 INFO Layer 62: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:00,863 INFO Layer 63: BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:00,866 INFO Layer 63: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:00,869 INFO Layer 64: ReLU(inplace)\n",
      "2018-11-26 12:50:00,873 INFO Layer 64: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:00,876 INFO Layer 65: Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:00,880 INFO Pytorch tensor shape detected: 128x160 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:00,884 INFO Layer 65: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:00,886 INFO     Weight matrix 1/1 (128,160): Analyzing ...\n",
      "2018-11-26 12:50:02,169 INFO     Weight matrix 1/1 (128,160): Alpha: 1.478385860010596, Alpha Weighted: 0.043118546865504113, D: 0.1885858818367563\n",
      "2018-11-26 12:50:02,171 INFO     Weight matrix 1/1 (128,160): Alpha 1.478385860010596 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:02,175 INFO     Weight matrix 1/1 (128,160): Lognorm: 0.598200798034668\n",
      "2018-11-26 12:50:02,178 INFO Layer 66: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:02,180 INFO Layer 66: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:02,183 INFO Layer 67: ReLU(inplace)\n",
      "2018-11-26 12:50:02,187 INFO Layer 67: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:02,190 INFO Layer 68: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:02,193 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:02,199 INFO Layer 68: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:02,202 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:02,209 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:02,213 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:02,216 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:02,220 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:02,223 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:02,226 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:02,229 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:02,232 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:02,235 INFO Layer 69: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:02,238 INFO Layer 69: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:02,241 INFO Layer 70: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:02,244 INFO Layer 70: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:02,251 INFO Layer 71: ReLU(inplace)\n",
      "2018-11-26 12:50:02,255 INFO Layer 71: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:02,258 INFO Layer 72: Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:02,262 INFO Pytorch tensor shape detected: 128x192 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:02,266 INFO Layer 72: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:02,270 INFO     Weight matrix 1/1 (128,192): Analyzing ...\n",
      "2018-11-26 12:50:03,444 INFO     Weight matrix 1/1 (128,192): Alpha: 1.5206465027230485, Alpha Weighted: 0.120804947100643, D: 0.19801380391582885\n",
      "2018-11-26 12:50:03,449 INFO     Weight matrix 1/1 (128,192): Lognorm: 0.6384468078613281\n",
      "2018-11-26 12:50:03,452 INFO Layer 73: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:03,456 INFO Layer 73: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:03,459 INFO Layer 74: ReLU(inplace)\n",
      "2018-11-26 12:50:03,462 INFO Layer 74: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:03,465 INFO Layer 75: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:03,469 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:03,472 INFO Layer 75: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:03,476 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:03,480 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:03,483 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:03,487 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:03,490 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:03,493 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:03,497 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:03,508 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:03,514 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:03,518 INFO Layer 76: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:03,521 INFO Layer 76: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:03,525 INFO Layer 77: BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:03,529 INFO Layer 77: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:03,532 INFO Layer 78: ReLU(inplace)\n",
      "2018-11-26 12:50:03,535 INFO Layer 78: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:03,538 INFO Layer 79: Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:03,542 INFO Pytorch tensor shape detected: 128x224 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:03,545 INFO Layer 79: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:03,549 INFO     Weight matrix 1/1 (128,224): Analyzing ...\n",
      "2018-11-26 12:50:04,747 INFO     Weight matrix 1/1 (128,224): Alpha: 1.8894357293704198, Alpha Weighted: 0.43839556015288794, D: 0.17082752036913307\n",
      "2018-11-26 12:50:04,750 INFO     Weight matrix 1/1 (128,224): Lognorm: 0.7061021327972412\n",
      "2018-11-26 12:50:04,753 INFO Layer 80: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:04,757 INFO Layer 80: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:04,761 INFO Layer 81: ReLU(inplace)\n",
      "2018-11-26 12:50:04,764 INFO Layer 81: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:04,767 INFO Layer 82: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:04,771 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:04,774 INFO Layer 82: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:04,777 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:04,779 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:04,781 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:04,784 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:04,787 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:04,789 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:04,792 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:04,795 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:04,797 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:04,801 INFO Layer 83: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:04,804 INFO Layer 83: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:04,807 INFO Layer 84: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:04,811 INFO Layer 84: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:04,814 INFO Layer 85: ReLU(inplace)\n",
      "2018-11-26 12:50:04,817 INFO Layer 85: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:04,821 INFO Layer 86: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:04,825 INFO Pytorch tensor shape detected: 128x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:04,828 INFO Layer 86: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:04,831 INFO     Weight matrix 1/1 (128,256): Analyzing ...\n",
      "2018-11-26 12:50:06,035 INFO     Weight matrix 1/1 (128,256): Alpha: 1.8087565900700295, Alpha Weighted: 0.3042906737467894, D: 0.18048240228055623\n",
      "2018-11-26 12:50:06,038 INFO     Weight matrix 1/1 (128,256): Lognorm: 0.6841765642166138\n",
      "2018-11-26 12:50:06,042 INFO Layer 87: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:06,046 INFO Layer 87: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:06,049 INFO Layer 88: ReLU(inplace)\n",
      "2018-11-26 12:50:06,052 INFO Layer 88: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:06,055 INFO Layer 89: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:06,060 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:06,062 INFO Layer 89: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:06,065 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:06,068 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:06,071 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:06,073 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:06,076 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:06,079 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:06,083 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:06,086 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:06,088 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:06,091 INFO Layer 90: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:06,093 INFO Layer 90: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:06,097 INFO Layer 91: BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:06,100 INFO Layer 91: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:06,103 INFO Layer 92: ReLU(inplace)\n",
      "2018-11-26 12:50:06,106 INFO Layer 92: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:06,110 INFO Layer 93: Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:06,114 INFO Pytorch tensor shape detected: 128x288 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:06,120 INFO Layer 93: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:06,126 INFO     Weight matrix 1/1 (128,288): Analyzing ...\n",
      "2018-11-26 12:50:07,404 INFO     Weight matrix 1/1 (128,288): Alpha: 6.021136485029262, Alpha Weighted: 1.6248441495236794, D: 0.14274345872699\n",
      "2018-11-26 12:50:07,407 INFO     Weight matrix 1/1 (128,288): Alpha 6.021136485029262 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:07,410 INFO     Weight matrix 1/1 (128,288): Lognorm: 0.7083194851875305\n",
      "2018-11-26 12:50:07,413 INFO Layer 94: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:07,416 INFO Layer 94: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:07,420 INFO Layer 95: ReLU(inplace)\n",
      "2018-11-26 12:50:07,424 INFO Layer 95: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:07,426 INFO Layer 96: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:07,430 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:07,433 INFO Layer 96: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:07,435 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:07,438 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:07,440 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:07,443 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:07,446 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:07,450 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:07,452 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:07,455 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:07,458 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:07,462 INFO Layer 97: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:07,465 INFO Layer 97: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:07,472 INFO Layer 98: BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:07,475 INFO Layer 98: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:07,477 INFO Layer 99: ReLU(inplace)\n",
      "2018-11-26 12:50:07,480 INFO Layer 99: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:07,483 INFO Layer 100: Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:07,488 INFO Pytorch tensor shape detected: 128x320 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:07,490 INFO Layer 100: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:07,494 INFO     Weight matrix 1/1 (128,320): Analyzing ...\n",
      "2018-11-26 12:50:08,714 INFO     Weight matrix 1/1 (128,320): Alpha: 2.242117210674278, Alpha Weighted: 0.3099542470051873, D: 0.18142491688562673\n",
      "2018-11-26 12:50:08,718 INFO     Weight matrix 1/1 (128,320): Lognorm: 0.7466636300086975\n",
      "2018-11-26 12:50:08,722 INFO Layer 101: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:08,726 INFO Layer 101: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:08,729 INFO Layer 102: ReLU(inplace)\n",
      "2018-11-26 12:50:08,732 INFO Layer 102: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:08,735 INFO Layer 103: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:08,739 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:08,741 INFO Layer 103: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:08,744 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:08,749 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:08,756 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:08,759 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:08,764 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:08,768 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:08,773 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:08,776 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:08,778 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:08,782 INFO Layer 104: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:08,784 INFO Layer 104: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:08,787 INFO Layer 105: BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:08,790 INFO Layer 105: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:08,793 INFO Layer 106: ReLU(inplace)\n",
      "2018-11-26 12:50:08,795 INFO Layer 106: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:08,799 INFO Layer 107: Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:08,806 INFO Pytorch tensor shape detected: 128x352 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:08,809 INFO Layer 107: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:08,813 INFO     Weight matrix 1/1 (128,352): Analyzing ...\n",
      "2018-11-26 12:50:10,003 INFO     Weight matrix 1/1 (128,352): Alpha: 3.0542302154673213, Alpha Weighted: 0.8892770040792306, D: 0.1183554488815981\n",
      "2018-11-26 12:50:10,006 INFO     Weight matrix 1/1 (128,352): Lognorm: 0.7385070323944092\n",
      "2018-11-26 12:50:10,009 INFO Layer 108: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:10,013 INFO Layer 108: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:10,017 INFO Layer 109: ReLU(inplace)\n",
      "2018-11-26 12:50:10,021 INFO Layer 109: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:10,024 INFO Layer 110: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:10,028 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:10,032 INFO Layer 110: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:10,035 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:10,039 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:10,042 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:10,046 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:10,050 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:10,054 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:10,060 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:10,066 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:10,070 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:10,074 INFO Layer 111: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:10,077 INFO Layer 111: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:10,080 INFO Layer 112: BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:10,082 INFO Layer 112: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:10,085 INFO Layer 113: ReLU(inplace)\n",
      "2018-11-26 12:50:10,089 INFO Layer 113: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:10,092 INFO Layer 114: Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:10,096 INFO Pytorch tensor shape detected: 128x384 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:10,104 INFO Layer 114: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:10,107 INFO     Weight matrix 1/1 (128,384): Analyzing ...\n",
      "2018-11-26 12:50:11,566 INFO     Weight matrix 1/1 (128,384): Alpha: 4.020770555155709, Alpha Weighted: 1.3518436891619103, D: 0.13738904485119907\n",
      "2018-11-26 12:50:11,569 INFO     Weight matrix 1/1 (128,384): Alpha 4.020770555155709 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:11,573 INFO     Weight matrix 1/1 (128,384): Lognorm: 0.7641022801399231\n",
      "2018-11-26 12:50:11,576 INFO Layer 115: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:11,579 INFO Layer 115: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:11,582 INFO Layer 116: ReLU(inplace)\n",
      "2018-11-26 12:50:11,585 INFO Layer 116: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:11,588 INFO Layer 117: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:11,592 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:11,595 INFO Layer 117: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:11,599 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:11,602 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:11,605 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:11,609 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:11,613 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:11,616 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:11,619 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:11,623 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:11,626 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:11,630 INFO Layer 118: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:11,633 INFO Layer 118: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:11,637 INFO Layer 119: BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:11,640 INFO Layer 119: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:11,643 INFO Layer 120: ReLU(inplace)\n",
      "2018-11-26 12:50:11,647 INFO Layer 120: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:11,649 INFO Layer 121: Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:11,653 INFO Pytorch tensor shape detected: 128x416 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:11,656 INFO Layer 121: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:11,660 INFO     Weight matrix 1/1 (128,416): Analyzing ...\n",
      "2018-11-26 12:50:12,964 INFO     Weight matrix 1/1 (128,416): Alpha: 2.429381672255332, Alpha Weighted: 0.5428853486164292, D: 0.1574598333577743\n",
      "2018-11-26 12:50:12,968 INFO     Weight matrix 1/1 (128,416): Lognorm: 0.8047155141830444\n",
      "2018-11-26 12:50:12,972 INFO Layer 122: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:12,975 INFO Layer 122: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:12,978 INFO Layer 123: ReLU(inplace)\n",
      "2018-11-26 12:50:12,981 INFO Layer 123: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:12,985 INFO Layer 124: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:12,988 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:12,990 INFO Layer 124: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:12,993 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:12,996 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:12,999 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:13,002 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:13,006 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:13,010 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:13,013 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:13,019 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:13,025 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:13,030 INFO Layer 125: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:13,033 INFO Layer 125: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:13,036 INFO Layer 126: BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:13,039 INFO Layer 126: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:13,042 INFO Layer 127: ReLU(inplace)\n",
      "2018-11-26 12:50:13,046 INFO Layer 127: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:13,052 INFO Layer 128: Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:13,057 INFO Pytorch tensor shape detected: 128x448 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:13,065 INFO Layer 128: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:13,070 INFO     Weight matrix 1/1 (128,448): Analyzing ...\n",
      "2018-11-26 12:50:14,395 INFO     Weight matrix 1/1 (128,448): Alpha: 3.5514356306430743, Alpha Weighted: 1.202579537689644, D: 0.12227946853394966\n",
      "2018-11-26 12:50:14,397 INFO     Weight matrix 1/1 (128,448): Alpha 3.5514356306430743 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:14,400 INFO     Weight matrix 1/1 (128,448): Lognorm: 0.793705940246582\n",
      "2018-11-26 12:50:14,403 INFO Layer 129: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:14,408 INFO Layer 129: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:14,412 INFO Layer 130: ReLU(inplace)\n",
      "2018-11-26 12:50:14,415 INFO Layer 130: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:14,418 INFO Layer 131: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:14,423 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:14,426 INFO Layer 131: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:14,429 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:14,433 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:14,436 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:14,438 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:14,442 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:14,446 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:14,448 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:14,452 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:14,456 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:14,461 INFO Layer 132: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:14,470 INFO Layer 132: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:14,476 INFO Layer 133: BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:14,485 INFO Layer 133: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:14,489 INFO Layer 134: ReLU(inplace)\n",
      "2018-11-26 12:50:14,494 INFO Layer 134: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:14,500 INFO Layer 135: Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:14,504 INFO Pytorch tensor shape detected: 128x480 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:14,516 INFO Layer 135: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:14,519 INFO     Weight matrix 1/1 (128,480): Analyzing ...\n",
      "2018-11-26 12:50:15,797 INFO     Weight matrix 1/1 (128,480): Alpha: 6.550383167809261, Alpha Weighted: 2.135368723112505, D: 0.12499999999999978\n",
      "2018-11-26 12:50:15,800 INFO     Weight matrix 1/1 (128,480): Alpha 6.550383167809261 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:15,803 INFO     Weight matrix 1/1 (128,480): Lognorm: 0.8326336145401001\n",
      "2018-11-26 12:50:15,806 INFO Layer 136: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:15,809 INFO Layer 136: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:15,812 INFO Layer 137: ReLU(inplace)\n",
      "2018-11-26 12:50:15,815 INFO Layer 137: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:15,817 INFO Layer 138: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:15,821 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:15,823 INFO Layer 138: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:15,828 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:15,830 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:15,832 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:15,835 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:15,838 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:15,840 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:15,842 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:15,845 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:15,848 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:15,850 INFO Layer 139: _Transition(\n",
      "  (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "2018-11-26 12:50:15,853 INFO Layer 139: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:15,856 INFO Layer 140: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:15,858 INFO Layer 140: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:15,861 INFO Layer 141: ReLU(inplace)\n",
      "2018-11-26 12:50:15,863 INFO Layer 141: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:15,866 INFO Layer 142: Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:15,878 INFO Pytorch tensor shape detected: 256x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:15,882 INFO Layer 142: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:15,885 INFO     Weight matrix 1/1 (256,512): Analyzing ...\n",
      "2018-11-26 12:50:19,029 INFO     Weight matrix 1/1 (256,512): Alpha: 5.347566209735007, Alpha Weighted: 3.5047447349279244, D: 0.11882561786252233\n",
      "2018-11-26 12:50:19,032 INFO     Weight matrix 1/1 (256,512): Alpha 5.347566209735007 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:19,035 INFO     Weight matrix 1/1 (256,512): Lognorm: 1.1703954935073853\n",
      "2018-11-26 12:50:19,040 INFO Layer 143: AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "2018-11-26 12:50:19,042 INFO Layer 143: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:19,054 INFO Layer 144: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer7): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer8): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer9): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer10): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer11): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer12): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer13): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer14): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer15): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer16): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer17): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer18): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer19): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer20): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer21): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer22): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer23): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer24): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:19,057 INFO Layer 144: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:19,060 INFO Layer 145: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:19,063 INFO Layer 145: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:19,067 INFO Layer 146: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:19,069 INFO Layer 146: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:19,071 INFO Layer 147: ReLU(inplace)\n",
      "2018-11-26 12:50:19,074 INFO Layer 147: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:19,077 INFO Layer 148: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:19,081 INFO Pytorch tensor shape detected: 128x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:19,086 INFO Layer 148: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:19,090 INFO     Weight matrix 1/1 (128,256): Analyzing ...\n",
      "2018-11-26 12:50:20,588 INFO     Weight matrix 1/1 (128,256): Alpha: 1.9326885966736622, Alpha Weighted: 0.008693578495666087, D: 0.1742916473186591\n",
      "2018-11-26 12:50:20,591 INFO     Weight matrix 1/1 (128,256): Lognorm: 0.6184055209159851\n",
      "2018-11-26 12:50:20,595 INFO Layer 149: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:20,600 INFO Layer 149: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:20,603 INFO Layer 150: ReLU(inplace)\n",
      "2018-11-26 12:50:20,605 INFO Layer 150: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:20,608 INFO Layer 151: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:20,612 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:20,619 INFO Layer 151: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:20,622 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:20,626 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:20,631 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:20,634 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:20,637 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:20,641 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:20,646 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:20,650 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:20,654 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:20,658 INFO Layer 152: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:20,662 INFO Layer 152: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:20,665 INFO Layer 153: BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:20,668 INFO Layer 153: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:20,671 INFO Layer 154: ReLU(inplace)\n",
      "2018-11-26 12:50:20,674 INFO Layer 154: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:20,677 INFO Layer 155: Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:20,681 INFO Pytorch tensor shape detected: 128x288 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:20,685 INFO Layer 155: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:20,688 INFO     Weight matrix 1/1 (128,288): Analyzing ...\n",
      "2018-11-26 12:50:22,033 INFO     Weight matrix 1/1 (128,288): Alpha: 4.340126284679503, Alpha Weighted: 0.21034127170533667, D: 0.17260028319349163\n",
      "2018-11-26 12:50:22,036 INFO     Weight matrix 1/1 (128,288): Alpha 4.340126284679503 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:22,040 INFO     Weight matrix 1/1 (128,288): Lognorm: 0.6271429657936096\n",
      "2018-11-26 12:50:22,043 INFO Layer 156: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:22,047 INFO Layer 156: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:22,050 INFO Layer 157: ReLU(inplace)\n",
      "2018-11-26 12:50:22,054 INFO Layer 157: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:22,057 INFO Layer 158: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:22,062 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:22,065 INFO Layer 158: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:22,068 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:22,071 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:22,075 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:22,078 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:22,082 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:22,085 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:22,088 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:22,091 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:22,093 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:22,097 INFO Layer 159: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:22,100 INFO Layer 159: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:22,104 INFO Layer 160: BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:22,107 INFO Layer 160: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:22,110 INFO Layer 161: ReLU(inplace)\n",
      "2018-11-26 12:50:22,113 INFO Layer 161: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:22,116 INFO Layer 162: Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:22,120 INFO Pytorch tensor shape detected: 128x320 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:22,122 INFO Layer 162: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:22,126 INFO     Weight matrix 1/1 (128,320): Analyzing ...\n",
      "2018-11-26 12:50:23,370 INFO     Weight matrix 1/1 (128,320): Alpha: 3.4097227431983357, Alpha Weighted: 0.07451059404262196, D: 0.13956244321153932\n",
      "2018-11-26 12:50:23,374 INFO     Weight matrix 1/1 (128,320): Lognorm: 0.6755089163780212\n",
      "2018-11-26 12:50:23,378 INFO Layer 163: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:23,380 INFO Layer 163: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:23,383 INFO Layer 164: ReLU(inplace)\n",
      "2018-11-26 12:50:23,388 INFO Layer 164: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:23,390 INFO Layer 165: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:23,393 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:23,396 INFO Layer 165: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:23,398 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:23,402 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:23,405 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:23,407 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:23,409 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:23,412 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:23,414 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:23,423 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:23,427 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:23,430 INFO Layer 166: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:23,433 INFO Layer 166: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:23,437 INFO Layer 167: BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:23,439 INFO Layer 167: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:23,442 INFO Layer 168: ReLU(inplace)\n",
      "2018-11-26 12:50:23,445 INFO Layer 168: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:23,450 INFO Layer 169: Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:23,458 INFO Pytorch tensor shape detected: 128x352 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:23,462 INFO Layer 169: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:23,465 INFO     Weight matrix 1/1 (128,352): Analyzing ...\n",
      "2018-11-26 12:50:24,748 INFO     Weight matrix 1/1 (128,352): Alpha: 5.183769114100147, Alpha Weighted: 0.636770501551651, D: 0.11233360061210185\n",
      "2018-11-26 12:50:24,751 INFO     Weight matrix 1/1 (128,352): Alpha 5.183769114100147 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:24,754 INFO     Weight matrix 1/1 (128,352): Lognorm: 0.6975308656692505\n",
      "2018-11-26 12:50:24,758 INFO Layer 170: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:24,761 INFO Layer 170: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:24,763 INFO Layer 171: ReLU(inplace)\n",
      "2018-11-26 12:50:24,766 INFO Layer 171: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:24,768 INFO Layer 172: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:24,771 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:24,773 INFO Layer 172: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:24,776 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:24,778 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:24,781 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:24,784 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:24,786 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:24,789 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:24,791 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:24,794 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:24,796 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:24,799 INFO Layer 173: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:24,801 INFO Layer 173: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:24,804 INFO Layer 174: BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:24,807 INFO Layer 174: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:24,810 INFO Layer 175: ReLU(inplace)\n",
      "2018-11-26 12:50:24,818 INFO Layer 175: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:24,821 INFO Layer 176: Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:24,824 INFO Pytorch tensor shape detected: 128x384 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:24,826 INFO Layer 176: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:24,829 INFO     Weight matrix 1/1 (128,384): Analyzing ...\n",
      "2018-11-26 12:50:26,072 INFO     Weight matrix 1/1 (128,384): Alpha: 7.023843523022496, Alpha Weighted: 0.09327145183955246, D: 0.18176775257876132\n",
      "2018-11-26 12:50:26,075 INFO     Weight matrix 1/1 (128,384): Alpha 7.023843523022496 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:26,080 INFO     Weight matrix 1/1 (128,384): Lognorm: 0.6815582513809204\n",
      "2018-11-26 12:50:26,083 INFO Layer 177: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:26,086 INFO Layer 177: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:26,089 INFO Layer 178: ReLU(inplace)\n",
      "2018-11-26 12:50:26,092 INFO Layer 178: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:26,096 INFO Layer 179: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:26,101 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:26,106 INFO Layer 179: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:26,111 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:26,114 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:26,117 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:26,121 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:26,124 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:26,127 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:26,130 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:26,133 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:26,136 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:26,140 INFO Layer 180: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:26,143 INFO Layer 180: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:26,147 INFO Layer 181: BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:26,151 INFO Layer 181: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:26,155 INFO Layer 182: ReLU(inplace)\n",
      "2018-11-26 12:50:26,157 INFO Layer 182: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:26,161 INFO Layer 183: Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:26,166 INFO Pytorch tensor shape detected: 128x416 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:26,173 INFO Layer 183: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:26,178 INFO     Weight matrix 1/1 (128,416): Analyzing ...\n",
      "2018-11-26 12:50:27,330 INFO     Weight matrix 1/1 (128,416): Alpha: 3.335676862284965, Alpha Weighted: 0.9433768983303495, D: 0.09307780140429578\n",
      "2018-11-26 12:50:27,333 INFO     Weight matrix 1/1 (128,416): Lognorm: 0.732858419418335\n",
      "2018-11-26 12:50:27,336 INFO Layer 184: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:27,339 INFO Layer 184: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:27,342 INFO Layer 185: ReLU(inplace)\n",
      "2018-11-26 12:50:27,345 INFO Layer 185: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:27,349 INFO Layer 186: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:27,354 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:27,356 INFO Layer 186: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:27,360 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:27,364 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:27,369 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:27,372 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:27,376 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:27,378 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:27,382 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:27,384 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:27,387 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:27,390 INFO Layer 187: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:27,392 INFO Layer 187: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:27,394 INFO Layer 188: BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:27,398 INFO Layer 188: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:27,401 INFO Layer 189: ReLU(inplace)\n",
      "2018-11-26 12:50:27,412 INFO Layer 189: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:27,417 INFO Layer 190: Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:27,424 INFO Pytorch tensor shape detected: 128x448 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:27,430 INFO Layer 190: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:27,434 INFO     Weight matrix 1/1 (128,448): Analyzing ...\n",
      "2018-11-26 12:50:28,638 INFO     Weight matrix 1/1 (128,448): Alpha: 1.8350038795667436, Alpha Weighted: 0.08332471621774798, D: 0.1859525791618164\n",
      "2018-11-26 12:50:28,642 INFO     Weight matrix 1/1 (128,448): Lognorm: 0.693450391292572\n",
      "2018-11-26 12:50:28,646 INFO Layer 191: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:28,649 INFO Layer 191: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:28,653 INFO Layer 192: ReLU(inplace)\n",
      "2018-11-26 12:50:28,656 INFO Layer 192: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:28,660 INFO Layer 193: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:28,665 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:28,668 INFO Layer 193: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:28,671 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:28,674 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:28,678 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:28,681 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:28,685 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:28,688 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:28,691 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:28,694 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:28,699 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:28,702 INFO Layer 194: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:28,705 INFO Layer 194: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:28,708 INFO Layer 195: BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:28,711 INFO Layer 195: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:28,713 INFO Layer 196: ReLU(inplace)\n",
      "2018-11-26 12:50:28,715 INFO Layer 196: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:28,718 INFO Layer 197: Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:28,725 INFO Pytorch tensor shape detected: 128x480 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:28,728 INFO Layer 197: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:28,731 INFO     Weight matrix 1/1 (128,480): Analyzing ...\n",
      "2018-11-26 12:50:29,901 INFO     Weight matrix 1/1 (128,480): Alpha: 3.558890313038112, Alpha Weighted: 0.6545547514011743, D: 0.11040175618497672\n",
      "2018-11-26 12:50:29,904 INFO     Weight matrix 1/1 (128,480): Alpha 3.558890313038112 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:29,907 INFO     Weight matrix 1/1 (128,480): Lognorm: 0.7797842025756836\n",
      "2018-11-26 12:50:29,911 INFO Layer 198: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:29,914 INFO Layer 198: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:29,916 INFO Layer 199: ReLU(inplace)\n",
      "2018-11-26 12:50:29,919 INFO Layer 199: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:29,922 INFO Layer 200: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:29,925 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:29,928 INFO Layer 200: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:29,930 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:29,934 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:29,936 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:29,939 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:29,942 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:29,945 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:29,948 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:29,952 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:29,957 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:29,961 INFO Layer 201: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:29,964 INFO Layer 201: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:29,967 INFO Layer 202: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:29,970 INFO Layer 202: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:29,973 INFO Layer 203: ReLU(inplace)\n",
      "2018-11-26 12:50:29,977 INFO Layer 203: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:29,980 INFO Layer 204: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:29,984 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:29,987 INFO Layer 204: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:30,006 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 12:50:31,308 INFO     Weight matrix 1/1 (128,512): Alpha: 3.6853682769007112, Alpha Weighted: 1.0129943529571799, D: 0.09607797134421348\n",
      "2018-11-26 12:50:31,311 INFO     Weight matrix 1/1 (128,512): Alpha 3.6853682769007112 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:31,315 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.7929549217224121\n",
      "2018-11-26 12:50:31,318 INFO Layer 205: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:31,324 INFO Layer 205: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:31,329 INFO Layer 206: ReLU(inplace)\n",
      "2018-11-26 12:50:31,333 INFO Layer 206: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:31,337 INFO Layer 207: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:31,341 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:31,345 INFO Layer 207: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:31,349 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:31,352 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:31,357 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:31,366 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:31,370 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:31,376 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:31,381 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:31,385 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:31,388 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:31,392 INFO Layer 208: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:31,395 INFO Layer 208: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:31,398 INFO Layer 209: BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:31,402 INFO Layer 209: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:31,406 INFO Layer 210: ReLU(inplace)\n",
      "2018-11-26 12:50:31,409 INFO Layer 210: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:31,415 INFO Layer 211: Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:31,420 INFO Pytorch tensor shape detected: 128x544 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:31,423 INFO Layer 211: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:31,427 INFO     Weight matrix 1/1 (128,544): Analyzing ...\n",
      "2018-11-26 12:50:32,709 INFO     Weight matrix 1/1 (128,544): Alpha: 2.21144032220666, Alpha Weighted: 0.14068585470723957, D: 0.17558706388743567\n",
      "2018-11-26 12:50:32,715 INFO     Weight matrix 1/1 (128,544): Lognorm: 0.7338912487030029\n",
      "2018-11-26 12:50:32,718 INFO Layer 212: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:32,721 INFO Layer 212: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:32,724 INFO Layer 213: ReLU(inplace)\n",
      "2018-11-26 12:50:32,727 INFO Layer 213: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:32,731 INFO Layer 214: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:32,734 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:32,736 INFO Layer 214: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:32,740 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:32,742 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:32,745 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:32,749 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:32,752 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:32,756 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:32,758 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:32,762 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:32,766 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:32,769 INFO Layer 215: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:32,772 INFO Layer 215: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:32,775 INFO Layer 216: BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:32,778 INFO Layer 216: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:32,780 INFO Layer 217: ReLU(inplace)\n",
      "2018-11-26 12:50:32,783 INFO Layer 217: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:32,786 INFO Layer 218: Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:32,790 INFO Pytorch tensor shape detected: 128x576 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:32,796 INFO Layer 218: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:32,801 INFO     Weight matrix 1/1 (128,576): Analyzing ...\n",
      "2018-11-26 12:50:34,019 INFO     Weight matrix 1/1 (128,576): Alpha: 6.22817119030097, Alpha Weighted: 1.1225601324553132, D: 0.1250392254914296\n",
      "2018-11-26 12:50:34,022 INFO     Weight matrix 1/1 (128,576): Alpha 6.22817119030097 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:34,025 INFO     Weight matrix 1/1 (128,576): Lognorm: 0.7607789635658264\n",
      "2018-11-26 12:50:34,028 INFO Layer 219: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:34,030 INFO Layer 219: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:34,033 INFO Layer 220: ReLU(inplace)\n",
      "2018-11-26 12:50:34,036 INFO Layer 220: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:34,038 INFO Layer 221: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:34,042 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:34,045 INFO Layer 221: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:34,049 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:34,051 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:34,054 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:34,057 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:34,060 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:34,063 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:34,065 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:34,069 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:34,071 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:34,073 INFO Layer 222: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:34,077 INFO Layer 222: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:34,079 INFO Layer 223: BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:34,082 INFO Layer 223: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:34,084 INFO Layer 224: ReLU(inplace)\n",
      "2018-11-26 12:50:34,087 INFO Layer 224: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:34,090 INFO Layer 225: Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:34,095 INFO Pytorch tensor shape detected: 128x608 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:34,100 INFO Layer 225: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:34,103 INFO     Weight matrix 1/1 (128,608): Analyzing ...\n",
      "2018-11-26 12:50:35,321 INFO     Weight matrix 1/1 (128,608): Alpha: 3.042524416134094, Alpha Weighted: 0.5384996226319526, D: 0.13411421754102054\n",
      "2018-11-26 12:50:35,325 INFO     Weight matrix 1/1 (128,608): Lognorm: 0.7940155267715454\n",
      "2018-11-26 12:50:35,328 INFO Layer 226: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:35,332 INFO Layer 226: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:35,335 INFO Layer 227: ReLU(inplace)\n",
      "2018-11-26 12:50:35,338 INFO Layer 227: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:35,341 INFO Layer 228: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:35,344 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:35,347 INFO Layer 228: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:35,351 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:35,356 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:35,359 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:35,362 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:35,365 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:35,368 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:35,371 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:35,376 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:35,379 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:35,381 INFO Layer 229: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:35,384 INFO Layer 229: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:35,386 INFO Layer 230: BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:35,389 INFO Layer 230: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:35,392 INFO Layer 231: ReLU(inplace)\n",
      "2018-11-26 12:50:35,394 INFO Layer 231: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:35,397 INFO Layer 232: Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:35,401 INFO Pytorch tensor shape detected: 128x640 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:35,403 INFO Layer 232: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:35,406 INFO     Weight matrix 1/1 (128,640): Analyzing ...\n",
      "2018-11-26 12:50:36,693 INFO     Weight matrix 1/1 (128,640): Alpha: 2.230120422975948, Alpha Weighted: 0.17757032140272686, D: 0.16137836486168744\n",
      "2018-11-26 12:50:36,697 INFO     Weight matrix 1/1 (128,640): Lognorm: 0.764450192451477\n",
      "2018-11-26 12:50:36,701 INFO Layer 233: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:36,704 INFO Layer 233: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:36,707 INFO Layer 234: ReLU(inplace)\n",
      "2018-11-26 12:50:36,710 INFO Layer 234: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:36,714 INFO Layer 235: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:36,718 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:36,723 INFO Layer 235: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:36,726 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:36,732 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:36,734 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:36,737 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:36,740 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:36,743 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:36,748 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:36,752 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:36,755 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:36,760 INFO Layer 236: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:36,764 INFO Layer 236: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:36,767 INFO Layer 237: BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:36,770 INFO Layer 237: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:36,772 INFO Layer 238: ReLU(inplace)\n",
      "2018-11-26 12:50:36,775 INFO Layer 238: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:36,777 INFO Layer 239: Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:36,782 INFO Pytorch tensor shape detected: 128x672 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:36,786 INFO Layer 239: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:36,789 INFO     Weight matrix 1/1 (128,672): Analyzing ...\n",
      "2018-11-26 12:50:38,156 INFO     Weight matrix 1/1 (128,672): Alpha: 3.1456928080735893, Alpha Weighted: 0.6788712177387202, D: 0.1300888525469489\n",
      "2018-11-26 12:50:38,160 INFO     Weight matrix 1/1 (128,672): Lognorm: 0.7673153281211853\n",
      "2018-11-26 12:50:38,166 INFO Layer 240: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:38,170 INFO Layer 240: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:38,173 INFO Layer 241: ReLU(inplace)\n",
      "2018-11-26 12:50:38,182 INFO Layer 241: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:38,184 INFO Layer 242: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:38,189 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:38,192 INFO Layer 242: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:38,196 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:38,200 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:38,203 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:38,214 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:38,218 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:38,221 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:38,225 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:38,229 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:38,233 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:38,236 INFO Layer 243: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:38,239 INFO Layer 243: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:38,242 INFO Layer 244: BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:38,245 INFO Layer 244: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:38,250 INFO Layer 245: ReLU(inplace)\n",
      "2018-11-26 12:50:38,253 INFO Layer 245: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:38,256 INFO Layer 246: Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:38,260 INFO Pytorch tensor shape detected: 128x704 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:38,267 INFO Layer 246: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:38,272 INFO     Weight matrix 1/1 (128,704): Analyzing ...\n",
      "2018-11-26 12:50:39,708 INFO     Weight matrix 1/1 (128,704): Alpha: 8.112021422482236, Alpha Weighted: 1.4467061437055695, D: 0.12499999999999978\n",
      "2018-11-26 12:50:39,712 INFO     Weight matrix 1/1 (128,704): Alpha 8.112021422482236 is in the danger zone (1.5,3.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:39,716 INFO     Weight matrix 1/1 (128,704): Lognorm: 0.8156046271324158\n",
      "2018-11-26 12:50:39,719 INFO Layer 247: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:39,723 INFO Layer 247: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:39,726 INFO Layer 248: ReLU(inplace)\n",
      "2018-11-26 12:50:39,729 INFO Layer 248: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:39,732 INFO Layer 249: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:39,735 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:39,737 INFO Layer 249: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:39,740 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:39,744 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:39,747 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:39,752 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:39,755 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:39,758 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:39,761 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:39,765 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:39,768 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:39,771 INFO Layer 250: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:39,774 INFO Layer 250: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:39,778 INFO Layer 251: BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:39,781 INFO Layer 251: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:39,784 INFO Layer 252: ReLU(inplace)\n",
      "2018-11-26 12:50:39,786 INFO Layer 252: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:39,789 INFO Layer 253: Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:39,792 INFO Pytorch tensor shape detected: 128x736 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:39,796 INFO Layer 253: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:39,800 INFO     Weight matrix 1/1 (128,736): Analyzing ...\n",
      "2018-11-26 12:50:41,203 INFO     Weight matrix 1/1 (128,736): Alpha: 5.027632505731705, Alpha Weighted: 0.6479750327785241, D: 0.14347516349652367\n",
      "2018-11-26 12:50:41,205 INFO     Weight matrix 1/1 (128,736): Alpha 5.027632505731705 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:41,208 INFO     Weight matrix 1/1 (128,736): Lognorm: 0.7965323328971863\n",
      "2018-11-26 12:50:41,211 INFO Layer 254: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:41,215 INFO Layer 254: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:41,218 INFO Layer 255: ReLU(inplace)\n",
      "2018-11-26 12:50:41,221 INFO Layer 255: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:41,224 INFO Layer 256: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:41,227 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:41,232 INFO Layer 256: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:41,236 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:41,238 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:41,241 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:41,244 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:41,247 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:41,249 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:41,253 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:41,256 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:41,259 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:41,262 INFO Layer 257: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:41,265 INFO Layer 257: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:41,267 INFO Layer 258: BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:41,274 INFO Layer 258: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:41,277 INFO Layer 259: ReLU(inplace)\n",
      "2018-11-26 12:50:41,281 INFO Layer 259: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:41,285 INFO Layer 260: Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:41,290 INFO Pytorch tensor shape detected: 128x768 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:41,293 INFO Layer 260: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:41,298 INFO     Weight matrix 1/1 (128,768): Analyzing ...\n",
      "2018-11-26 12:50:42,779 INFO     Weight matrix 1/1 (128,768): Alpha: 2.7657890029596963, Alpha Weighted: 1.0162566897597503, D: 0.09820138570040521\n",
      "2018-11-26 12:50:42,785 INFO     Weight matrix 1/1 (128,768): Lognorm: 0.8472602963447571\n",
      "2018-11-26 12:50:42,788 INFO Layer 261: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:42,791 INFO Layer 261: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:42,794 INFO Layer 262: ReLU(inplace)\n",
      "2018-11-26 12:50:42,797 INFO Layer 262: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:42,801 INFO Layer 263: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:42,806 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:42,810 INFO Layer 263: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:42,815 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:42,818 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:42,821 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:42,825 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:42,829 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:42,832 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:42,835 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:42,837 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:42,840 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:42,844 INFO Layer 264: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:42,847 INFO Layer 264: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:42,850 INFO Layer 265: BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:42,853 INFO Layer 265: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:42,857 INFO Layer 266: ReLU(inplace)\n",
      "2018-11-26 12:50:42,861 INFO Layer 266: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:42,865 INFO Layer 267: Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:42,870 INFO Pytorch tensor shape detected: 128x800 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:42,874 INFO Layer 267: Analyzing 1 weight matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:42,878 INFO     Weight matrix 1/1 (128,800): Analyzing ...\n",
      "2018-11-26 12:50:44,315 INFO     Weight matrix 1/1 (128,800): Alpha: 3.729422214332309, Alpha Weighted: 0.7631258908498614, D: 0.13378527091769166\n",
      "2018-11-26 12:50:44,318 INFO     Weight matrix 1/1 (128,800): Alpha 3.729422214332309 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:44,322 INFO     Weight matrix 1/1 (128,800): Lognorm: 0.8362366557121277\n",
      "2018-11-26 12:50:44,326 INFO Layer 268: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:44,329 INFO Layer 268: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:44,332 INFO Layer 269: ReLU(inplace)\n",
      "2018-11-26 12:50:44,334 INFO Layer 269: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:44,337 INFO Layer 270: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:44,342 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:44,345 INFO Layer 270: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:44,351 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:44,355 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:44,358 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:44,362 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:44,366 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:44,369 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:44,373 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:44,376 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:44,379 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:44,381 INFO Layer 271: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:44,384 INFO Layer 271: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:44,388 INFO Layer 272: BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:44,392 INFO Layer 272: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:44,396 INFO Layer 273: ReLU(inplace)\n",
      "2018-11-26 12:50:44,399 INFO Layer 273: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:44,403 INFO Layer 274: Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:44,407 INFO Pytorch tensor shape detected: 128x832 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:44,410 INFO Layer 274: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:44,412 INFO     Weight matrix 1/1 (128,832): Analyzing ...\n",
      "2018-11-26 12:50:45,829 INFO     Weight matrix 1/1 (128,832): Alpha: 2.6266989220860584, Alpha Weighted: 0.6716531563745269, D: 0.12176844048679075\n",
      "2018-11-26 12:50:45,833 INFO     Weight matrix 1/1 (128,832): Lognorm: 0.8550697565078735\n",
      "2018-11-26 12:50:45,835 INFO Layer 275: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:45,838 INFO Layer 275: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:45,842 INFO Layer 276: ReLU(inplace)\n",
      "2018-11-26 12:50:45,845 INFO Layer 276: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:45,851 INFO Layer 277: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:45,856 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:45,859 INFO Layer 277: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:45,863 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:45,867 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:45,870 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:45,873 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:45,878 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:45,881 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:45,885 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:45,889 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:45,892 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:45,895 INFO Layer 278: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:45,897 INFO Layer 278: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:45,901 INFO Layer 279: BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:45,903 INFO Layer 279: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:45,906 INFO Layer 280: ReLU(inplace)\n",
      "2018-11-26 12:50:45,910 INFO Layer 280: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:45,912 INFO Layer 281: Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:45,920 INFO Pytorch tensor shape detected: 128x864 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:45,922 INFO Layer 281: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:45,927 INFO     Weight matrix 1/1 (128,864): Analyzing ...\n",
      "2018-11-26 12:50:47,424 INFO     Weight matrix 1/1 (128,864): Alpha: 4.716730746163366, Alpha Weighted: 1.5198248293486138, D: 0.06517603520760706\n",
      "2018-11-26 12:50:47,426 INFO     Weight matrix 1/1 (128,864): Alpha 4.716730746163366 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:47,430 INFO     Weight matrix 1/1 (128,864): Lognorm: 0.8518842458724976\n",
      "2018-11-26 12:50:47,433 INFO Layer 282: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:47,436 INFO Layer 282: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:47,438 INFO Layer 283: ReLU(inplace)\n",
      "2018-11-26 12:50:47,440 INFO Layer 283: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:47,443 INFO Layer 284: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:47,449 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:47,453 INFO Layer 284: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:47,456 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:47,459 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:47,464 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:47,467 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:47,470 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:47,473 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:47,476 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:47,482 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:47,486 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:47,490 INFO Layer 285: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:47,493 INFO Layer 285: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:47,495 INFO Layer 286: BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:47,499 INFO Layer 286: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:47,503 INFO Layer 287: ReLU(inplace)\n",
      "2018-11-26 12:50:47,506 INFO Layer 287: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:47,509 INFO Layer 288: Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:47,516 INFO Pytorch tensor shape detected: 128x896 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:47,519 INFO Layer 288: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:47,525 INFO     Weight matrix 1/1 (128,896): Analyzing ...\n",
      "2018-11-26 12:50:48,943 INFO     Weight matrix 1/1 (128,896): Alpha: 3.6265808219729028, Alpha Weighted: 1.3192456581590486, D: 0.09869674154555474\n",
      "2018-11-26 12:50:48,946 INFO     Weight matrix 1/1 (128,896): Alpha 3.6265808219729028 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:48,951 INFO     Weight matrix 1/1 (128,896): Lognorm: 0.8671711683273315\n",
      "2018-11-26 12:50:48,956 INFO Layer 289: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:48,960 INFO Layer 289: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:48,964 INFO Layer 290: ReLU(inplace)\n",
      "2018-11-26 12:50:48,968 INFO Layer 290: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:48,972 INFO Layer 291: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:48,975 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:48,978 INFO Layer 291: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:48,981 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:48,984 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:48,986 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:48,989 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:48,992 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:48,996 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:49,000 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:49,004 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:49,008 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:49,011 INFO Layer 292: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:49,015 INFO Layer 292: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:49,019 INFO Layer 293: BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:49,022 INFO Layer 293: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:49,025 INFO Layer 294: ReLU(inplace)\n",
      "2018-11-26 12:50:49,027 INFO Layer 294: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:49,032 INFO Layer 295: Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:49,035 INFO Pytorch tensor shape detected: 128x928 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:49,038 INFO Layer 295: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:49,040 INFO     Weight matrix 1/1 (128,928): Analyzing ...\n",
      "2018-11-26 12:50:50,540 INFO     Weight matrix 1/1 (128,928): Alpha: 2.8779688514734456, Alpha Weighted: 1.1389365775778024, D: 0.11607808567003658\n",
      "2018-11-26 12:50:50,544 INFO     Weight matrix 1/1 (128,928): Lognorm: 0.8731569051742554\n",
      "2018-11-26 12:50:50,547 INFO Layer 296: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:50,552 INFO Layer 296: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:50,559 INFO Layer 297: ReLU(inplace)\n",
      "2018-11-26 12:50:50,568 INFO Layer 297: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:50,572 INFO Layer 298: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:50,579 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:50,581 INFO Layer 298: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:50,587 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:50,595 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:50,601 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:50,607 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:50,611 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:50,615 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:50,623 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:50,629 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:50,634 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:50,640 INFO Layer 299: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:50,643 INFO Layer 299: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:50,647 INFO Layer 300: BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:50,650 INFO Layer 300: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:50,659 INFO Layer 301: ReLU(inplace)\n",
      "2018-11-26 12:50:50,665 INFO Layer 301: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:50,669 INFO Layer 302: Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:50,675 INFO Pytorch tensor shape detected: 128x960 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:50,678 INFO Layer 302: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:50,686 INFO     Weight matrix 1/1 (128,960): Analyzing ...\n",
      "2018-11-26 12:50:52,143 INFO     Weight matrix 1/1 (128,960): Alpha: 7.017961277500751, Alpha Weighted: 2.497547194538578, D: 0.11111111111111094\n",
      "2018-11-26 12:50:52,146 INFO     Weight matrix 1/1 (128,960): Alpha 7.017961277500751 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:52,150 INFO     Weight matrix 1/1 (128,960): Lognorm: 0.8773079514503479\n",
      "2018-11-26 12:50:52,156 INFO Layer 303: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:52,162 INFO Layer 303: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:52,166 INFO Layer 304: ReLU(inplace)\n",
      "2018-11-26 12:50:52,171 INFO Layer 304: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:52,176 INFO Layer 305: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:52,182 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:52,185 INFO Layer 305: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:52,188 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:52,191 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:52,194 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:52,202 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:52,208 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:52,220 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:52,225 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:52,232 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:52,236 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:52,241 INFO Layer 306: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:52,248 INFO Layer 306: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:52,251 INFO Layer 307: BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:52,258 INFO Layer 307: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:52,261 INFO Layer 308: ReLU(inplace)\n",
      "2018-11-26 12:50:52,265 INFO Layer 308: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:52,272 INFO Layer 309: Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:52,279 INFO Pytorch tensor shape detected: 128x992 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:52,283 INFO Layer 309: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:52,288 INFO     Weight matrix 1/1 (128,992): Analyzing ...\n",
      "2018-11-26 12:50:53,833 INFO     Weight matrix 1/1 (128,992): Alpha: 5.361488919179802, Alpha Weighted: 1.6233249435135044, D: 0.09601706046422215\n",
      "2018-11-26 12:50:53,837 INFO     Weight matrix 1/1 (128,992): Alpha 5.361488919179802 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:53,840 INFO     Weight matrix 1/1 (128,992): Lognorm: 0.873934805393219\n",
      "2018-11-26 12:50:53,842 INFO Layer 310: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:53,845 INFO Layer 310: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:53,849 INFO Layer 311: ReLU(inplace)\n",
      "2018-11-26 12:50:53,852 INFO Layer 311: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:53,855 INFO Layer 312: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:53,861 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:53,865 INFO Layer 312: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:53,868 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:53,872 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:53,875 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:53,879 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:53,885 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:53,888 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:53,893 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:53,895 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:53,899 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:53,903 INFO Layer 313: _Transition(\n",
      "  (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "2018-11-26 12:50:53,906 INFO Layer 313: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:53,909 INFO Layer 314: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:53,913 INFO Layer 314: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:53,917 INFO Layer 315: ReLU(inplace)\n",
      "2018-11-26 12:50:53,920 INFO Layer 315: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:53,923 INFO Layer 316: Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:53,939 INFO Pytorch tensor shape detected: 512x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:53,941 INFO Layer 316: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:53,943 INFO     Weight matrix 1/1 (512,1024): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:50:53,946 INFO Layer 317: AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "2018-11-26 12:50:53,950 INFO Layer 317: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:53,958 INFO Layer 318: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer7): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer8): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer9): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer10): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer11): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer12): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer13): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer14): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer15): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer16): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:53,962 INFO Layer 318: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:53,964 INFO Layer 319: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:53,967 INFO Layer 319: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:53,970 INFO Layer 320: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:53,973 INFO Layer 320: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:53,976 INFO Layer 321: ReLU(inplace)\n",
      "2018-11-26 12:50:53,978 INFO Layer 321: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:53,981 INFO Layer 322: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:53,985 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:53,989 INFO Layer 322: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:53,992 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 12:50:55,650 INFO     Weight matrix 1/1 (128,512): Alpha: 7.6186794989405895, Alpha Weighted: 1.1073703671442012, D: 0.09999999999999987\n",
      "2018-11-26 12:50:55,652 INFO     Weight matrix 1/1 (128,512): Alpha 7.6186794989405895 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:55,659 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.8213497400283813\n",
      "2018-11-26 12:50:55,665 INFO Layer 323: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:55,668 INFO Layer 323: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:55,671 INFO Layer 324: ReLU(inplace)\n",
      "2018-11-26 12:50:55,674 INFO Layer 324: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:55,676 INFO Layer 325: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:55,680 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:55,683 INFO Layer 325: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:55,686 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:55,690 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:55,692 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:55,696 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:55,699 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:55,704 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:55,707 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:55,711 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:55,715 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:55,719 INFO Layer 326: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:55,722 INFO Layer 326: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:55,726 INFO Layer 327: BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:55,728 INFO Layer 327: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:55,731 INFO Layer 328: ReLU(inplace)\n",
      "2018-11-26 12:50:55,734 INFO Layer 328: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:55,737 INFO Layer 329: Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:55,740 INFO Pytorch tensor shape detected: 128x544 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:55,745 INFO Layer 329: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:55,748 INFO     Weight matrix 1/1 (128,544): Analyzing ...\n",
      "2018-11-26 12:50:57,131 INFO     Weight matrix 1/1 (128,544): Alpha: 6.194094447198584, Alpha Weighted: 1.6209725764998422, D: 0.0898355374161946\n",
      "2018-11-26 12:50:57,133 INFO     Weight matrix 1/1 (128,544): Alpha 6.194094447198584 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:57,137 INFO     Weight matrix 1/1 (128,544): Lognorm: 0.8356072306632996\n",
      "2018-11-26 12:50:57,140 INFO Layer 330: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:57,143 INFO Layer 330: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:57,146 INFO Layer 331: ReLU(inplace)\n",
      "2018-11-26 12:50:57,153 INFO Layer 331: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:57,158 INFO Layer 332: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:57,161 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:57,166 INFO Layer 332: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:57,168 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:57,171 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:57,174 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:57,177 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:57,180 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:57,184 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:57,188 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:57,195 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:57,199 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:57,203 INFO Layer 333: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:57,205 INFO Layer 333: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:57,210 INFO Layer 334: BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:57,214 INFO Layer 334: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:57,218 INFO Layer 335: ReLU(inplace)\n",
      "2018-11-26 12:50:57,221 INFO Layer 335: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:57,224 INFO Layer 336: Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:57,227 INFO Pytorch tensor shape detected: 128x576 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:57,230 INFO Layer 336: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:57,233 INFO     Weight matrix 1/1 (128,576): Analyzing ...\n",
      "2018-11-26 12:50:58,446 INFO     Weight matrix 1/1 (128,576): Alpha: 5.9669455971042975, Alpha Weighted: 1.6289613995971013, D: 0.07692307692307676\n",
      "2018-11-26 12:50:58,449 INFO     Weight matrix 1/1 (128,576): Alpha 5.9669455971042975 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:50:58,453 INFO     Weight matrix 1/1 (128,576): Lognorm: 0.8379430174827576\n",
      "2018-11-26 12:50:58,456 INFO Layer 337: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:58,459 INFO Layer 337: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:58,462 INFO Layer 338: ReLU(inplace)\n",
      "2018-11-26 12:50:58,465 INFO Layer 338: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:58,468 INFO Layer 339: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:50:58,471 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:50:58,474 INFO Layer 339: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:50:58,477 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:58,479 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:58,482 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:50:58,485 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:58,488 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:58,492 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:58,494 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:58,496 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:58,499 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:50:58,501 INFO Layer 340: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:50:58,504 INFO Layer 340: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:58,507 INFO Layer 341: BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:50:58,510 INFO Layer 341: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:58,513 INFO Layer 342: ReLU(inplace)\n",
      "2018-11-26 12:50:58,516 INFO Layer 342: Skipping (Layer not supported)\n",
      "2018-11-26 12:50:58,520 INFO Layer 343: Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:50:58,524 INFO Pytorch tensor shape detected: 128x608 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:50:58,527 INFO Layer 343: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:50:58,529 INFO     Weight matrix 1/1 (128,608): Analyzing ...\n",
      "2018-11-26 12:51:00,042 INFO     Weight matrix 1/1 (128,608): Alpha: 5.7825565056501755, Alpha Weighted: 1.2409715051950387, D: 0.09815590113453299\n",
      "2018-11-26 12:51:00,045 INFO     Weight matrix 1/1 (128,608): Alpha 5.7825565056501755 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:00,048 INFO     Weight matrix 1/1 (128,608): Lognorm: 0.8247463703155518\n",
      "2018-11-26 12:51:00,051 INFO Layer 344: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:00,055 INFO Layer 344: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:00,057 INFO Layer 345: ReLU(inplace)\n",
      "2018-11-26 12:51:00,060 INFO Layer 345: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:00,063 INFO Layer 346: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:00,068 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:00,070 INFO Layer 346: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:00,074 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:00,077 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:00,079 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:00,082 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:00,085 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:00,087 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:00,090 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:00,092 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:00,095 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:00,098 INFO Layer 347: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:00,102 INFO Layer 347: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:00,106 INFO Layer 348: BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:00,109 INFO Layer 348: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:00,112 INFO Layer 349: ReLU(inplace)\n",
      "2018-11-26 12:51:00,118 INFO Layer 349: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:00,121 INFO Layer 350: Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:00,125 INFO Pytorch tensor shape detected: 128x640 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:00,128 INFO Layer 350: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:00,132 INFO     Weight matrix 1/1 (128,640): Analyzing ...\n",
      "2018-11-26 12:51:01,384 INFO     Weight matrix 1/1 (128,640): Alpha: 6.0727363212649745, Alpha Weighted: 2.062899379639133, D: 0.09999999999999987\n",
      "2018-11-26 12:51:01,387 INFO     Weight matrix 1/1 (128,640): Alpha 6.0727363212649745 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:01,390 INFO     Weight matrix 1/1 (128,640): Lognorm: 0.8270646333694458\n",
      "2018-11-26 12:51:01,394 INFO Layer 351: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:01,396 INFO Layer 351: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:01,400 INFO Layer 352: ReLU(inplace)\n",
      "2018-11-26 12:51:01,403 INFO Layer 352: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:01,408 INFO Layer 353: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:01,412 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:01,415 INFO Layer 353: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:01,419 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:01,423 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:01,426 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:01,430 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:01,433 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:01,436 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:01,438 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:01,443 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:01,445 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:01,448 INFO Layer 354: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:01,450 INFO Layer 354: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:01,453 INFO Layer 355: BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:01,456 INFO Layer 355: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:01,462 INFO Layer 356: ReLU(inplace)\n",
      "2018-11-26 12:51:01,466 INFO Layer 356: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:01,471 INFO Layer 357: Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:01,492 INFO Pytorch tensor shape detected: 128x672 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:01,495 INFO Layer 357: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:01,497 INFO     Weight matrix 1/1 (128,672): Analyzing ...\n",
      "2018-11-26 12:51:02,868 INFO     Weight matrix 1/1 (128,672): Alpha: 4.925074259726942, Alpha Weighted: 2.1969559857548275, D: 0.06427255560681225\n",
      "2018-11-26 12:51:02,871 INFO     Weight matrix 1/1 (128,672): Alpha 4.925074259726942 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:02,874 INFO     Weight matrix 1/1 (128,672): Lognorm: 0.8531308174133301\n",
      "2018-11-26 12:51:02,877 INFO Layer 358: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:02,881 INFO Layer 358: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:02,885 INFO Layer 359: ReLU(inplace)\n",
      "2018-11-26 12:51:02,888 INFO Layer 359: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:02,890 INFO Layer 360: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:02,893 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:02,897 INFO Layer 360: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:02,901 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:02,905 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:02,909 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:02,913 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:02,916 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:02,923 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:02,927 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:02,931 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:02,934 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:02,938 INFO Layer 361: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:02,940 INFO Layer 361: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:02,944 INFO Layer 362: BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:02,947 INFO Layer 362: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:02,951 INFO Layer 363: ReLU(inplace)\n",
      "2018-11-26 12:51:02,954 INFO Layer 363: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:02,958 INFO Layer 364: Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:02,962 INFO Pytorch tensor shape detected: 128x704 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:02,965 INFO Layer 364: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:02,968 INFO     Weight matrix 1/1 (128,704): Analyzing ...\n",
      "2018-11-26 12:51:04,404 INFO     Weight matrix 1/1 (128,704): Alpha: 6.442710057997228, Alpha Weighted: 1.3747072242064653, D: 0.08086079237072297\n",
      "2018-11-26 12:51:04,406 INFO     Weight matrix 1/1 (128,704): Alpha 6.442710057997228 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:04,412 INFO     Weight matrix 1/1 (128,704): Lognorm: 0.8277413249015808\n",
      "2018-11-26 12:51:04,416 INFO Layer 365: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:04,422 INFO Layer 365: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:04,425 INFO Layer 366: ReLU(inplace)\n",
      "2018-11-26 12:51:04,428 INFO Layer 366: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:04,431 INFO Layer 367: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:04,434 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:04,437 INFO Layer 367: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:04,441 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:04,445 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:04,448 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:04,454 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:04,461 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:04,468 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:04,474 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:04,482 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:04,485 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:04,489 INFO Layer 368: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:04,494 INFO Layer 368: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:04,497 INFO Layer 369: BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:04,512 INFO Layer 369: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:04,516 INFO Layer 370: ReLU(inplace)\n",
      "2018-11-26 12:51:04,521 INFO Layer 370: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:04,523 INFO Layer 371: Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:04,530 INFO Pytorch tensor shape detected: 128x736 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:04,534 INFO Layer 371: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:04,538 INFO     Weight matrix 1/1 (128,736): Analyzing ...\n",
      "2018-11-26 12:51:05,797 INFO     Weight matrix 1/1 (128,736): Alpha: 5.056364420292422, Alpha Weighted: 1.5702955830073748, D: 0.09303436328904185\n",
      "2018-11-26 12:51:05,800 INFO     Weight matrix 1/1 (128,736): Alpha 5.056364420292422 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:05,805 INFO     Weight matrix 1/1 (128,736): Lognorm: 0.8333000540733337\n",
      "2018-11-26 12:51:05,810 INFO Layer 372: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:05,815 INFO Layer 372: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:05,818 INFO Layer 373: ReLU(inplace)\n",
      "2018-11-26 12:51:05,822 INFO Layer 373: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:05,826 INFO Layer 374: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:05,830 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:05,833 INFO Layer 374: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:05,837 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:05,841 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:05,844 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:05,848 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:05,852 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:05,856 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:05,860 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:05,865 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:05,872 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:05,876 INFO Layer 375: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:05,879 INFO Layer 375: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:05,882 INFO Layer 376: BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:05,887 INFO Layer 376: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:05,890 INFO Layer 377: ReLU(inplace)\n",
      "2018-11-26 12:51:05,893 INFO Layer 377: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:05,896 INFO Layer 378: Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:05,903 INFO Pytorch tensor shape detected: 128x768 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:05,909 INFO Layer 378: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:05,913 INFO     Weight matrix 1/1 (128,768): Analyzing ...\n",
      "2018-11-26 12:51:07,128 INFO     Weight matrix 1/1 (128,768): Alpha: 5.497456241401422, Alpha Weighted: 1.5866115694606486, D: 0.07142857142857129\n",
      "2018-11-26 12:51:07,130 INFO     Weight matrix 1/1 (128,768): Alpha 5.497456241401422 is in the danger zone (1.5,3.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:07,133 INFO     Weight matrix 1/1 (128,768): Lognorm: 0.8277435302734375\n",
      "2018-11-26 12:51:07,139 INFO Layer 379: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:07,141 INFO Layer 379: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:07,144 INFO Layer 380: ReLU(inplace)\n",
      "2018-11-26 12:51:07,146 INFO Layer 380: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:07,149 INFO Layer 381: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:07,155 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:07,157 INFO Layer 381: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:07,160 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:07,163 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:07,166 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:07,169 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:07,173 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:07,175 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:07,178 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:07,180 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:07,183 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:07,186 INFO Layer 382: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:07,189 INFO Layer 382: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:07,192 INFO Layer 383: BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:07,195 INFO Layer 383: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:07,198 INFO Layer 384: ReLU(inplace)\n",
      "2018-11-26 12:51:07,200 INFO Layer 384: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:07,202 INFO Layer 385: Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:07,207 INFO Pytorch tensor shape detected: 128x800 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:07,213 INFO Layer 385: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:07,216 INFO     Weight matrix 1/1 (128,800): Analyzing ...\n",
      "2018-11-26 12:51:08,496 INFO     Weight matrix 1/1 (128,800): Alpha: 6.041507829723641, Alpha Weighted: 1.7800925813727697, D: 0.06666666666666654\n",
      "2018-11-26 12:51:08,499 INFO     Weight matrix 1/1 (128,800): Alpha 6.041507829723641 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:08,506 INFO     Weight matrix 1/1 (128,800): Lognorm: 0.8320222496986389\n",
      "2018-11-26 12:51:08,513 INFO Layer 386: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:08,517 INFO Layer 386: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:08,520 INFO Layer 387: ReLU(inplace)\n",
      "2018-11-26 12:51:08,524 INFO Layer 387: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:08,529 INFO Layer 388: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:08,536 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:08,541 INFO Layer 388: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:08,546 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:08,551 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:08,564 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:08,567 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:08,572 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:08,576 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:08,584 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:08,589 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:08,595 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:08,599 INFO Layer 389: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:08,603 INFO Layer 389: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:08,607 INFO Layer 390: BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:08,620 INFO Layer 390: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:08,623 INFO Layer 391: ReLU(inplace)\n",
      "2018-11-26 12:51:08,627 INFO Layer 391: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:08,632 INFO Layer 392: Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:08,641 INFO Pytorch tensor shape detected: 128x832 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:08,643 INFO Layer 392: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:08,650 INFO     Weight matrix 1/1 (128,832): Analyzing ...\n",
      "2018-11-26 12:51:09,818 INFO     Weight matrix 1/1 (128,832): Alpha: 5.59953507224407, Alpha Weighted: 1.6435002918273753, D: 0.08242203096412959\n",
      "2018-11-26 12:51:09,821 INFO     Weight matrix 1/1 (128,832): Alpha 5.59953507224407 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:09,824 INFO     Weight matrix 1/1 (128,832): Lognorm: 0.8372523188591003\n",
      "2018-11-26 12:51:09,827 INFO Layer 393: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:09,829 INFO Layer 393: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:09,833 INFO Layer 394: ReLU(inplace)\n",
      "2018-11-26 12:51:09,835 INFO Layer 394: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:09,838 INFO Layer 395: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:09,842 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:09,844 INFO Layer 395: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:09,847 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:09,850 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:09,854 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:09,856 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:09,859 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:09,862 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:09,865 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:09,869 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:09,875 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:09,879 INFO Layer 396: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:09,882 INFO Layer 396: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:09,884 INFO Layer 397: BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:09,886 INFO Layer 397: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:09,888 INFO Layer 398: ReLU(inplace)\n",
      "2018-11-26 12:51:09,891 INFO Layer 398: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:09,893 INFO Layer 399: Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:09,897 INFO Pytorch tensor shape detected: 128x864 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:09,900 INFO Layer 399: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:09,904 INFO     Weight matrix 1/1 (128,864): Analyzing ...\n",
      "2018-11-26 12:51:11,198 INFO     Weight matrix 1/1 (128,864): Alpha: 5.249576860084428, Alpha Weighted: 1.4212038041433637, D: 0.07594115090033282\n",
      "2018-11-26 12:51:11,201 INFO     Weight matrix 1/1 (128,864): Alpha 5.249576860084428 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:11,205 INFO     Weight matrix 1/1 (128,864): Lognorm: 0.8359741568565369\n",
      "2018-11-26 12:51:11,209 INFO Layer 400: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:11,211 INFO Layer 400: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:11,215 INFO Layer 401: ReLU(inplace)\n",
      "2018-11-26 12:51:11,218 INFO Layer 401: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:11,222 INFO Layer 402: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:11,226 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:11,229 INFO Layer 402: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:11,232 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:11,237 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:11,240 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:11,244 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:11,247 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:11,253 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:11,256 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:11,260 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:11,265 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:11,268 INFO Layer 403: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:11,273 INFO Layer 403: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:11,276 INFO Layer 404: BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:11,279 INFO Layer 404: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:11,286 INFO Layer 405: ReLU(inplace)\n",
      "2018-11-26 12:51:11,288 INFO Layer 405: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:11,292 INFO Layer 406: Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:11,299 INFO Pytorch tensor shape detected: 128x896 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:11,302 INFO Layer 406: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:11,305 INFO     Weight matrix 1/1 (128,896): Analyzing ...\n",
      "2018-11-26 12:51:12,649 INFO     Weight matrix 1/1 (128,896): Alpha: 5.796381601975489, Alpha Weighted: 1.9552221401776666, D: 0.08333333333333315\n",
      "2018-11-26 12:51:12,652 INFO     Weight matrix 1/1 (128,896): Alpha 5.796381601975489 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:12,658 INFO     Weight matrix 1/1 (128,896): Lognorm: 0.8387634754180908\n",
      "2018-11-26 12:51:12,661 INFO Layer 407: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:12,663 INFO Layer 407: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:12,667 INFO Layer 408: ReLU(inplace)\n",
      "2018-11-26 12:51:12,670 INFO Layer 408: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:12,678 INFO Layer 409: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:12,682 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:12,685 INFO Layer 409: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:12,688 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:12,692 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:12,695 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:12,700 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:12,705 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:12,710 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:12,712 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:12,715 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:12,723 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:12,728 INFO Layer 410: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:12,731 INFO Layer 410: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:12,735 INFO Layer 411: BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:12,738 INFO Layer 411: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:12,740 INFO Layer 412: ReLU(inplace)\n",
      "2018-11-26 12:51:12,743 INFO Layer 412: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:12,745 INFO Layer 413: Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:12,749 INFO Pytorch tensor shape detected: 128x928 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:12,753 INFO Layer 413: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:12,758 INFO     Weight matrix 1/1 (128,928): Analyzing ...\n",
      "2018-11-26 12:51:14,193 INFO     Weight matrix 1/1 (128,928): Alpha: 5.070701510401034, Alpha Weighted: 1.443538080476963, D: 0.11027391435347933\n",
      "2018-11-26 12:51:14,196 INFO     Weight matrix 1/1 (128,928): Alpha 5.070701510401034 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:14,199 INFO     Weight matrix 1/1 (128,928): Lognorm: 0.8392280340194702\n",
      "2018-11-26 12:51:14,202 INFO Layer 414: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:14,205 INFO Layer 414: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:14,208 INFO Layer 415: ReLU(inplace)\n",
      "2018-11-26 12:51:14,211 INFO Layer 415: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:14,215 INFO Layer 416: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:14,221 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:14,225 INFO Layer 416: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:14,228 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:14,230 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:14,234 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:14,237 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:14,240 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:14,244 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:14,246 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:14,249 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:14,252 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:14,256 INFO Layer 417: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:14,258 INFO Layer 417: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:14,261 INFO Layer 418: BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:14,265 INFO Layer 418: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:14,268 INFO Layer 419: ReLU(inplace)\n",
      "2018-11-26 12:51:14,272 INFO Layer 419: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:14,275 INFO Layer 420: Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:14,281 INFO Pytorch tensor shape detected: 128x960 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:14,284 INFO Layer 420: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:14,287 INFO     Weight matrix 1/1 (128,960): Analyzing ...\n",
      "2018-11-26 12:51:15,669 INFO     Weight matrix 1/1 (128,960): Alpha: 6.225426103435561, Alpha Weighted: 1.8866082158395694, D: 0.09090909090909083\n",
      "2018-11-26 12:51:15,672 INFO     Weight matrix 1/1 (128,960): Alpha 6.225426103435561 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:15,675 INFO     Weight matrix 1/1 (128,960): Lognorm: 0.8404957056045532\n",
      "2018-11-26 12:51:15,678 INFO Layer 421: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:15,681 INFO Layer 421: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:15,684 INFO Layer 422: ReLU(inplace)\n",
      "2018-11-26 12:51:15,687 INFO Layer 422: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:15,690 INFO Layer 423: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:15,694 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:15,697 INFO Layer 423: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:15,700 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:15,704 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:15,707 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:15,711 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:15,715 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:15,720 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:15,723 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:15,728 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:15,732 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:15,737 INFO Layer 424: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:15,740 INFO Layer 424: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:15,743 INFO Layer 425: BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:15,747 INFO Layer 425: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:15,750 INFO Layer 426: ReLU(inplace)\n",
      "2018-11-26 12:51:15,753 INFO Layer 426: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:15,760 INFO Layer 427: Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:15,765 INFO Pytorch tensor shape detected: 128x992 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:15,769 INFO Layer 427: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:15,772 INFO     Weight matrix 1/1 (128,992): Analyzing ...\n",
      "2018-11-26 12:51:17,165 INFO     Weight matrix 1/1 (128,992): Alpha: 5.095758999123086, Alpha Weighted: 1.637913249944753, D: 0.08406684853152957\n",
      "2018-11-26 12:51:17,168 INFO     Weight matrix 1/1 (128,992): Alpha 5.095758999123086 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:17,173 INFO     Weight matrix 1/1 (128,992): Lognorm: 0.8579921126365662\n",
      "2018-11-26 12:51:17,176 INFO Layer 428: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:17,179 INFO Layer 428: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:17,182 INFO Layer 429: ReLU(inplace)\n",
      "2018-11-26 12:51:17,187 INFO Layer 429: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:17,190 INFO Layer 430: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:17,193 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:17,197 INFO Layer 430: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:17,207 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:17,210 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:17,215 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:17,218 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:17,223 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:17,229 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:17,231 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:17,238 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:17,243 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:51:17,246 INFO Layer 431: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:17,249 INFO Layer 431: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:17,252 INFO Layer 432: Linear(in_features=1024, out_features=1000, bias=True)\n",
      "2018-11-26 12:51:17,281 INFO Layer 432: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:17,284 INFO     Weight matrix 1/1 (1000,1024): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:51:17,288 INFO ### Printing results ###\n",
      "2018-11-26 12:51:17,290 DEBUG Layer 10: Lognorm: 0.709526777267456\n",
      "2018-11-26 12:51:17,293 DEBUG Layer 17: Lognorm: 0.7301000952720642\n",
      "2018-11-26 12:51:17,296 DEBUG Layer 24: Lognorm: 0.7291272878646851\n",
      "2018-11-26 12:51:17,306 DEBUG Layer 31: Lognorm: 0.7076682448387146\n",
      "2018-11-26 12:51:17,310 DEBUG Layer 38: Lognorm: 0.6634426712989807\n",
      "2018-11-26 12:51:17,314 DEBUG Layer 45: Lognorm: 0.766674816608429\n",
      "2018-11-26 12:51:17,319 DEBUG Layer 52: Lognorm: 1.033071756362915\n",
      "2018-11-26 12:51:17,324 DEBUG Layer 58: Lognorm: 0.4764324724674225\n",
      "2018-11-26 12:51:17,331 DEBUG Layer 65: Lognorm: 0.598200798034668\n",
      "2018-11-26 12:51:17,335 DEBUG Layer 72: Lognorm: 0.6384468078613281\n",
      "2018-11-26 12:51:17,340 DEBUG Layer 79: Lognorm: 0.7061021327972412\n",
      "2018-11-26 12:51:17,347 DEBUG Layer 86: Lognorm: 0.6841765642166138\n",
      "2018-11-26 12:51:17,356 DEBUG Layer 93: Lognorm: 0.7083194851875305\n",
      "2018-11-26 12:51:17,359 DEBUG Layer 100: Lognorm: 0.7466636300086975\n",
      "2018-11-26 12:51:17,364 DEBUG Layer 107: Lognorm: 0.7385070323944092\n",
      "2018-11-26 12:51:17,369 DEBUG Layer 114: Lognorm: 0.7641022801399231\n",
      "2018-11-26 12:51:17,373 DEBUG Layer 121: Lognorm: 0.8047155141830444\n",
      "2018-11-26 12:51:17,376 DEBUG Layer 128: Lognorm: 0.793705940246582\n",
      "2018-11-26 12:51:17,382 DEBUG Layer 135: Lognorm: 0.8326336145401001\n",
      "2018-11-26 12:51:17,385 DEBUG Layer 142: Lognorm: 1.1703954935073853\n",
      "2018-11-26 12:51:17,390 DEBUG Layer 148: Lognorm: 0.6184055209159851\n",
      "2018-11-26 12:51:17,393 DEBUG Layer 155: Lognorm: 0.6271429657936096\n",
      "2018-11-26 12:51:17,397 DEBUG Layer 162: Lognorm: 0.6755089163780212\n",
      "2018-11-26 12:51:17,400 DEBUG Layer 169: Lognorm: 0.6975308656692505\n",
      "2018-11-26 12:51:17,406 DEBUG Layer 176: Lognorm: 0.6815582513809204\n",
      "2018-11-26 12:51:17,413 DEBUG Layer 183: Lognorm: 0.732858419418335\n",
      "2018-11-26 12:51:17,415 DEBUG Layer 190: Lognorm: 0.693450391292572\n",
      "2018-11-26 12:51:17,419 DEBUG Layer 197: Lognorm: 0.7797842025756836\n",
      "2018-11-26 12:51:17,422 DEBUG Layer 204: Lognorm: 0.7929549217224121\n",
      "2018-11-26 12:51:17,425 DEBUG Layer 211: Lognorm: 0.7338912487030029\n",
      "2018-11-26 12:51:17,428 DEBUG Layer 218: Lognorm: 0.7607789635658264\n",
      "2018-11-26 12:51:17,431 DEBUG Layer 225: Lognorm: 0.7940155267715454\n",
      "2018-11-26 12:51:17,435 DEBUG Layer 232: Lognorm: 0.764450192451477\n",
      "2018-11-26 12:51:17,439 DEBUG Layer 239: Lognorm: 0.7673153281211853\n",
      "2018-11-26 12:51:17,445 DEBUG Layer 246: Lognorm: 0.8156046271324158\n",
      "2018-11-26 12:51:17,449 DEBUG Layer 253: Lognorm: 0.7965323328971863\n",
      "2018-11-26 12:51:17,457 DEBUG Layer 260: Lognorm: 0.8472602963447571\n",
      "2018-11-26 12:51:17,459 DEBUG Layer 267: Lognorm: 0.8362366557121277\n",
      "2018-11-26 12:51:17,463 DEBUG Layer 274: Lognorm: 0.8550697565078735\n",
      "2018-11-26 12:51:17,467 DEBUG Layer 281: Lognorm: 0.8518842458724976\n",
      "2018-11-26 12:51:17,475 DEBUG Layer 288: Lognorm: 0.8671711683273315\n",
      "2018-11-26 12:51:17,478 DEBUG Layer 295: Lognorm: 0.8731569051742554\n",
      "2018-11-26 12:51:17,481 DEBUG Layer 302: Lognorm: 0.8773079514503479\n",
      "2018-11-26 12:51:17,485 DEBUG Layer 309: Lognorm: 0.873934805393219\n",
      "2018-11-26 12:51:17,491 DEBUG Layer 322: Lognorm: 0.8213497400283813\n",
      "2018-11-26 12:51:17,495 DEBUG Layer 329: Lognorm: 0.8356072306632996\n",
      "2018-11-26 12:51:17,501 DEBUG Layer 336: Lognorm: 0.8379430174827576\n",
      "2018-11-26 12:51:17,503 DEBUG Layer 343: Lognorm: 0.8247463703155518\n",
      "2018-11-26 12:51:17,510 DEBUG Layer 350: Lognorm: 0.8270646333694458\n",
      "2018-11-26 12:51:17,513 DEBUG Layer 357: Lognorm: 0.8531308174133301\n",
      "2018-11-26 12:51:17,518 DEBUG Layer 364: Lognorm: 0.8277413249015808\n",
      "2018-11-26 12:51:17,524 DEBUG Layer 371: Lognorm: 0.8333000540733337\n",
      "2018-11-26 12:51:17,532 DEBUG Layer 378: Lognorm: 0.8277435302734375\n",
      "2018-11-26 12:51:17,536 DEBUG Layer 385: Lognorm: 0.8320222496986389\n",
      "2018-11-26 12:51:17,540 DEBUG Layer 392: Lognorm: 0.8372523188591003\n",
      "2018-11-26 12:51:17,544 DEBUG Layer 399: Lognorm: 0.8359741568565369\n",
      "2018-11-26 12:51:17,547 DEBUG Layer 406: Lognorm: 0.8387634754180908\n",
      "2018-11-26 12:51:17,552 DEBUG Layer 413: Lognorm: 0.8392280340194702\n",
      "2018-11-26 12:51:17,555 DEBUG Layer 420: Lognorm: 0.8404957056045532\n",
      "2018-11-26 12:51:17,562 DEBUG Layer 427: Lognorm: 0.8579921126365662\n",
      "2018-11-26 12:51:17,566 INFO LogNorm: min: 0.4764324724674225, max: 1.1703954935073853, avg: 0.7831028699874878\n",
      "2018-11-26 12:51:17,570 INFO LogNorm compound: min: 0.4764324724674225, max: 1.1703954935073853, avg: 0.7831028774380684\n",
      "2018-11-26 12:51:17,573 DEBUG Layer 10: Alpha: 1.3668460840132695\n",
      "2018-11-26 12:51:17,577 DEBUG Layer 17: Alpha: 1.4743413466988615\n",
      "2018-11-26 12:51:17,580 DEBUG Layer 24: Alpha: 2.652969717491138\n",
      "2018-11-26 12:51:17,582 DEBUG Layer 31: Alpha: 3.681430475331508\n",
      "2018-11-26 12:51:17,585 DEBUG Layer 38: Alpha: 4.541338909120677\n",
      "2018-11-26 12:51:17,588 DEBUG Layer 45: Alpha: 6.899438229738612\n",
      "2018-11-26 12:51:17,593 DEBUG Layer 52: Alpha: 4.728791683628474\n",
      "2018-11-26 12:51:17,596 DEBUG Layer 58: Alpha: 1.4750179780911636\n",
      "2018-11-26 12:51:17,599 DEBUG Layer 65: Alpha: 1.478385860010596\n",
      "2018-11-26 12:51:17,602 DEBUG Layer 72: Alpha: 1.5206465027230485\n",
      "2018-11-26 12:51:17,605 DEBUG Layer 79: Alpha: 1.8894357293704198\n",
      "2018-11-26 12:51:17,611 DEBUG Layer 86: Alpha: 1.8087565900700295\n",
      "2018-11-26 12:51:17,615 DEBUG Layer 93: Alpha: 6.021136485029262\n",
      "2018-11-26 12:51:17,619 DEBUG Layer 100: Alpha: 2.242117210674278\n",
      "2018-11-26 12:51:17,622 DEBUG Layer 107: Alpha: 3.0542302154673213\n",
      "2018-11-26 12:51:17,628 DEBUG Layer 114: Alpha: 4.020770555155709\n",
      "2018-11-26 12:51:17,634 DEBUG Layer 121: Alpha: 2.429381672255332\n",
      "2018-11-26 12:51:17,642 DEBUG Layer 128: Alpha: 3.5514356306430743\n",
      "2018-11-26 12:51:17,645 DEBUG Layer 135: Alpha: 6.550383167809261\n",
      "2018-11-26 12:51:17,654 DEBUG Layer 142: Alpha: 5.347566209735007\n",
      "2018-11-26 12:51:17,662 DEBUG Layer 148: Alpha: 1.9326885966736622\n",
      "2018-11-26 12:51:17,669 DEBUG Layer 155: Alpha: 4.340126284679503\n",
      "2018-11-26 12:51:17,672 DEBUG Layer 162: Alpha: 3.4097227431983357\n",
      "2018-11-26 12:51:17,676 DEBUG Layer 169: Alpha: 5.183769114100147\n",
      "2018-11-26 12:51:17,680 DEBUG Layer 176: Alpha: 7.023843523022496\n",
      "2018-11-26 12:51:17,684 DEBUG Layer 183: Alpha: 3.335676862284965\n",
      "2018-11-26 12:51:17,692 DEBUG Layer 190: Alpha: 1.8350038795667436\n",
      "2018-11-26 12:51:17,695 DEBUG Layer 197: Alpha: 3.558890313038112\n",
      "2018-11-26 12:51:17,709 DEBUG Layer 204: Alpha: 3.6853682769007112\n",
      "2018-11-26 12:51:17,712 DEBUG Layer 211: Alpha: 2.21144032220666\n",
      "2018-11-26 12:51:17,716 DEBUG Layer 218: Alpha: 6.22817119030097\n",
      "2018-11-26 12:51:17,719 DEBUG Layer 225: Alpha: 3.042524416134094\n",
      "2018-11-26 12:51:17,723 DEBUG Layer 232: Alpha: 2.230120422975948\n",
      "2018-11-26 12:51:17,728 DEBUG Layer 239: Alpha: 3.1456928080735893\n",
      "2018-11-26 12:51:17,733 DEBUG Layer 246: Alpha: 8.112021422482236\n",
      "2018-11-26 12:51:17,737 DEBUG Layer 253: Alpha: 5.027632505731705\n",
      "2018-11-26 12:51:17,743 DEBUG Layer 260: Alpha: 2.7657890029596963\n",
      "2018-11-26 12:51:17,750 DEBUG Layer 267: Alpha: 3.729422214332309\n",
      "2018-11-26 12:51:17,758 DEBUG Layer 274: Alpha: 2.6266989220860584\n",
      "2018-11-26 12:51:17,760 DEBUG Layer 281: Alpha: 4.716730746163366\n",
      "2018-11-26 12:51:17,763 DEBUG Layer 288: Alpha: 3.6265808219729028\n",
      "2018-11-26 12:51:17,765 DEBUG Layer 295: Alpha: 2.8779688514734456\n",
      "2018-11-26 12:51:17,768 DEBUG Layer 302: Alpha: 7.017961277500751\n",
      "2018-11-26 12:51:17,771 DEBUG Layer 309: Alpha: 5.361488919179802\n",
      "2018-11-26 12:51:17,773 DEBUG Layer 322: Alpha: 7.6186794989405895\n",
      "2018-11-26 12:51:17,775 DEBUG Layer 329: Alpha: 6.194094447198584\n",
      "2018-11-26 12:51:17,777 DEBUG Layer 336: Alpha: 5.9669455971042975\n",
      "2018-11-26 12:51:17,780 DEBUG Layer 343: Alpha: 5.7825565056501755\n",
      "2018-11-26 12:51:17,783 DEBUG Layer 350: Alpha: 6.0727363212649745\n",
      "2018-11-26 12:51:17,788 DEBUG Layer 357: Alpha: 4.925074259726942\n",
      "2018-11-26 12:51:17,790 DEBUG Layer 364: Alpha: 6.442710057997228\n",
      "2018-11-26 12:51:17,793 DEBUG Layer 371: Alpha: 5.056364420292422\n",
      "2018-11-26 12:51:17,795 DEBUG Layer 378: Alpha: 5.497456241401422\n",
      "2018-11-26 12:51:17,799 DEBUG Layer 385: Alpha: 6.041507829723641\n",
      "2018-11-26 12:51:17,801 DEBUG Layer 392: Alpha: 5.59953507224407\n",
      "2018-11-26 12:51:17,805 DEBUG Layer 399: Alpha: 5.249576860084428\n",
      "2018-11-26 12:51:17,807 DEBUG Layer 406: Alpha: 5.796381601975489\n",
      "2018-11-26 12:51:17,809 DEBUG Layer 413: Alpha: 5.070701510401034\n",
      "2018-11-26 12:51:17,813 DEBUG Layer 420: Alpha: 6.225426103435561\n",
      "2018-11-26 12:51:17,815 DEBUG Layer 427: Alpha: 5.095758999123086\n",
      "2018-11-26 12:51:17,817 INFO Alpha: min: 1.3668460840132695, max: 8.112021422482236, avg: 4.273254316944319\n",
      "2018-11-26 12:51:17,820 INFO Alpha compound: min: 1.3668460840132695, max: 8.112021422482236, avg: 4.273254316944319\n",
      "2018-11-26 12:51:17,824 DEBUG Layer 10: Alpha Weigthed: 0.4280255137910998\n",
      "2018-11-26 12:51:17,830 DEBUG Layer 17: Alpha Weigthed: 0.5642373262187819\n",
      "2018-11-26 12:51:17,833 DEBUG Layer 24: Alpha Weigthed: 0.6473188070893642\n",
      "2018-11-26 12:51:17,835 DEBUG Layer 31: Alpha Weigthed: 0.7929452181953638\n",
      "2018-11-26 12:51:17,837 DEBUG Layer 38: Alpha Weigthed: 0.5665688905107779\n",
      "2018-11-26 12:51:17,839 DEBUG Layer 45: Alpha Weigthed: 2.2829355810852054\n",
      "2018-11-26 12:51:17,842 DEBUG Layer 52: Alpha Weigthed: 3.6784390190162175\n",
      "2018-11-26 12:51:17,844 DEBUG Layer 58: Alpha Weigthed: 0.02715868976033257\n",
      "2018-11-26 12:51:17,847 DEBUG Layer 65: Alpha Weigthed: 0.043118546865504113\n",
      "2018-11-26 12:51:17,850 DEBUG Layer 72: Alpha Weigthed: 0.120804947100643\n",
      "2018-11-26 12:51:17,853 DEBUG Layer 79: Alpha Weigthed: 0.43839556015288794\n",
      "2018-11-26 12:51:17,856 DEBUG Layer 86: Alpha Weigthed: 0.3042906737467894\n",
      "2018-11-26 12:51:17,861 DEBUG Layer 93: Alpha Weigthed: 1.6248441495236794\n",
      "2018-11-26 12:51:17,863 DEBUG Layer 100: Alpha Weigthed: 0.3099542470051873\n",
      "2018-11-26 12:51:17,866 DEBUG Layer 107: Alpha Weigthed: 0.8892770040792306\n",
      "2018-11-26 12:51:17,868 DEBUG Layer 114: Alpha Weigthed: 1.3518436891619103\n",
      "2018-11-26 12:51:17,870 DEBUG Layer 121: Alpha Weigthed: 0.5428853486164292\n",
      "2018-11-26 12:51:17,873 DEBUG Layer 128: Alpha Weigthed: 1.202579537689644\n",
      "2018-11-26 12:51:17,875 DEBUG Layer 135: Alpha Weigthed: 2.135368723112505\n",
      "2018-11-26 12:51:17,878 DEBUG Layer 142: Alpha Weigthed: 3.5047447349279244\n",
      "2018-11-26 12:51:17,881 DEBUG Layer 148: Alpha Weigthed: 0.008693578495666087\n",
      "2018-11-26 12:51:17,884 DEBUG Layer 155: Alpha Weigthed: 0.21034127170533667\n",
      "2018-11-26 12:51:17,886 DEBUG Layer 162: Alpha Weigthed: 0.07451059404262196\n",
      "2018-11-26 12:51:17,889 DEBUG Layer 169: Alpha Weigthed: 0.636770501551651\n",
      "2018-11-26 12:51:17,891 DEBUG Layer 176: Alpha Weigthed: 0.09327145183955246\n",
      "2018-11-26 12:51:17,893 DEBUG Layer 183: Alpha Weigthed: 0.9433768983303495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:17,895 DEBUG Layer 190: Alpha Weigthed: 0.08332471621774798\n",
      "2018-11-26 12:51:17,898 DEBUG Layer 197: Alpha Weigthed: 0.6545547514011743\n",
      "2018-11-26 12:51:17,901 DEBUG Layer 204: Alpha Weigthed: 1.0129943529571799\n",
      "2018-11-26 12:51:17,904 DEBUG Layer 211: Alpha Weigthed: 0.14068585470723957\n",
      "2018-11-26 12:51:17,906 DEBUG Layer 218: Alpha Weigthed: 1.1225601324553132\n",
      "2018-11-26 12:51:17,909 DEBUG Layer 225: Alpha Weigthed: 0.5384996226319526\n",
      "2018-11-26 12:51:17,912 DEBUG Layer 232: Alpha Weigthed: 0.17757032140272686\n",
      "2018-11-26 12:51:17,915 DEBUG Layer 239: Alpha Weigthed: 0.6788712177387202\n",
      "2018-11-26 12:51:17,918 DEBUG Layer 246: Alpha Weigthed: 1.4467061437055695\n",
      "2018-11-26 12:51:17,921 DEBUG Layer 253: Alpha Weigthed: 0.6479750327785241\n",
      "2018-11-26 12:51:17,924 DEBUG Layer 260: Alpha Weigthed: 1.0162566897597503\n",
      "2018-11-26 12:51:17,927 DEBUG Layer 267: Alpha Weigthed: 0.7631258908498614\n",
      "2018-11-26 12:51:17,931 DEBUG Layer 274: Alpha Weigthed: 0.6716531563745269\n",
      "2018-11-26 12:51:17,934 DEBUG Layer 281: Alpha Weigthed: 1.5198248293486138\n",
      "2018-11-26 12:51:17,937 DEBUG Layer 288: Alpha Weigthed: 1.3192456581590486\n",
      "2018-11-26 12:51:17,939 DEBUG Layer 295: Alpha Weigthed: 1.1389365775778024\n",
      "2018-11-26 12:51:17,942 DEBUG Layer 302: Alpha Weigthed: 2.497547194538578\n",
      "2018-11-26 12:51:17,945 DEBUG Layer 309: Alpha Weigthed: 1.6233249435135044\n",
      "2018-11-26 12:51:17,949 DEBUG Layer 322: Alpha Weigthed: 1.1073703671442012\n",
      "2018-11-26 12:51:17,954 DEBUG Layer 329: Alpha Weigthed: 1.6209725764998422\n",
      "2018-11-26 12:51:17,956 DEBUG Layer 336: Alpha Weigthed: 1.6289613995971013\n",
      "2018-11-26 12:51:17,959 DEBUG Layer 343: Alpha Weigthed: 1.2409715051950387\n",
      "2018-11-26 12:51:17,962 DEBUG Layer 350: Alpha Weigthed: 2.062899379639133\n",
      "2018-11-26 12:51:17,965 DEBUG Layer 357: Alpha Weigthed: 2.1969559857548275\n",
      "2018-11-26 12:51:17,970 DEBUG Layer 364: Alpha Weigthed: 1.3747072242064653\n",
      "2018-11-26 12:51:17,974 DEBUG Layer 371: Alpha Weigthed: 1.5702955830073748\n",
      "2018-11-26 12:51:17,978 DEBUG Layer 378: Alpha Weigthed: 1.5866115694606486\n",
      "2018-11-26 12:51:17,980 DEBUG Layer 385: Alpha Weigthed: 1.7800925813727697\n",
      "2018-11-26 12:51:17,991 DEBUG Layer 392: Alpha Weigthed: 1.6435002918273753\n",
      "2018-11-26 12:51:17,997 DEBUG Layer 399: Alpha Weigthed: 1.4212038041433637\n",
      "2018-11-26 12:51:18,000 DEBUG Layer 406: Alpha Weigthed: 1.9552221401776666\n",
      "2018-11-26 12:51:18,004 DEBUG Layer 413: Alpha Weigthed: 1.443538080476963\n",
      "2018-11-26 12:51:18,007 DEBUG Layer 420: Alpha Weigthed: 1.8866082158395694\n",
      "2018-11-26 12:51:18,011 DEBUG Layer 427: Alpha Weigthed: 1.637913249944753\n",
      "2018-11-26 12:51:18,014 INFO Alpha Weighted: min: 0.008693578495666087, max: 3.6784390190162175, avg: 1.1105696924003263\n",
      "2018-11-26 12:51:18,018 INFO Alpha Weighted compound: min: 0.008693578495666087, max: 3.6784390190162175, avg: 1.1105696924003263\n",
      "/Users/charlesmartin14/anaconda3/envs/py3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "2018-11-26 12:51:21,747 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 12:51:21,749 INFO Analyzing model\n",
      "2018-11-26 12:51:21,781 INFO Layer 0: DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer25): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer26): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer27): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer28): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer29): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer30): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer31): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer32): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer33): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer34): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer35): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer36): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=2208, out_features=1000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:21,785 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:21,811 INFO Layer 1: Sequential(\n",
      "  (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu0): ReLU(inplace)\n",
      "  (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (denseblock1): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition1): _Transition(\n",
      "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock2): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition2): _Transition(\n",
      "    (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock3): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer13): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer14): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer15): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer16): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer17): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer18): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer19): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer20): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer21): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer22): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer23): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer24): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer25): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer26): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer27): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer28): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer29): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer30): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer31): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer32): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer33): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer34): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer35): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer36): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition3): _Transition(\n",
      "    (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock4): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer13): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer14): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer15): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer16): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer17): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer18): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer19): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer20): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer21): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer22): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer23): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer24): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:21,815 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:21,818 INFO Layer 2: Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "2018-11-26 12:51:21,824 INFO Pytorch tensor shape detected: 96x3 (NxM), 7x7 (i,j)\n",
      "2018-11-26 12:51:21,829 INFO Layer 2: Analyzing 49 weight matrices...\n",
      "2018-11-26 12:51:21,834 INFO     Weight matrix 1/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,839 INFO     Weight matrix 2/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,842 INFO     Weight matrix 3/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,847 INFO     Weight matrix 4/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,850 INFO     Weight matrix 5/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,856 INFO     Weight matrix 6/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,861 INFO     Weight matrix 7/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,866 INFO     Weight matrix 8/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,868 INFO     Weight matrix 9/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,872 INFO     Weight matrix 10/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,876 INFO     Weight matrix 11/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,880 INFO     Weight matrix 12/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,886 INFO     Weight matrix 13/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,889 INFO     Weight matrix 14/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,893 INFO     Weight matrix 15/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,897 INFO     Weight matrix 16/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,901 INFO     Weight matrix 17/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,904 INFO     Weight matrix 18/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,910 INFO     Weight matrix 19/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,914 INFO     Weight matrix 20/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,917 INFO     Weight matrix 21/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,920 INFO     Weight matrix 22/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,924 INFO     Weight matrix 23/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,927 INFO     Weight matrix 24/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,930 INFO     Weight matrix 25/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,937 INFO     Weight matrix 26/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,940 INFO     Weight matrix 27/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,943 INFO     Weight matrix 28/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,946 INFO     Weight matrix 29/49 (3,96): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:21,950 INFO     Weight matrix 30/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,956 INFO     Weight matrix 31/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,960 INFO     Weight matrix 32/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,963 INFO     Weight matrix 33/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,966 INFO     Weight matrix 34/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,969 INFO     Weight matrix 35/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,972 INFO     Weight matrix 36/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,976 INFO     Weight matrix 37/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,980 INFO     Weight matrix 38/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,983 INFO     Weight matrix 39/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,986 INFO     Weight matrix 40/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,989 INFO     Weight matrix 41/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,992 INFO     Weight matrix 42/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,996 INFO     Weight matrix 43/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:21,999 INFO     Weight matrix 44/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,003 INFO     Weight matrix 45/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,007 INFO     Weight matrix 46/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,011 INFO     Weight matrix 47/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,014 INFO     Weight matrix 48/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,019 INFO     Weight matrix 49/49 (3,96): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,022 INFO Layer 3: BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:22,026 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:22,029 INFO Layer 4: ReLU(inplace)\n",
      "2018-11-26 12:51:22,032 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:22,034 INFO Layer 5: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:51:22,038 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:22,042 INFO Layer 6: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:51:22,046 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:22,050 INFO Layer 7: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:22,053 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:22,057 INFO Layer 8: BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:22,060 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:22,065 INFO Layer 9: ReLU(inplace)\n",
      "2018-11-26 12:51:22,069 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:22,072 INFO Layer 10: Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:22,076 INFO Pytorch tensor shape detected: 192x96 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:22,079 INFO Layer 10: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:22,083 INFO     Weight matrix 1/1 (96,192): Analyzing ...\n",
      "2018-11-26 12:51:22,819 INFO     Weight matrix 1/1 (96,192): Alpha: 1.364728432119429, Alpha Weighted: 0.25652257028583964, D: 0.2531063808100118\n",
      "2018-11-26 12:51:22,822 INFO     Weight matrix 1/1 (96,192): Alpha 1.364728432119429 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:22,829 INFO     Weight matrix 1/1 (96,192): Lognorm: 0.5801879167556763\n",
      "2018-11-26 12:51:22,832 INFO Layer 11: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:22,834 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:22,837 INFO Layer 12: ReLU(inplace)\n",
      "2018-11-26 12:51:22,840 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:22,843 INFO Layer 13: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:22,847 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:22,850 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:22,854 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,857 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,861 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,864 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,868 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,871 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,874 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,878 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,881 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:22,886 INFO Layer 14: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:22,888 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:22,892 INFO Layer 15: BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:22,896 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:22,899 INFO Layer 16: ReLU(inplace)\n",
      "2018-11-26 12:51:22,903 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:22,908 INFO Layer 17: Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:22,912 INFO Pytorch tensor shape detected: 192x144 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:22,915 INFO Layer 17: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:22,920 INFO     Weight matrix 1/1 (144,192): Analyzing ...\n",
      "2018-11-26 12:51:23,945 INFO     Weight matrix 1/1 (144,192): Alpha: 1.3985980445049089, Alpha Weighted: 0.31954800809731193, D: 0.20873753567227415\n",
      "2018-11-26 12:51:23,948 INFO     Weight matrix 1/1 (144,192): Alpha 1.3985980445049089 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:23,954 INFO     Weight matrix 1/1 (144,192): Lognorm: 0.5731354355812073\n",
      "2018-11-26 12:51:23,959 INFO Layer 18: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:23,963 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:23,966 INFO Layer 19: ReLU(inplace)\n",
      "2018-11-26 12:51:23,969 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:23,972 INFO Layer 20: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:23,979 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:23,987 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:23,991 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:23,995 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:24,011 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:24,015 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:24,020 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:24,029 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:24,032 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:24,035 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:24,039 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:24,043 INFO Layer 21: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:24,046 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:24,053 INFO Layer 22: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:24,057 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:24,061 INFO Layer 23: ReLU(inplace)\n",
      "2018-11-26 12:51:24,069 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:24,077 INFO Layer 24: Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:24,082 INFO Pytorch tensor shape detected: 192x192 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:24,086 INFO Layer 24: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:24,092 INFO     Weight matrix 1/1 (192,192): Analyzing ...\n",
      "2018-11-26 12:51:25,745 INFO     Weight matrix 1/1 (192,192): Alpha: 2.6651763904820136, Alpha Weighted: 0.49362233513035075, D: 0.17722282890433272\n",
      "2018-11-26 12:51:25,748 INFO     Weight matrix 1/1 (192,192): Lognorm: 0.6840506792068481\n",
      "2018-11-26 12:51:25,752 INFO Layer 25: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:25,756 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:25,758 INFO Layer 26: ReLU(inplace)\n",
      "2018-11-26 12:51:25,761 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:25,764 INFO Layer 27: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:25,771 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:25,776 INFO Layer 27: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:25,779 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:25,782 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:25,785 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:25,788 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:25,790 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:25,792 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:25,795 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:25,798 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:25,803 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:25,806 INFO Layer 28: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:25,809 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:25,815 INFO Layer 29: BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:25,819 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:25,823 INFO Layer 30: ReLU(inplace)\n",
      "2018-11-26 12:51:25,826 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:25,830 INFO Layer 31: Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:25,835 INFO Pytorch tensor shape detected: 192x240 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:25,838 INFO Layer 31: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:25,842 INFO     Weight matrix 1/1 (192,240): Analyzing ...\n",
      "2018-11-26 12:51:27,713 INFO     Weight matrix 1/1 (192,240): Alpha: 4.288261534252063, Alpha Weighted: 1.4345516023492229, D: 0.14285714285714157\n",
      "2018-11-26 12:51:27,716 INFO     Weight matrix 1/1 (192,240): Alpha 4.288261534252063 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:27,720 INFO     Weight matrix 1/1 (192,240): Lognorm: 0.6385344862937927\n",
      "2018-11-26 12:51:27,723 INFO Layer 32: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:27,726 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:27,731 INFO Layer 33: ReLU(inplace)\n",
      "2018-11-26 12:51:27,734 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:27,736 INFO Layer 34: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:27,740 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:27,742 INFO Layer 34: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:27,745 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:27,747 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:27,751 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:27,754 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:27,760 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:27,763 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:27,765 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:27,768 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:27,772 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:27,775 INFO Layer 35: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:27,779 INFO Layer 35: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:27,781 INFO Layer 36: BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:27,784 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:27,786 INFO Layer 37: ReLU(inplace)\n",
      "2018-11-26 12:51:27,789 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:27,791 INFO Layer 38: Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:27,797 INFO Pytorch tensor shape detected: 192x288 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:27,800 INFO Layer 38: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:27,804 INFO     Weight matrix 1/1 (192,288): Analyzing ...\n",
      "2018-11-26 12:51:29,724 INFO     Weight matrix 1/1 (192,288): Alpha: 3.0452406470189164, Alpha Weighted: 0.8087975706559052, D: 0.1585844505098637\n",
      "2018-11-26 12:51:29,729 INFO     Weight matrix 1/1 (192,288): Lognorm: 0.73655766248703\n",
      "2018-11-26 12:51:29,734 INFO Layer 39: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:29,737 INFO Layer 39: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:29,740 INFO Layer 40: ReLU(inplace)\n",
      "2018-11-26 12:51:29,742 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:29,745 INFO Layer 41: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:29,750 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:29,753 INFO Layer 41: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:29,764 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:29,770 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:29,776 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:29,778 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:29,784 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:29,789 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:29,792 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:29,803 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:29,809 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:29,813 INFO Layer 42: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:29,816 INFO Layer 42: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:29,820 INFO Layer 43: BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:29,823 INFO Layer 43: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:29,828 INFO Layer 44: ReLU(inplace)\n",
      "2018-11-26 12:51:29,836 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:29,841 INFO Layer 45: Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:29,846 INFO Pytorch tensor shape detected: 192x336 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:29,852 INFO Layer 45: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:29,858 INFO     Weight matrix 1/1 (192,336): Analyzing ...\n",
      "2018-11-26 12:51:31,500 INFO     Weight matrix 1/1 (192,336): Alpha: 5.913571061390133, Alpha Weighted: 1.5314175379093353, D: 0.14881692126467372\n",
      "2018-11-26 12:51:31,503 INFO     Weight matrix 1/1 (192,336): Alpha 5.913571061390133 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:31,508 INFO     Weight matrix 1/1 (192,336): Lognorm: 0.7018465995788574\n",
      "2018-11-26 12:51:31,511 INFO Layer 46: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:31,513 INFO Layer 46: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:31,516 INFO Layer 47: ReLU(inplace)\n",
      "2018-11-26 12:51:31,521 INFO Layer 47: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:31,524 INFO Layer 48: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:31,529 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:31,534 INFO Layer 48: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:31,537 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:31,540 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:31,543 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:31,546 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:31,550 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:31,553 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:31,555 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:31,558 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:31,561 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:31,564 INFO Layer 49: _Transition(\n",
      "  (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "2018-11-26 12:51:31,566 INFO Layer 49: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:31,569 INFO Layer 50: BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:31,572 INFO Layer 50: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:31,575 INFO Layer 51: ReLU(inplace)\n",
      "2018-11-26 12:51:31,577 INFO Layer 51: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:31,579 INFO Layer 52: Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:31,583 INFO Pytorch tensor shape detected: 192x384 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:31,586 INFO Layer 52: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:31,589 INFO     Weight matrix 1/1 (192,384): Analyzing ...\n",
      "2018-11-26 12:51:33,635 INFO     Weight matrix 1/1 (192,384): Alpha: 4.584068296198838, Alpha Weighted: 3.929632868727833, D: 0.1125411608431065\n",
      "2018-11-26 12:51:33,638 INFO     Weight matrix 1/1 (192,384): Alpha 4.584068296198838 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:33,641 INFO     Weight matrix 1/1 (192,384): Lognorm: 1.0374387502670288\n",
      "2018-11-26 12:51:33,645 INFO Layer 53: AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "2018-11-26 12:51:33,648 INFO Layer 53: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:33,655 INFO Layer 54: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer7): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer8): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer9): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer10): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer11): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer12): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:33,659 INFO Layer 54: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:33,662 INFO Layer 55: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:33,666 INFO Layer 55: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:33,670 INFO Layer 56: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:33,673 INFO Layer 56: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:33,677 INFO Layer 57: ReLU(inplace)\n",
      "2018-11-26 12:51:33,680 INFO Layer 57: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:33,684 INFO Layer 58: Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:33,689 INFO Pytorch tensor shape detected: 192x192 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:33,692 INFO Layer 58: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:33,696 INFO     Weight matrix 1/1 (192,192): Analyzing ...\n",
      "2018-11-26 12:51:35,607 INFO     Weight matrix 1/1 (192,192): Alpha: 1.5709556372980185, Alpha Weighted: 0.02906707764230325, D: 0.15924079867218782\n",
      "2018-11-26 12:51:35,611 INFO     Weight matrix 1/1 (192,192): Lognorm: 0.49740296602249146\n",
      "2018-11-26 12:51:35,614 INFO Layer 59: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:35,619 INFO Layer 59: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:35,622 INFO Layer 60: ReLU(inplace)\n",
      "2018-11-26 12:51:35,626 INFO Layer 60: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:35,629 INFO Layer 61: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:35,633 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:35,637 INFO Layer 61: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:35,640 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:35,644 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:35,648 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:35,651 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:35,655 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:35,659 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:35,663 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:35,667 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:35,671 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:35,674 INFO Layer 62: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:35,678 INFO Layer 62: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:35,681 INFO Layer 63: BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:35,684 INFO Layer 63: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:35,687 INFO Layer 64: ReLU(inplace)\n",
      "2018-11-26 12:51:35,691 INFO Layer 64: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:35,694 INFO Layer 65: Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:35,698 INFO Pytorch tensor shape detected: 192x240 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:35,707 INFO Layer 65: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:35,710 INFO     Weight matrix 1/1 (192,240): Analyzing ...\n",
      "2018-11-26 12:51:36,238 INFO     Weight matrix 1/1 (192,240): Alpha: 1.4826087623520958, Alpha Weighted: -0.16847425261837323, D: 0.2071709773265506\n",
      "2018-11-26 12:51:36,241 INFO     Weight matrix 1/1 (192,240): Alpha 1.4826087623520958 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:36,244 INFO     Weight matrix 1/1 (192,240): Lognorm: 0.26298975944519043\n",
      "2018-11-26 12:51:36,248 INFO Layer 66: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:36,251 INFO Layer 66: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:36,254 INFO Layer 67: ReLU(inplace)\n",
      "2018-11-26 12:51:36,257 INFO Layer 67: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:36,260 INFO Layer 68: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:36,266 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:36,273 INFO Layer 68: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:36,277 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:36,281 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:36,284 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:36,287 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:36,290 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:36,293 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:36,298 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:36,302 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:36,305 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:36,312 INFO Layer 69: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:36,316 INFO Layer 69: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:36,330 INFO Layer 70: BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:36,334 INFO Layer 70: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:36,338 INFO Layer 71: ReLU(inplace)\n",
      "2018-11-26 12:51:36,342 INFO Layer 71: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:36,346 INFO Layer 72: Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:36,350 INFO Pytorch tensor shape detected: 192x288 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:36,354 INFO Layer 72: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:36,360 INFO     Weight matrix 1/1 (192,288): Analyzing ...\n",
      "2018-11-26 12:51:38,569 INFO     Weight matrix 1/1 (192,288): Alpha: 1.9773239053631602, Alpha Weighted: 0.12230637477791156, D: 0.1429427819912335\n",
      "2018-11-26 12:51:38,577 INFO     Weight matrix 1/1 (192,288): Lognorm: 0.6122696399688721\n",
      "2018-11-26 12:51:38,582 INFO Layer 73: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:38,586 INFO Layer 73: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:38,592 INFO Layer 74: ReLU(inplace)\n",
      "2018-11-26 12:51:38,598 INFO Layer 74: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:38,602 INFO Layer 75: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:38,614 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:38,620 INFO Layer 75: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:38,626 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:38,633 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:38,637 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:38,641 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:38,648 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:38,652 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:38,661 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:38,668 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:38,673 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:38,678 INFO Layer 76: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:38,683 INFO Layer 76: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:38,686 INFO Layer 77: BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:38,689 INFO Layer 77: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:38,694 INFO Layer 78: ReLU(inplace)\n",
      "2018-11-26 12:51:38,701 INFO Layer 78: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:38,705 INFO Layer 79: Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:38,713 INFO Pytorch tensor shape detected: 192x336 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:38,721 INFO Layer 79: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:38,726 INFO     Weight matrix 1/1 (192,336): Analyzing ...\n",
      "2018-11-26 12:51:40,776 INFO     Weight matrix 1/1 (192,336): Alpha: 1.5926322378202347, Alpha Weighted: -0.09659123238100824, D: 0.16745400622355433\n",
      "2018-11-26 12:51:40,779 INFO     Weight matrix 1/1 (192,336): Lognorm: 0.5999976992607117\n",
      "2018-11-26 12:51:40,782 INFO Layer 80: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:40,785 INFO Layer 80: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:40,788 INFO Layer 81: ReLU(inplace)\n",
      "2018-11-26 12:51:40,791 INFO Layer 81: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:40,794 INFO Layer 82: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:40,801 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:40,810 INFO Layer 82: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:40,814 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:40,817 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:40,820 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:40,824 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:40,828 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:40,831 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:40,835 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:40,839 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:40,842 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:40,845 INFO Layer 83: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:40,847 INFO Layer 83: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:40,851 INFO Layer 84: BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:40,854 INFO Layer 84: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:40,858 INFO Layer 85: ReLU(inplace)\n",
      "2018-11-26 12:51:40,861 INFO Layer 85: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:40,864 INFO Layer 86: Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:40,868 INFO Pytorch tensor shape detected: 192x384 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:40,872 INFO Layer 86: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:40,875 INFO     Weight matrix 1/1 (192,384): Analyzing ...\n",
      "2018-11-26 12:51:43,077 INFO     Weight matrix 1/1 (192,384): Alpha: 1.5619159746513103, Alpha Weighted: -0.05541017480338204, D: 0.19165603418864763\n",
      "2018-11-26 12:51:43,079 INFO     Weight matrix 1/1 (192,384): Lognorm: 0.6401392817497253\n",
      "2018-11-26 12:51:43,082 INFO Layer 87: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:43,085 INFO Layer 87: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:43,088 INFO Layer 88: ReLU(inplace)\n",
      "2018-11-26 12:51:43,091 INFO Layer 88: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:43,093 INFO Layer 89: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:43,096 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:43,100 INFO Layer 89: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:43,105 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:43,108 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:43,113 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:43,118 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:43,123 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:43,126 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:43,130 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:43,133 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:43,137 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:43,140 INFO Layer 90: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:43,142 INFO Layer 90: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:43,145 INFO Layer 91: BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:43,149 INFO Layer 91: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:43,152 INFO Layer 92: ReLU(inplace)\n",
      "2018-11-26 12:51:43,155 INFO Layer 92: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:43,159 INFO Layer 93: Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:43,164 INFO Pytorch tensor shape detected: 192x432 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:43,166 INFO Layer 93: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:43,170 INFO     Weight matrix 1/1 (192,432): Analyzing ...\n",
      "2018-11-26 12:51:45,237 INFO     Weight matrix 1/1 (192,432): Alpha: 1.597483497459631, Alpha Weighted: 0.3443154861160087, D: 0.14045173735475847\n",
      "2018-11-26 12:51:45,241 INFO     Weight matrix 1/1 (192,432): Lognorm: 0.6598575711250305\n",
      "2018-11-26 12:51:45,244 INFO Layer 94: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:45,247 INFO Layer 94: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:45,250 INFO Layer 95: ReLU(inplace)\n",
      "2018-11-26 12:51:45,256 INFO Layer 95: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:45,259 INFO Layer 96: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:45,264 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:45,272 INFO Layer 96: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:45,276 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:45,281 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:45,286 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:45,289 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:45,292 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:45,296 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:45,300 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:45,303 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:45,306 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:45,310 INFO Layer 97: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:45,313 INFO Layer 97: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:45,317 INFO Layer 98: BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:45,327 INFO Layer 98: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:45,330 INFO Layer 99: ReLU(inplace)\n",
      "2018-11-26 12:51:45,333 INFO Layer 99: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:45,336 INFO Layer 100: Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:45,340 INFO Pytorch tensor shape detected: 192x480 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:45,344 INFO Layer 100: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:45,347 INFO     Weight matrix 1/1 (192,480): Analyzing ...\n",
      "2018-11-26 12:51:47,506 INFO     Weight matrix 1/1 (192,480): Alpha: 2.426961822675583, Alpha Weighted: 0.8689134754874381, D: 0.10953168329280444\n",
      "2018-11-26 12:51:47,509 INFO     Weight matrix 1/1 (192,480): Lognorm: 0.7495948076248169\n",
      "2018-11-26 12:51:47,512 INFO Layer 101: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:47,514 INFO Layer 101: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:47,517 INFO Layer 102: ReLU(inplace)\n",
      "2018-11-26 12:51:47,520 INFO Layer 102: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:47,523 INFO Layer 103: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:47,526 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:47,529 INFO Layer 103: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:47,531 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:47,534 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:47,537 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:47,539 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:47,542 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:47,545 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:47,547 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:47,550 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:47,553 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:47,556 INFO Layer 104: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:47,559 INFO Layer 104: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:47,563 INFO Layer 105: BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:47,566 INFO Layer 105: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:47,569 INFO Layer 106: ReLU(inplace)\n",
      "2018-11-26 12:51:47,572 INFO Layer 106: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:47,575 INFO Layer 107: Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:47,579 INFO Pytorch tensor shape detected: 192x528 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:47,581 INFO Layer 107: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:47,585 INFO     Weight matrix 1/1 (192,528): Analyzing ...\n",
      "2018-11-26 12:51:49,711 INFO     Weight matrix 1/1 (192,528): Alpha: 6.939540804908551, Alpha Weighted: 0.5445981367102605, D: 0.17865600218657418\n",
      "2018-11-26 12:51:49,713 INFO     Weight matrix 1/1 (192,528): Alpha 6.939540804908551 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:51:49,716 INFO     Weight matrix 1/1 (192,528): Lognorm: 0.7282037734985352\n",
      "2018-11-26 12:51:49,719 INFO Layer 108: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:49,722 INFO Layer 108: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:49,725 INFO Layer 109: ReLU(inplace)\n",
      "2018-11-26 12:51:49,729 INFO Layer 109: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:49,731 INFO Layer 110: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:49,737 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:49,741 INFO Layer 110: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:49,743 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:49,746 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:49,749 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:49,751 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:49,754 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:49,757 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:49,759 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:49,762 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:49,765 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:49,767 INFO Layer 111: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:49,769 INFO Layer 111: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:49,772 INFO Layer 112: BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:49,776 INFO Layer 112: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:49,779 INFO Layer 113: ReLU(inplace)\n",
      "2018-11-26 12:51:49,783 INFO Layer 113: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:49,786 INFO Layer 114: Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:49,792 INFO Pytorch tensor shape detected: 192x576 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:49,795 INFO Layer 114: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:49,798 INFO     Weight matrix 1/1 (192,576): Analyzing ...\n",
      "2018-11-26 12:51:51,677 INFO     Weight matrix 1/1 (192,576): Alpha: 1.8863985775744938, Alpha Weighted: 0.23474567268450722, D: 0.15086005540152664\n",
      "2018-11-26 12:51:51,680 INFO     Weight matrix 1/1 (192,576): Lognorm: 0.7259364128112793\n",
      "2018-11-26 12:51:51,684 INFO Layer 115: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:51,687 INFO Layer 115: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:51,690 INFO Layer 116: ReLU(inplace)\n",
      "2018-11-26 12:51:51,692 INFO Layer 116: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:51,695 INFO Layer 117: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:51,699 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:51,704 INFO Layer 117: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:51,708 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:51,714 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:51,718 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:51,720 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:51,723 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:51,726 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:51,730 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:51,733 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:51,736 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:51,738 INFO Layer 118: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:51,741 INFO Layer 118: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:51,744 INFO Layer 119: BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:51,746 INFO Layer 119: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:51,749 INFO Layer 120: ReLU(inplace)\n",
      "2018-11-26 12:51:51,751 INFO Layer 120: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:51,754 INFO Layer 121: Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:51,762 INFO Pytorch tensor shape detected: 192x624 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:51,765 INFO Layer 121: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:51,769 INFO     Weight matrix 1/1 (192,624): Analyzing ...\n",
      "2018-11-26 12:51:53,474 INFO     Weight matrix 1/1 (192,624): Alpha: 1.9261791921137368, Alpha Weighted: 0.49151907920078514, D: 0.12088935125554506\n",
      "2018-11-26 12:51:53,478 INFO     Weight matrix 1/1 (192,624): Lognorm: 0.6818564534187317\n",
      "2018-11-26 12:51:53,482 INFO Layer 122: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:53,485 INFO Layer 122: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:53,488 INFO Layer 123: ReLU(inplace)\n",
      "2018-11-26 12:51:53,491 INFO Layer 123: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:53,493 INFO Layer 124: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:53,499 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:53,502 INFO Layer 124: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:53,505 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:53,508 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:53,511 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:53,514 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:53,517 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:53,520 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:53,523 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:53,527 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:53,530 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:53,533 INFO Layer 125: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:53,536 INFO Layer 125: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:53,539 INFO Layer 126: BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:53,543 INFO Layer 126: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:53,546 INFO Layer 127: ReLU(inplace)\n",
      "2018-11-26 12:51:53,549 INFO Layer 127: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:53,553 INFO Layer 128: Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:53,563 INFO Pytorch tensor shape detected: 192x672 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:53,568 INFO Layer 128: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:53,572 INFO     Weight matrix 1/1 (192,672): Analyzing ...\n",
      "2018-11-26 12:51:55,328 INFO     Weight matrix 1/1 (192,672): Alpha: 2.1724480727242605, Alpha Weighted: 0.21397308588108827, D: 0.15296650635098696\n",
      "2018-11-26 12:51:55,332 INFO     Weight matrix 1/1 (192,672): Lognorm: 0.7229810953140259\n",
      "2018-11-26 12:51:55,335 INFO Layer 129: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:55,338 INFO Layer 129: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:55,341 INFO Layer 130: ReLU(inplace)\n",
      "2018-11-26 12:51:55,343 INFO Layer 130: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:55,346 INFO Layer 131: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:55,349 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:55,351 INFO Layer 131: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:55,355 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:55,358 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:55,365 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:55,368 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:55,371 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:55,374 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:55,378 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:55,382 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:55,385 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:55,389 INFO Layer 132: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:55,392 INFO Layer 132: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:55,395 INFO Layer 133: BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:55,398 INFO Layer 133: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:55,402 INFO Layer 134: ReLU(inplace)\n",
      "2018-11-26 12:51:55,406 INFO Layer 134: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:55,409 INFO Layer 135: Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:55,417 INFO Pytorch tensor shape detected: 192x720 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:55,420 INFO Layer 135: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:55,423 INFO     Weight matrix 1/1 (192,720): Analyzing ...\n",
      "2018-11-26 12:51:57,158 INFO     Weight matrix 1/1 (192,720): Alpha: 1.8758850700728624, Alpha Weighted: 0.5863906346982273, D: 0.11894906982420889\n",
      "2018-11-26 12:51:57,162 INFO     Weight matrix 1/1 (192,720): Lognorm: 0.8070092797279358\n",
      "2018-11-26 12:51:57,165 INFO Layer 136: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:57,168 INFO Layer 136: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:57,171 INFO Layer 137: ReLU(inplace)\n",
      "2018-11-26 12:51:57,174 INFO Layer 137: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:57,177 INFO Layer 138: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:57,181 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:57,183 INFO Layer 138: Analyzing 9 weight matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:57,187 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:57,189 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:57,192 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:57,195 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:57,198 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:57,202 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:57,206 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:57,209 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:57,213 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:57,217 INFO Layer 139: _Transition(\n",
      "  (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "2018-11-26 12:51:57,220 INFO Layer 139: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:57,223 INFO Layer 140: BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:57,226 INFO Layer 140: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:57,229 INFO Layer 141: ReLU(inplace)\n",
      "2018-11-26 12:51:57,231 INFO Layer 141: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:57,234 INFO Layer 142: Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:57,249 INFO Pytorch tensor shape detected: 384x768 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:57,252 INFO Layer 142: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:57,255 INFO     Weight matrix 1/1 (384,768): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:51:57,259 INFO Layer 143: AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "2018-11-26 12:51:57,263 INFO Layer 143: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:57,278 INFO Layer 144: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer7): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer8): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer9): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer10): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer11): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer12): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer13): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer14): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer15): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer16): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer17): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer18): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer19): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer20): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer21): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer22): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer23): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer24): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer25): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer26): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer27): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer28): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer29): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer30): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer31): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer32): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer33): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer34): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer35): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer36): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:51:57,281 INFO Layer 144: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:57,284 INFO Layer 145: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:57,286 INFO Layer 145: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:57,289 INFO Layer 146: BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:57,293 INFO Layer 146: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:57,295 INFO Layer 147: ReLU(inplace)\n",
      "2018-11-26 12:51:57,298 INFO Layer 147: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:57,301 INFO Layer 148: Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:57,307 INFO Pytorch tensor shape detected: 192x384 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:57,312 INFO Layer 148: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:57,315 INFO     Weight matrix 1/1 (192,384): Analyzing ...\n",
      "2018-11-26 12:51:59,126 INFO     Weight matrix 1/1 (192,384): Alpha: 1.9092336619229995, Alpha Weighted: -0.29622741072678443, D: 0.1776340086628564\n",
      "2018-11-26 12:51:59,129 INFO     Weight matrix 1/1 (192,384): Lognorm: 0.4810558259487152\n",
      "2018-11-26 12:51:59,132 INFO Layer 149: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:59,135 INFO Layer 149: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:59,138 INFO Layer 150: ReLU(inplace)\n",
      "2018-11-26 12:51:59,141 INFO Layer 150: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:59,144 INFO Layer 151: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:51:59,148 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:51:59,151 INFO Layer 151: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:51:59,154 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:59,157 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:59,159 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:59,163 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:59,166 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:59,169 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:59,172 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:59,175 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:59,179 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:51:59,181 INFO Layer 152: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:51:59,184 INFO Layer 152: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:59,187 INFO Layer 153: BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:51:59,190 INFO Layer 153: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:59,194 INFO Layer 154: ReLU(inplace)\n",
      "2018-11-26 12:51:59,197 INFO Layer 154: Skipping (Layer not supported)\n",
      "2018-11-26 12:51:59,201 INFO Layer 155: Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:51:59,206 INFO Pytorch tensor shape detected: 192x432 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:51:59,214 INFO Layer 155: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:51:59,217 INFO     Weight matrix 1/1 (192,432): Analyzing ...\n",
      "2018-11-26 12:52:00,924 INFO     Weight matrix 1/1 (192,432): Alpha: 3.959131269442642, Alpha Weighted: -0.3539789930275831, D: 0.14460434570797343\n",
      "2018-11-26 12:52:00,926 INFO     Weight matrix 1/1 (192,432): Alpha 3.959131269442642 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:52:00,934 INFO     Weight matrix 1/1 (192,432): Lognorm: 0.48302948474884033\n",
      "2018-11-26 12:52:00,937 INFO Layer 156: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:00,943 INFO Layer 156: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:00,946 INFO Layer 157: ReLU(inplace)\n",
      "2018-11-26 12:52:00,948 INFO Layer 157: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:00,951 INFO Layer 158: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:00,956 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:00,958 INFO Layer 158: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:00,961 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:00,964 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:00,966 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:00,969 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:00,973 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:00,979 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:00,982 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:00,986 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:00,989 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:00,992 INFO Layer 159: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:00,995 INFO Layer 159: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:00,997 INFO Layer 160: BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:01,001 INFO Layer 160: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:01,004 INFO Layer 161: ReLU(inplace)\n",
      "2018-11-26 12:52:01,007 INFO Layer 161: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:01,010 INFO Layer 162: Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:01,017 INFO Pytorch tensor shape detected: 192x480 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:01,021 INFO Layer 162: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:01,027 INFO     Weight matrix 1/1 (192,480): Analyzing ...\n",
      "2018-11-26 12:52:02,774 INFO     Weight matrix 1/1 (192,480): Alpha: 1.4669502325284431, Alpha Weighted: -0.30258187049734875, D: 0.1619965638432842\n",
      "2018-11-26 12:52:02,777 INFO     Weight matrix 1/1 (192,480): Alpha 1.4669502325284431 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:52:02,781 INFO     Weight matrix 1/1 (192,480): Lognorm: 0.3447718024253845\n",
      "2018-11-26 12:52:02,786 INFO Layer 163: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:02,788 INFO Layer 163: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:02,791 INFO Layer 164: ReLU(inplace)\n",
      "2018-11-26 12:52:02,795 INFO Layer 164: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:02,797 INFO Layer 165: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:02,806 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:02,809 INFO Layer 165: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:02,815 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:02,820 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:02,826 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:02,830 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:52:02,834 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:02,838 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:02,841 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:02,843 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:02,847 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:02,851 INFO Layer 166: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:02,855 INFO Layer 166: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:02,870 INFO Layer 167: BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:02,876 INFO Layer 167: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:02,879 INFO Layer 168: ReLU(inplace)\n",
      "2018-11-26 12:52:02,882 INFO Layer 168: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:02,884 INFO Layer 169: Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:02,889 INFO Pytorch tensor shape detected: 192x528 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:02,891 INFO Layer 169: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:02,893 INFO     Weight matrix 1/1 (192,528): Analyzing ...\n",
      "2018-11-26 12:52:05,247 INFO     Weight matrix 1/1 (192,528): Alpha: 1.7644531664542407, Alpha Weighted: -0.3380648531515397, D: 0.17032547845208013\n",
      "2018-11-26 12:52:05,250 INFO     Weight matrix 1/1 (192,528): Lognorm: 0.437405526638031\n",
      "2018-11-26 12:52:05,254 INFO Layer 170: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:05,258 INFO Layer 170: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:05,261 INFO Layer 171: ReLU(inplace)\n",
      "2018-11-26 12:52:05,264 INFO Layer 171: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:05,267 INFO Layer 172: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:05,276 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:05,279 INFO Layer 172: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:05,283 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:05,285 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:05,288 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:05,291 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:05,294 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:05,296 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:05,300 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:05,304 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:05,308 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:05,313 INFO Layer 173: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:05,317 INFO Layer 173: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:05,321 INFO Layer 174: BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:05,325 INFO Layer 174: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:05,329 INFO Layer 175: ReLU(inplace)\n",
      "2018-11-26 12:52:05,333 INFO Layer 175: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:05,337 INFO Layer 176: Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:05,340 INFO Pytorch tensor shape detected: 192x576 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:05,343 INFO Layer 176: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:05,347 INFO     Weight matrix 1/1 (192,576): Analyzing ...\n",
      "2018-11-26 12:52:07,455 INFO     Weight matrix 1/1 (192,576): Alpha: 1.4872276062882435, Alpha Weighted: -0.4409077994325044, D: 0.17849967253008886\n",
      "2018-11-26 12:52:07,458 INFO     Weight matrix 1/1 (192,576): Alpha 1.4872276062882435 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:52:07,462 INFO     Weight matrix 1/1 (192,576): Lognorm: 0.37494415044784546\n",
      "2018-11-26 12:52:07,465 INFO Layer 177: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:07,468 INFO Layer 177: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:07,471 INFO Layer 178: ReLU(inplace)\n",
      "2018-11-26 12:52:07,474 INFO Layer 178: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:07,476 INFO Layer 179: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:07,480 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:07,483 INFO Layer 179: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:07,487 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:07,490 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:07,493 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:07,495 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:07,498 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:07,502 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:07,505 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:07,515 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:07,519 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:07,523 INFO Layer 180: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:07,526 INFO Layer 180: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:07,529 INFO Layer 181: BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:07,534 INFO Layer 181: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:07,537 INFO Layer 182: ReLU(inplace)\n",
      "2018-11-26 12:52:07,542 INFO Layer 182: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:07,544 INFO Layer 183: Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:07,547 INFO Pytorch tensor shape detected: 192x624 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:07,550 INFO Layer 183: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:07,553 INFO     Weight matrix 1/1 (192,624): Analyzing ...\n",
      "2018-11-26 12:52:09,365 INFO     Weight matrix 1/1 (192,624): Alpha: 1.801517360013925, Alpha Weighted: -0.18418922191940582, D: 0.17671721038993132\n",
      "2018-11-26 12:52:09,368 INFO     Weight matrix 1/1 (192,624): Lognorm: 0.5717402696609497\n",
      "2018-11-26 12:52:09,371 INFO Layer 184: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:09,375 INFO Layer 184: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:09,379 INFO Layer 185: ReLU(inplace)\n",
      "2018-11-26 12:52:09,381 INFO Layer 185: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:09,385 INFO Layer 186: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:09,389 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:09,392 INFO Layer 186: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:09,395 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:52:09,398 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:09,401 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:09,403 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:09,406 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:09,408 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:09,411 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:09,413 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:09,417 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:09,420 INFO Layer 187: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:09,423 INFO Layer 187: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:09,426 INFO Layer 188: BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:09,429 INFO Layer 188: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:09,432 INFO Layer 189: ReLU(inplace)\n",
      "2018-11-26 12:52:09,438 INFO Layer 189: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:09,441 INFO Layer 190: Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:09,446 INFO Pytorch tensor shape detected: 192x672 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:09,448 INFO Layer 190: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:09,451 INFO     Weight matrix 1/1 (192,672): Analyzing ...\n",
      "2018-11-26 12:52:11,281 INFO     Weight matrix 1/1 (192,672): Alpha: 4.016283506262169, Alpha Weighted: -0.151017404523778, D: 0.12593771753965177\n",
      "2018-11-26 12:52:11,284 INFO     Weight matrix 1/1 (192,672): Alpha 4.016283506262169 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:52:11,286 INFO     Weight matrix 1/1 (192,672): Lognorm: 0.563644528388977\n",
      "2018-11-26 12:52:11,289 INFO Layer 191: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:11,292 INFO Layer 191: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:11,294 INFO Layer 192: ReLU(inplace)\n",
      "2018-11-26 12:52:11,298 INFO Layer 192: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:11,300 INFO Layer 193: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:11,303 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:11,305 INFO Layer 193: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:11,308 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:11,311 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:11,313 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:11,316 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:11,318 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:11,321 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:11,323 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:11,326 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:11,329 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:11,332 INFO Layer 194: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:11,334 INFO Layer 194: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:11,337 INFO Layer 195: BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:11,341 INFO Layer 195: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:11,343 INFO Layer 196: ReLU(inplace)\n",
      "2018-11-26 12:52:11,346 INFO Layer 196: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:11,349 INFO Layer 197: Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:11,352 INFO Pytorch tensor shape detected: 192x720 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:11,355 INFO Layer 197: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:11,358 INFO     Weight matrix 1/1 (192,720): Analyzing ...\n",
      "2018-11-26 12:52:13,195 INFO     Weight matrix 1/1 (192,720): Alpha: 1.5973660761604047, Alpha Weighted: -0.239859394642055, D: 0.17077331404976265\n",
      "2018-11-26 12:52:13,198 INFO     Weight matrix 1/1 (192,720): Lognorm: 0.5315535068511963\n",
      "2018-11-26 12:52:13,201 INFO Layer 198: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:13,205 INFO Layer 198: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:13,207 INFO Layer 199: ReLU(inplace)\n",
      "2018-11-26 12:52:13,210 INFO Layer 199: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:13,213 INFO Layer 200: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:13,216 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:13,220 INFO Layer 200: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:13,222 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:13,226 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:13,228 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:13,232 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:13,235 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:13,240 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:13,243 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:13,245 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:13,247 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:13,250 INFO Layer 201: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:13,253 INFO Layer 201: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:13,258 INFO Layer 202: BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:13,261 INFO Layer 202: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:13,265 INFO Layer 203: ReLU(inplace)\n",
      "2018-11-26 12:52:13,268 INFO Layer 203: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:13,272 INFO Layer 204: Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:13,281 INFO Pytorch tensor shape detected: 192x768 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:13,284 INFO Layer 204: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:13,287 INFO     Weight matrix 1/1 (192,768): Analyzing ...\n",
      "2018-11-26 12:52:15,368 INFO     Weight matrix 1/1 (192,768): Alpha: 6.929515762281742, Alpha Weighted: -0.9750275613771333, D: 0.1517225112562698\n",
      "2018-11-26 12:52:15,371 INFO     Weight matrix 1/1 (192,768): Alpha 6.929515762281742 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:52:15,376 INFO     Weight matrix 1/1 (192,768): Lognorm: 0.5711762309074402\n",
      "2018-11-26 12:52:15,381 INFO Layer 205: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:15,384 INFO Layer 205: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:15,386 INFO Layer 206: ReLU(inplace)\n",
      "2018-11-26 12:52:15,390 INFO Layer 206: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:52:15,393 INFO Layer 207: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:15,398 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:15,401 INFO Layer 207: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:15,406 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:15,410 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:15,413 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:15,416 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:15,420 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:15,423 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:15,429 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:15,433 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:15,437 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:15,440 INFO Layer 208: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:15,443 INFO Layer 208: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:15,446 INFO Layer 209: BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:15,449 INFO Layer 209: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:15,453 INFO Layer 210: ReLU(inplace)\n",
      "2018-11-26 12:52:15,456 INFO Layer 210: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:15,459 INFO Layer 211: Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:15,465 INFO Pytorch tensor shape detected: 192x816 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:15,468 INFO Layer 211: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:15,472 INFO     Weight matrix 1/1 (192,816): Analyzing ...\n",
      "2018-11-26 12:52:17,678 INFO     Weight matrix 1/1 (192,816): Alpha: 1.8063709861570616, Alpha Weighted: 0.15936923290511654, D: 0.15221376932201613\n",
      "2018-11-26 12:52:17,682 INFO     Weight matrix 1/1 (192,816): Lognorm: 0.6827049851417542\n",
      "2018-11-26 12:52:17,686 INFO Layer 212: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:17,688 INFO Layer 212: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:17,692 INFO Layer 213: ReLU(inplace)\n",
      "2018-11-26 12:52:17,695 INFO Layer 213: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:17,698 INFO Layer 214: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:17,700 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:17,703 INFO Layer 214: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:17,706 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:17,710 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:17,713 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:17,715 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:17,717 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:17,720 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:17,722 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:17,725 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:17,728 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:17,731 INFO Layer 215: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:17,734 INFO Layer 215: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:17,737 INFO Layer 216: BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:17,740 INFO Layer 216: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:17,743 INFO Layer 217: ReLU(inplace)\n",
      "2018-11-26 12:52:17,746 INFO Layer 217: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:17,749 INFO Layer 218: Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:17,754 INFO Pytorch tensor shape detected: 192x864 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:17,758 INFO Layer 218: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:17,762 INFO     Weight matrix 1/1 (192,864): Analyzing ...\n",
      "2018-11-26 12:52:19,801 INFO     Weight matrix 1/1 (192,864): Alpha: 2.1578379294985046, Alpha Weighted: 0.6404072353108399, D: 0.08277793877031225\n",
      "2018-11-26 12:52:19,805 INFO     Weight matrix 1/1 (192,864): Lognorm: 0.6588689684867859\n",
      "2018-11-26 12:52:19,808 INFO Layer 219: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:19,811 INFO Layer 219: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:19,814 INFO Layer 220: ReLU(inplace)\n",
      "2018-11-26 12:52:19,817 INFO Layer 220: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:19,819 INFO Layer 221: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:19,823 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:19,826 INFO Layer 221: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:19,829 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:19,832 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:19,835 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:19,837 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:19,840 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:19,843 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:19,847 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:19,850 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:19,855 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:19,858 INFO Layer 222: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:19,864 INFO Layer 222: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:19,868 INFO Layer 223: BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:19,871 INFO Layer 223: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:19,875 INFO Layer 224: ReLU(inplace)\n",
      "2018-11-26 12:52:19,882 INFO Layer 224: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:19,886 INFO Layer 225: Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:19,894 INFO Pytorch tensor shape detected: 192x912 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:19,898 INFO Layer 225: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:19,902 INFO     Weight matrix 1/1 (192,912): Analyzing ...\n",
      "2018-11-26 12:52:22,278 INFO     Weight matrix 1/1 (192,912): Alpha: 1.8181471312124842, Alpha Weighted: -0.12326690821928553, D: 0.15750870200166572\n",
      "2018-11-26 12:52:22,282 INFO     Weight matrix 1/1 (192,912): Lognorm: 0.6808460354804993\n",
      "2018-11-26 12:52:22,284 INFO Layer 226: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:22,288 INFO Layer 226: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:52:22,292 INFO Layer 227: ReLU(inplace)\n",
      "2018-11-26 12:52:22,297 INFO Layer 227: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:22,306 INFO Layer 228: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:22,313 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:22,317 INFO Layer 228: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:22,322 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:22,326 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:22,328 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:22,335 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:22,341 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:22,347 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:22,354 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:22,356 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:22,359 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:22,364 INFO Layer 229: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:22,375 INFO Layer 229: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:22,379 INFO Layer 230: BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:22,383 INFO Layer 230: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:22,389 INFO Layer 231: ReLU(inplace)\n",
      "2018-11-26 12:52:22,395 INFO Layer 231: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:22,400 INFO Layer 232: Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:22,405 INFO Pytorch tensor shape detected: 192x960 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:22,415 INFO Layer 232: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:22,419 INFO     Weight matrix 1/1 (192,960): Analyzing ...\n",
      "2018-11-26 12:52:24,906 INFO     Weight matrix 1/1 (192,960): Alpha: 3.7729124585070304, Alpha Weighted: 0.46523859312356736, D: 0.091033961193073\n",
      "2018-11-26 12:52:24,909 INFO     Weight matrix 1/1 (192,960): Alpha 3.7729124585070304 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:52:24,913 INFO     Weight matrix 1/1 (192,960): Lognorm: 0.5675647854804993\n",
      "2018-11-26 12:52:24,918 INFO Layer 233: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:24,922 INFO Layer 233: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:24,926 INFO Layer 234: ReLU(inplace)\n",
      "2018-11-26 12:52:24,929 INFO Layer 234: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:24,936 INFO Layer 235: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:24,940 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:24,943 INFO Layer 235: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:24,947 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:24,951 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:24,955 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:24,958 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:24,963 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:24,967 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:24,970 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:24,974 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:24,978 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:24,982 INFO Layer 236: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:24,985 INFO Layer 236: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:24,990 INFO Layer 237: BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:24,993 INFO Layer 237: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:24,997 INFO Layer 238: ReLU(inplace)\n",
      "2018-11-26 12:52:25,001 INFO Layer 238: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:25,006 INFO Layer 239: Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:25,014 INFO Pytorch tensor shape detected: 192x1008 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:25,017 INFO Layer 239: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:25,022 INFO     Weight matrix 1/1 (192,1008): Analyzing ...\n",
      "2018-11-26 12:52:27,153 INFO     Weight matrix 1/1 (192,1008): Alpha: 4.647784690042033, Alpha Weighted: 0.7046129005117765, D: 0.10717694658042476\n",
      "2018-11-26 12:52:27,156 INFO     Weight matrix 1/1 (192,1008): Alpha 4.647784690042033 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:52:27,159 INFO     Weight matrix 1/1 (192,1008): Lognorm: 0.7580776214599609\n",
      "2018-11-26 12:52:27,163 INFO Layer 240: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:27,169 INFO Layer 240: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:27,171 INFO Layer 241: ReLU(inplace)\n",
      "2018-11-26 12:52:27,175 INFO Layer 241: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:27,181 INFO Layer 242: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:27,190 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:27,195 INFO Layer 242: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:27,199 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:27,206 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:27,211 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:27,214 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:27,225 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:27,229 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:27,233 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:27,239 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:27,243 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:27,247 INFO Layer 243: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:27,251 INFO Layer 243: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:27,255 INFO Layer 244: BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:27,267 INFO Layer 244: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:27,270 INFO Layer 245: ReLU(inplace)\n",
      "2018-11-26 12:52:27,273 INFO Layer 245: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:27,283 INFO Layer 246: Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:27,287 INFO Pytorch tensor shape detected: 192x1056 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:27,290 INFO Layer 246: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:27,295 INFO     Weight matrix 1/1 (192,1056): Analyzing ...\n",
      "2018-11-26 12:52:29,411 INFO     Weight matrix 1/1 (192,1056): Alpha: 2.152911362195699, Alpha Weighted: -0.047197445685523684, D: 0.15803274287959002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:52:29,415 INFO     Weight matrix 1/1 (192,1056): Lognorm: 0.7064769268035889\n",
      "2018-11-26 12:52:29,421 INFO Layer 247: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:29,424 INFO Layer 247: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:29,428 INFO Layer 248: ReLU(inplace)\n",
      "2018-11-26 12:52:29,431 INFO Layer 248: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:29,436 INFO Layer 249: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:29,442 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:29,446 INFO Layer 249: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:29,449 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:29,452 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:29,456 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:29,462 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:29,465 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:29,469 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:29,472 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:29,476 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:29,480 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:29,485 INFO Layer 250: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:29,488 INFO Layer 250: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:29,491 INFO Layer 251: BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:29,495 INFO Layer 251: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:29,498 INFO Layer 252: ReLU(inplace)\n",
      "2018-11-26 12:52:29,501 INFO Layer 252: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:29,505 INFO Layer 253: Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:29,510 INFO Pytorch tensor shape detected: 192x1104 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:29,513 INFO Layer 253: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:29,516 INFO     Weight matrix 1/1 (192,1104): Analyzing ...\n",
      "2018-11-26 12:52:31,576 INFO     Weight matrix 1/1 (192,1104): Alpha: 4.256215260756702, Alpha Weighted: 0.5475540796288769, D: 0.08605954674262406\n",
      "2018-11-26 12:52:31,579 INFO     Weight matrix 1/1 (192,1104): Alpha 4.256215260756702 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:52:31,582 INFO     Weight matrix 1/1 (192,1104): Lognorm: 0.7156630754470825\n",
      "2018-11-26 12:52:31,584 INFO Layer 254: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:31,586 INFO Layer 254: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:31,588 INFO Layer 255: ReLU(inplace)\n",
      "2018-11-26 12:52:31,592 INFO Layer 255: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:31,594 INFO Layer 256: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:31,599 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:31,603 INFO Layer 256: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:31,607 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:31,610 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:31,613 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:31,615 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:31,620 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:31,622 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:31,625 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:31,628 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:31,632 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:31,635 INFO Layer 257: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:31,638 INFO Layer 257: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:31,641 INFO Layer 258: BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:31,644 INFO Layer 258: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:31,647 INFO Layer 259: ReLU(inplace)\n",
      "2018-11-26 12:52:31,650 INFO Layer 259: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:31,654 INFO Layer 260: Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:31,659 INFO Pytorch tensor shape detected: 192x1152 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:31,662 INFO Layer 260: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:31,666 INFO     Weight matrix 1/1 (192,1152): Analyzing ...\n",
      "2018-11-26 12:52:33,834 INFO     Weight matrix 1/1 (192,1152): Alpha: 2.6849162656831527, Alpha Weighted: 0.22471595235161196, D: 0.12915754539370938\n",
      "2018-11-26 12:52:33,837 INFO     Weight matrix 1/1 (192,1152): Lognorm: 0.711022138595581\n",
      "2018-11-26 12:52:33,839 INFO Layer 261: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:33,843 INFO Layer 261: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:33,846 INFO Layer 262: ReLU(inplace)\n",
      "2018-11-26 12:52:33,848 INFO Layer 262: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:33,851 INFO Layer 263: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:33,856 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:33,859 INFO Layer 263: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:33,862 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:33,866 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:33,872 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:33,875 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:33,878 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:33,881 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:33,884 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:33,887 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:33,891 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:33,895 INFO Layer 264: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:33,898 INFO Layer 264: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:33,901 INFO Layer 265: BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:33,906 INFO Layer 265: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:33,908 INFO Layer 266: ReLU(inplace)\n",
      "2018-11-26 12:52:33,911 INFO Layer 266: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:33,915 INFO Layer 267: Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:33,920 INFO Pytorch tensor shape detected: 192x1200 (NxM), 1x1 (i,j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:52:33,923 INFO Layer 267: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:33,926 INFO     Weight matrix 1/1 (192,1200): Analyzing ...\n",
      "2018-11-26 12:52:35,892 INFO     Weight matrix 1/1 (192,1200): Alpha: 5.39870433468153, Alpha Weighted: 0.20371212507245778, D: 0.11266056469601682\n",
      "2018-11-26 12:52:35,894 INFO     Weight matrix 1/1 (192,1200): Alpha 5.39870433468153 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:52:35,897 INFO     Weight matrix 1/1 (192,1200): Lognorm: 0.7174281477928162\n",
      "2018-11-26 12:52:35,900 INFO Layer 268: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:35,906 INFO Layer 268: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:35,909 INFO Layer 269: ReLU(inplace)\n",
      "2018-11-26 12:52:35,911 INFO Layer 269: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:35,914 INFO Layer 270: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:35,921 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:35,924 INFO Layer 270: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:35,927 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:35,930 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:35,935 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:35,938 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:35,941 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:35,945 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:35,948 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:35,952 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:35,956 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:35,959 INFO Layer 271: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:35,964 INFO Layer 271: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:35,967 INFO Layer 272: BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:35,969 INFO Layer 272: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:35,971 INFO Layer 273: ReLU(inplace)\n",
      "2018-11-26 12:52:35,974 INFO Layer 273: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:35,976 INFO Layer 274: Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:35,981 INFO Pytorch tensor shape detected: 192x1248 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:35,983 INFO Layer 274: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:35,986 INFO     Weight matrix 1/1 (192,1248): Analyzing ...\n",
      "2018-11-26 12:52:37,756 INFO     Weight matrix 1/1 (192,1248): Alpha: 2.122631184537568, Alpha Weighted: 0.4353067416156264, D: 0.11157345096580806\n",
      "2018-11-26 12:52:37,759 INFO     Weight matrix 1/1 (192,1248): Lognorm: 0.7501013278961182\n",
      "2018-11-26 12:52:37,762 INFO Layer 275: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:37,764 INFO Layer 275: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:37,767 INFO Layer 276: ReLU(inplace)\n",
      "2018-11-26 12:52:37,769 INFO Layer 276: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:37,776 INFO Layer 277: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:37,778 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:37,781 INFO Layer 277: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:37,784 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:37,786 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:37,789 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:37,791 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:37,794 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:37,796 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:37,799 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:37,802 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:37,804 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:37,807 INFO Layer 278: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:37,809 INFO Layer 278: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:37,813 INFO Layer 279: BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:37,817 INFO Layer 279: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:37,820 INFO Layer 280: ReLU(inplace)\n",
      "2018-11-26 12:52:37,823 INFO Layer 280: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:37,826 INFO Layer 281: Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:37,831 INFO Pytorch tensor shape detected: 192x1296 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:37,834 INFO Layer 281: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:37,838 INFO     Weight matrix 1/1 (192,1296): Analyzing ...\n",
      "2018-11-26 12:52:40,007 INFO     Weight matrix 1/1 (192,1296): Alpha: 2.260201271211387, Alpha Weighted: 0.18308814189464703, D: 0.11892854476853232\n",
      "2018-11-26 12:52:40,010 INFO     Weight matrix 1/1 (192,1296): Lognorm: 0.7236207723617554\n",
      "2018-11-26 12:52:40,013 INFO Layer 282: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:40,016 INFO Layer 282: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:40,019 INFO Layer 283: ReLU(inplace)\n",
      "2018-11-26 12:52:40,022 INFO Layer 283: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:40,025 INFO Layer 284: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:40,031 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:40,033 INFO Layer 284: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:40,036 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:40,039 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:40,041 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:40,044 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:40,047 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:40,050 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:40,053 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:40,057 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:40,061 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:40,064 INFO Layer 285: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:40,067 INFO Layer 285: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:40,071 INFO Layer 286: BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:40,075 INFO Layer 286: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:52:40,077 INFO Layer 287: ReLU(inplace)\n",
      "2018-11-26 12:52:40,080 INFO Layer 287: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:40,083 INFO Layer 288: Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:40,087 INFO Pytorch tensor shape detected: 192x1344 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:40,089 INFO Layer 288: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:40,093 INFO     Weight matrix 1/1 (192,1344): Analyzing ...\n",
      "2018-11-26 12:52:42,257 INFO     Weight matrix 1/1 (192,1344): Alpha: 2.3428383871074594, Alpha Weighted: 0.7102334078231448, D: 0.11173867194750342\n",
      "2018-11-26 12:52:42,260 INFO     Weight matrix 1/1 (192,1344): Lognorm: 0.8077215552330017\n",
      "2018-11-26 12:52:42,263 INFO Layer 289: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:42,267 INFO Layer 289: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:42,271 INFO Layer 290: ReLU(inplace)\n",
      "2018-11-26 12:52:42,273 INFO Layer 290: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:42,277 INFO Layer 291: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:42,282 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:42,286 INFO Layer 291: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:42,289 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:42,293 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:42,295 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:42,297 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:42,300 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:42,302 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:42,306 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:42,309 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:42,312 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:42,315 INFO Layer 292: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:42,319 INFO Layer 292: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:42,323 INFO Layer 293: BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:42,326 INFO Layer 293: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:42,329 INFO Layer 294: ReLU(inplace)\n",
      "2018-11-26 12:52:42,331 INFO Layer 294: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:42,335 INFO Layer 295: Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:42,339 INFO Pytorch tensor shape detected: 192x1392 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:42,341 INFO Layer 295: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:42,344 INFO     Weight matrix 1/1 (192,1392): Analyzing ...\n",
      "2018-11-26 12:52:44,415 INFO     Weight matrix 1/1 (192,1392): Alpha: 5.229841406978098, Alpha Weighted: 0.4278219066606518, D: 0.10540333349786313\n",
      "2018-11-26 12:52:44,418 INFO     Weight matrix 1/1 (192,1392): Alpha 5.229841406978098 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:52:44,421 INFO     Weight matrix 1/1 (192,1392): Lognorm: 0.7644276022911072\n",
      "2018-11-26 12:52:44,424 INFO Layer 296: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:44,426 INFO Layer 296: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:44,428 INFO Layer 297: ReLU(inplace)\n",
      "2018-11-26 12:52:44,431 INFO Layer 297: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:44,434 INFO Layer 298: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:44,439 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:44,442 INFO Layer 298: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:44,444 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:44,447 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:44,450 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:44,452 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:44,456 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:44,458 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:44,461 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:44,463 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:44,466 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:44,469 INFO Layer 299: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:44,472 INFO Layer 299: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:44,475 INFO Layer 300: BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:44,479 INFO Layer 300: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:44,482 INFO Layer 301: ReLU(inplace)\n",
      "2018-11-26 12:52:44,485 INFO Layer 301: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:44,488 INFO Layer 302: Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:44,492 INFO Pytorch tensor shape detected: 192x1440 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:44,495 INFO Layer 302: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:44,499 INFO     Weight matrix 1/1 (192,1440): Analyzing ...\n",
      "2018-11-26 12:52:46,543 INFO     Weight matrix 1/1 (192,1440): Alpha: 2.034615217479879, Alpha Weighted: 0.10189935392753398, D: 0.13062616358515122\n",
      "2018-11-26 12:52:46,546 INFO     Weight matrix 1/1 (192,1440): Lognorm: 0.6728474497795105\n",
      "2018-11-26 12:52:46,549 INFO Layer 303: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:46,552 INFO Layer 303: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:46,556 INFO Layer 304: ReLU(inplace)\n",
      "2018-11-26 12:52:46,558 INFO Layer 304: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:46,560 INFO Layer 305: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:46,564 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:46,567 INFO Layer 305: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:46,569 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:46,572 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:46,576 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:46,578 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:46,582 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:46,584 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:46,587 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:46,590 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:46,592 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:46,595 INFO Layer 306: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:52:46,598 INFO Layer 306: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:46,601 INFO Layer 307: BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:46,603 INFO Layer 307: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:46,607 INFO Layer 308: ReLU(inplace)\n",
      "2018-11-26 12:52:46,611 INFO Layer 308: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:46,615 INFO Layer 309: Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:46,619 INFO Pytorch tensor shape detected: 192x1488 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:46,623 INFO Layer 309: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:46,626 INFO     Weight matrix 1/1 (192,1488): Analyzing ...\n",
      "2018-11-26 12:52:48,702 INFO     Weight matrix 1/1 (192,1488): Alpha: 2.6160348806870113, Alpha Weighted: 0.7316686537592805, D: 0.11776858665457046\n",
      "2018-11-26 12:52:48,705 INFO     Weight matrix 1/1 (192,1488): Lognorm: 0.8135579228401184\n",
      "2018-11-26 12:52:48,708 INFO Layer 310: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:48,710 INFO Layer 310: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:48,713 INFO Layer 311: ReLU(inplace)\n",
      "2018-11-26 12:52:48,717 INFO Layer 311: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:48,720 INFO Layer 312: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:48,724 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:48,728 INFO Layer 312: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:48,732 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:48,734 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:48,737 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:48,739 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:48,743 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:48,746 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:48,749 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:48,752 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:48,755 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:48,759 INFO Layer 313: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:48,763 INFO Layer 313: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:48,767 INFO Layer 314: BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:48,770 INFO Layer 314: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:48,774 INFO Layer 315: ReLU(inplace)\n",
      "2018-11-26 12:52:48,778 INFO Layer 315: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:48,781 INFO Layer 316: Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:48,787 INFO Pytorch tensor shape detected: 192x1536 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:48,790 INFO Layer 316: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:48,793 INFO     Weight matrix 1/1 (192,1536): Analyzing ...\n",
      "2018-11-26 12:52:51,011 INFO     Weight matrix 1/1 (192,1536): Alpha: 5.355429052664251, Alpha Weighted: 1.0341997742827416, D: 0.110118485838681\n",
      "2018-11-26 12:52:51,017 INFO     Weight matrix 1/1 (192,1536): Alpha 5.355429052664251 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:52:51,022 INFO     Weight matrix 1/1 (192,1536): Lognorm: 0.7962035536766052\n",
      "2018-11-26 12:52:51,026 INFO Layer 317: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:51,030 INFO Layer 317: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:51,032 INFO Layer 318: ReLU(inplace)\n",
      "2018-11-26 12:52:51,038 INFO Layer 318: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:51,041 INFO Layer 319: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:51,045 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:51,048 INFO Layer 319: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:51,051 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:51,055 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:51,059 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:51,062 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:51,065 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:51,069 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:51,077 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:51,080 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:51,084 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:51,088 INFO Layer 320: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:51,090 INFO Layer 320: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:51,095 INFO Layer 321: BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:51,097 INFO Layer 321: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:51,100 INFO Layer 322: ReLU(inplace)\n",
      "2018-11-26 12:52:51,103 INFO Layer 322: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:51,106 INFO Layer 323: Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:51,113 INFO Pytorch tensor shape detected: 192x1584 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:51,116 INFO Layer 323: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:51,120 INFO     Weight matrix 1/1 (192,1584): Analyzing ...\n",
      "2018-11-26 12:52:53,302 INFO     Weight matrix 1/1 (192,1584): Alpha: 3.589854234798129, Alpha Weighted: 0.7960455445009221, D: 0.10098094846374905\n",
      "2018-11-26 12:52:53,306 INFO     Weight matrix 1/1 (192,1584): Alpha 3.589854234798129 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:52:53,311 INFO     Weight matrix 1/1 (192,1584): Lognorm: 0.8070045113563538\n",
      "2018-11-26 12:52:53,315 INFO Layer 324: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:53,319 INFO Layer 324: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:53,321 INFO Layer 325: ReLU(inplace)\n",
      "2018-11-26 12:52:53,325 INFO Layer 325: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:53,328 INFO Layer 326: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:53,332 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:53,334 INFO Layer 326: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:53,337 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:53,340 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:53,344 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:53,349 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:53,353 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:53,357 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:53,360 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:53,364 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:53,368 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:53,372 INFO Layer 327: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:52:53,376 INFO Layer 327: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:53,380 INFO Layer 328: BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:53,386 INFO Layer 328: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:53,392 INFO Layer 329: ReLU(inplace)\n",
      "2018-11-26 12:52:53,396 INFO Layer 329: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:53,399 INFO Layer 330: Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:53,403 INFO Pytorch tensor shape detected: 192x1632 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:53,408 INFO Layer 330: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:53,414 INFO     Weight matrix 1/1 (192,1632): Analyzing ...\n",
      "2018-11-26 12:52:55,455 INFO     Weight matrix 1/1 (192,1632): Alpha: 4.044777552097419, Alpha Weighted: 0.8855214259748723, D: 0.0955048451099797\n",
      "2018-11-26 12:52:55,457 INFO     Weight matrix 1/1 (192,1632): Alpha 4.044777552097419 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:52:55,461 INFO     Weight matrix 1/1 (192,1632): Lognorm: 0.8285072445869446\n",
      "2018-11-26 12:52:55,466 INFO Layer 331: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:55,468 INFO Layer 331: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:55,471 INFO Layer 332: ReLU(inplace)\n",
      "2018-11-26 12:52:55,474 INFO Layer 332: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:55,477 INFO Layer 333: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:55,480 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:55,482 INFO Layer 333: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:55,485 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:55,488 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:55,491 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:55,495 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:55,498 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:55,500 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:55,504 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:55,507 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:55,511 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:55,515 INFO Layer 334: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:55,519 INFO Layer 334: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:55,522 INFO Layer 335: BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:55,524 INFO Layer 335: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:55,527 INFO Layer 336: ReLU(inplace)\n",
      "2018-11-26 12:52:55,531 INFO Layer 336: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:55,533 INFO Layer 337: Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:55,538 INFO Pytorch tensor shape detected: 192x1680 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:55,540 INFO Layer 337: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:55,544 INFO     Weight matrix 1/1 (192,1680): Analyzing ...\n",
      "2018-11-26 12:52:57,403 INFO     Weight matrix 1/1 (192,1680): Alpha: 3.4438802933092276, Alpha Weighted: 0.777426619960904, D: 0.097107286077451\n",
      "2018-11-26 12:52:57,407 INFO     Weight matrix 1/1 (192,1680): Lognorm: 0.8077895641326904\n",
      "2018-11-26 12:52:57,409 INFO Layer 338: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:57,412 INFO Layer 338: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:57,415 INFO Layer 339: ReLU(inplace)\n",
      "2018-11-26 12:52:57,417 INFO Layer 339: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:57,420 INFO Layer 340: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:57,423 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:57,425 INFO Layer 340: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:57,427 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:57,430 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:57,432 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:57,435 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:57,438 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:57,441 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:57,443 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:57,446 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:57,449 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:57,452 INFO Layer 341: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:52:57,454 INFO Layer 341: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:57,457 INFO Layer 342: BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:57,459 INFO Layer 342: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:57,462 INFO Layer 343: ReLU(inplace)\n",
      "2018-11-26 12:52:57,464 INFO Layer 343: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:57,466 INFO Layer 344: Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:57,471 INFO Pytorch tensor shape detected: 192x1728 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:57,474 INFO Layer 344: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:57,478 INFO     Weight matrix 1/1 (192,1728): Analyzing ...\n",
      "2018-11-26 12:52:59,743 INFO     Weight matrix 1/1 (192,1728): Alpha: 2.4647485806413663, Alpha Weighted: 1.007440414040072, D: 0.07929504001591992\n",
      "2018-11-26 12:52:59,749 INFO     Weight matrix 1/1 (192,1728): Lognorm: 0.8212069869041443\n",
      "2018-11-26 12:52:59,752 INFO Layer 345: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:59,757 INFO Layer 345: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:59,764 INFO Layer 346: ReLU(inplace)\n",
      "2018-11-26 12:52:59,767 INFO Layer 346: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:59,772 INFO Layer 347: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:52:59,778 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:52:59,781 INFO Layer 347: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:52:59,785 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:59,792 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:59,796 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:59,800 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:59,805 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:59,812 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:59,818 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:59,824 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:59,827 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:52:59,833 INFO Layer 348: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:52:59,835 INFO Layer 348: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:59,838 INFO Layer 349: BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:52:59,840 INFO Layer 349: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:59,843 INFO Layer 350: ReLU(inplace)\n",
      "2018-11-26 12:52:59,846 INFO Layer 350: Skipping (Layer not supported)\n",
      "2018-11-26 12:52:59,850 INFO Layer 351: Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:52:59,859 INFO Pytorch tensor shape detected: 192x1776 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:52:59,863 INFO Layer 351: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:52:59,868 INFO     Weight matrix 1/1 (192,1776): Analyzing ...\n",
      "2018-11-26 12:53:02,096 INFO     Weight matrix 1/1 (192,1776): Alpha: 3.450458612968661, Alpha Weighted: 1.1795825094204948, D: 0.0767845964478251\n",
      "2018-11-26 12:53:02,099 INFO     Weight matrix 1/1 (192,1776): Lognorm: 0.8491942882537842\n",
      "2018-11-26 12:53:02,102 INFO Layer 352: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:02,105 INFO Layer 352: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:02,107 INFO Layer 353: ReLU(inplace)\n",
      "2018-11-26 12:53:02,111 INFO Layer 353: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:02,115 INFO Layer 354: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:02,118 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:02,121 INFO Layer 354: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:02,125 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:02,128 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:02,131 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:02,134 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:02,137 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:02,140 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:02,143 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:02,146 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:02,149 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:02,151 INFO Layer 355: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:02,155 INFO Layer 355: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:02,158 INFO Layer 356: BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:02,162 INFO Layer 356: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:02,165 INFO Layer 357: ReLU(inplace)\n",
      "2018-11-26 12:53:02,169 INFO Layer 357: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:02,175 INFO Layer 358: Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:02,180 INFO Pytorch tensor shape detected: 192x1824 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:02,182 INFO Layer 358: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:02,185 INFO     Weight matrix 1/1 (192,1824): Analyzing ...\n",
      "2018-11-26 12:53:04,309 INFO     Weight matrix 1/1 (192,1824): Alpha: 3.139420427234135, Alpha Weighted: 0.7123058536591103, D: 0.1012066150943553\n",
      "2018-11-26 12:53:04,313 INFO     Weight matrix 1/1 (192,1824): Lognorm: 0.8259353637695312\n",
      "2018-11-26 12:53:04,317 INFO Layer 359: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:04,324 INFO Layer 359: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:04,327 INFO Layer 360: ReLU(inplace)\n",
      "2018-11-26 12:53:04,330 INFO Layer 360: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:04,332 INFO Layer 361: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:04,338 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:04,341 INFO Layer 361: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:04,344 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:04,346 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:04,349 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:04,352 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:04,354 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:04,358 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:04,360 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:04,363 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:04,369 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:04,373 INFO Layer 362: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:04,376 INFO Layer 362: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:04,378 INFO Layer 363: BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:04,381 INFO Layer 363: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:04,384 INFO Layer 364: ReLU(inplace)\n",
      "2018-11-26 12:53:04,387 INFO Layer 364: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:04,391 INFO Layer 365: Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:04,396 INFO Pytorch tensor shape detected: 192x1872 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:04,399 INFO Layer 365: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:04,402 INFO     Weight matrix 1/1 (192,1872): Analyzing ...\n",
      "2018-11-26 12:53:06,595 INFO     Weight matrix 1/1 (192,1872): Alpha: 5.337704468531211, Alpha Weighted: 1.5733243699979407, D: 0.07662689862912675\n",
      "2018-11-26 12:53:06,598 INFO     Weight matrix 1/1 (192,1872): Alpha 5.337704468531211 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:06,604 INFO     Weight matrix 1/1 (192,1872): Lognorm: 0.8487169742584229\n",
      "2018-11-26 12:53:06,608 INFO Layer 366: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:06,611 INFO Layer 366: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:06,613 INFO Layer 367: ReLU(inplace)\n",
      "2018-11-26 12:53:06,616 INFO Layer 367: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:06,619 INFO Layer 368: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:06,623 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:06,626 INFO Layer 368: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:06,629 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:06,636 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:06,639 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:06,642 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:06,645 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:06,648 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:06,651 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:06,655 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:06,659 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:06,663 INFO Layer 369: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:53:06,666 INFO Layer 369: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:06,670 INFO Layer 370: BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:06,674 INFO Layer 370: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:06,677 INFO Layer 371: ReLU(inplace)\n",
      "2018-11-26 12:53:06,680 INFO Layer 371: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:06,683 INFO Layer 372: Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:06,687 INFO Pytorch tensor shape detected: 192x1920 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:06,690 INFO Layer 372: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:06,693 INFO     Weight matrix 1/1 (192,1920): Analyzing ...\n",
      "2018-11-26 12:53:09,051 INFO     Weight matrix 1/1 (192,1920): Alpha: 3.7180184814466775, Alpha Weighted: 0.8494795523017086, D: 0.08667515615227694\n",
      "2018-11-26 12:53:09,054 INFO     Weight matrix 1/1 (192,1920): Alpha 3.7180184814466775 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:09,058 INFO     Weight matrix 1/1 (192,1920): Lognorm: 0.8398658633232117\n",
      "2018-11-26 12:53:09,061 INFO Layer 373: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:09,065 INFO Layer 373: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:09,067 INFO Layer 374: ReLU(inplace)\n",
      "2018-11-26 12:53:09,070 INFO Layer 374: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:09,072 INFO Layer 375: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:09,078 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:09,081 INFO Layer 375: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:09,084 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:09,087 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:09,091 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:09,093 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:09,096 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:09,098 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:09,101 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:09,104 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:09,109 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:09,115 INFO Layer 376: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:09,119 INFO Layer 376: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:09,123 INFO Layer 377: BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:09,126 INFO Layer 377: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:09,129 INFO Layer 378: ReLU(inplace)\n",
      "2018-11-26 12:53:09,131 INFO Layer 378: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:09,135 INFO Layer 379: Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:09,144 INFO Pytorch tensor shape detected: 192x1968 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:09,147 INFO Layer 379: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:09,151 INFO     Weight matrix 1/1 (192,1968): Analyzing ...\n",
      "2018-11-26 12:53:11,327 INFO     Weight matrix 1/1 (192,1968): Alpha: 5.012821130454169, Alpha Weighted: 1.7345800561611018, D: 0.062499999999999445\n",
      "2018-11-26 12:53:11,330 INFO     Weight matrix 1/1 (192,1968): Alpha 5.012821130454169 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:11,334 INFO     Weight matrix 1/1 (192,1968): Lognorm: 0.8748267889022827\n",
      "2018-11-26 12:53:11,338 INFO Layer 380: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:11,341 INFO Layer 380: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:11,345 INFO Layer 381: ReLU(inplace)\n",
      "2018-11-26 12:53:11,347 INFO Layer 381: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:11,350 INFO Layer 382: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:11,354 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:11,358 INFO Layer 382: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:11,363 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:11,367 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:11,370 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:11,374 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:11,377 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:11,381 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:11,384 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:11,389 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:11,392 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:11,396 INFO Layer 383: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:11,399 INFO Layer 383: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:11,402 INFO Layer 384: BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:11,406 INFO Layer 384: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:11,410 INFO Layer 385: ReLU(inplace)\n",
      "2018-11-26 12:53:11,414 INFO Layer 385: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:11,418 INFO Layer 386: Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:11,424 INFO Pytorch tensor shape detected: 192x2016 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:11,427 INFO Layer 386: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:11,431 INFO     Weight matrix 1/1 (192,2016): Analyzing ...\n",
      "2018-11-26 12:53:14,020 INFO     Weight matrix 1/1 (192,2016): Alpha: 3.2322367235718805, Alpha Weighted: 1.1835185131227655, D: 0.08425576139835211\n",
      "2018-11-26 12:53:14,025 INFO     Weight matrix 1/1 (192,2016): Lognorm: 0.8580556511878967\n",
      "2018-11-26 12:53:14,030 INFO Layer 387: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:14,033 INFO Layer 387: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:14,037 INFO Layer 388: ReLU(inplace)\n",
      "2018-11-26 12:53:14,040 INFO Layer 388: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:14,043 INFO Layer 389: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:14,049 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:14,051 INFO Layer 389: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:14,054 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:14,058 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:14,061 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:14,065 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:14,068 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:14,070 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:14,073 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:14,076 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:14,079 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:14,082 INFO Layer 390: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:53:14,085 INFO Layer 390: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:14,087 INFO Layer 391: BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:14,090 INFO Layer 391: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:14,092 INFO Layer 392: ReLU(inplace)\n",
      "2018-11-26 12:53:14,095 INFO Layer 392: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:14,097 INFO Layer 393: Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:14,103 INFO Pytorch tensor shape detected: 192x2064 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:14,109 INFO Layer 393: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:14,113 INFO     Weight matrix 1/1 (192,2064): Analyzing ...\n",
      "2018-11-26 12:53:16,294 INFO     Weight matrix 1/1 (192,2064): Alpha: 5.810022453582131, Alpha Weighted: 1.5788876450939104, D: 0.0769230769230762\n",
      "2018-11-26 12:53:16,297 INFO     Weight matrix 1/1 (192,2064): Alpha 5.810022453582131 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:16,301 INFO     Weight matrix 1/1 (192,2064): Lognorm: 0.8535867929458618\n",
      "2018-11-26 12:53:16,305 INFO Layer 394: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:16,309 INFO Layer 394: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:16,313 INFO Layer 395: ReLU(inplace)\n",
      "2018-11-26 12:53:16,316 INFO Layer 395: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:16,319 INFO Layer 396: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:16,323 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:16,326 INFO Layer 396: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:16,330 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:16,335 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:16,338 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:16,340 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:16,344 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:16,346 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:16,349 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:16,353 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:16,357 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:16,361 INFO Layer 397: _Transition(\n",
      "  (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "2018-11-26 12:53:16,365 INFO Layer 397: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:16,368 INFO Layer 398: BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:16,371 INFO Layer 398: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:16,375 INFO Layer 399: ReLU(inplace)\n",
      "2018-11-26 12:53:16,378 INFO Layer 399: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:16,382 INFO Layer 400: Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:16,442 INFO Pytorch tensor shape detected: 1056x2112 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:16,444 INFO Layer 400: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:16,447 INFO     Weight matrix 1/1 (1056,2112): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:53:16,450 INFO Layer 401: AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "2018-11-26 12:53:16,454 INFO Layer 401: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:16,464 INFO Layer 402: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer7): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer8): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer9): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer10): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer11): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer12): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer13): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer14): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer15): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer16): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer17): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer18): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer19): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer20): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer21): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer22): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer23): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer24): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:53:16,469 INFO Layer 402: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:16,472 INFO Layer 403: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:16,475 INFO Layer 403: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:16,477 INFO Layer 404: BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:16,481 INFO Layer 404: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:16,486 INFO Layer 405: ReLU(inplace)\n",
      "2018-11-26 12:53:16,489 INFO Layer 405: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:16,491 INFO Layer 406: Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:16,499 INFO Pytorch tensor shape detected: 192x1056 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:16,504 INFO Layer 406: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:16,508 INFO     Weight matrix 1/1 (192,1056): Analyzing ...\n",
      "2018-11-26 12:53:18,531 INFO     Weight matrix 1/1 (192,1056): Alpha: 2.828585162503657, Alpha Weighted: -0.0442425910645382, D: 0.14109243506842228\n",
      "2018-11-26 12:53:18,534 INFO     Weight matrix 1/1 (192,1056): Lognorm: 0.7011712193489075\n",
      "2018-11-26 12:53:18,539 INFO Layer 407: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:18,542 INFO Layer 407: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:18,545 INFO Layer 408: ReLU(inplace)\n",
      "2018-11-26 12:53:18,548 INFO Layer 408: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:18,550 INFO Layer 409: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:18,554 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:18,556 INFO Layer 409: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:18,559 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:18,561 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:18,564 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:18,568 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:18,571 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:18,573 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:18,576 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:18,579 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:18,582 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:18,584 INFO Layer 410: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:18,587 INFO Layer 410: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:18,591 INFO Layer 411: BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:18,594 INFO Layer 411: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:18,598 INFO Layer 412: ReLU(inplace)\n",
      "2018-11-26 12:53:18,601 INFO Layer 412: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:18,604 INFO Layer 413: Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:18,609 INFO Pytorch tensor shape detected: 192x1104 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:18,613 INFO Layer 413: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:18,616 INFO     Weight matrix 1/1 (192,1104): Analyzing ...\n",
      "2018-11-26 12:53:20,562 INFO     Weight matrix 1/1 (192,1104): Alpha: 2.7234924643189835, Alpha Weighted: 0.10759759956065726, D: 0.1439060835006159\n",
      "2018-11-26 12:53:20,566 INFO     Weight matrix 1/1 (192,1104): Lognorm: 0.6863213777542114\n",
      "2018-11-26 12:53:20,568 INFO Layer 414: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:20,571 INFO Layer 414: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:20,576 INFO Layer 415: ReLU(inplace)\n",
      "2018-11-26 12:53:20,580 INFO Layer 415: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:20,584 INFO Layer 416: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:20,588 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:20,590 INFO Layer 416: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:20,593 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:20,596 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:20,599 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:20,603 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:20,606 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:20,610 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:20,614 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:20,617 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:20,621 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:20,625 INFO Layer 417: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:20,628 INFO Layer 417: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:20,632 INFO Layer 418: BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:20,636 INFO Layer 418: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:20,639 INFO Layer 419: ReLU(inplace)\n",
      "2018-11-26 12:53:20,643 INFO Layer 419: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:20,647 INFO Layer 420: Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:20,652 INFO Pytorch tensor shape detected: 192x1152 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:20,659 INFO Layer 420: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:20,662 INFO     Weight matrix 1/1 (192,1152): Analyzing ...\n",
      "2018-11-26 12:53:22,765 INFO     Weight matrix 1/1 (192,1152): Alpha: 3.4952507103125434, Alpha Weighted: 1.030130372769079, D: 0.0710709777990518\n",
      "2018-11-26 12:53:22,768 INFO     Weight matrix 1/1 (192,1152): Lognorm: 0.8150581121444702\n",
      "2018-11-26 12:53:22,771 INFO Layer 421: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:22,774 INFO Layer 421: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:22,776 INFO Layer 422: ReLU(inplace)\n",
      "2018-11-26 12:53:22,779 INFO Layer 422: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:22,784 INFO Layer 423: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:22,788 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:22,791 INFO Layer 423: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:22,794 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:22,797 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:22,800 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:22,802 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:22,806 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:22,809 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:53:22,812 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:22,815 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:22,819 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:22,823 INFO Layer 424: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:22,826 INFO Layer 424: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:22,829 INFO Layer 425: BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:22,832 INFO Layer 425: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:22,834 INFO Layer 426: ReLU(inplace)\n",
      "2018-11-26 12:53:22,837 INFO Layer 426: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:22,839 INFO Layer 427: Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:22,843 INFO Pytorch tensor shape detected: 192x1200 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:22,846 INFO Layer 427: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:22,849 INFO     Weight matrix 1/1 (192,1200): Analyzing ...\n",
      "2018-11-26 12:53:24,902 INFO     Weight matrix 1/1 (192,1200): Alpha: 3.400688498954868, Alpha Weighted: 0.7377521555286304, D: 0.08531184142667692\n",
      "2018-11-26 12:53:24,906 INFO     Weight matrix 1/1 (192,1200): Lognorm: 0.7890795469284058\n",
      "2018-11-26 12:53:24,909 INFO Layer 428: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:24,914 INFO Layer 428: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:24,917 INFO Layer 429: ReLU(inplace)\n",
      "2018-11-26 12:53:24,920 INFO Layer 429: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:24,922 INFO Layer 430: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:24,927 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:24,930 INFO Layer 430: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:24,934 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:24,937 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:24,940 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:24,943 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:24,947 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:24,950 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:24,954 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:24,957 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:24,962 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:24,966 INFO Layer 431: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:24,971 INFO Layer 431: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:24,973 INFO Layer 432: BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:24,977 INFO Layer 432: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:24,982 INFO Layer 433: ReLU(inplace)\n",
      "2018-11-26 12:53:24,987 INFO Layer 433: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:24,990 INFO Layer 434: Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:24,997 INFO Pytorch tensor shape detected: 192x1248 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:25,000 INFO Layer 434: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:25,004 INFO     Weight matrix 1/1 (192,1248): Analyzing ...\n",
      "2018-11-26 12:53:27,077 INFO     Weight matrix 1/1 (192,1248): Alpha: 2.165450148282992, Alpha Weighted: 0.528525921088255, D: 0.1235597380764219\n",
      "2018-11-26 12:53:27,081 INFO     Weight matrix 1/1 (192,1248): Lognorm: 0.8213930726051331\n",
      "2018-11-26 12:53:27,085 INFO Layer 435: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:27,088 INFO Layer 435: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:27,092 INFO Layer 436: ReLU(inplace)\n",
      "2018-11-26 12:53:27,094 INFO Layer 436: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:27,097 INFO Layer 437: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:27,102 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:27,105 INFO Layer 437: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:27,107 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:27,111 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:27,115 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:27,121 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:27,124 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:27,126 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:27,130 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:27,133 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:27,136 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:27,139 INFO Layer 438: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:27,141 INFO Layer 438: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:27,143 INFO Layer 439: BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:27,146 INFO Layer 439: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:27,148 INFO Layer 440: ReLU(inplace)\n",
      "2018-11-26 12:53:27,151 INFO Layer 440: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:27,154 INFO Layer 441: Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:27,159 INFO Pytorch tensor shape detected: 192x1296 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:27,162 INFO Layer 441: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:27,167 INFO     Weight matrix 1/1 (192,1296): Analyzing ...\n",
      "2018-11-26 12:53:29,443 INFO     Weight matrix 1/1 (192,1296): Alpha: 5.205555992472794, Alpha Weighted: 0.6303882207419235, D: 0.12301767416676546\n",
      "2018-11-26 12:53:29,446 INFO     Weight matrix 1/1 (192,1296): Alpha 5.205555992472794 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:29,452 INFO     Weight matrix 1/1 (192,1296): Lognorm: 0.8187857866287231\n",
      "2018-11-26 12:53:29,455 INFO Layer 442: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:29,458 INFO Layer 442: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:29,462 INFO Layer 443: ReLU(inplace)\n",
      "2018-11-26 12:53:29,466 INFO Layer 443: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:29,471 INFO Layer 444: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:29,474 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:29,476 INFO Layer 444: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:29,490 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:29,493 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:29,497 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:53:29,500 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:29,503 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:29,507 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:29,510 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:29,513 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:29,518 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:29,524 INFO Layer 445: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:29,528 INFO Layer 445: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:29,531 INFO Layer 446: BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:29,535 INFO Layer 446: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:29,537 INFO Layer 447: ReLU(inplace)\n",
      "2018-11-26 12:53:29,540 INFO Layer 447: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:29,543 INFO Layer 448: Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:29,548 INFO Pytorch tensor shape detected: 192x1344 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:29,550 INFO Layer 448: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:29,553 INFO     Weight matrix 1/1 (192,1344): Analyzing ...\n",
      "2018-11-26 12:53:31,824 INFO     Weight matrix 1/1 (192,1344): Alpha: 3.7910483961180437, Alpha Weighted: 0.8533713047817459, D: 0.11353436333118372\n",
      "2018-11-26 12:53:31,827 INFO     Weight matrix 1/1 (192,1344): Alpha 3.7910483961180437 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:31,832 INFO     Weight matrix 1/1 (192,1344): Lognorm: 0.8517548441886902\n",
      "2018-11-26 12:53:31,836 INFO Layer 449: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:31,839 INFO Layer 449: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:31,842 INFO Layer 450: ReLU(inplace)\n",
      "2018-11-26 12:53:31,846 INFO Layer 450: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:31,849 INFO Layer 451: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:31,856 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:31,859 INFO Layer 451: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:31,864 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:31,867 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:31,871 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:31,875 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:31,879 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:31,883 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:31,886 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:31,890 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:31,892 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:31,895 INFO Layer 452: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:31,899 INFO Layer 452: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:31,901 INFO Layer 453: BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:31,905 INFO Layer 453: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:31,911 INFO Layer 454: ReLU(inplace)\n",
      "2018-11-26 12:53:31,917 INFO Layer 454: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:31,921 INFO Layer 455: Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:31,927 INFO Pytorch tensor shape detected: 192x1392 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:31,931 INFO Layer 455: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:31,934 INFO     Weight matrix 1/1 (192,1392): Analyzing ...\n",
      "2018-11-26 12:53:34,255 INFO     Weight matrix 1/1 (192,1392): Alpha: 4.091712221221073, Alpha Weighted: 0.7959845990180129, D: 0.08814331144162435\n",
      "2018-11-26 12:53:34,259 INFO     Weight matrix 1/1 (192,1392): Alpha 4.091712221221073 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:34,262 INFO     Weight matrix 1/1 (192,1392): Lognorm: 0.8242639899253845\n",
      "2018-11-26 12:53:34,267 INFO Layer 456: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:34,270 INFO Layer 456: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:34,274 INFO Layer 457: ReLU(inplace)\n",
      "2018-11-26 12:53:34,277 INFO Layer 457: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:34,280 INFO Layer 458: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:34,288 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:34,290 INFO Layer 458: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:34,301 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:34,304 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:34,308 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:34,311 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:34,315 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:34,318 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:34,321 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:34,325 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:34,330 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:34,343 INFO Layer 459: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:34,347 INFO Layer 459: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:34,351 INFO Layer 460: BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:34,356 INFO Layer 460: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:34,359 INFO Layer 461: ReLU(inplace)\n",
      "2018-11-26 12:53:34,363 INFO Layer 461: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:34,367 INFO Layer 462: Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:34,378 INFO Pytorch tensor shape detected: 192x1440 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:34,384 INFO Layer 462: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:34,389 INFO     Weight matrix 1/1 (192,1440): Analyzing ...\n",
      "2018-11-26 12:53:36,653 INFO     Weight matrix 1/1 (192,1440): Alpha: 5.6990349863041985, Alpha Weighted: 1.0318209991470495, D: 0.0769230769230762\n",
      "2018-11-26 12:53:36,657 INFO     Weight matrix 1/1 (192,1440): Alpha 5.6990349863041985 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:36,661 INFO     Weight matrix 1/1 (192,1440): Lognorm: 0.8270306587219238\n",
      "2018-11-26 12:53:36,665 INFO Layer 463: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:36,670 INFO Layer 463: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:36,673 INFO Layer 464: ReLU(inplace)\n",
      "2018-11-26 12:53:36,682 INFO Layer 464: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:53:36,684 INFO Layer 465: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:36,689 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:36,692 INFO Layer 465: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:36,697 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:36,699 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:36,702 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:36,705 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:36,709 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:36,714 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:36,726 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:36,733 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:36,736 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:36,738 INFO Layer 466: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:36,742 INFO Layer 466: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:36,746 INFO Layer 467: BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:36,748 INFO Layer 467: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:36,751 INFO Layer 468: ReLU(inplace)\n",
      "2018-11-26 12:53:36,759 INFO Layer 468: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:36,764 INFO Layer 469: Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:36,782 INFO Pytorch tensor shape detected: 192x1488 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:36,785 INFO Layer 469: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:36,790 INFO     Weight matrix 1/1 (192,1488): Analyzing ...\n",
      "2018-11-26 12:53:38,992 INFO     Weight matrix 1/1 (192,1488): Alpha: 5.582419900597981, Alpha Weighted: 1.047059345265451, D: 0.07142857142857073\n",
      "2018-11-26 12:53:38,994 INFO     Weight matrix 1/1 (192,1488): Alpha 5.582419900597981 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:38,998 INFO     Weight matrix 1/1 (192,1488): Lognorm: 0.7893422245979309\n",
      "2018-11-26 12:53:39,000 INFO Layer 470: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:39,003 INFO Layer 470: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:39,005 INFO Layer 471: ReLU(inplace)\n",
      "2018-11-26 12:53:39,008 INFO Layer 471: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:39,011 INFO Layer 472: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:39,015 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:39,018 INFO Layer 472: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:39,021 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:39,024 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:39,028 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:39,031 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:39,033 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:39,037 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:39,039 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:39,042 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:39,045 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:39,048 INFO Layer 473: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:39,051 INFO Layer 473: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:39,054 INFO Layer 474: BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:39,057 INFO Layer 474: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:39,060 INFO Layer 475: ReLU(inplace)\n",
      "2018-11-26 12:53:39,063 INFO Layer 475: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:39,066 INFO Layer 476: Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:39,071 INFO Pytorch tensor shape detected: 192x1536 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:39,074 INFO Layer 476: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:39,077 INFO     Weight matrix 1/1 (192,1536): Analyzing ...\n",
      "2018-11-26 12:53:41,344 INFO     Weight matrix 1/1 (192,1536): Alpha: 5.519941740700157, Alpha Weighted: 1.1853922271642252, D: 0.08440538196949954\n",
      "2018-11-26 12:53:41,346 INFO     Weight matrix 1/1 (192,1536): Alpha 5.519941740700157 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:41,349 INFO     Weight matrix 1/1 (192,1536): Lognorm: 0.8007251620292664\n",
      "2018-11-26 12:53:41,352 INFO Layer 477: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:41,355 INFO Layer 477: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:41,360 INFO Layer 478: ReLU(inplace)\n",
      "2018-11-26 12:53:41,363 INFO Layer 478: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:41,369 INFO Layer 479: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:41,377 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:41,381 INFO Layer 479: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:41,385 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:41,387 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:41,390 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:41,393 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:41,395 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:41,400 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:41,402 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:41,409 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:41,418 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:41,421 INFO Layer 480: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:41,425 INFO Layer 480: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:41,429 INFO Layer 481: BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:41,433 INFO Layer 481: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:41,435 INFO Layer 482: ReLU(inplace)\n",
      "2018-11-26 12:53:41,437 INFO Layer 482: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:41,440 INFO Layer 483: Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:41,445 INFO Pytorch tensor shape detected: 192x1584 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:41,451 INFO Layer 483: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:41,455 INFO     Weight matrix 1/1 (192,1584): Analyzing ...\n",
      "2018-11-26 12:53:43,732 INFO     Weight matrix 1/1 (192,1584): Alpha: 5.825719566776671, Alpha Weighted: 1.8875484237490756, D: 0.0769230769230762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:53:43,735 INFO     Weight matrix 1/1 (192,1584): Alpha 5.825719566776671 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:43,738 INFO     Weight matrix 1/1 (192,1584): Lognorm: 0.8397857546806335\n",
      "2018-11-26 12:53:43,741 INFO Layer 484: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:43,743 INFO Layer 484: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:43,745 INFO Layer 485: ReLU(inplace)\n",
      "2018-11-26 12:53:43,747 INFO Layer 485: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:43,750 INFO Layer 486: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:43,754 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:43,759 INFO Layer 486: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:43,761 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:43,764 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:43,767 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:43,769 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:43,773 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:43,777 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:43,781 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:43,784 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:43,787 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:43,790 INFO Layer 487: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:43,793 INFO Layer 487: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:43,795 INFO Layer 488: BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:43,797 INFO Layer 488: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:43,799 INFO Layer 489: ReLU(inplace)\n",
      "2018-11-26 12:53:43,801 INFO Layer 489: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:43,804 INFO Layer 490: Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:43,810 INFO Pytorch tensor shape detected: 192x1632 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:43,813 INFO Layer 490: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:43,816 INFO     Weight matrix 1/1 (192,1632): Analyzing ...\n",
      "2018-11-26 12:53:45,948 INFO     Weight matrix 1/1 (192,1632): Alpha: 5.111809449479451, Alpha Weighted: 1.1063571125412859, D: 0.05627066092525068\n",
      "2018-11-26 12:53:45,951 INFO     Weight matrix 1/1 (192,1632): Alpha 5.111809449479451 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:45,954 INFO     Weight matrix 1/1 (192,1632): Lognorm: 0.809495210647583\n",
      "2018-11-26 12:53:45,956 INFO Layer 491: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:45,959 INFO Layer 491: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:45,962 INFO Layer 492: ReLU(inplace)\n",
      "2018-11-26 12:53:45,964 INFO Layer 492: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:45,967 INFO Layer 493: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:45,976 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:45,979 INFO Layer 493: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:45,982 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:45,985 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:45,988 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:45,991 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:45,993 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:45,996 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:45,999 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:46,002 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:46,005 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:46,008 INFO Layer 494: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:46,011 INFO Layer 494: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:46,014 INFO Layer 495: BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:46,017 INFO Layer 495: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:46,024 INFO Layer 496: ReLU(inplace)\n",
      "2018-11-26 12:53:46,033 INFO Layer 496: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:46,035 INFO Layer 497: Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:46,042 INFO Pytorch tensor shape detected: 192x1680 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:46,049 INFO Layer 497: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:46,052 INFO     Weight matrix 1/1 (192,1680): Analyzing ...\n",
      "2018-11-26 12:53:48,159 INFO     Weight matrix 1/1 (192,1680): Alpha: 5.092227915572095, Alpha Weighted: 1.2643549721121352, D: 0.09016112737368176\n",
      "2018-11-26 12:53:48,161 INFO     Weight matrix 1/1 (192,1680): Alpha 5.092227915572095 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:48,165 INFO     Weight matrix 1/1 (192,1680): Lognorm: 0.8074411749839783\n",
      "2018-11-26 12:53:48,168 INFO Layer 498: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:48,171 INFO Layer 498: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:48,174 INFO Layer 499: ReLU(inplace)\n",
      "2018-11-26 12:53:48,177 INFO Layer 499: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:48,181 INFO Layer 500: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:48,189 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:48,193 INFO Layer 500: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:48,196 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:48,200 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:48,203 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:48,207 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:48,210 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:48,214 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:48,218 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:48,224 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:48,227 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:48,232 INFO Layer 501: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:48,237 INFO Layer 501: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:48,239 INFO Layer 502: BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:48,242 INFO Layer 502: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:48,246 INFO Layer 503: ReLU(inplace)\n",
      "2018-11-26 12:53:48,248 INFO Layer 503: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:53:48,251 INFO Layer 504: Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:48,257 INFO Pytorch tensor shape detected: 192x1728 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:48,260 INFO Layer 504: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:48,264 INFO     Weight matrix 1/1 (192,1728): Analyzing ...\n",
      "2018-11-26 12:53:50,657 INFO     Weight matrix 1/1 (192,1728): Alpha: 4.887719369119834, Alpha Weighted: 1.1921628288339143, D: 0.09163514201863587\n",
      "2018-11-26 12:53:50,659 INFO     Weight matrix 1/1 (192,1728): Alpha 4.887719369119834 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:50,664 INFO     Weight matrix 1/1 (192,1728): Lognorm: 0.8086658120155334\n",
      "2018-11-26 12:53:50,667 INFO Layer 505: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:50,670 INFO Layer 505: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:50,674 INFO Layer 506: ReLU(inplace)\n",
      "2018-11-26 12:53:50,678 INFO Layer 506: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:50,680 INFO Layer 507: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:50,686 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:50,689 INFO Layer 507: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:50,692 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:50,696 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:50,699 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:50,703 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:50,706 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:50,711 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:50,715 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:50,717 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:50,723 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:50,727 INFO Layer 508: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:50,730 INFO Layer 508: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:50,733 INFO Layer 509: BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:50,737 INFO Layer 509: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:50,739 INFO Layer 510: ReLU(inplace)\n",
      "2018-11-26 12:53:50,743 INFO Layer 510: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:50,745 INFO Layer 511: Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:50,750 INFO Pytorch tensor shape detected: 192x1776 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:50,752 INFO Layer 511: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:50,758 INFO     Weight matrix 1/1 (192,1776): Analyzing ...\n",
      "2018-11-26 12:53:52,910 INFO     Weight matrix 1/1 (192,1776): Alpha: 6.099914667948356, Alpha Weighted: 1.4104171308119267, D: 0.06666666666666599\n",
      "2018-11-26 12:53:52,912 INFO     Weight matrix 1/1 (192,1776): Alpha 6.099914667948356 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:52,919 INFO     Weight matrix 1/1 (192,1776): Lognorm: 0.8309832215309143\n",
      "2018-11-26 12:53:52,922 INFO Layer 512: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:52,925 INFO Layer 512: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:52,934 INFO Layer 513: ReLU(inplace)\n",
      "2018-11-26 12:53:52,938 INFO Layer 513: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:52,943 INFO Layer 514: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:52,947 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:52,951 INFO Layer 514: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:52,954 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:52,958 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:52,967 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:52,975 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:52,978 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:52,985 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:52,988 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:52,993 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:52,997 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:53,000 INFO Layer 515: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:53,004 INFO Layer 515: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:53,008 INFO Layer 516: BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:53,016 INFO Layer 516: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:53,023 INFO Layer 517: ReLU(inplace)\n",
      "2018-11-26 12:53:53,027 INFO Layer 517: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:53,032 INFO Layer 518: Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:53,037 INFO Pytorch tensor shape detected: 192x1824 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:53,041 INFO Layer 518: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:53,044 INFO     Weight matrix 1/1 (192,1824): Analyzing ...\n",
      "2018-11-26 12:53:55,248 INFO     Weight matrix 1/1 (192,1824): Alpha: 6.15896343098434, Alpha Weighted: 1.5140778921605573, D: 0.08484280174368392\n",
      "2018-11-26 12:53:55,251 INFO     Weight matrix 1/1 (192,1824): Alpha 6.15896343098434 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:55,254 INFO     Weight matrix 1/1 (192,1824): Lognorm: 0.8397676944732666\n",
      "2018-11-26 12:53:55,256 INFO Layer 519: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:55,259 INFO Layer 519: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:55,263 INFO Layer 520: ReLU(inplace)\n",
      "2018-11-26 12:53:55,264 INFO Layer 520: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:55,268 INFO Layer 521: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:55,271 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:55,274 INFO Layer 521: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:55,277 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:55,281 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:55,283 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:55,286 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:55,288 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:55,291 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:55,295 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:55,298 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:55,300 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:55,303 INFO Layer 522: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:53:55,306 INFO Layer 522: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:55,308 INFO Layer 523: BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:55,311 INFO Layer 523: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:55,314 INFO Layer 524: ReLU(inplace)\n",
      "2018-11-26 12:53:55,317 INFO Layer 524: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:55,320 INFO Layer 525: Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:55,328 INFO Pytorch tensor shape detected: 192x1872 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:55,330 INFO Layer 525: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:55,333 INFO     Weight matrix 1/1 (192,1872): Analyzing ...\n",
      "2018-11-26 12:53:57,483 INFO     Weight matrix 1/1 (192,1872): Alpha: 5.447231643611024, Alpha Weighted: 1.5650079447369278, D: 0.08268870000315393\n",
      "2018-11-26 12:53:57,486 INFO     Weight matrix 1/1 (192,1872): Alpha 5.447231643611024 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:57,490 INFO     Weight matrix 1/1 (192,1872): Lognorm: 0.8378505110740662\n",
      "2018-11-26 12:53:57,494 INFO Layer 526: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:57,497 INFO Layer 526: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:57,499 INFO Layer 527: ReLU(inplace)\n",
      "2018-11-26 12:53:57,502 INFO Layer 527: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:57,505 INFO Layer 528: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:57,509 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:57,514 INFO Layer 528: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:57,517 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:57,520 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:57,522 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:57,528 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:57,532 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:57,535 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:57,538 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:57,541 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:57,544 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:57,548 INFO Layer 529: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:57,551 INFO Layer 529: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:57,554 INFO Layer 530: BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:57,557 INFO Layer 530: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:57,561 INFO Layer 531: ReLU(inplace)\n",
      "2018-11-26 12:53:57,564 INFO Layer 531: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:57,568 INFO Layer 532: Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:57,574 INFO Pytorch tensor shape detected: 192x1920 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:57,577 INFO Layer 532: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:57,581 INFO     Weight matrix 1/1 (192,1920): Analyzing ...\n",
      "2018-11-26 12:53:59,726 INFO     Weight matrix 1/1 (192,1920): Alpha: 4.568231462826866, Alpha Weighted: 1.2898471138591716, D: 0.05470819845178182\n",
      "2018-11-26 12:53:59,729 INFO     Weight matrix 1/1 (192,1920): Alpha 4.568231462826866 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:53:59,733 INFO     Weight matrix 1/1 (192,1920): Lognorm: 0.8182133436203003\n",
      "2018-11-26 12:53:59,736 INFO Layer 533: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:59,739 INFO Layer 533: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:59,743 INFO Layer 534: ReLU(inplace)\n",
      "2018-11-26 12:53:59,745 INFO Layer 534: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:59,748 INFO Layer 535: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:53:59,753 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:53:59,755 INFO Layer 535: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:53:59,758 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:59,761 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:59,764 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:59,768 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:59,771 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:59,775 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:59,778 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:59,780 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:59,783 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:53:59,786 INFO Layer 536: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:53:59,792 INFO Layer 536: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:59,794 INFO Layer 537: BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:53:59,797 INFO Layer 537: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:59,800 INFO Layer 538: ReLU(inplace)\n",
      "2018-11-26 12:53:59,802 INFO Layer 538: Skipping (Layer not supported)\n",
      "2018-11-26 12:53:59,805 INFO Layer 539: Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:53:59,809 INFO Pytorch tensor shape detected: 192x1968 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:53:59,812 INFO Layer 539: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:53:59,815 INFO     Weight matrix 1/1 (192,1968): Analyzing ...\n",
      "2018-11-26 12:54:01,983 INFO     Weight matrix 1/1 (192,1968): Alpha: 6.043895524070481, Alpha Weighted: 1.6612710225518248, D: 0.07651303191276781\n",
      "2018-11-26 12:54:01,986 INFO     Weight matrix 1/1 (192,1968): Alpha 6.043895524070481 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:54:01,990 INFO     Weight matrix 1/1 (192,1968): Lognorm: 0.819762110710144\n",
      "2018-11-26 12:54:01,993 INFO Layer 540: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:01,997 INFO Layer 540: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:02,000 INFO Layer 541: ReLU(inplace)\n",
      "2018-11-26 12:54:02,003 INFO Layer 541: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:02,006 INFO Layer 542: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:02,013 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:02,020 INFO Layer 542: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:02,023 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:02,027 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:02,030 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:02,035 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:02,038 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:02,041 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:02,044 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:02,047 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:02,050 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:02,056 INFO Layer 543: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:02,065 INFO Layer 543: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:02,070 INFO Layer 544: BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:02,078 INFO Layer 544: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:02,082 INFO Layer 545: ReLU(inplace)\n",
      "2018-11-26 12:54:02,085 INFO Layer 545: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:02,088 INFO Layer 546: Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:02,095 INFO Pytorch tensor shape detected: 192x2016 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:02,097 INFO Layer 546: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:02,102 INFO     Weight matrix 1/1 (192,2016): Analyzing ...\n",
      "2018-11-26 12:54:04,257 INFO     Weight matrix 1/1 (192,2016): Alpha: 5.671212428241174, Alpha Weighted: 1.5297257155202137, D: 0.07595693387544256\n",
      "2018-11-26 12:54:04,259 INFO     Weight matrix 1/1 (192,2016): Alpha 5.671212428241174 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:54:04,262 INFO     Weight matrix 1/1 (192,2016): Lognorm: 0.8476815819740295\n",
      "2018-11-26 12:54:04,268 INFO Layer 547: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:04,270 INFO Layer 547: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:04,273 INFO Layer 548: ReLU(inplace)\n",
      "2018-11-26 12:54:04,275 INFO Layer 548: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:04,278 INFO Layer 549: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:04,281 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:04,284 INFO Layer 549: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:04,286 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:04,288 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:04,291 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:04,293 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:04,295 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:04,299 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:04,301 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:04,305 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:04,308 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:04,311 INFO Layer 550: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:04,316 INFO Layer 550: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:04,319 INFO Layer 551: BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:04,322 INFO Layer 551: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:04,325 INFO Layer 552: ReLU(inplace)\n",
      "2018-11-26 12:54:04,335 INFO Layer 552: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:04,341 INFO Layer 553: Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:04,348 INFO Pytorch tensor shape detected: 192x2064 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:04,350 INFO Layer 553: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:04,353 INFO     Weight matrix 1/1 (192,2064): Analyzing ...\n",
      "2018-11-26 12:54:06,492 INFO     Weight matrix 1/1 (192,2064): Alpha: 6.160688482542975, Alpha Weighted: 1.842077772326501, D: 0.0769230769230762\n",
      "2018-11-26 12:54:06,494 INFO     Weight matrix 1/1 (192,2064): Alpha 6.160688482542975 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:54:06,499 INFO     Weight matrix 1/1 (192,2064): Lognorm: 0.8597205281257629\n",
      "2018-11-26 12:54:06,503 INFO Layer 554: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:06,505 INFO Layer 554: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:06,509 INFO Layer 555: ReLU(inplace)\n",
      "2018-11-26 12:54:06,511 INFO Layer 555: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:06,513 INFO Layer 556: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:06,516 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:06,518 INFO Layer 556: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:06,520 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:06,523 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:06,526 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:06,528 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:06,531 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:06,536 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:06,538 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:06,541 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:06,544 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:06,547 INFO Layer 557: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:06,549 INFO Layer 557: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:06,552 INFO Layer 558: BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:06,555 INFO Layer 558: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:06,559 INFO Layer 559: ReLU(inplace)\n",
      "2018-11-26 12:54:06,562 INFO Layer 559: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:06,570 INFO Layer 560: Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:06,575 INFO Pytorch tensor shape detected: 192x2112 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:06,583 INFO Layer 560: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:06,587 INFO     Weight matrix 1/1 (192,2112): Analyzing ...\n",
      "2018-11-26 12:54:08,591 INFO     Weight matrix 1/1 (192,2112): Alpha: 5.897818459371629, Alpha Weighted: 1.8776648192375531, D: 0.07142857142857073\n",
      "2018-11-26 12:54:08,595 INFO     Weight matrix 1/1 (192,2112): Alpha 5.897818459371629 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:54:08,599 INFO     Weight matrix 1/1 (192,2112): Lognorm: 0.9027345180511475\n",
      "2018-11-26 12:54:08,603 INFO Layer 561: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:08,605 INFO Layer 561: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:08,609 INFO Layer 562: ReLU(inplace)\n",
      "2018-11-26 12:54:08,612 INFO Layer 562: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:08,618 INFO Layer 563: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:08,627 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:08,632 INFO Layer 563: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:08,638 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:08,640 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:08,643 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:08,646 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:08,648 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:08,651 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:08,655 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:08,657 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:08,662 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:08,665 INFO Layer 564: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:08,670 INFO Layer 564: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:08,673 INFO Layer 565: BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:08,680 INFO Layer 565: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:08,684 INFO Layer 566: ReLU(inplace)\n",
      "2018-11-26 12:54:08,688 INFO Layer 566: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:08,692 INFO Layer 567: Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:08,701 INFO Pytorch tensor shape detected: 192x2160 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:08,703 INFO Layer 567: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:08,711 INFO     Weight matrix 1/1 (192,2160): Analyzing ...\n",
      "2018-11-26 12:54:11,002 INFO     Weight matrix 1/1 (192,2160): Alpha: 5.363154773502516, Alpha Weighted: 1.4518674147960386, D: 0.06806184365538359\n",
      "2018-11-26 12:54:11,004 INFO     Weight matrix 1/1 (192,2160): Alpha 5.363154773502516 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:54:11,009 INFO     Weight matrix 1/1 (192,2160): Lognorm: 0.8300938010215759\n",
      "2018-11-26 12:54:11,014 INFO Layer 568: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:11,017 INFO Layer 568: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:11,021 INFO Layer 569: ReLU(inplace)\n",
      "2018-11-26 12:54:11,024 INFO Layer 569: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:11,027 INFO Layer 570: Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:11,031 INFO Pytorch tensor shape detected: 48x192 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:11,034 INFO Layer 570: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:11,038 INFO     Weight matrix 1/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:11,042 INFO     Weight matrix 2/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:11,045 INFO     Weight matrix 3/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:11,048 INFO     Weight matrix 4/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:11,051 INFO     Weight matrix 5/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:11,054 INFO     Weight matrix 6/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:11,058 INFO     Weight matrix 7/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:11,061 INFO     Weight matrix 8/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:11,065 INFO     Weight matrix 9/9 (48,192): Skipping: too small (<50)\n",
      "2018-11-26 12:54:11,071 INFO Layer 571: BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:11,074 INFO Layer 571: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:11,078 INFO Layer 572: Linear(in_features=2208, out_features=1000, bias=True)\n",
      "2018-11-26 12:54:11,125 INFO Layer 572: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:11,129 INFO     Weight matrix 1/1 (1000,2208): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:54:11,133 INFO ### Printing results ###\n",
      "2018-11-26 12:54:11,136 DEBUG Layer 10: Lognorm: 0.5801879167556763\n",
      "2018-11-26 12:54:11,140 DEBUG Layer 17: Lognorm: 0.5731354355812073\n",
      "2018-11-26 12:54:11,143 DEBUG Layer 24: Lognorm: 0.6840506792068481\n",
      "2018-11-26 12:54:11,146 DEBUG Layer 31: Lognorm: 0.6385344862937927\n",
      "2018-11-26 12:54:11,150 DEBUG Layer 38: Lognorm: 0.73655766248703\n",
      "2018-11-26 12:54:11,154 DEBUG Layer 45: Lognorm: 0.7018465995788574\n",
      "2018-11-26 12:54:11,158 DEBUG Layer 52: Lognorm: 1.0374387502670288\n",
      "2018-11-26 12:54:11,161 DEBUG Layer 58: Lognorm: 0.49740296602249146\n",
      "2018-11-26 12:54:11,165 DEBUG Layer 65: Lognorm: 0.26298975944519043\n",
      "2018-11-26 12:54:11,169 DEBUG Layer 72: Lognorm: 0.6122696399688721\n",
      "2018-11-26 12:54:11,172 DEBUG Layer 79: Lognorm: 0.5999976992607117\n",
      "2018-11-26 12:54:11,176 DEBUG Layer 86: Lognorm: 0.6401392817497253\n",
      "2018-11-26 12:54:11,179 DEBUG Layer 93: Lognorm: 0.6598575711250305\n",
      "2018-11-26 12:54:11,185 DEBUG Layer 100: Lognorm: 0.7495948076248169\n",
      "2018-11-26 12:54:11,191 DEBUG Layer 107: Lognorm: 0.7282037734985352\n",
      "2018-11-26 12:54:11,194 DEBUG Layer 114: Lognorm: 0.7259364128112793\n",
      "2018-11-26 12:54:11,196 DEBUG Layer 121: Lognorm: 0.6818564534187317\n",
      "2018-11-26 12:54:11,199 DEBUG Layer 128: Lognorm: 0.7229810953140259\n",
      "2018-11-26 12:54:11,203 DEBUG Layer 135: Lognorm: 0.8070092797279358\n",
      "2018-11-26 12:54:11,207 DEBUG Layer 148: Lognorm: 0.4810558259487152\n",
      "2018-11-26 12:54:11,210 DEBUG Layer 155: Lognorm: 0.48302948474884033\n",
      "2018-11-26 12:54:11,213 DEBUG Layer 162: Lognorm: 0.3447718024253845\n",
      "2018-11-26 12:54:11,217 DEBUG Layer 169: Lognorm: 0.437405526638031\n",
      "2018-11-26 12:54:11,222 DEBUG Layer 176: Lognorm: 0.37494415044784546\n",
      "2018-11-26 12:54:11,226 DEBUG Layer 183: Lognorm: 0.5717402696609497\n",
      "2018-11-26 12:54:11,229 DEBUG Layer 190: Lognorm: 0.563644528388977\n",
      "2018-11-26 12:54:11,232 DEBUG Layer 197: Lognorm: 0.5315535068511963\n",
      "2018-11-26 12:54:11,235 DEBUG Layer 204: Lognorm: 0.5711762309074402\n",
      "2018-11-26 12:54:11,239 DEBUG Layer 211: Lognorm: 0.6827049851417542\n",
      "2018-11-26 12:54:11,242 DEBUG Layer 218: Lognorm: 0.6588689684867859\n",
      "2018-11-26 12:54:11,246 DEBUG Layer 225: Lognorm: 0.6808460354804993\n",
      "2018-11-26 12:54:11,249 DEBUG Layer 232: Lognorm: 0.5675647854804993\n",
      "2018-11-26 12:54:11,252 DEBUG Layer 239: Lognorm: 0.7580776214599609\n",
      "2018-11-26 12:54:11,261 DEBUG Layer 246: Lognorm: 0.7064769268035889\n",
      "2018-11-26 12:54:11,265 DEBUG Layer 253: Lognorm: 0.7156630754470825\n",
      "2018-11-26 12:54:11,271 DEBUG Layer 260: Lognorm: 0.711022138595581\n",
      "2018-11-26 12:54:11,274 DEBUG Layer 267: Lognorm: 0.7174281477928162\n",
      "2018-11-26 12:54:11,281 DEBUG Layer 274: Lognorm: 0.7501013278961182\n",
      "2018-11-26 12:54:11,285 DEBUG Layer 281: Lognorm: 0.7236207723617554\n",
      "2018-11-26 12:54:11,289 DEBUG Layer 288: Lognorm: 0.8077215552330017\n",
      "2018-11-26 12:54:11,292 DEBUG Layer 295: Lognorm: 0.7644276022911072\n",
      "2018-11-26 12:54:11,296 DEBUG Layer 302: Lognorm: 0.6728474497795105\n",
      "2018-11-26 12:54:11,299 DEBUG Layer 309: Lognorm: 0.8135579228401184\n",
      "2018-11-26 12:54:11,303 DEBUG Layer 316: Lognorm: 0.7962035536766052\n",
      "2018-11-26 12:54:11,306 DEBUG Layer 323: Lognorm: 0.8070045113563538\n",
      "2018-11-26 12:54:11,309 DEBUG Layer 330: Lognorm: 0.8285072445869446\n",
      "2018-11-26 12:54:11,312 DEBUG Layer 337: Lognorm: 0.8077895641326904\n",
      "2018-11-26 12:54:11,316 DEBUG Layer 344: Lognorm: 0.8212069869041443\n",
      "2018-11-26 12:54:11,319 DEBUG Layer 351: Lognorm: 0.8491942882537842\n",
      "2018-11-26 12:54:11,322 DEBUG Layer 358: Lognorm: 0.8259353637695312\n",
      "2018-11-26 12:54:11,326 DEBUG Layer 365: Lognorm: 0.8487169742584229\n",
      "2018-11-26 12:54:11,328 DEBUG Layer 372: Lognorm: 0.8398658633232117\n",
      "2018-11-26 12:54:11,331 DEBUG Layer 379: Lognorm: 0.8748267889022827\n",
      "2018-11-26 12:54:11,334 DEBUG Layer 386: Lognorm: 0.8580556511878967\n",
      "2018-11-26 12:54:11,336 DEBUG Layer 393: Lognorm: 0.8535867929458618\n",
      "2018-11-26 12:54:11,340 DEBUG Layer 406: Lognorm: 0.7011712193489075\n",
      "2018-11-26 12:54:11,343 DEBUG Layer 413: Lognorm: 0.6863213777542114\n",
      "2018-11-26 12:54:11,346 DEBUG Layer 420: Lognorm: 0.8150581121444702\n",
      "2018-11-26 12:54:11,350 DEBUG Layer 427: Lognorm: 0.7890795469284058\n",
      "2018-11-26 12:54:11,353 DEBUG Layer 434: Lognorm: 0.8213930726051331\n",
      "2018-11-26 12:54:11,357 DEBUG Layer 441: Lognorm: 0.8187857866287231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:11,361 DEBUG Layer 448: Lognorm: 0.8517548441886902\n",
      "2018-11-26 12:54:11,364 DEBUG Layer 455: Lognorm: 0.8242639899253845\n",
      "2018-11-26 12:54:11,368 DEBUG Layer 462: Lognorm: 0.8270306587219238\n",
      "2018-11-26 12:54:11,372 DEBUG Layer 469: Lognorm: 0.7893422245979309\n",
      "2018-11-26 12:54:11,376 DEBUG Layer 476: Lognorm: 0.8007251620292664\n",
      "2018-11-26 12:54:11,381 DEBUG Layer 483: Lognorm: 0.8397857546806335\n",
      "2018-11-26 12:54:11,385 DEBUG Layer 490: Lognorm: 0.809495210647583\n",
      "2018-11-26 12:54:11,388 DEBUG Layer 497: Lognorm: 0.8074411749839783\n",
      "2018-11-26 12:54:11,391 DEBUG Layer 504: Lognorm: 0.8086658120155334\n",
      "2018-11-26 12:54:11,393 DEBUG Layer 511: Lognorm: 0.8309832215309143\n",
      "2018-11-26 12:54:11,397 DEBUG Layer 518: Lognorm: 0.8397676944732666\n",
      "2018-11-26 12:54:11,400 DEBUG Layer 525: Lognorm: 0.8378505110740662\n",
      "2018-11-26 12:54:11,403 DEBUG Layer 532: Lognorm: 0.8182133436203003\n",
      "2018-11-26 12:54:11,406 DEBUG Layer 539: Lognorm: 0.819762110710144\n",
      "2018-11-26 12:54:11,409 DEBUG Layer 546: Lognorm: 0.8476815819740295\n",
      "2018-11-26 12:54:11,412 DEBUG Layer 553: Lognorm: 0.8597205281257629\n",
      "2018-11-26 12:54:11,416 DEBUG Layer 560: Lognorm: 0.9027345180511475\n",
      "2018-11-26 12:54:11,418 DEBUG Layer 567: Lognorm: 0.8300938010215759\n",
      "2018-11-26 12:54:11,422 INFO LogNorm: min: 0.26298975944519043, max: 1.0374387502670288, avg: 0.7255475521087646\n",
      "2018-11-26 12:54:11,425 INFO LogNorm compound: min: 0.26298975944519043, max: 1.0374387502670288, avg: 0.7255475411686716\n",
      "2018-11-26 12:54:11,429 DEBUG Layer 10: Alpha: 1.364728432119429\n",
      "2018-11-26 12:54:11,431 DEBUG Layer 17: Alpha: 1.3985980445049089\n",
      "2018-11-26 12:54:11,434 DEBUG Layer 24: Alpha: 2.6651763904820136\n",
      "2018-11-26 12:54:11,436 DEBUG Layer 31: Alpha: 4.288261534252063\n",
      "2018-11-26 12:54:11,439 DEBUG Layer 38: Alpha: 3.0452406470189164\n",
      "2018-11-26 12:54:11,441 DEBUG Layer 45: Alpha: 5.913571061390133\n",
      "2018-11-26 12:54:11,443 DEBUG Layer 52: Alpha: 4.584068296198838\n",
      "2018-11-26 12:54:11,447 DEBUG Layer 58: Alpha: 1.5709556372980185\n",
      "2018-11-26 12:54:11,451 DEBUG Layer 65: Alpha: 1.4826087623520958\n",
      "2018-11-26 12:54:11,454 DEBUG Layer 72: Alpha: 1.9773239053631602\n",
      "2018-11-26 12:54:11,456 DEBUG Layer 79: Alpha: 1.5926322378202347\n",
      "2018-11-26 12:54:11,458 DEBUG Layer 86: Alpha: 1.5619159746513103\n",
      "2018-11-26 12:54:11,462 DEBUG Layer 93: Alpha: 1.597483497459631\n",
      "2018-11-26 12:54:11,465 DEBUG Layer 100: Alpha: 2.426961822675583\n",
      "2018-11-26 12:54:11,469 DEBUG Layer 107: Alpha: 6.939540804908551\n",
      "2018-11-26 12:54:11,472 DEBUG Layer 114: Alpha: 1.8863985775744938\n",
      "2018-11-26 12:54:11,475 DEBUG Layer 121: Alpha: 1.9261791921137368\n",
      "2018-11-26 12:54:11,484 DEBUG Layer 128: Alpha: 2.1724480727242605\n",
      "2018-11-26 12:54:11,488 DEBUG Layer 135: Alpha: 1.8758850700728624\n",
      "2018-11-26 12:54:11,493 DEBUG Layer 148: Alpha: 1.9092336619229995\n",
      "2018-11-26 12:54:11,496 DEBUG Layer 155: Alpha: 3.959131269442642\n",
      "2018-11-26 12:54:11,500 DEBUG Layer 162: Alpha: 1.4669502325284431\n",
      "2018-11-26 12:54:11,503 DEBUG Layer 169: Alpha: 1.7644531664542407\n",
      "2018-11-26 12:54:11,507 DEBUG Layer 176: Alpha: 1.4872276062882435\n",
      "2018-11-26 12:54:11,510 DEBUG Layer 183: Alpha: 1.801517360013925\n",
      "2018-11-26 12:54:11,514 DEBUG Layer 190: Alpha: 4.016283506262169\n",
      "2018-11-26 12:54:11,518 DEBUG Layer 197: Alpha: 1.5973660761604047\n",
      "2018-11-26 12:54:11,523 DEBUG Layer 204: Alpha: 6.929515762281742\n",
      "2018-11-26 12:54:11,529 DEBUG Layer 211: Alpha: 1.8063709861570616\n",
      "2018-11-26 12:54:11,534 DEBUG Layer 218: Alpha: 2.1578379294985046\n",
      "2018-11-26 12:54:11,539 DEBUG Layer 225: Alpha: 1.8181471312124842\n",
      "2018-11-26 12:54:11,543 DEBUG Layer 232: Alpha: 3.7729124585070304\n",
      "2018-11-26 12:54:11,547 DEBUG Layer 239: Alpha: 4.647784690042033\n",
      "2018-11-26 12:54:11,551 DEBUG Layer 246: Alpha: 2.152911362195699\n",
      "2018-11-26 12:54:11,553 DEBUG Layer 253: Alpha: 4.256215260756702\n",
      "2018-11-26 12:54:11,557 DEBUG Layer 260: Alpha: 2.6849162656831527\n",
      "2018-11-26 12:54:11,561 DEBUG Layer 267: Alpha: 5.39870433468153\n",
      "2018-11-26 12:54:11,567 DEBUG Layer 274: Alpha: 2.122631184537568\n",
      "2018-11-26 12:54:11,574 DEBUG Layer 281: Alpha: 2.260201271211387\n",
      "2018-11-26 12:54:11,579 DEBUG Layer 288: Alpha: 2.3428383871074594\n",
      "2018-11-26 12:54:11,582 DEBUG Layer 295: Alpha: 5.229841406978098\n",
      "2018-11-26 12:54:11,585 DEBUG Layer 302: Alpha: 2.034615217479879\n",
      "2018-11-26 12:54:11,588 DEBUG Layer 309: Alpha: 2.6160348806870113\n",
      "2018-11-26 12:54:11,593 DEBUG Layer 316: Alpha: 5.355429052664251\n",
      "2018-11-26 12:54:11,596 DEBUG Layer 323: Alpha: 3.589854234798129\n",
      "2018-11-26 12:54:11,599 DEBUG Layer 330: Alpha: 4.044777552097419\n",
      "2018-11-26 12:54:11,603 DEBUG Layer 337: Alpha: 3.4438802933092276\n",
      "2018-11-26 12:54:11,607 DEBUG Layer 344: Alpha: 2.4647485806413663\n",
      "2018-11-26 12:54:11,610 DEBUG Layer 351: Alpha: 3.450458612968661\n",
      "2018-11-26 12:54:11,612 DEBUG Layer 358: Alpha: 3.139420427234135\n",
      "2018-11-26 12:54:11,616 DEBUG Layer 365: Alpha: 5.337704468531211\n",
      "2018-11-26 12:54:11,619 DEBUG Layer 372: Alpha: 3.7180184814466775\n",
      "2018-11-26 12:54:11,622 DEBUG Layer 379: Alpha: 5.012821130454169\n",
      "2018-11-26 12:54:11,627 DEBUG Layer 386: Alpha: 3.2322367235718805\n",
      "2018-11-26 12:54:11,631 DEBUG Layer 393: Alpha: 5.810022453582131\n",
      "2018-11-26 12:54:11,636 DEBUG Layer 406: Alpha: 2.828585162503657\n",
      "2018-11-26 12:54:11,639 DEBUG Layer 413: Alpha: 2.7234924643189835\n",
      "2018-11-26 12:54:11,643 DEBUG Layer 420: Alpha: 3.4952507103125434\n",
      "2018-11-26 12:54:11,647 DEBUG Layer 427: Alpha: 3.400688498954868\n",
      "2018-11-26 12:54:11,650 DEBUG Layer 434: Alpha: 2.165450148282992\n",
      "2018-11-26 12:54:11,654 DEBUG Layer 441: Alpha: 5.205555992472794\n",
      "2018-11-26 12:54:11,658 DEBUG Layer 448: Alpha: 3.7910483961180437\n",
      "2018-11-26 12:54:11,662 DEBUG Layer 455: Alpha: 4.091712221221073\n",
      "2018-11-26 12:54:11,665 DEBUG Layer 462: Alpha: 5.6990349863041985\n",
      "2018-11-26 12:54:11,668 DEBUG Layer 469: Alpha: 5.582419900597981\n",
      "2018-11-26 12:54:11,672 DEBUG Layer 476: Alpha: 5.519941740700157\n",
      "2018-11-26 12:54:11,676 DEBUG Layer 483: Alpha: 5.825719566776671\n",
      "2018-11-26 12:54:11,679 DEBUG Layer 490: Alpha: 5.111809449479451\n",
      "2018-11-26 12:54:11,683 DEBUG Layer 497: Alpha: 5.092227915572095\n",
      "2018-11-26 12:54:11,686 DEBUG Layer 504: Alpha: 4.887719369119834\n",
      "2018-11-26 12:54:11,689 DEBUG Layer 511: Alpha: 6.099914667948356\n",
      "2018-11-26 12:54:11,692 DEBUG Layer 518: Alpha: 6.15896343098434\n",
      "2018-11-26 12:54:11,697 DEBUG Layer 525: Alpha: 5.447231643611024\n",
      "2018-11-26 12:54:11,701 DEBUG Layer 532: Alpha: 4.568231462826866\n",
      "2018-11-26 12:54:11,705 DEBUG Layer 539: Alpha: 6.043895524070481\n",
      "2018-11-26 12:54:11,709 DEBUG Layer 546: Alpha: 5.671212428241174\n",
      "2018-11-26 12:54:11,713 DEBUG Layer 553: Alpha: 6.160688482542975\n",
      "2018-11-26 12:54:11,717 DEBUG Layer 560: Alpha: 5.897818459371629\n",
      "2018-11-26 12:54:11,720 DEBUG Layer 567: Alpha: 5.363154773502516\n",
      "2018-11-26 12:54:11,724 INFO Alpha: min: 1.364728432119429, max: 6.939540804908551, avg: 3.619427326281071\n",
      "2018-11-26 12:54:11,728 INFO Alpha compound: min: 1.364728432119429, max: 6.939540804908551, avg: 3.619427326281071\n",
      "2018-11-26 12:54:11,731 DEBUG Layer 10: Alpha Weigthed: 0.25652257028583964\n",
      "2018-11-26 12:54:11,734 DEBUG Layer 17: Alpha Weigthed: 0.31954800809731193\n",
      "2018-11-26 12:54:11,737 DEBUG Layer 24: Alpha Weigthed: 0.49362233513035075\n",
      "2018-11-26 12:54:11,740 DEBUG Layer 31: Alpha Weigthed: 1.4345516023492229\n",
      "2018-11-26 12:54:11,743 DEBUG Layer 38: Alpha Weigthed: 0.8087975706559052\n",
      "2018-11-26 12:54:11,748 DEBUG Layer 45: Alpha Weigthed: 1.5314175379093353\n",
      "2018-11-26 12:54:11,751 DEBUG Layer 52: Alpha Weigthed: 3.929632868727833\n",
      "2018-11-26 12:54:11,755 DEBUG Layer 58: Alpha Weigthed: 0.02906707764230325\n",
      "2018-11-26 12:54:11,758 DEBUG Layer 65: Alpha Weigthed: -0.16847425261837323\n",
      "2018-11-26 12:54:11,762 DEBUG Layer 72: Alpha Weigthed: 0.12230637477791156\n",
      "2018-11-26 12:54:11,766 DEBUG Layer 79: Alpha Weigthed: -0.09659123238100824\n",
      "2018-11-26 12:54:11,769 DEBUG Layer 86: Alpha Weigthed: -0.05541017480338204\n",
      "2018-11-26 12:54:11,775 DEBUG Layer 93: Alpha Weigthed: 0.3443154861160087\n",
      "2018-11-26 12:54:11,778 DEBUG Layer 100: Alpha Weigthed: 0.8689134754874381\n",
      "2018-11-26 12:54:11,781 DEBUG Layer 107: Alpha Weigthed: 0.5445981367102605\n",
      "2018-11-26 12:54:11,785 DEBUG Layer 114: Alpha Weigthed: 0.23474567268450722\n",
      "2018-11-26 12:54:11,790 DEBUG Layer 121: Alpha Weigthed: 0.49151907920078514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:11,794 DEBUG Layer 128: Alpha Weigthed: 0.21397308588108827\n",
      "2018-11-26 12:54:11,798 DEBUG Layer 135: Alpha Weigthed: 0.5863906346982273\n",
      "2018-11-26 12:54:11,801 DEBUG Layer 148: Alpha Weigthed: -0.29622741072678443\n",
      "2018-11-26 12:54:11,806 DEBUG Layer 155: Alpha Weigthed: -0.3539789930275831\n",
      "2018-11-26 12:54:11,810 DEBUG Layer 162: Alpha Weigthed: -0.30258187049734875\n",
      "2018-11-26 12:54:11,813 DEBUG Layer 169: Alpha Weigthed: -0.3380648531515397\n",
      "2018-11-26 12:54:11,817 DEBUG Layer 176: Alpha Weigthed: -0.4409077994325044\n",
      "2018-11-26 12:54:11,821 DEBUG Layer 183: Alpha Weigthed: -0.18418922191940582\n",
      "2018-11-26 12:54:11,824 DEBUG Layer 190: Alpha Weigthed: -0.151017404523778\n",
      "2018-11-26 12:54:11,827 DEBUG Layer 197: Alpha Weigthed: -0.239859394642055\n",
      "2018-11-26 12:54:11,831 DEBUG Layer 204: Alpha Weigthed: -0.9750275613771333\n",
      "2018-11-26 12:54:11,834 DEBUG Layer 211: Alpha Weigthed: 0.15936923290511654\n",
      "2018-11-26 12:54:11,837 DEBUG Layer 218: Alpha Weigthed: 0.6404072353108399\n",
      "2018-11-26 12:54:11,841 DEBUG Layer 225: Alpha Weigthed: -0.12326690821928553\n",
      "2018-11-26 12:54:11,844 DEBUG Layer 232: Alpha Weigthed: 0.46523859312356736\n",
      "2018-11-26 12:54:11,847 DEBUG Layer 239: Alpha Weigthed: 0.7046129005117765\n",
      "2018-11-26 12:54:11,851 DEBUG Layer 246: Alpha Weigthed: -0.047197445685523684\n",
      "2018-11-26 12:54:11,853 DEBUG Layer 253: Alpha Weigthed: 0.5475540796288769\n",
      "2018-11-26 12:54:11,858 DEBUG Layer 260: Alpha Weigthed: 0.22471595235161196\n",
      "2018-11-26 12:54:11,863 DEBUG Layer 267: Alpha Weigthed: 0.20371212507245778\n",
      "2018-11-26 12:54:11,865 DEBUG Layer 274: Alpha Weigthed: 0.4353067416156264\n",
      "2018-11-26 12:54:11,869 DEBUG Layer 281: Alpha Weigthed: 0.18308814189464703\n",
      "2018-11-26 12:54:11,872 DEBUG Layer 288: Alpha Weigthed: 0.7102334078231448\n",
      "2018-11-26 12:54:11,881 DEBUG Layer 295: Alpha Weigthed: 0.4278219066606518\n",
      "2018-11-26 12:54:11,885 DEBUG Layer 302: Alpha Weigthed: 0.10189935392753398\n",
      "2018-11-26 12:54:11,888 DEBUG Layer 309: Alpha Weigthed: 0.7316686537592805\n",
      "2018-11-26 12:54:11,891 DEBUG Layer 316: Alpha Weigthed: 1.0341997742827416\n",
      "2018-11-26 12:54:11,897 DEBUG Layer 323: Alpha Weigthed: 0.7960455445009221\n",
      "2018-11-26 12:54:11,900 DEBUG Layer 330: Alpha Weigthed: 0.8855214259748723\n",
      "2018-11-26 12:54:11,903 DEBUG Layer 337: Alpha Weigthed: 0.777426619960904\n",
      "2018-11-26 12:54:11,906 DEBUG Layer 344: Alpha Weigthed: 1.007440414040072\n",
      "2018-11-26 12:54:11,910 DEBUG Layer 351: Alpha Weigthed: 1.1795825094204948\n",
      "2018-11-26 12:54:11,916 DEBUG Layer 358: Alpha Weigthed: 0.7123058536591103\n",
      "2018-11-26 12:54:11,919 DEBUG Layer 365: Alpha Weigthed: 1.5733243699979407\n",
      "2018-11-26 12:54:11,924 DEBUG Layer 372: Alpha Weigthed: 0.8494795523017086\n",
      "2018-11-26 12:54:11,928 DEBUG Layer 379: Alpha Weigthed: 1.7345800561611018\n",
      "2018-11-26 12:54:11,931 DEBUG Layer 386: Alpha Weigthed: 1.1835185131227655\n",
      "2018-11-26 12:54:11,934 DEBUG Layer 393: Alpha Weigthed: 1.5788876450939104\n",
      "2018-11-26 12:54:11,938 DEBUG Layer 406: Alpha Weigthed: -0.0442425910645382\n",
      "2018-11-26 12:54:11,941 DEBUG Layer 413: Alpha Weigthed: 0.10759759956065726\n",
      "2018-11-26 12:54:11,945 DEBUG Layer 420: Alpha Weigthed: 1.030130372769079\n",
      "2018-11-26 12:54:11,948 DEBUG Layer 427: Alpha Weigthed: 0.7377521555286304\n",
      "2018-11-26 12:54:11,951 DEBUG Layer 434: Alpha Weigthed: 0.528525921088255\n",
      "2018-11-26 12:54:11,954 DEBUG Layer 441: Alpha Weigthed: 0.6303882207419235\n",
      "2018-11-26 12:54:11,956 DEBUG Layer 448: Alpha Weigthed: 0.8533713047817459\n",
      "2018-11-26 12:54:11,959 DEBUG Layer 455: Alpha Weigthed: 0.7959845990180129\n",
      "2018-11-26 12:54:11,962 DEBUG Layer 462: Alpha Weigthed: 1.0318209991470495\n",
      "2018-11-26 12:54:11,966 DEBUG Layer 469: Alpha Weigthed: 1.047059345265451\n",
      "2018-11-26 12:54:11,970 DEBUG Layer 476: Alpha Weigthed: 1.1853922271642252\n",
      "2018-11-26 12:54:11,973 DEBUG Layer 483: Alpha Weigthed: 1.8875484237490756\n",
      "2018-11-26 12:54:11,977 DEBUG Layer 490: Alpha Weigthed: 1.1063571125412859\n",
      "2018-11-26 12:54:11,982 DEBUG Layer 497: Alpha Weigthed: 1.2643549721121352\n",
      "2018-11-26 12:54:11,985 DEBUG Layer 504: Alpha Weigthed: 1.1921628288339143\n",
      "2018-11-26 12:54:11,988 DEBUG Layer 511: Alpha Weigthed: 1.4104171308119267\n",
      "2018-11-26 12:54:11,991 DEBUG Layer 518: Alpha Weigthed: 1.5140778921605573\n",
      "2018-11-26 12:54:11,995 DEBUG Layer 525: Alpha Weigthed: 1.5650079447369278\n",
      "2018-11-26 12:54:11,998 DEBUG Layer 532: Alpha Weigthed: 1.2898471138591716\n",
      "2018-11-26 12:54:12,001 DEBUG Layer 539: Alpha Weigthed: 1.6612710225518248\n",
      "2018-11-26 12:54:12,004 DEBUG Layer 546: Alpha Weigthed: 1.5297257155202137\n",
      "2018-11-26 12:54:12,009 DEBUG Layer 553: Alpha Weigthed: 1.842077772326501\n",
      "2018-11-26 12:54:12,015 DEBUG Layer 560: Alpha Weigthed: 1.8776648192375531\n",
      "2018-11-26 12:54:12,019 DEBUG Layer 567: Alpha Weigthed: 1.4518674147960386\n",
      "2018-11-26 12:54:12,024 INFO Alpha Weighted: min: -0.9750275613771333, max: 3.929632868727833, avg: 0.6934332647302267\n",
      "2018-11-26 12:54:12,027 INFO Alpha Weighted compound: min: -0.9750275613771333, max: 3.929632868727833, avg: 0.6934332647302267\n",
      "/Users/charlesmartin14/anaconda3/envs/py3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "2018-11-26 12:54:14,789 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 12:54:14,791 INFO Analyzing model\n",
      "2018-11-26 12:54:14,822 INFO Layer 0: DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer25): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer26): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer27): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer28): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer29): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer30): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer31): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer32): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer25): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer26): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer27): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer28): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer29): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer30): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer31): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer32): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1664, out_features=1000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:14,828 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:14,854 INFO Layer 1: Sequential(\n",
      "  (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu0): ReLU(inplace)\n",
      "  (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (denseblock1): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition1): _Transition(\n",
      "    (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock2): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition2): _Transition(\n",
      "    (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock3): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer13): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer14): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer15): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer16): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer17): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer18): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer19): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer20): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer21): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer22): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer23): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer24): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer25): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer26): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer27): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer28): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer29): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer30): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer31): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer32): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition3): _Transition(\n",
      "    (norm): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock4): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer13): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer14): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer15): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer16): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer17): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer18): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer19): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer20): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer21): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer22): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer23): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer24): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer25): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer26): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer27): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer28): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer29): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer30): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer31): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer32): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (norm5): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:14,858 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:14,862 INFO Layer 2: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "2018-11-26 12:54:14,870 INFO Pytorch tensor shape detected: 64x3 (NxM), 7x7 (i,j)\n",
      "2018-11-26 12:54:14,875 INFO Layer 2: Analyzing 49 weight matrices...\n",
      "2018-11-26 12:54:14,880 INFO     Weight matrix 1/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,885 INFO     Weight matrix 2/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,890 INFO     Weight matrix 3/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,895 INFO     Weight matrix 4/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,903 INFO     Weight matrix 5/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,907 INFO     Weight matrix 6/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,912 INFO     Weight matrix 7/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,919 INFO     Weight matrix 8/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,925 INFO     Weight matrix 9/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,931 INFO     Weight matrix 10/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,935 INFO     Weight matrix 11/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,943 INFO     Weight matrix 12/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,952 INFO     Weight matrix 13/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,959 INFO     Weight matrix 14/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,963 INFO     Weight matrix 15/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,969 INFO     Weight matrix 16/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,976 INFO     Weight matrix 17/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,984 INFO     Weight matrix 18/49 (3,64): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:14,987 INFO     Weight matrix 19/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:14,996 INFO     Weight matrix 20/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,001 INFO     Weight matrix 21/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,007 INFO     Weight matrix 22/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,015 INFO     Weight matrix 23/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,020 INFO     Weight matrix 24/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,025 INFO     Weight matrix 25/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,029 INFO     Weight matrix 26/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,032 INFO     Weight matrix 27/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,036 INFO     Weight matrix 28/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,042 INFO     Weight matrix 29/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,049 INFO     Weight matrix 30/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,055 INFO     Weight matrix 31/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,063 INFO     Weight matrix 32/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,067 INFO     Weight matrix 33/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,076 INFO     Weight matrix 34/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,081 INFO     Weight matrix 35/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,086 INFO     Weight matrix 36/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,090 INFO     Weight matrix 37/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,098 INFO     Weight matrix 38/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,100 INFO     Weight matrix 39/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,104 INFO     Weight matrix 40/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,111 INFO     Weight matrix 41/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,115 INFO     Weight matrix 42/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,119 INFO     Weight matrix 43/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,123 INFO     Weight matrix 44/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,129 INFO     Weight matrix 45/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,136 INFO     Weight matrix 46/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,140 INFO     Weight matrix 47/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,145 INFO     Weight matrix 48/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,147 INFO     Weight matrix 49/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,151 INFO Layer 3: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:15,154 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:15,158 INFO Layer 4: ReLU(inplace)\n",
      "2018-11-26 12:54:15,161 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:15,164 INFO Layer 5: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:54:15,168 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:15,173 INFO Layer 6: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:54:15,176 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:15,182 INFO Layer 7: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:15,186 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:15,189 INFO Layer 8: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:15,192 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:15,195 INFO Layer 9: ReLU(inplace)\n",
      "2018-11-26 12:54:15,198 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:15,201 INFO Layer 10: Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:15,205 INFO Pytorch tensor shape detected: 128x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:15,210 INFO Layer 10: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:15,213 INFO     Weight matrix 1/1 (64,128): Analyzing ...\n",
      "2018-11-26 12:54:15,906 INFO     Weight matrix 1/1 (64,128): Alpha: 17.103577541465995, Alpha Weighted: 4.0523294356593516, D: 0.25827059840952327\n",
      "2018-11-26 12:54:15,910 INFO     Weight matrix 1/1 (64,128): Alpha 17.103577541465995 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:54:15,914 INFO     Weight matrix 1/1 (64,128): Lognorm: 0.6628804206848145\n",
      "2018-11-26 12:54:15,921 INFO Layer 11: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:15,924 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:15,928 INFO Layer 12: ReLU(inplace)\n",
      "2018-11-26 12:54:15,933 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:15,935 INFO Layer 13: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:15,940 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:15,943 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:15,947 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,950 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:15,953 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,960 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,964 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,969 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,978 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,985 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,988 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:15,991 INFO Layer 14: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:15,993 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:15,996 INFO Layer 15: BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:15,999 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:16,001 INFO Layer 16: ReLU(inplace)\n",
      "2018-11-26 12:54:16,003 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:16,007 INFO Layer 17: Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:16,013 INFO Pytorch tensor shape detected: 128x96 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:16,015 INFO Layer 17: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:16,018 INFO     Weight matrix 1/1 (96,128): Analyzing ...\n",
      "2018-11-26 12:54:16,930 INFO     Weight matrix 1/1 (96,128): Alpha: 2.5770547449291823, Alpha Weighted: 0.8674491604046812, D: 0.19578019352608417\n",
      "2018-11-26 12:54:16,933 INFO     Weight matrix 1/1 (96,128): Lognorm: 0.7082341909408569\n",
      "2018-11-26 12:54:16,936 INFO Layer 18: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:16,939 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:16,942 INFO Layer 19: ReLU(inplace)\n",
      "2018-11-26 12:54:16,944 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:16,947 INFO Layer 20: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:16,951 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:16,953 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:16,955 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:16,959 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:16,962 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:16,965 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:16,968 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:16,972 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:16,976 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:16,980 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:16,983 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:16,987 INFO Layer 21: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:16,990 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:16,993 INFO Layer 22: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:16,997 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:17,000 INFO Layer 23: ReLU(inplace)\n",
      "2018-11-26 12:54:17,003 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:17,007 INFO Layer 24: Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:17,011 INFO Pytorch tensor shape detected: 128x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:17,015 INFO Layer 24: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:17,017 INFO     Weight matrix 1/1 (128,128): Analyzing ...\n",
      "2018-11-26 12:54:18,546 INFO     Weight matrix 1/1 (128,128): Alpha: 13.92533794559396, Alpha Weighted: 2.370643720226937, D: 0.1999999999999994\n",
      "2018-11-26 12:54:18,549 INFO     Weight matrix 1/1 (128,128): Alpha 13.92533794559396 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:54:18,553 INFO     Weight matrix 1/1 (128,128): Lognorm: 0.6662705540657043\n",
      "2018-11-26 12:54:18,555 INFO Layer 25: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:18,558 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:18,562 INFO Layer 26: ReLU(inplace)\n",
      "2018-11-26 12:54:18,566 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:18,570 INFO Layer 27: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:18,573 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:18,576 INFO Layer 27: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:18,579 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:18,583 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:18,589 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:18,593 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:18,595 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:18,598 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:18,601 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:18,603 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:18,606 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:18,609 INFO Layer 28: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:18,613 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:18,617 INFO Layer 29: BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:18,621 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:18,624 INFO Layer 30: ReLU(inplace)\n",
      "2018-11-26 12:54:18,628 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:18,631 INFO Layer 31: Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:18,639 INFO Pytorch tensor shape detected: 128x160 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:18,643 INFO Layer 31: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:18,646 INFO     Weight matrix 1/1 (128,160): Analyzing ...\n",
      "2018-11-26 12:54:20,106 INFO     Weight matrix 1/1 (128,160): Alpha: 3.9763399815253497, Alpha Weighted: 0.6322501222086847, D: 0.17489526683270806\n",
      "2018-11-26 12:54:20,112 INFO     Weight matrix 1/1 (128,160): Alpha 3.9763399815253497 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:54:20,127 INFO     Weight matrix 1/1 (128,160): Lognorm: 0.6788043975830078\n",
      "2018-11-26 12:54:20,132 INFO Layer 32: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:20,135 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:20,140 INFO Layer 33: ReLU(inplace)\n",
      "2018-11-26 12:54:20,146 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:20,153 INFO Layer 34: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:20,159 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:20,163 INFO Layer 34: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:20,166 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:20,175 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:20,178 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:20,185 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:20,190 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:20,193 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:20,200 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:20,211 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:20,216 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:20,220 INFO Layer 35: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:20,226 INFO Layer 35: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:20,235 INFO Layer 36: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:20,241 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:20,245 INFO Layer 37: ReLU(inplace)\n",
      "2018-11-26 12:54:20,252 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:20,256 INFO Layer 38: Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:20,265 INFO Pytorch tensor shape detected: 128x192 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:20,271 INFO Layer 38: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:20,276 INFO     Weight matrix 1/1 (128,192): Analyzing ...\n",
      "2018-11-26 12:54:22,082 INFO     Weight matrix 1/1 (128,192): Alpha: 1.5424511829232852, Alpha Weighted: 0.16623169301817434, D: 0.211047010432882\n",
      "2018-11-26 12:54:22,085 INFO     Weight matrix 1/1 (128,192): Lognorm: 0.6521271467208862\n",
      "2018-11-26 12:54:22,089 INFO Layer 39: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:22,093 INFO Layer 39: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:22,098 INFO Layer 40: ReLU(inplace)\n",
      "2018-11-26 12:54:22,103 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:22,107 INFO Layer 41: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:22,113 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:22,116 INFO Layer 41: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:22,122 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:22,134 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:22,137 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:22,141 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:22,147 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:22,154 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:22,165 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:22,175 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:22,183 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:22,188 INFO Layer 42: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:22,190 INFO Layer 42: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:22,194 INFO Layer 43: BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:22,200 INFO Layer 43: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:22,205 INFO Layer 44: ReLU(inplace)\n",
      "2018-11-26 12:54:22,208 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:22,217 INFO Layer 45: Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:22,222 INFO Pytorch tensor shape detected: 128x224 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:22,225 INFO Layer 45: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:22,230 INFO     Weight matrix 1/1 (128,224): Analyzing ...\n",
      "2018-11-26 12:54:23,800 INFO     Weight matrix 1/1 (128,224): Alpha: 1.4873554350229614, Alpha Weighted: 0.28358131469354203, D: 0.18516958839537712\n",
      "2018-11-26 12:54:23,804 INFO     Weight matrix 1/1 (128,224): Alpha 1.4873554350229614 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:54:23,810 INFO     Weight matrix 1/1 (128,224): Lognorm: 0.6803149580955505\n",
      "2018-11-26 12:54:23,817 INFO Layer 46: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:23,820 INFO Layer 46: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:23,827 INFO Layer 47: ReLU(inplace)\n",
      "2018-11-26 12:54:23,836 INFO Layer 47: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:23,841 INFO Layer 48: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:23,847 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:23,852 INFO Layer 48: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:23,855 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:23,862 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:23,871 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:23,877 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:23,881 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:23,886 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:23,892 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:23,898 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:23,905 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:23,909 INFO Layer 49: _Transition(\n",
      "  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "2018-11-26 12:54:23,913 INFO Layer 49: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:23,918 INFO Layer 50: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:23,925 INFO Layer 50: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:23,928 INFO Layer 51: ReLU(inplace)\n",
      "2018-11-26 12:54:23,937 INFO Layer 51: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:23,942 INFO Layer 52: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:23,947 INFO Pytorch tensor shape detected: 128x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:23,954 INFO Layer 52: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:23,959 INFO     Weight matrix 1/1 (128,256): Analyzing ...\n",
      "2018-11-26 12:54:25,385 INFO     Weight matrix 1/1 (128,256): Alpha: 4.598715274857987, Alpha Weighted: 3.4545075877594966, D: 0.10547075388980187\n",
      "2018-11-26 12:54:25,388 INFO     Weight matrix 1/1 (128,256): Alpha 4.598715274857987 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:54:25,392 INFO     Weight matrix 1/1 (128,256): Lognorm: 0.9959068894386292\n",
      "2018-11-26 12:54:25,397 INFO Layer 53: AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "2018-11-26 12:54:25,399 INFO Layer 53: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:25,405 INFO Layer 54: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer7): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer8): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer9): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer10): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer11): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer12): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:25,409 INFO Layer 54: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:25,412 INFO Layer 55: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:25,415 INFO Layer 55: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:25,419 INFO Layer 56: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:25,422 INFO Layer 56: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:25,425 INFO Layer 57: ReLU(inplace)\n",
      "2018-11-26 12:54:25,429 INFO Layer 57: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:25,432 INFO Layer 58: Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:25,438 INFO Pytorch tensor shape detected: 128x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:25,441 INFO Layer 58: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:25,445 INFO     Weight matrix 1/1 (128,128): Analyzing ...\n",
      "2018-11-26 12:54:26,800 INFO     Weight matrix 1/1 (128,128): Alpha: 1.9712193042565547, Alpha Weighted: -0.19721177208001575, D: 0.22046433690616973\n",
      "2018-11-26 12:54:26,804 INFO     Weight matrix 1/1 (128,128): Lognorm: 0.384185254573822\n",
      "2018-11-26 12:54:26,808 INFO Layer 59: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:26,813 INFO Layer 59: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:26,823 INFO Layer 60: ReLU(inplace)\n",
      "2018-11-26 12:54:26,830 INFO Layer 60: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:26,835 INFO Layer 61: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:26,841 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:26,845 INFO Layer 61: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:26,851 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:26,854 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:26,858 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:26,862 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:26,866 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:26,870 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:26,873 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:26,877 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:26,880 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:26,884 INFO Layer 62: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:26,887 INFO Layer 62: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:26,890 INFO Layer 63: BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:26,893 INFO Layer 63: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:26,896 INFO Layer 64: ReLU(inplace)\n",
      "2018-11-26 12:54:26,900 INFO Layer 64: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:26,903 INFO Layer 65: Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:26,907 INFO Pytorch tensor shape detected: 128x160 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:26,910 INFO Layer 65: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:26,914 INFO     Weight matrix 1/1 (128,160): Analyzing ...\n",
      "2018-11-26 12:54:28,292 INFO     Weight matrix 1/1 (128,160): Alpha: 1.9371152997133256, Alpha Weighted: 0.05932468760761852, D: 0.16340829622907854\n",
      "2018-11-26 12:54:28,296 INFO     Weight matrix 1/1 (128,160): Lognorm: 0.6056005358695984\n",
      "2018-11-26 12:54:28,298 INFO Layer 66: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:28,301 INFO Layer 66: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:28,304 INFO Layer 67: ReLU(inplace)\n",
      "2018-11-26 12:54:28,307 INFO Layer 67: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:28,310 INFO Layer 68: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:28,316 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:28,319 INFO Layer 68: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:28,322 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:28,325 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:28,330 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:28,333 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:28,337 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:28,340 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:28,343 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:28,346 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:28,350 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:28,353 INFO Layer 69: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:28,356 INFO Layer 69: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:28,360 INFO Layer 70: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:28,364 INFO Layer 70: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:28,367 INFO Layer 71: ReLU(inplace)\n",
      "2018-11-26 12:54:28,369 INFO Layer 71: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:28,372 INFO Layer 72: Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:28,377 INFO Pytorch tensor shape detected: 128x192 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:28,382 INFO Layer 72: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:28,385 INFO     Weight matrix 1/1 (128,192): Analyzing ...\n",
      "2018-11-26 12:54:29,832 INFO     Weight matrix 1/1 (128,192): Alpha: 2.291997430505141, Alpha Weighted: -0.09743981021976622, D: 0.19368844438599986\n",
      "2018-11-26 12:54:29,835 INFO     Weight matrix 1/1 (128,192): Lognorm: 0.5647442936897278\n",
      "2018-11-26 12:54:29,841 INFO Layer 73: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:29,844 INFO Layer 73: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:29,847 INFO Layer 74: ReLU(inplace)\n",
      "2018-11-26 12:54:29,850 INFO Layer 74: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:29,854 INFO Layer 75: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:29,858 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:29,864 INFO Layer 75: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:29,867 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:29,871 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:29,875 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:29,878 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:29,881 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:29,885 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:29,887 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:29,891 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:29,895 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:29,899 INFO Layer 76: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:29,902 INFO Layer 76: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:29,905 INFO Layer 77: BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:29,911 INFO Layer 77: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:29,914 INFO Layer 78: ReLU(inplace)\n",
      "2018-11-26 12:54:29,917 INFO Layer 78: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:29,919 INFO Layer 79: Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:29,923 INFO Pytorch tensor shape detected: 128x224 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:29,926 INFO Layer 79: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:29,930 INFO     Weight matrix 1/1 (128,224): Analyzing ...\n",
      "2018-11-26 12:54:31,351 INFO     Weight matrix 1/1 (128,224): Alpha: 1.7220053448508905, Alpha Weighted: -0.0770388029273832, D: 0.19700870202200593\n",
      "2018-11-26 12:54:31,355 INFO     Weight matrix 1/1 (128,224): Lognorm: 0.603904664516449\n",
      "2018-11-26 12:54:31,358 INFO Layer 80: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:31,362 INFO Layer 80: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:31,365 INFO Layer 81: ReLU(inplace)\n",
      "2018-11-26 12:54:31,369 INFO Layer 81: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:31,372 INFO Layer 82: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:31,377 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:31,382 INFO Layer 82: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:31,386 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:31,389 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:31,393 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:31,397 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:31,401 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:31,404 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:31,407 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:31,412 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:31,415 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:31,422 INFO Layer 83: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:31,427 INFO Layer 83: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:31,432 INFO Layer 84: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:31,435 INFO Layer 84: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:31,439 INFO Layer 85: ReLU(inplace)\n",
      "2018-11-26 12:54:31,447 INFO Layer 85: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:31,451 INFO Layer 86: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:31,456 INFO Pytorch tensor shape detected: 128x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:31,460 INFO Layer 86: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:31,464 INFO     Weight matrix 1/1 (128,256): Analyzing ...\n",
      "2018-11-26 12:54:32,933 INFO     Weight matrix 1/1 (128,256): Alpha: 1.6464272811928575, Alpha Weighted: -0.022197763931461834, D: 0.20018181674735958\n",
      "2018-11-26 12:54:32,937 INFO     Weight matrix 1/1 (128,256): Lognorm: 0.6348459720611572\n",
      "2018-11-26 12:54:32,939 INFO Layer 87: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:32,943 INFO Layer 87: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:32,946 INFO Layer 88: ReLU(inplace)\n",
      "2018-11-26 12:54:32,949 INFO Layer 88: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:32,952 INFO Layer 89: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:32,955 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:32,958 INFO Layer 89: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:32,962 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:32,966 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:32,970 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:32,973 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:32,977 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:32,982 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:32,986 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:32,989 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:32,993 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:32,997 INFO Layer 90: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:32,999 INFO Layer 90: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:33,003 INFO Layer 91: BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:33,006 INFO Layer 91: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:33,009 INFO Layer 92: ReLU(inplace)\n",
      "2018-11-26 12:54:33,012 INFO Layer 92: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:33,018 INFO Layer 93: Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:33,024 INFO Pytorch tensor shape detected: 128x288 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:33,027 INFO Layer 93: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:33,031 INFO     Weight matrix 1/1 (128,288): Analyzing ...\n",
      "2018-11-26 12:54:34,504 INFO     Weight matrix 1/1 (128,288): Alpha: 3.7824280637991103, Alpha Weighted: 0.2663167799720304, D: 0.12379014021719814\n",
      "2018-11-26 12:54:34,507 INFO     Weight matrix 1/1 (128,288): Alpha 3.7824280637991103 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:54:34,511 INFO     Weight matrix 1/1 (128,288): Lognorm: 0.6459779739379883\n",
      "2018-11-26 12:54:34,514 INFO Layer 94: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:34,518 INFO Layer 94: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:34,521 INFO Layer 95: ReLU(inplace)\n",
      "2018-11-26 12:54:34,525 INFO Layer 95: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:34,531 INFO Layer 96: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:34,534 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:34,537 INFO Layer 96: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:34,541 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:34,544 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:34,548 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:34,551 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:34,554 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:34,557 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:34,562 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:34,568 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:34,573 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:34,577 INFO Layer 97: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:34,581 INFO Layer 97: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:34,583 INFO Layer 98: BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:34,586 INFO Layer 98: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:34,590 INFO Layer 99: ReLU(inplace)\n",
      "2018-11-26 12:54:34,593 INFO Layer 99: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:34,596 INFO Layer 100: Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:34,602 INFO Pytorch tensor shape detected: 128x320 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:34,604 INFO Layer 100: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:34,608 INFO     Weight matrix 1/1 (128,320): Analyzing ...\n",
      "2018-11-26 12:54:35,905 INFO     Weight matrix 1/1 (128,320): Alpha: 1.6903296572405917, Alpha Weighted: -0.011966826172071057, D: 0.18508111554567186\n",
      "2018-11-26 12:54:35,909 INFO     Weight matrix 1/1 (128,320): Lognorm: 0.6464845538139343\n",
      "2018-11-26 12:54:35,913 INFO Layer 101: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:35,917 INFO Layer 101: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:35,920 INFO Layer 102: ReLU(inplace)\n",
      "2018-11-26 12:54:35,925 INFO Layer 102: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:35,929 INFO Layer 103: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:35,933 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:35,937 INFO Layer 103: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:35,940 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:35,943 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:35,948 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:35,951 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:35,955 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:35,959 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:35,965 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:35,969 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:35,973 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:35,980 INFO Layer 104: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:35,983 INFO Layer 104: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:35,986 INFO Layer 105: BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:35,990 INFO Layer 105: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:35,993 INFO Layer 106: ReLU(inplace)\n",
      "2018-11-26 12:54:35,995 INFO Layer 106: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:35,998 INFO Layer 107: Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:36,001 INFO Pytorch tensor shape detected: 128x352 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:36,004 INFO Layer 107: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:36,008 INFO     Weight matrix 1/1 (128,352): Analyzing ...\n",
      "2018-11-26 12:54:37,290 INFO     Weight matrix 1/1 (128,352): Alpha: 8.054599596017644, Alpha Weighted: 1.0135056634346233, D: 0.1725225833369477\n",
      "2018-11-26 12:54:37,293 INFO     Weight matrix 1/1 (128,352): Alpha 8.054599596017644 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:54:37,296 INFO     Weight matrix 1/1 (128,352): Lognorm: 0.6824978590011597\n",
      "2018-11-26 12:54:37,298 INFO Layer 108: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:37,301 INFO Layer 108: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:37,304 INFO Layer 109: ReLU(inplace)\n",
      "2018-11-26 12:54:37,306 INFO Layer 109: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:37,309 INFO Layer 110: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:37,313 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:37,317 INFO Layer 110: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:37,323 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:37,328 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:37,331 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:37,335 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:37,338 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:37,343 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:37,346 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:37,350 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:37,354 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:37,357 INFO Layer 111: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:37,359 INFO Layer 111: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:37,362 INFO Layer 112: BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:37,365 INFO Layer 112: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:37,367 INFO Layer 113: ReLU(inplace)\n",
      "2018-11-26 12:54:37,370 INFO Layer 113: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:37,374 INFO Layer 114: Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:37,380 INFO Pytorch tensor shape detected: 128x384 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:37,382 INFO Layer 114: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:37,386 INFO     Weight matrix 1/1 (128,384): Analyzing ...\n",
      "2018-11-26 12:54:38,841 INFO     Weight matrix 1/1 (128,384): Alpha: 1.6742162004816419, Alpha Weighted: 0.4466364524337585, D: 0.1447955082717392\n",
      "2018-11-26 12:54:38,845 INFO     Weight matrix 1/1 (128,384): Lognorm: 0.6937096118927002\n",
      "2018-11-26 12:54:38,848 INFO Layer 115: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:38,852 INFO Layer 115: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:38,857 INFO Layer 116: ReLU(inplace)\n",
      "2018-11-26 12:54:38,860 INFO Layer 116: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:38,864 INFO Layer 117: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:38,869 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:38,873 INFO Layer 117: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:38,877 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:38,880 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:38,884 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:38,887 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:38,890 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:38,896 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:38,900 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:38,903 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:38,906 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:38,910 INFO Layer 118: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:38,914 INFO Layer 118: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:38,920 INFO Layer 119: BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:38,924 INFO Layer 119: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:38,928 INFO Layer 120: ReLU(inplace)\n",
      "2018-11-26 12:54:38,932 INFO Layer 120: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:38,936 INFO Layer 121: Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:38,946 INFO Pytorch tensor shape detected: 128x416 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:38,950 INFO Layer 121: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:38,954 INFO     Weight matrix 1/1 (128,416): Analyzing ...\n",
      "2018-11-26 12:54:40,353 INFO     Weight matrix 1/1 (128,416): Alpha: 2.3860073484654256, Alpha Weighted: 0.43304402087389215, D: 0.14379441888699174\n",
      "2018-11-26 12:54:40,357 INFO     Weight matrix 1/1 (128,416): Lognorm: 0.7336108088493347\n",
      "2018-11-26 12:54:40,362 INFO Layer 122: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:40,366 INFO Layer 122: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:40,370 INFO Layer 123: ReLU(inplace)\n",
      "2018-11-26 12:54:40,373 INFO Layer 123: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:40,377 INFO Layer 124: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:40,384 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:40,386 INFO Layer 124: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:40,390 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:40,393 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:40,396 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:40,400 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:40,405 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:40,408 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:40,414 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:40,417 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:40,421 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:40,425 INFO Layer 125: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:40,428 INFO Layer 125: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:40,432 INFO Layer 126: BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:40,434 INFO Layer 126: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:40,438 INFO Layer 127: ReLU(inplace)\n",
      "2018-11-26 12:54:40,441 INFO Layer 127: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:40,444 INFO Layer 128: Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:40,448 INFO Pytorch tensor shape detected: 128x448 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:40,451 INFO Layer 128: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:40,455 INFO     Weight matrix 1/1 (128,448): Analyzing ...\n",
      "2018-11-26 12:54:41,780 INFO     Weight matrix 1/1 (128,448): Alpha: 2.1487801908422233, Alpha Weighted: 0.693710478854593, D: 0.1311585130046492\n",
      "2018-11-26 12:54:41,783 INFO     Weight matrix 1/1 (128,448): Lognorm: 0.780185878276825\n",
      "2018-11-26 12:54:41,786 INFO Layer 129: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:41,789 INFO Layer 129: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:41,792 INFO Layer 130: ReLU(inplace)\n",
      "2018-11-26 12:54:41,795 INFO Layer 130: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:41,798 INFO Layer 131: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:41,803 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:41,806 INFO Layer 131: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:41,809 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:41,813 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:41,816 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:41,820 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:41,823 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:41,827 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:41,830 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:41,835 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:41,838 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:41,842 INFO Layer 132: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:41,850 INFO Layer 132: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:41,853 INFO Layer 133: BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:41,856 INFO Layer 133: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:41,858 INFO Layer 134: ReLU(inplace)\n",
      "2018-11-26 12:54:41,861 INFO Layer 134: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:41,865 INFO Layer 135: Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:41,870 INFO Pytorch tensor shape detected: 128x480 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:41,873 INFO Layer 135: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:41,876 INFO     Weight matrix 1/1 (128,480): Analyzing ...\n",
      "2018-11-26 12:54:43,255 INFO     Weight matrix 1/1 (128,480): Alpha: 2.109053590730394, Alpha Weighted: 0.35002852563181314, D: 0.14829371083404375\n",
      "2018-11-26 12:54:43,259 INFO     Weight matrix 1/1 (128,480): Lognorm: 0.7551169991493225\n",
      "2018-11-26 12:54:43,261 INFO Layer 136: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:43,267 INFO Layer 136: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:43,270 INFO Layer 137: ReLU(inplace)\n",
      "2018-11-26 12:54:43,276 INFO Layer 137: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:43,281 INFO Layer 138: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:43,285 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:43,288 INFO Layer 138: Analyzing 9 weight matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:43,291 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:43,294 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:43,296 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:43,299 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:43,302 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:43,305 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:43,310 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:43,313 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:43,317 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:43,321 INFO Layer 139: _Transition(\n",
      "  (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "2018-11-26 12:54:43,325 INFO Layer 139: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:43,332 INFO Layer 140: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:43,340 INFO Layer 140: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:43,343 INFO Layer 141: ReLU(inplace)\n",
      "2018-11-26 12:54:43,348 INFO Layer 141: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:43,355 INFO Layer 142: Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:43,364 INFO Pytorch tensor shape detected: 256x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:43,367 INFO Layer 142: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:43,371 INFO     Weight matrix 1/1 (256,512): Analyzing ...\n",
      "2018-11-26 12:54:46,532 INFO     Weight matrix 1/1 (256,512): Alpha: 2.930404259481442, Alpha Weighted: 1.5519769252807962, D: 0.16798124699817468\n",
      "2018-11-26 12:54:46,535 INFO     Weight matrix 1/1 (256,512): Lognorm: 1.1360725164413452\n",
      "2018-11-26 12:54:46,539 INFO Layer 143: AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "2018-11-26 12:54:46,542 INFO Layer 143: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:46,552 INFO Layer 144: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer7): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer8): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer9): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer10): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer11): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer12): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer13): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer14): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer15): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer16): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer17): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer18): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer19): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer20): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer21): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer22): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer23): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer24): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer25): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer26): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer27): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer28): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer29): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer30): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer31): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer32): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:46,555 INFO Layer 144: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:46,558 INFO Layer 145: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:46,565 INFO Layer 145: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:46,572 INFO Layer 146: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:46,582 INFO Layer 146: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:46,585 INFO Layer 147: ReLU(inplace)\n",
      "2018-11-26 12:54:46,588 INFO Layer 147: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:46,592 INFO Layer 148: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:46,597 INFO Pytorch tensor shape detected: 128x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:46,600 INFO Layer 148: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:46,603 INFO     Weight matrix 1/1 (128,256): Analyzing ...\n",
      "2018-11-26 12:54:47,893 INFO     Weight matrix 1/1 (128,256): Alpha: 2.370546853032188, Alpha Weighted: -0.26177928228183267, D: 0.15128780367043354\n",
      "2018-11-26 12:54:47,898 INFO     Weight matrix 1/1 (128,256): Lognorm: 0.5364353656768799\n",
      "2018-11-26 12:54:47,901 INFO Layer 149: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:47,903 INFO Layer 149: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:47,907 INFO Layer 150: ReLU(inplace)\n",
      "2018-11-26 12:54:47,910 INFO Layer 150: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:47,914 INFO Layer 151: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:47,918 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:47,922 INFO Layer 151: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:47,927 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:47,931 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:47,933 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:47,936 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:47,939 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:47,943 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:47,947 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:47,950 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:47,954 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:47,956 INFO Layer 152: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:47,960 INFO Layer 152: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:47,964 INFO Layer 153: BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:47,967 INFO Layer 153: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:47,970 INFO Layer 154: ReLU(inplace)\n",
      "2018-11-26 12:54:47,973 INFO Layer 154: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:47,977 INFO Layer 155: Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:47,982 INFO Pytorch tensor shape detected: 128x288 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:47,985 INFO Layer 155: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:47,989 INFO     Weight matrix 1/1 (128,288): Analyzing ...\n",
      "2018-11-26 12:54:49,396 INFO     Weight matrix 1/1 (128,288): Alpha: 2.237817976337199, Alpha Weighted: -0.3042498589335454, D: 0.1563520486399569\n",
      "2018-11-26 12:54:49,399 INFO     Weight matrix 1/1 (128,288): Lognorm: 0.5058788657188416\n",
      "2018-11-26 12:54:49,403 INFO Layer 156: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:49,406 INFO Layer 156: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:49,409 INFO Layer 157: ReLU(inplace)\n",
      "2018-11-26 12:54:49,412 INFO Layer 157: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:49,416 INFO Layer 158: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:49,420 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:49,424 INFO Layer 158: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:49,428 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:49,434 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:49,438 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:49,442 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:49,445 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:49,448 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:49,451 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:49,454 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:49,458 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:49,463 INFO Layer 159: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:49,467 INFO Layer 159: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:49,470 INFO Layer 160: BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:49,475 INFO Layer 160: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:49,478 INFO Layer 161: ReLU(inplace)\n",
      "2018-11-26 12:54:49,482 INFO Layer 161: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:49,486 INFO Layer 162: Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:49,490 INFO Pytorch tensor shape detected: 128x320 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:49,493 INFO Layer 162: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:49,497 INFO     Weight matrix 1/1 (128,320): Analyzing ...\n",
      "2018-11-26 12:54:50,860 INFO     Weight matrix 1/1 (128,320): Alpha: 2.1334286817035837, Alpha Weighted: -0.3658363129775079, D: 0.18399104690737317\n",
      "2018-11-26 12:54:50,864 INFO     Weight matrix 1/1 (128,320): Lognorm: 0.5342400670051575\n",
      "2018-11-26 12:54:50,867 INFO Layer 163: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:50,869 INFO Layer 163: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:50,872 INFO Layer 164: ReLU(inplace)\n",
      "2018-11-26 12:54:50,874 INFO Layer 164: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:50,877 INFO Layer 165: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:50,880 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:50,882 INFO Layer 165: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:50,885 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:50,889 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:50,891 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:50,894 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:50,897 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:50,900 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:50,902 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:50,904 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:50,907 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:50,910 INFO Layer 166: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:50,915 INFO Layer 166: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:50,917 INFO Layer 167: BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:50,919 INFO Layer 167: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:50,923 INFO Layer 168: ReLU(inplace)\n",
      "2018-11-26 12:54:50,926 INFO Layer 168: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:50,929 INFO Layer 169: Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:50,933 INFO Pytorch tensor shape detected: 128x352 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:50,936 INFO Layer 169: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:50,939 INFO     Weight matrix 1/1 (128,352): Analyzing ...\n",
      "2018-11-26 12:54:52,136 INFO     Weight matrix 1/1 (128,352): Alpha: 4.631142116291371, Alpha Weighted: -0.16362688300048991, D: 0.11630340542471018\n",
      "2018-11-26 12:54:52,139 INFO     Weight matrix 1/1 (128,352): Alpha 4.631142116291371 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:54:52,142 INFO     Weight matrix 1/1 (128,352): Lognorm: 0.5610538125038147\n",
      "2018-11-26 12:54:52,145 INFO Layer 170: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:52,147 INFO Layer 170: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:52,149 INFO Layer 171: ReLU(inplace)\n",
      "2018-11-26 12:54:52,153 INFO Layer 171: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:52,155 INFO Layer 172: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:52,160 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:52,162 INFO Layer 172: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:52,165 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:52,169 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:52,173 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:52,176 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:52,179 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:52,182 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:52,186 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:52,189 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:52,191 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:52,196 INFO Layer 173: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:52,198 INFO Layer 173: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:52,201 INFO Layer 174: BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:52,204 INFO Layer 174: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:52,208 INFO Layer 175: ReLU(inplace)\n",
      "2018-11-26 12:54:52,210 INFO Layer 175: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:52,215 INFO Layer 176: Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:52,220 INFO Pytorch tensor shape detected: 128x384 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:52,224 INFO Layer 176: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:52,230 INFO     Weight matrix 1/1 (128,384): Analyzing ...\n",
      "2018-11-26 12:54:53,488 INFO     Weight matrix 1/1 (128,384): Alpha: 1.8324645180252213, Alpha Weighted: -0.24409468593629502, D: 0.17344606686037356\n",
      "2018-11-26 12:54:53,491 INFO     Weight matrix 1/1 (128,384): Lognorm: 0.5786291360855103\n",
      "2018-11-26 12:54:53,497 INFO Layer 177: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:53,502 INFO Layer 177: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:53,507 INFO Layer 178: ReLU(inplace)\n",
      "2018-11-26 12:54:53,511 INFO Layer 178: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:53,515 INFO Layer 179: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:53,519 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:53,527 INFO Layer 179: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:53,530 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:53,538 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:53,543 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:53,547 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:53,553 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:53,563 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:53,570 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:53,574 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:53,586 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:53,589 INFO Layer 180: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:53,593 INFO Layer 180: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:53,597 INFO Layer 181: BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:53,600 INFO Layer 181: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:53,607 INFO Layer 182: ReLU(inplace)\n",
      "2018-11-26 12:54:53,611 INFO Layer 182: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:53,614 INFO Layer 183: Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:53,619 INFO Pytorch tensor shape detected: 128x416 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:53,625 INFO Layer 183: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:53,629 INFO     Weight matrix 1/1 (128,416): Analyzing ...\n",
      "2018-11-26 12:54:54,798 INFO     Weight matrix 1/1 (128,416): Alpha: 1.8128510924692096, Alpha Weighted: -0.2032502777195054, D: 0.16791019592764111\n",
      "2018-11-26 12:54:54,801 INFO     Weight matrix 1/1 (128,416): Lognorm: 0.5725449323654175\n",
      "2018-11-26 12:54:54,804 INFO Layer 184: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:54,811 INFO Layer 184: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:54,814 INFO Layer 185: ReLU(inplace)\n",
      "2018-11-26 12:54:54,818 INFO Layer 185: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:54,822 INFO Layer 186: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:54,825 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:54,828 INFO Layer 186: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:54,831 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:54,835 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:54,838 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:54,841 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:54,843 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:54,846 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:54,849 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:54,852 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:54,856 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:54,858 INFO Layer 187: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:54,862 INFO Layer 187: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:54,865 INFO Layer 188: BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:54,868 INFO Layer 188: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:54,872 INFO Layer 189: ReLU(inplace)\n",
      "2018-11-26 12:54:54,874 INFO Layer 189: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:54,878 INFO Layer 190: Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:54,882 INFO Pytorch tensor shape detected: 128x448 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:54,884 INFO Layer 190: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:54,888 INFO     Weight matrix 1/1 (128,448): Analyzing ...\n",
      "2018-11-26 12:54:56,275 INFO     Weight matrix 1/1 (128,448): Alpha: 1.7344639556903467, Alpha Weighted: -0.09099536776729306, D: 0.15884383138523356\n",
      "2018-11-26 12:54:56,279 INFO     Weight matrix 1/1 (128,448): Lognorm: 0.5461074709892273\n",
      "2018-11-26 12:54:56,281 INFO Layer 191: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:56,285 INFO Layer 191: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:56,288 INFO Layer 192: ReLU(inplace)\n",
      "2018-11-26 12:54:56,291 INFO Layer 192: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:56,294 INFO Layer 193: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:56,299 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:56,302 INFO Layer 193: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:56,306 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:56,309 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:56,313 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:56,317 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:56,321 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:56,324 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:56,328 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:56,332 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:56,335 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:56,338 INFO Layer 194: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:56,341 INFO Layer 194: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:56,347 INFO Layer 195: BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:56,350 INFO Layer 195: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:56,353 INFO Layer 196: ReLU(inplace)\n",
      "2018-11-26 12:54:56,356 INFO Layer 196: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:56,359 INFO Layer 197: Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:56,363 INFO Pytorch tensor shape detected: 128x480 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:56,375 INFO Layer 197: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:56,385 INFO     Weight matrix 1/1 (128,480): Analyzing ...\n",
      "2018-11-26 12:54:57,779 INFO     Weight matrix 1/1 (128,480): Alpha: 2.77118198862717, Alpha Weighted: 0.9319157582881287, D: 0.07743928798796873\n",
      "2018-11-26 12:54:57,782 INFO     Weight matrix 1/1 (128,480): Lognorm: 0.6868124008178711\n",
      "2018-11-26 12:54:57,787 INFO Layer 198: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:57,790 INFO Layer 198: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:57,792 INFO Layer 199: ReLU(inplace)\n",
      "2018-11-26 12:54:57,795 INFO Layer 199: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:57,797 INFO Layer 200: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:57,802 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:57,804 INFO Layer 200: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:57,808 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:57,811 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:57,815 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:57,818 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:57,821 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:57,824 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:57,827 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:57,831 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:57,834 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:57,838 INFO Layer 201: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:57,842 INFO Layer 201: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:57,845 INFO Layer 202: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:57,848 INFO Layer 202: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:57,851 INFO Layer 203: ReLU(inplace)\n",
      "2018-11-26 12:54:57,854 INFO Layer 203: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:57,858 INFO Layer 204: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:57,861 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:57,864 INFO Layer 204: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:57,868 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 12:54:59,295 INFO     Weight matrix 1/1 (128,512): Alpha: 1.7758665373130913, Alpha Weighted: -0.2284501899832328, D: 0.18372227836803523\n",
      "2018-11-26 12:54:59,299 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.6185997724533081\n",
      "2018-11-26 12:54:59,301 INFO Layer 205: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:59,305 INFO Layer 205: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:59,307 INFO Layer 206: ReLU(inplace)\n",
      "2018-11-26 12:54:59,311 INFO Layer 206: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:59,317 INFO Layer 207: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:54:59,321 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:54:59,324 INFO Layer 207: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:54:59,328 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:59,331 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:54:59,335 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:59,339 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:59,342 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:59,345 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:59,348 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:59,351 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:59,354 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:54:59,357 INFO Layer 208: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:54:59,361 INFO Layer 208: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:59,364 INFO Layer 209: BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:54:59,366 INFO Layer 209: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:59,370 INFO Layer 210: ReLU(inplace)\n",
      "2018-11-26 12:54:59,374 INFO Layer 210: Skipping (Layer not supported)\n",
      "2018-11-26 12:54:59,377 INFO Layer 211: Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:54:59,381 INFO Pytorch tensor shape detected: 128x544 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:54:59,383 INFO Layer 211: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:54:59,386 INFO     Weight matrix 1/1 (128,544): Analyzing ...\n",
      "2018-11-26 12:55:00,804 INFO     Weight matrix 1/1 (128,544): Alpha: 2.1814484760652944, Alpha Weighted: -0.13552175759341295, D: 0.1764593228859746\n",
      "2018-11-26 12:55:00,807 INFO     Weight matrix 1/1 (128,544): Lognorm: 0.6431679129600525\n",
      "2018-11-26 12:55:00,810 INFO Layer 212: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:00,812 INFO Layer 212: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:00,815 INFO Layer 213: ReLU(inplace)\n",
      "2018-11-26 12:55:00,817 INFO Layer 213: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:00,820 INFO Layer 214: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:00,825 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:00,829 INFO Layer 214: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:00,832 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:00,836 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:00,840 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:00,844 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:00,847 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:00,849 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:00,852 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:00,855 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:00,858 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:00,861 INFO Layer 215: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:00,864 INFO Layer 215: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:00,868 INFO Layer 216: BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:00,870 INFO Layer 216: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:00,873 INFO Layer 217: ReLU(inplace)\n",
      "2018-11-26 12:55:00,876 INFO Layer 217: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:00,880 INFO Layer 218: Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:00,884 INFO Pytorch tensor shape detected: 128x576 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:00,887 INFO Layer 218: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:00,891 INFO     Weight matrix 1/1 (128,576): Analyzing ...\n",
      "2018-11-26 12:55:02,161 INFO     Weight matrix 1/1 (128,576): Alpha: 5.139587084626642, Alpha Weighted: -0.40373966518121546, D: 0.15782582410067514\n",
      "2018-11-26 12:55:02,164 INFO     Weight matrix 1/1 (128,576): Alpha 5.139587084626642 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:02,167 INFO     Weight matrix 1/1 (128,576): Lognorm: 0.6612580418586731\n",
      "2018-11-26 12:55:02,171 INFO Layer 219: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:02,178 INFO Layer 219: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:02,184 INFO Layer 220: ReLU(inplace)\n",
      "2018-11-26 12:55:02,188 INFO Layer 220: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:02,192 INFO Layer 221: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:02,195 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:02,200 INFO Layer 221: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:02,203 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:02,206 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:02,209 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:02,214 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:02,221 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:02,226 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:02,231 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:02,234 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:02,237 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:02,242 INFO Layer 222: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:02,245 INFO Layer 222: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:02,249 INFO Layer 223: BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:02,253 INFO Layer 223: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:02,255 INFO Layer 224: ReLU(inplace)\n",
      "2018-11-26 12:55:02,258 INFO Layer 224: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:02,262 INFO Layer 225: Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:02,267 INFO Pytorch tensor shape detected: 128x608 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:02,272 INFO Layer 225: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:02,275 INFO     Weight matrix 1/1 (128,608): Analyzing ...\n",
      "2018-11-26 12:55:03,388 INFO     Weight matrix 1/1 (128,608): Alpha: 3.9001065377244726, Alpha Weighted: -0.28090291094244824, D: 0.1511120430643229\n",
      "2018-11-26 12:55:03,390 INFO     Weight matrix 1/1 (128,608): Alpha 3.9001065377244726 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:03,394 INFO     Weight matrix 1/1 (128,608): Lognorm: 0.6408177614212036\n",
      "2018-11-26 12:55:03,397 INFO Layer 226: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:03,400 INFO Layer 226: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:03,404 INFO Layer 227: ReLU(inplace)\n",
      "2018-11-26 12:55:03,406 INFO Layer 227: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:03,410 INFO Layer 228: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:03,416 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:03,421 INFO Layer 228: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:03,424 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:03,428 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:03,430 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:03,434 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:03,438 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:03,440 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:03,444 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:03,446 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:03,449 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:03,451 INFO Layer 229: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:03,454 INFO Layer 229: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:03,458 INFO Layer 230: BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:03,464 INFO Layer 230: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:03,467 INFO Layer 231: ReLU(inplace)\n",
      "2018-11-26 12:55:03,471 INFO Layer 231: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:03,474 INFO Layer 232: Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:03,479 INFO Pytorch tensor shape detected: 128x640 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:03,482 INFO Layer 232: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:03,487 INFO     Weight matrix 1/1 (128,640): Analyzing ...\n",
      "2018-11-26 12:55:04,762 INFO     Weight matrix 1/1 (128,640): Alpha: 2.7682997796422084, Alpha Weighted: 0.052118219660074266, D: 0.1528231112317534\n",
      "2018-11-26 12:55:04,765 INFO     Weight matrix 1/1 (128,640): Lognorm: 0.7037506699562073\n",
      "2018-11-26 12:55:04,768 INFO Layer 233: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:04,772 INFO Layer 233: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:04,774 INFO Layer 234: ReLU(inplace)\n",
      "2018-11-26 12:55:04,777 INFO Layer 234: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:04,780 INFO Layer 235: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:04,785 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:04,788 INFO Layer 235: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:04,792 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:04,795 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:04,798 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:04,801 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:04,804 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:04,806 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:04,809 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:04,816 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:04,820 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:04,824 INFO Layer 236: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:04,828 INFO Layer 236: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:04,833 INFO Layer 237: BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:04,837 INFO Layer 237: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:04,840 INFO Layer 238: ReLU(inplace)\n",
      "2018-11-26 12:55:04,843 INFO Layer 238: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:04,846 INFO Layer 239: Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:04,850 INFO Pytorch tensor shape detected: 128x672 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:04,853 INFO Layer 239: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:04,856 INFO     Weight matrix 1/1 (128,672): Analyzing ...\n",
      "2018-11-26 12:55:06,028 INFO     Weight matrix 1/1 (128,672): Alpha: 1.8649098205426444, Alpha Weighted: -0.04985549191352576, D: 0.1605496599976003\n",
      "2018-11-26 12:55:06,031 INFO     Weight matrix 1/1 (128,672): Lognorm: 0.6707753539085388\n",
      "2018-11-26 12:55:06,035 INFO Layer 240: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:06,038 INFO Layer 240: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:06,041 INFO Layer 241: ReLU(inplace)\n",
      "2018-11-26 12:55:06,044 INFO Layer 241: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:06,047 INFO Layer 242: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:06,051 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:06,054 INFO Layer 242: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:06,057 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:06,061 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:06,065 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:06,068 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:06,071 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:06,075 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:06,078 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:06,080 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:06,082 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:06,085 INFO Layer 243: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:06,088 INFO Layer 243: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:06,091 INFO Layer 244: BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:06,093 INFO Layer 244: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:06,096 INFO Layer 245: ReLU(inplace)\n",
      "2018-11-26 12:55:06,099 INFO Layer 245: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:06,102 INFO Layer 246: Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:06,106 INFO Pytorch tensor shape detected: 128x704 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:06,108 INFO Layer 246: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:06,112 INFO     Weight matrix 1/1 (128,704): Analyzing ...\n",
      "2018-11-26 12:55:07,389 INFO     Weight matrix 1/1 (128,704): Alpha: 3.849618067722745, Alpha Weighted: 0.4107771194073228, D: 0.13877721091233353\n",
      "2018-11-26 12:55:07,391 INFO     Weight matrix 1/1 (128,704): Alpha 3.849618067722745 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:07,394 INFO     Weight matrix 1/1 (128,704): Lognorm: 0.7297888398170471\n",
      "2018-11-26 12:55:07,401 INFO Layer 247: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:07,403 INFO Layer 247: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:07,406 INFO Layer 248: ReLU(inplace)\n",
      "2018-11-26 12:55:07,408 INFO Layer 248: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:07,412 INFO Layer 249: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:07,415 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:07,418 INFO Layer 249: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:07,420 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:07,422 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:07,425 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:07,427 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:07,431 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:07,434 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:07,437 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:07,440 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:07,444 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:07,447 INFO Layer 250: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:07,449 INFO Layer 250: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:07,452 INFO Layer 251: BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:07,454 INFO Layer 251: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:07,456 INFO Layer 252: ReLU(inplace)\n",
      "2018-11-26 12:55:07,459 INFO Layer 252: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:07,461 INFO Layer 253: Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:07,464 INFO Pytorch tensor shape detected: 128x736 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:07,470 INFO Layer 253: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:07,474 INFO     Weight matrix 1/1 (128,736): Analyzing ...\n",
      "2018-11-26 12:55:08,681 INFO     Weight matrix 1/1 (128,736): Alpha: 3.91888744628046, Alpha Weighted: 0.38408383662447926, D: 0.10940725262415013\n",
      "2018-11-26 12:55:08,684 INFO     Weight matrix 1/1 (128,736): Alpha 3.91888744628046 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:08,690 INFO     Weight matrix 1/1 (128,736): Lognorm: 0.7284191250801086\n",
      "2018-11-26 12:55:08,694 INFO Layer 254: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:08,699 INFO Layer 254: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:08,701 INFO Layer 255: ReLU(inplace)\n",
      "2018-11-26 12:55:08,704 INFO Layer 255: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:08,707 INFO Layer 256: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:08,714 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:08,716 INFO Layer 256: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:08,724 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:08,730 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:08,733 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:08,737 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:08,739 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:08,745 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:08,747 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:08,750 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:08,753 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:08,756 INFO Layer 257: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:08,761 INFO Layer 257: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:08,766 INFO Layer 258: BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:08,772 INFO Layer 258: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:08,777 INFO Layer 259: ReLU(inplace)\n",
      "2018-11-26 12:55:08,779 INFO Layer 259: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:08,783 INFO Layer 260: Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:08,791 INFO Pytorch tensor shape detected: 128x768 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:08,794 INFO Layer 260: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:08,797 INFO     Weight matrix 1/1 (128,768): Analyzing ...\n",
      "2018-11-26 12:55:10,413 INFO     Weight matrix 1/1 (128,768): Alpha: 4.573183163100828, Alpha Weighted: 0.7787243983248218, D: 0.08281697280862257\n",
      "2018-11-26 12:55:10,415 INFO     Weight matrix 1/1 (128,768): Alpha 4.573183163100828 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:10,418 INFO     Weight matrix 1/1 (128,768): Lognorm: 0.7068647742271423\n",
      "2018-11-26 12:55:10,422 INFO Layer 261: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:10,425 INFO Layer 261: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:10,428 INFO Layer 262: ReLU(inplace)\n",
      "2018-11-26 12:55:10,430 INFO Layer 262: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:10,434 INFO Layer 263: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:10,438 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:10,441 INFO Layer 263: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:10,443 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:10,446 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:10,449 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:10,453 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:10,455 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:10,458 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:10,463 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:10,467 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:10,470 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:10,474 INFO Layer 264: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:10,477 INFO Layer 264: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:10,480 INFO Layer 265: BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:10,485 INFO Layer 265: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:10,488 INFO Layer 266: ReLU(inplace)\n",
      "2018-11-26 12:55:10,491 INFO Layer 266: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:10,495 INFO Layer 267: Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:10,499 INFO Pytorch tensor shape detected: 128x800 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:10,502 INFO Layer 267: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:10,506 INFO     Weight matrix 1/1 (128,800): Analyzing ...\n",
      "2018-11-26 12:55:11,753 INFO     Weight matrix 1/1 (128,800): Alpha: 4.496461274862021, Alpha Weighted: -0.19570798749494742, D: 0.15072409047127644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:11,756 INFO     Weight matrix 1/1 (128,800): Alpha 4.496461274862021 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:11,758 INFO     Weight matrix 1/1 (128,800): Lognorm: 0.6702701449394226\n",
      "2018-11-26 12:55:11,762 INFO Layer 268: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:11,765 INFO Layer 268: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:11,768 INFO Layer 269: ReLU(inplace)\n",
      "2018-11-26 12:55:11,770 INFO Layer 269: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:11,773 INFO Layer 270: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:11,777 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:11,780 INFO Layer 270: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:11,783 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:11,787 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:11,790 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:11,792 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:11,795 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:11,797 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:11,800 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:11,803 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:11,808 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:11,810 INFO Layer 271: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:11,813 INFO Layer 271: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:11,815 INFO Layer 272: BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:11,818 INFO Layer 272: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:11,820 INFO Layer 273: ReLU(inplace)\n",
      "2018-11-26 12:55:11,822 INFO Layer 273: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:11,824 INFO Layer 274: Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:11,828 INFO Pytorch tensor shape detected: 128x832 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:11,830 INFO Layer 274: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:11,832 INFO     Weight matrix 1/1 (128,832): Analyzing ...\n",
      "2018-11-26 12:55:13,045 INFO     Weight matrix 1/1 (128,832): Alpha: 2.377113316388721, Alpha Weighted: 0.18669310714933413, D: 0.1402384844341773\n",
      "2018-11-26 12:55:13,048 INFO     Weight matrix 1/1 (128,832): Lognorm: 0.6986064910888672\n",
      "2018-11-26 12:55:13,053 INFO Layer 275: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:13,056 INFO Layer 275: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:13,058 INFO Layer 276: ReLU(inplace)\n",
      "2018-11-26 12:55:13,064 INFO Layer 276: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:13,067 INFO Layer 277: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:13,072 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:13,076 INFO Layer 277: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:13,080 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:13,082 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:13,086 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:13,088 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:13,091 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:13,095 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:13,098 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:13,102 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:13,106 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:13,109 INFO Layer 278: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:13,113 INFO Layer 278: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:13,116 INFO Layer 279: BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:13,120 INFO Layer 279: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:13,125 INFO Layer 280: ReLU(inplace)\n",
      "2018-11-26 12:55:13,129 INFO Layer 280: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:13,133 INFO Layer 281: Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:13,137 INFO Pytorch tensor shape detected: 128x864 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:13,141 INFO Layer 281: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:13,144 INFO     Weight matrix 1/1 (128,864): Analyzing ...\n",
      "2018-11-26 12:55:14,505 INFO     Weight matrix 1/1 (128,864): Alpha: 3.3235660068940804, Alpha Weighted: 0.6615994264110525, D: 0.1031950907286534\n",
      "2018-11-26 12:55:14,509 INFO     Weight matrix 1/1 (128,864): Lognorm: 0.773578941822052\n",
      "2018-11-26 12:55:14,515 INFO Layer 282: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:14,517 INFO Layer 282: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:14,520 INFO Layer 283: ReLU(inplace)\n",
      "2018-11-26 12:55:14,525 INFO Layer 283: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:14,528 INFO Layer 284: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:14,534 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:14,535 INFO Layer 284: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:14,539 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:14,541 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:14,544 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:14,547 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:14,550 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:14,553 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:14,556 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:14,559 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:14,570 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:14,573 INFO Layer 285: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:14,578 INFO Layer 285: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:14,581 INFO Layer 286: BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:14,586 INFO Layer 286: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:14,589 INFO Layer 287: ReLU(inplace)\n",
      "2018-11-26 12:55:14,594 INFO Layer 287: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:14,596 INFO Layer 288: Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:14,603 INFO Pytorch tensor shape detected: 128x896 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:14,610 INFO Layer 288: Analyzing 1 weight matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:14,614 INFO     Weight matrix 1/1 (128,896): Analyzing ...\n",
      "2018-11-26 12:55:15,973 INFO     Weight matrix 1/1 (128,896): Alpha: 3.5660532001570937, Alpha Weighted: 0.2805621116240357, D: 0.12484925961160498\n",
      "2018-11-26 12:55:15,975 INFO     Weight matrix 1/1 (128,896): Alpha 3.5660532001570937 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:15,980 INFO     Weight matrix 1/1 (128,896): Lognorm: 0.7320337891578674\n",
      "2018-11-26 12:55:15,984 INFO Layer 289: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:15,987 INFO Layer 289: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:15,990 INFO Layer 290: ReLU(inplace)\n",
      "2018-11-26 12:55:15,992 INFO Layer 290: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:15,995 INFO Layer 291: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:16,000 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:16,002 INFO Layer 291: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:16,006 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:16,010 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:16,013 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:16,018 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:16,022 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:16,025 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:16,029 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:16,032 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:16,035 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:16,039 INFO Layer 292: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:16,043 INFO Layer 292: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:16,047 INFO Layer 293: BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:16,050 INFO Layer 293: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:16,053 INFO Layer 294: ReLU(inplace)\n",
      "2018-11-26 12:55:16,057 INFO Layer 294: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:16,060 INFO Layer 295: Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:16,066 INFO Pytorch tensor shape detected: 128x928 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:16,072 INFO Layer 295: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:16,075 INFO     Weight matrix 1/1 (128,928): Analyzing ...\n",
      "2018-11-26 12:55:17,396 INFO     Weight matrix 1/1 (128,928): Alpha: 3.0088890263357095, Alpha Weighted: 0.16619307762261698, D: 0.13010840735154483\n",
      "2018-11-26 12:55:17,399 INFO     Weight matrix 1/1 (128,928): Lognorm: 0.748719334602356\n",
      "2018-11-26 12:55:17,402 INFO Layer 296: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:17,405 INFO Layer 296: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:17,408 INFO Layer 297: ReLU(inplace)\n",
      "2018-11-26 12:55:17,413 INFO Layer 297: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:17,416 INFO Layer 298: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:17,420 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:17,423 INFO Layer 298: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:17,426 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:17,429 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:17,434 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:17,441 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:17,444 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:17,448 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:17,452 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:17,454 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:17,457 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:17,460 INFO Layer 299: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:17,464 INFO Layer 299: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:17,467 INFO Layer 300: BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:17,470 INFO Layer 300: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:17,473 INFO Layer 301: ReLU(inplace)\n",
      "2018-11-26 12:55:17,481 INFO Layer 301: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:17,484 INFO Layer 302: Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:17,488 INFO Pytorch tensor shape detected: 128x960 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:17,491 INFO Layer 302: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:17,494 INFO     Weight matrix 1/1 (128,960): Analyzing ...\n",
      "2018-11-26 12:55:18,924 INFO     Weight matrix 1/1 (128,960): Alpha: 4.546142259618181, Alpha Weighted: 0.7973839533217886, D: 0.10350878756514814\n",
      "2018-11-26 12:55:18,928 INFO     Weight matrix 1/1 (128,960): Alpha 4.546142259618181 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:18,931 INFO     Weight matrix 1/1 (128,960): Lognorm: 0.7782529592514038\n",
      "2018-11-26 12:55:18,942 INFO Layer 303: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:18,945 INFO Layer 303: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:18,954 INFO Layer 304: ReLU(inplace)\n",
      "2018-11-26 12:55:18,958 INFO Layer 304: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:18,962 INFO Layer 305: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:18,970 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:18,974 INFO Layer 305: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:18,978 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:18,986 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:18,991 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:18,996 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:19,001 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:19,006 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:19,016 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:19,021 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:19,028 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:19,033 INFO Layer 306: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:19,040 INFO Layer 306: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:19,045 INFO Layer 307: BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:19,049 INFO Layer 307: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:19,052 INFO Layer 308: ReLU(inplace)\n",
      "2018-11-26 12:55:19,057 INFO Layer 308: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:19,061 INFO Layer 309: Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:19,070 INFO Pytorch tensor shape detected: 128x992 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:19,077 INFO Layer 309: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:19,083 INFO     Weight matrix 1/1 (128,992): Analyzing ...\n",
      "2018-11-26 12:55:20,440 INFO     Weight matrix 1/1 (128,992): Alpha: 2.2651019171568993, Alpha Weighted: 0.5139195855845606, D: 0.12843244212036475\n",
      "2018-11-26 12:55:20,443 INFO     Weight matrix 1/1 (128,992): Lognorm: 0.7889545559883118\n",
      "2018-11-26 12:55:20,447 INFO Layer 310: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:20,450 INFO Layer 310: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:20,453 INFO Layer 311: ReLU(inplace)\n",
      "2018-11-26 12:55:20,457 INFO Layer 311: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:20,462 INFO Layer 312: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:20,467 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:20,474 INFO Layer 312: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:20,478 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:20,481 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:20,484 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:20,487 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:20,491 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:20,494 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:20,499 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:20,502 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:20,505 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:20,509 INFO Layer 313: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:20,512 INFO Layer 313: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:20,516 INFO Layer 314: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:20,521 INFO Layer 314: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:20,524 INFO Layer 315: ReLU(inplace)\n",
      "2018-11-26 12:55:20,528 INFO Layer 315: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:20,532 INFO Layer 316: Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:20,537 INFO Pytorch tensor shape detected: 128x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:20,541 INFO Layer 316: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:20,545 INFO     Weight matrix 1/1 (128,1024): Analyzing ...\n",
      "2018-11-26 12:55:21,882 INFO     Weight matrix 1/1 (128,1024): Alpha: 3.1643338858880683, Alpha Weighted: 0.29748148974096456, D: 0.1410578525857452\n",
      "2018-11-26 12:55:21,886 INFO     Weight matrix 1/1 (128,1024): Lognorm: 0.7701826691627502\n",
      "2018-11-26 12:55:21,889 INFO Layer 317: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:21,892 INFO Layer 317: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:21,896 INFO Layer 318: ReLU(inplace)\n",
      "2018-11-26 12:55:21,899 INFO Layer 318: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:21,903 INFO Layer 319: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:21,907 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:21,910 INFO Layer 319: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:21,915 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:21,919 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:21,922 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:21,928 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:21,931 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:21,935 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:21,937 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:21,941 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:21,944 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:21,947 INFO Layer 320: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:21,949 INFO Layer 320: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:21,952 INFO Layer 321: BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:21,955 INFO Layer 321: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:21,957 INFO Layer 322: ReLU(inplace)\n",
      "2018-11-26 12:55:21,960 INFO Layer 322: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:21,964 INFO Layer 323: Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:21,968 INFO Pytorch tensor shape detected: 128x1056 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:21,974 INFO Layer 323: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:21,977 INFO     Weight matrix 1/1 (128,1056): Analyzing ...\n",
      "2018-11-26 12:55:23,295 INFO     Weight matrix 1/1 (128,1056): Alpha: 3.787828819460362, Alpha Weighted: 0.357817004593928, D: 0.11913009333665758\n",
      "2018-11-26 12:55:23,298 INFO     Weight matrix 1/1 (128,1056): Alpha 3.787828819460362 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:23,302 INFO     Weight matrix 1/1 (128,1056): Lognorm: 0.7718908190727234\n",
      "2018-11-26 12:55:23,305 INFO Layer 324: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:23,310 INFO Layer 324: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:23,312 INFO Layer 325: ReLU(inplace)\n",
      "2018-11-26 12:55:23,317 INFO Layer 325: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:23,322 INFO Layer 326: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:23,329 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:23,332 INFO Layer 326: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:23,335 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:23,338 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:23,341 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:23,344 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:23,348 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:23,350 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:23,354 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:23,357 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:23,361 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:23,365 INFO Layer 327: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:23,369 INFO Layer 327: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:23,377 INFO Layer 328: BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:23,381 INFO Layer 328: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:23,384 INFO Layer 329: ReLU(inplace)\n",
      "2018-11-26 12:55:23,391 INFO Layer 329: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:23,397 INFO Layer 330: Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:23,402 INFO Pytorch tensor shape detected: 128x1088 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:23,405 INFO Layer 330: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:23,413 INFO     Weight matrix 1/1 (128,1088): Analyzing ...\n",
      "2018-11-26 12:55:24,909 INFO     Weight matrix 1/1 (128,1088): Alpha: 2.9537739049687133, Alpha Weighted: 0.5365945292544382, D: 0.12460903618284735\n",
      "2018-11-26 12:55:24,912 INFO     Weight matrix 1/1 (128,1088): Lognorm: 0.8019099235534668\n",
      "2018-11-26 12:55:24,916 INFO Layer 331: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:24,920 INFO Layer 331: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:24,924 INFO Layer 332: ReLU(inplace)\n",
      "2018-11-26 12:55:24,928 INFO Layer 332: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:24,932 INFO Layer 333: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:24,936 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:24,940 INFO Layer 333: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:24,943 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:24,947 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:24,951 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:24,954 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:24,957 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:24,960 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:24,964 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:24,968 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:24,971 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:24,975 INFO Layer 334: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:24,979 INFO Layer 334: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:24,982 INFO Layer 335: BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:24,988 INFO Layer 335: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:24,992 INFO Layer 336: ReLU(inplace)\n",
      "2018-11-26 12:55:24,995 INFO Layer 336: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:24,999 INFO Layer 337: Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:25,003 INFO Pytorch tensor shape detected: 128x1120 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:25,007 INFO Layer 337: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:25,012 INFO     Weight matrix 1/1 (128,1120): Analyzing ...\n",
      "2018-11-26 12:55:26,495 INFO     Weight matrix 1/1 (128,1120): Alpha: 5.620526974227303, Alpha Weighted: 0.5060469459464658, D: 0.11997217309315111\n",
      "2018-11-26 12:55:26,498 INFO     Weight matrix 1/1 (128,1120): Alpha 5.620526974227303 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:26,501 INFO     Weight matrix 1/1 (128,1120): Lognorm: 0.7833647727966309\n",
      "2018-11-26 12:55:26,505 INFO Layer 338: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:26,509 INFO Layer 338: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:26,511 INFO Layer 339: ReLU(inplace)\n",
      "2018-11-26 12:55:26,514 INFO Layer 339: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:26,517 INFO Layer 340: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:26,524 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:26,530 INFO Layer 340: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:26,537 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:26,542 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:26,545 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:26,551 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:26,554 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:26,559 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:26,562 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:26,567 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:26,578 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:26,584 INFO Layer 341: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:26,589 INFO Layer 341: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:26,597 INFO Layer 342: BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:26,601 INFO Layer 342: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:26,605 INFO Layer 343: ReLU(inplace)\n",
      "2018-11-26 12:55:26,611 INFO Layer 343: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:26,616 INFO Layer 344: Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:26,621 INFO Pytorch tensor shape detected: 128x1152 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:26,624 INFO Layer 344: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:26,627 INFO     Weight matrix 1/1 (128,1152): Analyzing ...\n",
      "2018-11-26 12:55:28,279 INFO     Weight matrix 1/1 (128,1152): Alpha: 5.2220533783932135, Alpha Weighted: 1.3639966636082295, D: 0.10364065458753918\n",
      "2018-11-26 12:55:28,283 INFO     Weight matrix 1/1 (128,1152): Alpha 5.2220533783932135 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:28,287 INFO     Weight matrix 1/1 (128,1152): Lognorm: 0.8105090260505676\n",
      "2018-11-26 12:55:28,290 INFO Layer 345: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:28,293 INFO Layer 345: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:28,296 INFO Layer 346: ReLU(inplace)\n",
      "2018-11-26 12:55:28,299 INFO Layer 346: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:28,302 INFO Layer 347: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:28,306 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:28,315 INFO Layer 347: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:28,318 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:28,322 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:28,326 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:28,329 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:28,332 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:28,336 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:28,339 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:28,342 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:28,346 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:28,350 INFO Layer 348: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:28,353 INFO Layer 348: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:28,357 INFO Layer 349: BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:28,360 INFO Layer 349: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:28,366 INFO Layer 350: ReLU(inplace)\n",
      "2018-11-26 12:55:28,370 INFO Layer 350: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:28,373 INFO Layer 351: Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:28,379 INFO Pytorch tensor shape detected: 128x1184 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:28,383 INFO Layer 351: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:28,388 INFO     Weight matrix 1/1 (128,1184): Analyzing ...\n",
      "2018-11-26 12:55:29,790 INFO     Weight matrix 1/1 (128,1184): Alpha: 2.662632585983574, Alpha Weighted: 0.680148413712937, D: 0.10739711598852852\n",
      "2018-11-26 12:55:29,794 INFO     Weight matrix 1/1 (128,1184): Lognorm: 0.8009234666824341\n",
      "2018-11-26 12:55:29,797 INFO Layer 352: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:29,799 INFO Layer 352: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:29,802 INFO Layer 353: ReLU(inplace)\n",
      "2018-11-26 12:55:29,804 INFO Layer 353: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:29,808 INFO Layer 354: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:29,813 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:29,817 INFO Layer 354: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:29,820 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:29,823 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:29,827 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:29,830 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:29,832 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:29,835 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:29,839 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:29,842 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:29,845 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:29,848 INFO Layer 355: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:29,851 INFO Layer 355: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:29,854 INFO Layer 356: BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:29,857 INFO Layer 356: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:29,861 INFO Layer 357: ReLU(inplace)\n",
      "2018-11-26 12:55:29,864 INFO Layer 357: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:29,867 INFO Layer 358: Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:29,872 INFO Pytorch tensor shape detected: 128x1216 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:29,877 INFO Layer 358: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:29,880 INFO     Weight matrix 1/1 (128,1216): Analyzing ...\n",
      "2018-11-26 12:55:31,182 INFO     Weight matrix 1/1 (128,1216): Alpha: 2.4890896159198523, Alpha Weighted: 0.6251885195587166, D: 0.10884798184921163\n",
      "2018-11-26 12:55:31,185 INFO     Weight matrix 1/1 (128,1216): Lognorm: 0.8085119128227234\n",
      "2018-11-26 12:55:31,189 INFO Layer 359: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:31,192 INFO Layer 359: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:31,195 INFO Layer 360: ReLU(inplace)\n",
      "2018-11-26 12:55:31,197 INFO Layer 360: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:31,200 INFO Layer 361: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:31,209 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:31,211 INFO Layer 361: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:31,214 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:31,217 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:31,221 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:31,224 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:31,228 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:31,232 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:31,235 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:31,240 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:31,243 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:31,247 INFO Layer 362: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:31,249 INFO Layer 362: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:31,252 INFO Layer 363: BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:31,255 INFO Layer 363: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:31,258 INFO Layer 364: ReLU(inplace)\n",
      "2018-11-26 12:55:31,261 INFO Layer 364: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:31,265 INFO Layer 365: Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:31,269 INFO Pytorch tensor shape detected: 128x1248 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:31,274 INFO Layer 365: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:31,277 INFO     Weight matrix 1/1 (128,1248): Analyzing ...\n",
      "2018-11-26 12:55:32,664 INFO     Weight matrix 1/1 (128,1248): Alpha: 6.6501287828896, Alpha Weighted: 1.4605934698852678, D: 0.10958914232072842\n",
      "2018-11-26 12:55:32,667 INFO     Weight matrix 1/1 (128,1248): Alpha 6.6501287828896 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:32,670 INFO     Weight matrix 1/1 (128,1248): Lognorm: 0.8089067935943604\n",
      "2018-11-26 12:55:32,675 INFO Layer 366: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:32,684 INFO Layer 366: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:32,688 INFO Layer 367: ReLU(inplace)\n",
      "2018-11-26 12:55:32,694 INFO Layer 367: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:32,698 INFO Layer 368: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:32,702 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:32,708 INFO Layer 368: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:32,714 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:32,718 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:32,721 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:32,726 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:32,733 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:32,737 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:32,742 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:32,746 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:32,748 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:32,752 INFO Layer 369: _Transition(\n",
      "  (norm): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:32,761 INFO Layer 369: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:32,764 INFO Layer 370: BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:32,767 INFO Layer 370: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:32,770 INFO Layer 371: ReLU(inplace)\n",
      "2018-11-26 12:55:32,772 INFO Layer 371: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:32,777 INFO Layer 372: Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:32,797 INFO Pytorch tensor shape detected: 640x1280 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:32,808 INFO Layer 372: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:32,811 INFO     Weight matrix 1/1 (640,1280): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:55:32,815 INFO Layer 373: AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "2018-11-26 12:55:32,818 INFO Layer 373: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:32,830 INFO Layer 374: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer7): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer8): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer9): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer10): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer11): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer12): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer13): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer14): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer15): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer16): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer17): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer18): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer19): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer20): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer21): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer22): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer23): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer24): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer25): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer26): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer27): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer28): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer29): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer30): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer31): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer32): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:32,833 INFO Layer 374: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:32,838 INFO Layer 375: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:32,841 INFO Layer 375: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:32,849 INFO Layer 376: BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:32,851 INFO Layer 376: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:32,854 INFO Layer 377: ReLU(inplace)\n",
      "2018-11-26 12:55:32,857 INFO Layer 377: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:32,860 INFO Layer 378: Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:32,864 INFO Pytorch tensor shape detected: 128x640 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:32,867 INFO Layer 378: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:32,869 INFO     Weight matrix 1/1 (128,640): Analyzing ...\n",
      "2018-11-26 12:55:34,314 INFO     Weight matrix 1/1 (128,640): Alpha: 5.576862638712635, Alpha Weighted: 0.2596385757927139, D: 0.11372756404992534\n",
      "2018-11-26 12:55:34,316 INFO     Weight matrix 1/1 (128,640): Alpha 5.576862638712635 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:34,320 INFO     Weight matrix 1/1 (128,640): Lognorm: 0.739496111869812\n",
      "2018-11-26 12:55:34,324 INFO Layer 379: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:34,330 INFO Layer 379: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:34,335 INFO Layer 380: ReLU(inplace)\n",
      "2018-11-26 12:55:34,340 INFO Layer 380: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:34,344 INFO Layer 381: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:34,348 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:34,351 INFO Layer 381: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:34,354 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:34,360 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:34,363 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:34,367 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:34,375 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:34,383 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:34,386 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:34,388 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:34,391 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:34,395 INFO Layer 382: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:34,398 INFO Layer 382: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:34,402 INFO Layer 383: BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:34,405 INFO Layer 383: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:34,408 INFO Layer 384: ReLU(inplace)\n",
      "2018-11-26 12:55:34,411 INFO Layer 384: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:34,414 INFO Layer 385: Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:34,421 INFO Pytorch tensor shape detected: 128x672 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:34,423 INFO Layer 385: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:34,429 INFO     Weight matrix 1/1 (128,672): Analyzing ...\n",
      "2018-11-26 12:55:35,548 INFO     Weight matrix 1/1 (128,672): Alpha: 3.1695034044766, Alpha Weighted: -0.018888748816430705, D: 0.14716691808781357\n",
      "2018-11-26 12:55:35,551 INFO     Weight matrix 1/1 (128,672): Lognorm: 0.6991075277328491\n",
      "2018-11-26 12:55:35,554 INFO Layer 386: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:35,556 INFO Layer 386: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:35,559 INFO Layer 387: ReLU(inplace)\n",
      "2018-11-26 12:55:35,562 INFO Layer 387: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:35,564 INFO Layer 388: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:35,568 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:35,571 INFO Layer 388: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:35,575 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:35,578 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:35,581 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:35,584 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:35,587 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:35,590 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:35,593 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:35,596 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:35,599 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:35,602 INFO Layer 389: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:35,605 INFO Layer 389: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:35,608 INFO Layer 390: BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:35,611 INFO Layer 390: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:35,614 INFO Layer 391: ReLU(inplace)\n",
      "2018-11-26 12:55:35,617 INFO Layer 391: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:35,619 INFO Layer 392: Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:35,627 INFO Pytorch tensor shape detected: 128x704 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:35,631 INFO Layer 392: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:35,635 INFO     Weight matrix 1/1 (128,704): Analyzing ...\n",
      "2018-11-26 12:55:36,856 INFO     Weight matrix 1/1 (128,704): Alpha: 3.954030150296511, Alpha Weighted: 0.23067528341581398, D: 0.1131833751283633\n",
      "2018-11-26 12:55:36,859 INFO     Weight matrix 1/1 (128,704): Alpha 3.954030150296511 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:36,863 INFO     Weight matrix 1/1 (128,704): Lognorm: 0.7276461720466614\n",
      "2018-11-26 12:55:36,865 INFO Layer 393: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:36,868 INFO Layer 393: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:36,870 INFO Layer 394: ReLU(inplace)\n",
      "2018-11-26 12:55:36,873 INFO Layer 394: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:36,875 INFO Layer 395: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:36,879 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:36,882 INFO Layer 395: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:36,885 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:36,888 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:36,891 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:36,894 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:36,897 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:36,899 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:36,902 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:36,905 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:36,907 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:36,910 INFO Layer 396: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:36,913 INFO Layer 396: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:36,916 INFO Layer 397: BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:36,919 INFO Layer 397: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:36,922 INFO Layer 398: ReLU(inplace)\n",
      "2018-11-26 12:55:36,925 INFO Layer 398: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:36,928 INFO Layer 399: Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:36,931 INFO Pytorch tensor shape detected: 128x736 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:36,934 INFO Layer 399: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:36,938 INFO     Weight matrix 1/1 (128,736): Analyzing ...\n",
      "2018-11-26 12:55:38,249 INFO     Weight matrix 1/1 (128,736): Alpha: 5.8970533753497, Alpha Weighted: -0.1145734112224207, D: 0.12545001744174222\n",
      "2018-11-26 12:55:38,254 INFO     Weight matrix 1/1 (128,736): Alpha 5.8970533753497 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:38,258 INFO     Weight matrix 1/1 (128,736): Lognorm: 0.7221860885620117\n",
      "2018-11-26 12:55:38,262 INFO Layer 400: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:38,266 INFO Layer 400: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:38,269 INFO Layer 401: ReLU(inplace)\n",
      "2018-11-26 12:55:38,272 INFO Layer 401: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:38,275 INFO Layer 402: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:38,279 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:38,282 INFO Layer 402: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:38,285 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:38,288 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:38,291 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:38,297 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:38,300 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:38,303 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:38,305 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:38,308 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:38,310 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:38,316 INFO Layer 403: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:38,319 INFO Layer 403: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:38,322 INFO Layer 404: BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:38,326 INFO Layer 404: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:38,329 INFO Layer 405: ReLU(inplace)\n",
      "2018-11-26 12:55:38,331 INFO Layer 405: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:38,334 INFO Layer 406: Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:38,338 INFO Pytorch tensor shape detected: 128x768 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:38,341 INFO Layer 406: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:38,344 INFO     Weight matrix 1/1 (128,768): Analyzing ...\n",
      "2018-11-26 12:55:39,697 INFO     Weight matrix 1/1 (128,768): Alpha: 2.553047680007487, Alpha Weighted: 0.3239665392690146, D: 0.13443173578326267\n",
      "2018-11-26 12:55:39,700 INFO     Weight matrix 1/1 (128,768): Lognorm: 0.7436009049415588\n",
      "2018-11-26 12:55:39,703 INFO Layer 407: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:39,708 INFO Layer 407: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:39,712 INFO Layer 408: ReLU(inplace)\n",
      "2018-11-26 12:55:39,715 INFO Layer 408: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:39,719 INFO Layer 409: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:39,726 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:39,731 INFO Layer 409: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:39,740 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:39,747 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:39,751 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:39,755 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:39,761 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:39,769 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:39,774 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:39,781 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:39,785 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:39,788 INFO Layer 410: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:39,792 INFO Layer 410: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:39,795 INFO Layer 411: BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:39,798 INFO Layer 411: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:39,801 INFO Layer 412: ReLU(inplace)\n",
      "2018-11-26 12:55:39,803 INFO Layer 412: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:39,811 INFO Layer 413: Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:39,817 INFO Pytorch tensor shape detected: 128x800 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:39,834 INFO Layer 413: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:39,839 INFO     Weight matrix 1/1 (128,800): Analyzing ...\n",
      "2018-11-26 12:55:41,195 INFO     Weight matrix 1/1 (128,800): Alpha: 2.318132044392585, Alpha Weighted: 0.1945933806671906, D: 0.13521983484447392\n",
      "2018-11-26 12:55:41,199 INFO     Weight matrix 1/1 (128,800): Lognorm: 0.7478145956993103\n",
      "2018-11-26 12:55:41,201 INFO Layer 414: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:41,204 INFO Layer 414: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:41,207 INFO Layer 415: ReLU(inplace)\n",
      "2018-11-26 12:55:41,209 INFO Layer 415: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:41,213 INFO Layer 416: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:41,218 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:41,221 INFO Layer 416: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:41,224 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:41,230 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:41,237 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:41,245 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:41,250 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:41,254 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:41,257 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:41,259 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:41,264 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:41,269 INFO Layer 417: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:41,272 INFO Layer 417: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:41,277 INFO Layer 418: BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:41,279 INFO Layer 418: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:41,285 INFO Layer 419: ReLU(inplace)\n",
      "2018-11-26 12:55:41,292 INFO Layer 419: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:41,297 INFO Layer 420: Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:41,307 INFO Pytorch tensor shape detected: 128x832 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:41,310 INFO Layer 420: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:41,313 INFO     Weight matrix 1/1 (128,832): Analyzing ...\n",
      "2018-11-26 12:55:42,859 INFO     Weight matrix 1/1 (128,832): Alpha: 5.251685003689215, Alpha Weighted: 0.00311210283937652, D: 0.10403269471684268\n",
      "2018-11-26 12:55:42,862 INFO     Weight matrix 1/1 (128,832): Alpha 5.251685003689215 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:42,865 INFO     Weight matrix 1/1 (128,832): Lognorm: 0.7609472870826721\n",
      "2018-11-26 12:55:42,869 INFO Layer 421: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:42,873 INFO Layer 421: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:42,876 INFO Layer 422: ReLU(inplace)\n",
      "2018-11-26 12:55:42,879 INFO Layer 422: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:42,882 INFO Layer 423: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:42,888 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:42,891 INFO Layer 423: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:42,895 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:42,898 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:42,903 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:42,907 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:42,911 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:42,917 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:42,921 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:42,925 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:42,928 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:42,934 INFO Layer 424: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:42,939 INFO Layer 424: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:42,942 INFO Layer 425: BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:42,945 INFO Layer 425: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:42,948 INFO Layer 426: ReLU(inplace)\n",
      "2018-11-26 12:55:42,951 INFO Layer 426: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:42,954 INFO Layer 427: Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:42,958 INFO Pytorch tensor shape detected: 128x864 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:42,961 INFO Layer 427: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:42,966 INFO     Weight matrix 1/1 (128,864): Analyzing ...\n",
      "2018-11-26 12:55:44,496 INFO     Weight matrix 1/1 (128,864): Alpha: 5.620612197900111, Alpha Weighted: 0.4650241255345615, D: 0.13106829741126047\n",
      "2018-11-26 12:55:44,499 INFO     Weight matrix 1/1 (128,864): Alpha 5.620612197900111 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:44,503 INFO     Weight matrix 1/1 (128,864): Lognorm: 0.7696356177330017\n",
      "2018-11-26 12:55:44,505 INFO Layer 428: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:44,508 INFO Layer 428: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:44,512 INFO Layer 429: ReLU(inplace)\n",
      "2018-11-26 12:55:44,516 INFO Layer 429: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:44,519 INFO Layer 430: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:44,523 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:44,526 INFO Layer 430: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:44,538 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:44,541 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:44,544 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:44,547 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:44,550 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:44,552 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:44,555 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:44,558 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:44,560 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:44,563 INFO Layer 431: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:44,566 INFO Layer 431: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:44,568 INFO Layer 432: BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:44,572 INFO Layer 432: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:44,575 INFO Layer 433: ReLU(inplace)\n",
      "2018-11-26 12:55:44,578 INFO Layer 433: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:44,580 INFO Layer 434: Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:44,585 INFO Pytorch tensor shape detected: 128x896 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:44,588 INFO Layer 434: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:44,591 INFO     Weight matrix 1/1 (128,896): Analyzing ...\n",
      "2018-11-26 12:55:45,939 INFO     Weight matrix 1/1 (128,896): Alpha: 5.024479294679638, Alpha Weighted: 0.5807368038528061, D: 0.07227908097595004\n",
      "2018-11-26 12:55:45,941 INFO     Weight matrix 1/1 (128,896): Alpha 5.024479294679638 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:45,945 INFO     Weight matrix 1/1 (128,896): Lognorm: 0.7776841521263123\n",
      "2018-11-26 12:55:45,948 INFO Layer 435: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:45,951 INFO Layer 435: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:45,954 INFO Layer 436: ReLU(inplace)\n",
      "2018-11-26 12:55:45,956 INFO Layer 436: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:45,960 INFO Layer 437: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:45,963 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:45,965 INFO Layer 437: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:45,968 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:45,971 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:45,974 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:45,976 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:45,979 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:45,983 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:45,986 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:45,990 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:45,993 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:45,996 INFO Layer 438: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:45,999 INFO Layer 438: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:46,003 INFO Layer 439: BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:46,007 INFO Layer 439: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:46,009 INFO Layer 440: ReLU(inplace)\n",
      "2018-11-26 12:55:46,012 INFO Layer 440: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:46,014 INFO Layer 441: Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:46,018 INFO Pytorch tensor shape detected: 128x928 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:46,021 INFO Layer 441: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:46,025 INFO     Weight matrix 1/1 (128,928): Analyzing ...\n",
      "2018-11-26 12:55:47,416 INFO     Weight matrix 1/1 (128,928): Alpha: 5.265628891024189, Alpha Weighted: 0.6968058518813457, D: 0.10647001100742048\n",
      "2018-11-26 12:55:47,419 INFO     Weight matrix 1/1 (128,928): Alpha 5.265628891024189 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:47,423 INFO     Weight matrix 1/1 (128,928): Lognorm: 0.7810474038124084\n",
      "2018-11-26 12:55:47,425 INFO Layer 442: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:47,429 INFO Layer 442: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:47,432 INFO Layer 443: ReLU(inplace)\n",
      "2018-11-26 12:55:47,435 INFO Layer 443: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:47,437 INFO Layer 444: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:47,441 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:47,444 INFO Layer 444: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:47,447 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:47,450 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:47,452 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:47,455 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:47,459 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:47,463 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:47,467 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:47,470 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:47,474 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:47,477 INFO Layer 445: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:47,480 INFO Layer 445: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:47,483 INFO Layer 446: BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:47,486 INFO Layer 446: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:47,490 INFO Layer 447: ReLU(inplace)\n",
      "2018-11-26 12:55:47,493 INFO Layer 447: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:47,497 INFO Layer 448: Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:47,501 INFO Pytorch tensor shape detected: 128x960 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:47,503 INFO Layer 448: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:47,507 INFO     Weight matrix 1/1 (128,960): Analyzing ...\n",
      "2018-11-26 12:55:49,098 INFO     Weight matrix 1/1 (128,960): Alpha: 6.274368980969305, Alpha Weighted: 0.958617704324638, D: 0.10459051429005267\n",
      "2018-11-26 12:55:49,100 INFO     Weight matrix 1/1 (128,960): Alpha 6.274368980969305 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:49,104 INFO     Weight matrix 1/1 (128,960): Lognorm: 0.7935295701026917\n",
      "2018-11-26 12:55:49,106 INFO Layer 449: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:49,109 INFO Layer 449: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:49,113 INFO Layer 450: ReLU(inplace)\n",
      "2018-11-26 12:55:49,117 INFO Layer 450: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:49,120 INFO Layer 451: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:49,124 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:49,129 INFO Layer 451: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:49,133 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:49,137 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:49,140 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:49,144 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:49,147 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:49,150 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:49,153 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:49,156 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:49,159 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:49,162 INFO Layer 452: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:49,165 INFO Layer 452: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:49,169 INFO Layer 453: BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:49,172 INFO Layer 453: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:49,176 INFO Layer 454: ReLU(inplace)\n",
      "2018-11-26 12:55:49,180 INFO Layer 454: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:49,184 INFO Layer 455: Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:49,188 INFO Pytorch tensor shape detected: 128x992 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:49,190 INFO Layer 455: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:49,193 INFO     Weight matrix 1/1 (128,992): Analyzing ...\n",
      "2018-11-26 12:55:51,058 INFO     Weight matrix 1/1 (128,992): Alpha: 5.901525643862882, Alpha Weighted: 0.6385142443841765, D: 0.08306932439591341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:51,063 INFO     Weight matrix 1/1 (128,992): Alpha 5.901525643862882 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:51,070 INFO     Weight matrix 1/1 (128,992): Lognorm: 0.7822313904762268\n",
      "2018-11-26 12:55:51,075 INFO Layer 456: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:51,082 INFO Layer 456: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:51,087 INFO Layer 457: ReLU(inplace)\n",
      "2018-11-26 12:55:51,093 INFO Layer 457: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:51,098 INFO Layer 458: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:51,106 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:51,114 INFO Layer 458: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:51,117 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:51,129 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:51,135 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:51,139 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:51,144 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:51,150 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:51,156 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:51,161 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:51,166 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:51,177 INFO Layer 459: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:51,184 INFO Layer 459: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:51,190 INFO Layer 460: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:51,195 INFO Layer 460: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:51,199 INFO Layer 461: ReLU(inplace)\n",
      "2018-11-26 12:55:51,203 INFO Layer 461: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:51,207 INFO Layer 462: Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:51,214 INFO Pytorch tensor shape detected: 128x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:51,227 INFO Layer 462: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:51,238 INFO     Weight matrix 1/1 (128,1024): Analyzing ...\n",
      "2018-11-26 12:55:52,784 INFO     Weight matrix 1/1 (128,1024): Alpha: 5.2015988484870155, Alpha Weighted: 1.2021673548369314, D: 0.07142857142857129\n",
      "2018-11-26 12:55:52,787 INFO     Weight matrix 1/1 (128,1024): Alpha 5.2015988484870155 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:52,791 INFO     Weight matrix 1/1 (128,1024): Lognorm: 0.8083719611167908\n",
      "2018-11-26 12:55:52,798 INFO Layer 463: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:52,804 INFO Layer 463: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:52,808 INFO Layer 464: ReLU(inplace)\n",
      "2018-11-26 12:55:52,812 INFO Layer 464: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:52,817 INFO Layer 465: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:52,825 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:52,832 INFO Layer 465: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:52,835 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:52,842 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:52,847 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:52,851 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:52,856 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:52,859 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:52,863 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:52,873 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:52,884 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:52,887 INFO Layer 466: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:52,892 INFO Layer 466: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:52,896 INFO Layer 467: BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:52,900 INFO Layer 467: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:52,904 INFO Layer 468: ReLU(inplace)\n",
      "2018-11-26 12:55:52,908 INFO Layer 468: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:52,911 INFO Layer 469: Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:52,917 INFO Pytorch tensor shape detected: 128x1056 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:52,928 INFO Layer 469: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:52,932 INFO     Weight matrix 1/1 (128,1056): Analyzing ...\n",
      "2018-11-26 12:55:54,520 INFO     Weight matrix 1/1 (128,1056): Alpha: 4.801889880619714, Alpha Weighted: 0.6390876235423372, D: 0.09699203036139925\n",
      "2018-11-26 12:55:54,523 INFO     Weight matrix 1/1 (128,1056): Alpha 4.801889880619714 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:54,530 INFO     Weight matrix 1/1 (128,1056): Lognorm: 0.7893091440200806\n",
      "2018-11-26 12:55:54,535 INFO Layer 470: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:54,537 INFO Layer 470: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:54,541 INFO Layer 471: ReLU(inplace)\n",
      "2018-11-26 12:55:54,545 INFO Layer 471: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:54,549 INFO Layer 472: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:54,554 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:54,557 INFO Layer 472: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:54,562 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:54,569 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:54,572 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:54,576 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:54,581 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:54,585 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:54,590 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:54,594 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:54,598 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:54,603 INFO Layer 473: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:54,606 INFO Layer 473: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:54,611 INFO Layer 474: BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:54,614 INFO Layer 474: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:54,619 INFO Layer 475: ReLU(inplace)\n",
      "2018-11-26 12:55:54,627 INFO Layer 475: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:54,631 INFO Layer 476: Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:54,639 INFO Pytorch tensor shape detected: 128x1088 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:54,646 INFO Layer 476: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:54,651 INFO     Weight matrix 1/1 (128,1088): Analyzing ...\n",
      "2018-11-26 12:55:56,182 INFO     Weight matrix 1/1 (128,1088): Alpha: 5.4384505767453435, Alpha Weighted: 0.4284860884163996, D: 0.09926122736094761\n",
      "2018-11-26 12:55:56,185 INFO     Weight matrix 1/1 (128,1088): Alpha 5.4384505767453435 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:56,189 INFO     Weight matrix 1/1 (128,1088): Lognorm: 0.7734553813934326\n",
      "2018-11-26 12:55:56,194 INFO Layer 477: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:56,197 INFO Layer 477: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:56,203 INFO Layer 478: ReLU(inplace)\n",
      "2018-11-26 12:55:56,207 INFO Layer 478: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:56,216 INFO Layer 479: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:56,220 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:56,229 INFO Layer 479: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:56,235 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:56,240 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:56,244 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:56,247 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:56,251 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:56,255 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:56,260 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:56,264 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:56,267 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:56,271 INFO Layer 480: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:56,275 INFO Layer 480: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:56,279 INFO Layer 481: BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:56,284 INFO Layer 481: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:56,289 INFO Layer 482: ReLU(inplace)\n",
      "2018-11-26 12:55:56,293 INFO Layer 482: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:56,297 INFO Layer 483: Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:56,302 INFO Pytorch tensor shape detected: 128x1120 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:56,307 INFO Layer 483: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:56,312 INFO     Weight matrix 1/1 (128,1120): Analyzing ...\n",
      "2018-11-26 12:55:57,788 INFO     Weight matrix 1/1 (128,1120): Alpha: 6.687288648287833, Alpha Weighted: 0.6184760044737043, D: 0.07271954773272382\n",
      "2018-11-26 12:55:57,792 INFO     Weight matrix 1/1 (128,1120): Alpha 6.687288648287833 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:57,796 INFO     Weight matrix 1/1 (128,1120): Lognorm: 0.7729695439338684\n",
      "2018-11-26 12:55:57,799 INFO Layer 484: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:57,803 INFO Layer 484: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:57,805 INFO Layer 485: ReLU(inplace)\n",
      "2018-11-26 12:55:57,808 INFO Layer 485: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:57,811 INFO Layer 486: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:57,815 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:57,819 INFO Layer 486: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:57,824 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:57,827 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:57,831 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:57,834 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:57,837 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:57,841 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:57,845 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:57,849 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:57,852 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:57,855 INFO Layer 487: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:55:57,858 INFO Layer 487: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:57,861 INFO Layer 488: BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:57,867 INFO Layer 488: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:57,872 INFO Layer 489: ReLU(inplace)\n",
      "2018-11-26 12:55:57,875 INFO Layer 489: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:57,878 INFO Layer 490: Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:57,885 INFO Pytorch tensor shape detected: 128x1152 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:57,888 INFO Layer 490: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:57,891 INFO     Weight matrix 1/1 (128,1152): Analyzing ...\n",
      "2018-11-26 12:55:59,363 INFO     Weight matrix 1/1 (128,1152): Alpha: 4.746577580267603, Alpha Weighted: 1.0612107587824118, D: 0.08295675176248607\n",
      "2018-11-26 12:55:59,367 INFO     Weight matrix 1/1 (128,1152): Alpha 4.746577580267603 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:55:59,373 INFO     Weight matrix 1/1 (128,1152): Lognorm: 0.7895529866218567\n",
      "2018-11-26 12:55:59,376 INFO Layer 491: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:59,379 INFO Layer 491: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:59,382 INFO Layer 492: ReLU(inplace)\n",
      "2018-11-26 12:55:59,385 INFO Layer 492: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:59,389 INFO Layer 493: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:55:59,392 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:55:59,395 INFO Layer 493: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:55:59,398 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:59,402 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:59,405 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:59,409 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:59,413 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:59,418 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:59,422 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:59,427 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:59,429 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:55:59,433 INFO Layer 494: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:55:59,436 INFO Layer 494: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:59,439 INFO Layer 495: BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:55:59,441 INFO Layer 495: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:59,444 INFO Layer 496: ReLU(inplace)\n",
      "2018-11-26 12:55:59,449 INFO Layer 496: Skipping (Layer not supported)\n",
      "2018-11-26 12:55:59,452 INFO Layer 497: Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:55:59,457 INFO Pytorch tensor shape detected: 128x1184 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:55:59,460 INFO Layer 497: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:55:59,464 INFO     Weight matrix 1/1 (128,1184): Analyzing ...\n",
      "2018-11-26 12:56:00,968 INFO     Weight matrix 1/1 (128,1184): Alpha: 5.767821478832888, Alpha Weighted: 0.7663555057280247, D: 0.10020051929379828\n",
      "2018-11-26 12:56:00,970 INFO     Weight matrix 1/1 (128,1184): Alpha 5.767821478832888 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:00,976 INFO     Weight matrix 1/1 (128,1184): Lognorm: 0.7633913159370422\n",
      "2018-11-26 12:56:00,980 INFO Layer 498: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:00,984 INFO Layer 498: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:00,989 INFO Layer 499: ReLU(inplace)\n",
      "2018-11-26 12:56:00,992 INFO Layer 499: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:00,996 INFO Layer 500: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:01,000 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:01,004 INFO Layer 500: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:01,014 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:01,019 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:01,024 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:01,027 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:01,035 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:01,040 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:01,045 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:01,051 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:01,055 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:01,061 INFO Layer 501: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:01,066 INFO Layer 501: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:01,072 INFO Layer 502: BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:01,080 INFO Layer 502: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:01,087 INFO Layer 503: ReLU(inplace)\n",
      "2018-11-26 12:56:01,093 INFO Layer 503: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:01,097 INFO Layer 504: Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:01,105 INFO Pytorch tensor shape detected: 128x1216 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:01,108 INFO Layer 504: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:01,117 INFO     Weight matrix 1/1 (128,1216): Analyzing ...\n",
      "2018-11-26 12:56:02,544 INFO     Weight matrix 1/1 (128,1216): Alpha: 6.117059992623959, Alpha Weighted: 0.892883650050567, D: 0.07877279731452491\n",
      "2018-11-26 12:56:02,546 INFO     Weight matrix 1/1 (128,1216): Alpha 6.117059992623959 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:02,551 INFO     Weight matrix 1/1 (128,1216): Lognorm: 0.7765175104141235\n",
      "2018-11-26 12:56:02,554 INFO Layer 505: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:02,557 INFO Layer 505: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:02,559 INFO Layer 506: ReLU(inplace)\n",
      "2018-11-26 12:56:02,562 INFO Layer 506: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:02,565 INFO Layer 507: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:02,568 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:02,571 INFO Layer 507: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:02,575 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:02,578 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:02,581 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:02,584 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:02,587 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:02,590 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:02,594 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:02,598 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:02,600 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:02,604 INFO Layer 508: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:02,607 INFO Layer 508: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:02,610 INFO Layer 509: BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:02,612 INFO Layer 509: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:02,615 INFO Layer 510: ReLU(inplace)\n",
      "2018-11-26 12:56:02,618 INFO Layer 510: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:02,622 INFO Layer 511: Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:02,629 INFO Pytorch tensor shape detected: 128x1248 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:02,633 INFO Layer 511: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:02,636 INFO     Weight matrix 1/1 (128,1248): Analyzing ...\n",
      "2018-11-26 12:56:04,122 INFO     Weight matrix 1/1 (128,1248): Alpha: 6.374530963840121, Alpha Weighted: 1.0196932558964709, D: 0.09090909090909083\n",
      "2018-11-26 12:56:04,124 INFO     Weight matrix 1/1 (128,1248): Alpha 6.374530963840121 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:04,130 INFO     Weight matrix 1/1 (128,1248): Lognorm: 0.7685816287994385\n",
      "2018-11-26 12:56:04,134 INFO Layer 512: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:04,137 INFO Layer 512: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:04,140 INFO Layer 513: ReLU(inplace)\n",
      "2018-11-26 12:56:04,144 INFO Layer 513: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:04,147 INFO Layer 514: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:04,151 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:04,155 INFO Layer 514: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:04,158 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:04,161 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:04,164 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:04,167 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:04,171 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:04,174 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:04,178 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:04,182 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:04,185 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:04,189 INFO Layer 515: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:04,193 INFO Layer 515: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:04,196 INFO Layer 516: BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:04,199 INFO Layer 516: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:04,202 INFO Layer 517: ReLU(inplace)\n",
      "2018-11-26 12:56:04,206 INFO Layer 517: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:04,209 INFO Layer 518: Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:04,214 INFO Pytorch tensor shape detected: 128x1280 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:04,220 INFO Layer 518: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:04,227 INFO     Weight matrix 1/1 (128,1280): Analyzing ...\n",
      "2018-11-26 12:56:05,669 INFO     Weight matrix 1/1 (128,1280): Alpha: 5.37342772196484, Alpha Weighted: 0.8523937178697979, D: 0.0843216945528723\n",
      "2018-11-26 12:56:05,673 INFO     Weight matrix 1/1 (128,1280): Alpha 5.37342772196484 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:05,678 INFO     Weight matrix 1/1 (128,1280): Lognorm: 0.7704346776008606\n",
      "2018-11-26 12:56:05,681 INFO Layer 519: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:05,684 INFO Layer 519: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:05,687 INFO Layer 520: ReLU(inplace)\n",
      "2018-11-26 12:56:05,691 INFO Layer 520: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:05,693 INFO Layer 521: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:05,697 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:05,700 INFO Layer 521: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:05,703 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:05,708 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:05,710 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:05,712 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:05,716 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:05,719 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:05,722 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:05,725 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:05,728 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:05,732 INFO Layer 522: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:05,735 INFO Layer 522: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:05,739 INFO Layer 523: BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:05,741 INFO Layer 523: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:05,744 INFO Layer 524: ReLU(inplace)\n",
      "2018-11-26 12:56:05,748 INFO Layer 524: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:05,751 INFO Layer 525: Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:05,757 INFO Pytorch tensor shape detected: 128x1312 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:05,765 INFO Layer 525: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:05,774 INFO     Weight matrix 1/1 (128,1312): Analyzing ...\n",
      "2018-11-26 12:56:07,288 INFO     Weight matrix 1/1 (128,1312): Alpha: 5.944022077178415, Alpha Weighted: 0.8246195234677595, D: 0.07498002419871808\n",
      "2018-11-26 12:56:07,291 INFO     Weight matrix 1/1 (128,1312): Alpha 5.944022077178415 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:07,295 INFO     Weight matrix 1/1 (128,1312): Lognorm: 0.7728348970413208\n",
      "2018-11-26 12:56:07,298 INFO Layer 526: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:07,301 INFO Layer 526: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:07,304 INFO Layer 527: ReLU(inplace)\n",
      "2018-11-26 12:56:07,306 INFO Layer 527: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:07,309 INFO Layer 528: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:07,313 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:07,316 INFO Layer 528: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:07,321 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:07,324 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:07,329 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:07,336 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:07,339 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:07,341 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:07,344 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:07,347 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:07,350 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:07,354 INFO Layer 529: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:07,357 INFO Layer 529: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:07,359 INFO Layer 530: BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:07,363 INFO Layer 530: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:07,367 INFO Layer 531: ReLU(inplace)\n",
      "2018-11-26 12:56:07,370 INFO Layer 531: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:07,373 INFO Layer 532: Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:07,380 INFO Pytorch tensor shape detected: 128x1344 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:07,383 INFO Layer 532: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:07,387 INFO     Weight matrix 1/1 (128,1344): Analyzing ...\n",
      "2018-11-26 12:56:08,768 INFO     Weight matrix 1/1 (128,1344): Alpha: 6.019460606000521, Alpha Weighted: 0.9370589530711309, D: 0.06737508880137555\n",
      "2018-11-26 12:56:08,770 INFO     Weight matrix 1/1 (128,1344): Alpha 6.019460606000521 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:08,776 INFO     Weight matrix 1/1 (128,1344): Lognorm: 0.7745780348777771\n",
      "2018-11-26 12:56:08,779 INFO Layer 533: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:08,782 INFO Layer 533: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:08,785 INFO Layer 534: ReLU(inplace)\n",
      "2018-11-26 12:56:08,788 INFO Layer 534: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:08,791 INFO Layer 535: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:08,794 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:08,797 INFO Layer 535: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:08,799 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:08,802 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:08,805 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:08,808 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:08,810 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:08,814 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:08,816 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:08,821 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:08,825 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:08,829 INFO Layer 536: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:08,832 INFO Layer 536: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:08,834 INFO Layer 537: BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:08,838 INFO Layer 537: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:08,840 INFO Layer 538: ReLU(inplace)\n",
      "2018-11-26 12:56:08,843 INFO Layer 538: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:08,847 INFO Layer 539: Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:08,850 INFO Pytorch tensor shape detected: 128x1376 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:08,853 INFO Layer 539: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:08,857 INFO     Weight matrix 1/1 (128,1376): Analyzing ...\n",
      "2018-11-26 12:56:10,275 INFO     Weight matrix 1/1 (128,1376): Alpha: 6.059853838577711, Alpha Weighted: 0.9501155630369605, D: 0.0810418161621067\n",
      "2018-11-26 12:56:10,278 INFO     Weight matrix 1/1 (128,1376): Alpha 6.059853838577711 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:10,282 INFO     Weight matrix 1/1 (128,1376): Lognorm: 0.7745174765586853\n",
      "2018-11-26 12:56:10,286 INFO Layer 540: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:10,289 INFO Layer 540: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:10,292 INFO Layer 541: ReLU(inplace)\n",
      "2018-11-26 12:56:10,295 INFO Layer 541: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:10,298 INFO Layer 542: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:10,302 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:10,305 INFO Layer 542: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:10,308 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:10,311 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:10,314 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:10,318 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:10,323 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:10,327 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:10,332 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:10,336 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:10,340 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:10,343 INFO Layer 543: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:10,348 INFO Layer 543: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:10,351 INFO Layer 544: BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:10,354 INFO Layer 544: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:10,358 INFO Layer 545: ReLU(inplace)\n",
      "2018-11-26 12:56:10,361 INFO Layer 545: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:10,364 INFO Layer 546: Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:10,370 INFO Pytorch tensor shape detected: 128x1408 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:10,372 INFO Layer 546: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:10,376 INFO     Weight matrix 1/1 (128,1408): Analyzing ...\n",
      "2018-11-26 12:56:11,719 INFO     Weight matrix 1/1 (128,1408): Alpha: 6.205969898510956, Alpha Weighted: 1.273347865795932, D: 0.06249999999999989\n",
      "2018-11-26 12:56:11,723 INFO     Weight matrix 1/1 (128,1408): Alpha 6.205969898510956 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:11,726 INFO     Weight matrix 1/1 (128,1408): Lognorm: 0.7881466150283813\n",
      "2018-11-26 12:56:11,729 INFO Layer 547: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:11,733 INFO Layer 547: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:11,736 INFO Layer 548: ReLU(inplace)\n",
      "2018-11-26 12:56:11,739 INFO Layer 548: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:11,743 INFO Layer 549: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:11,748 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:11,751 INFO Layer 549: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:11,754 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:11,758 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:11,760 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:11,767 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:11,770 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:11,773 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:11,775 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:11,778 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:11,781 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:11,784 INFO Layer 550: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:11,789 INFO Layer 550: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:11,792 INFO Layer 551: BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:11,796 INFO Layer 551: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:11,803 INFO Layer 552: ReLU(inplace)\n",
      "2018-11-26 12:56:11,805 INFO Layer 552: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:11,807 INFO Layer 553: Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:11,812 INFO Pytorch tensor shape detected: 128x1440 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:11,815 INFO Layer 553: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:11,820 INFO     Weight matrix 1/1 (128,1440): Analyzing ...\n",
      "2018-11-26 12:56:13,043 INFO     Weight matrix 1/1 (128,1440): Alpha: 6.11444232053226, Alpha Weighted: 0.8546578864160052, D: 0.08333333333333315\n",
      "2018-11-26 12:56:13,047 INFO     Weight matrix 1/1 (128,1440): Alpha 6.11444232053226 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:13,050 INFO     Weight matrix 1/1 (128,1440): Lognorm: 0.766076385974884\n",
      "2018-11-26 12:56:13,055 INFO Layer 554: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:13,057 INFO Layer 554: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:13,060 INFO Layer 555: ReLU(inplace)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:13,063 INFO Layer 555: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:13,067 INFO Layer 556: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:13,071 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:13,074 INFO Layer 556: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:13,076 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:13,079 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:13,081 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:13,083 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:13,087 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:13,090 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:13,093 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:13,096 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:13,099 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:13,102 INFO Layer 557: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:13,104 INFO Layer 557: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:13,106 INFO Layer 558: BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:13,109 INFO Layer 558: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:13,111 INFO Layer 559: ReLU(inplace)\n",
      "2018-11-26 12:56:13,114 INFO Layer 559: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:13,116 INFO Layer 560: Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:13,122 INFO Pytorch tensor shape detected: 128x1472 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:13,124 INFO Layer 560: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:13,127 INFO     Weight matrix 1/1 (128,1472): Analyzing ...\n",
      "2018-11-26 12:56:14,558 INFO     Weight matrix 1/1 (128,1472): Alpha: 5.746970288496086, Alpha Weighted: 0.7676605045497156, D: 0.062430385154776946\n",
      "2018-11-26 12:56:14,561 INFO     Weight matrix 1/1 (128,1472): Alpha 5.746970288496086 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:14,567 INFO     Weight matrix 1/1 (128,1472): Lognorm: 0.7647428512573242\n",
      "2018-11-26 12:56:14,573 INFO Layer 561: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:14,579 INFO Layer 561: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:14,582 INFO Layer 562: ReLU(inplace)\n",
      "2018-11-26 12:56:14,586 INFO Layer 562: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:14,592 INFO Layer 563: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:14,596 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:14,600 INFO Layer 563: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:14,603 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:14,607 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:14,611 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:14,614 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:14,619 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:14,622 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:14,628 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:14,633 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:14,636 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:14,639 INFO Layer 564: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:14,643 INFO Layer 564: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:14,646 INFO Layer 565: BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:14,649 INFO Layer 565: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:14,652 INFO Layer 566: ReLU(inplace)\n",
      "2018-11-26 12:56:14,654 INFO Layer 566: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:14,659 INFO Layer 567: Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:14,663 INFO Pytorch tensor shape detected: 128x1504 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:14,666 INFO Layer 567: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:14,670 INFO     Weight matrix 1/1 (128,1504): Analyzing ...\n",
      "2018-11-26 12:56:16,153 INFO     Weight matrix 1/1 (128,1504): Alpha: 6.077917878785389, Alpha Weighted: 1.0356239139952625, D: 0.08333333333333315\n",
      "2018-11-26 12:56:16,155 INFO     Weight matrix 1/1 (128,1504): Alpha 6.077917878785389 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:16,160 INFO     Weight matrix 1/1 (128,1504): Lognorm: 0.7859439253807068\n",
      "2018-11-26 12:56:16,163 INFO Layer 568: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:16,168 INFO Layer 568: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:16,171 INFO Layer 569: ReLU(inplace)\n",
      "2018-11-26 12:56:16,175 INFO Layer 569: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:16,179 INFO Layer 570: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:16,183 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:16,186 INFO Layer 570: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:16,189 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:16,194 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:16,198 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:16,202 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:16,205 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:16,211 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:16,217 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:16,220 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:16,224 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:16,228 INFO Layer 571: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:16,232 INFO Layer 571: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:16,235 INFO Layer 572: BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:16,238 INFO Layer 572: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:16,241 INFO Layer 573: ReLU(inplace)\n",
      "2018-11-26 12:56:16,247 INFO Layer 573: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:16,250 INFO Layer 574: Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:16,255 INFO Pytorch tensor shape detected: 128x1536 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:16,260 INFO Layer 574: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:16,263 INFO     Weight matrix 1/1 (128,1536): Analyzing ...\n",
      "2018-11-26 12:56:17,742 INFO     Weight matrix 1/1 (128,1536): Alpha: 6.120409643070594, Alpha Weighted: 1.0988566653330947, D: 0.07142857142857129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:17,746 INFO     Weight matrix 1/1 (128,1536): Alpha 6.120409643070594 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:17,761 INFO     Weight matrix 1/1 (128,1536): Lognorm: 0.7857402563095093\n",
      "2018-11-26 12:56:17,767 INFO Layer 575: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:17,772 INFO Layer 575: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:17,778 INFO Layer 576: ReLU(inplace)\n",
      "2018-11-26 12:56:17,782 INFO Layer 576: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:17,788 INFO Layer 577: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:17,792 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:17,795 INFO Layer 577: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:17,799 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:17,802 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:17,806 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:17,809 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:17,812 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:17,814 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:17,816 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:17,820 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:17,822 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:17,826 INFO Layer 578: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:17,832 INFO Layer 578: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:17,835 INFO Layer 579: BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:17,839 INFO Layer 579: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:17,845 INFO Layer 580: ReLU(inplace)\n",
      "2018-11-26 12:56:17,848 INFO Layer 580: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:17,851 INFO Layer 581: Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:17,855 INFO Pytorch tensor shape detected: 128x1568 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:17,857 INFO Layer 581: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:17,860 INFO     Weight matrix 1/1 (128,1568): Analyzing ...\n",
      "2018-11-26 12:56:19,325 INFO     Weight matrix 1/1 (128,1568): Alpha: 6.821124202164396, Alpha Weighted: 1.0316514633970493, D: 0.09839314513844899\n",
      "2018-11-26 12:56:19,328 INFO     Weight matrix 1/1 (128,1568): Alpha 6.821124202164396 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:19,332 INFO     Weight matrix 1/1 (128,1568): Lognorm: 0.7838059067726135\n",
      "2018-11-26 12:56:19,335 INFO Layer 582: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:19,338 INFO Layer 582: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:19,341 INFO Layer 583: ReLU(inplace)\n",
      "2018-11-26 12:56:19,344 INFO Layer 583: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:19,347 INFO Layer 584: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:19,351 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:19,354 INFO Layer 584: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:19,358 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:19,360 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:19,363 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:19,366 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:19,370 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:19,372 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:19,375 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:19,378 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:19,381 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:19,385 INFO Layer 585: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:19,388 INFO Layer 585: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:19,390 INFO Layer 586: BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:19,393 INFO Layer 586: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:19,396 INFO Layer 587: ReLU(inplace)\n",
      "2018-11-26 12:56:19,398 INFO Layer 587: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:19,401 INFO Layer 588: Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:19,405 INFO Pytorch tensor shape detected: 128x1600 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:19,408 INFO Layer 588: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:19,410 INFO     Weight matrix 1/1 (128,1600): Analyzing ...\n",
      "2018-11-26 12:56:20,760 INFO     Weight matrix 1/1 (128,1600): Alpha: 6.184561773224755, Alpha Weighted: 0.9565473698775306, D: 0.07692307692307676\n",
      "2018-11-26 12:56:20,762 INFO     Weight matrix 1/1 (128,1600): Alpha 6.184561773224755 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:20,767 INFO     Weight matrix 1/1 (128,1600): Lognorm: 0.7579707503318787\n",
      "2018-11-26 12:56:20,770 INFO Layer 589: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:20,774 INFO Layer 589: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:20,780 INFO Layer 590: ReLU(inplace)\n",
      "2018-11-26 12:56:20,783 INFO Layer 590: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:20,789 INFO Layer 591: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:20,793 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:20,799 INFO Layer 591: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:20,802 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:20,806 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:20,809 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:20,813 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:20,817 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:20,821 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:20,824 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:20,828 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:20,833 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:20,836 INFO Layer 592: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:20,840 INFO Layer 592: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:20,844 INFO Layer 593: BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:20,847 INFO Layer 593: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:20,851 INFO Layer 594: ReLU(inplace)\n",
      "2018-11-26 12:56:20,855 INFO Layer 594: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:20,858 INFO Layer 595: Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:20,863 INFO Pytorch tensor shape detected: 128x1632 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:20,866 INFO Layer 595: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:20,870 INFO     Weight matrix 1/1 (128,1632): Analyzing ...\n",
      "2018-11-26 12:56:22,155 INFO     Weight matrix 1/1 (128,1632): Alpha: 6.222120705592499, Alpha Weighted: 1.2686475424296686, D: 0.07723715044567628\n",
      "2018-11-26 12:56:22,157 INFO     Weight matrix 1/1 (128,1632): Alpha 6.222120705592499 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:22,161 INFO     Weight matrix 1/1 (128,1632): Lognorm: 0.8180046677589417\n",
      "2018-11-26 12:56:22,166 INFO Layer 596: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:22,169 INFO Layer 596: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:22,173 INFO Layer 597: ReLU(inplace)\n",
      "2018-11-26 12:56:22,176 INFO Layer 597: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:22,178 INFO Layer 598: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:22,182 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:22,184 INFO Layer 598: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:22,187 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:22,191 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:22,193 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:22,196 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:22,198 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:22,201 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:22,203 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:22,206 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:22,208 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:22,212 INFO Layer 599: BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:22,216 INFO Layer 599: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:22,219 INFO Layer 600: Linear(in_features=1664, out_features=1000, bias=True)\n",
      "2018-11-26 12:56:22,253 INFO Layer 600: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:22,256 INFO     Weight matrix 1/1 (1000,1664): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:56:22,259 INFO ### Printing results ###\n",
      "2018-11-26 12:56:22,262 DEBUG Layer 10: Lognorm: 0.6628804206848145\n",
      "2018-11-26 12:56:22,265 DEBUG Layer 17: Lognorm: 0.7082341909408569\n",
      "2018-11-26 12:56:22,268 DEBUG Layer 24: Lognorm: 0.6662705540657043\n",
      "2018-11-26 12:56:22,271 DEBUG Layer 31: Lognorm: 0.6788043975830078\n",
      "2018-11-26 12:56:22,275 DEBUG Layer 38: Lognorm: 0.6521271467208862\n",
      "2018-11-26 12:56:22,279 DEBUG Layer 45: Lognorm: 0.6803149580955505\n",
      "2018-11-26 12:56:22,283 DEBUG Layer 52: Lognorm: 0.9959068894386292\n",
      "2018-11-26 12:56:22,287 DEBUG Layer 58: Lognorm: 0.384185254573822\n",
      "2018-11-26 12:56:22,298 DEBUG Layer 65: Lognorm: 0.6056005358695984\n",
      "2018-11-26 12:56:22,303 DEBUG Layer 72: Lognorm: 0.5647442936897278\n",
      "2018-11-26 12:56:22,307 DEBUG Layer 79: Lognorm: 0.603904664516449\n",
      "2018-11-26 12:56:22,309 DEBUG Layer 86: Lognorm: 0.6348459720611572\n",
      "2018-11-26 12:56:22,313 DEBUG Layer 93: Lognorm: 0.6459779739379883\n",
      "2018-11-26 12:56:22,316 DEBUG Layer 100: Lognorm: 0.6464845538139343\n",
      "2018-11-26 12:56:22,323 DEBUG Layer 107: Lognorm: 0.6824978590011597\n",
      "2018-11-26 12:56:22,328 DEBUG Layer 114: Lognorm: 0.6937096118927002\n",
      "2018-11-26 12:56:22,331 DEBUG Layer 121: Lognorm: 0.7336108088493347\n",
      "2018-11-26 12:56:22,335 DEBUG Layer 128: Lognorm: 0.780185878276825\n",
      "2018-11-26 12:56:22,339 DEBUG Layer 135: Lognorm: 0.7551169991493225\n",
      "2018-11-26 12:56:22,343 DEBUG Layer 142: Lognorm: 1.1360725164413452\n",
      "2018-11-26 12:56:22,347 DEBUG Layer 148: Lognorm: 0.5364353656768799\n",
      "2018-11-26 12:56:22,350 DEBUG Layer 155: Lognorm: 0.5058788657188416\n",
      "2018-11-26 12:56:22,353 DEBUG Layer 162: Lognorm: 0.5342400670051575\n",
      "2018-11-26 12:56:22,355 DEBUG Layer 169: Lognorm: 0.5610538125038147\n",
      "2018-11-26 12:56:22,360 DEBUG Layer 176: Lognorm: 0.5786291360855103\n",
      "2018-11-26 12:56:22,364 DEBUG Layer 183: Lognorm: 0.5725449323654175\n",
      "2018-11-26 12:56:22,369 DEBUG Layer 190: Lognorm: 0.5461074709892273\n",
      "2018-11-26 12:56:22,372 DEBUG Layer 197: Lognorm: 0.6868124008178711\n",
      "2018-11-26 12:56:22,376 DEBUG Layer 204: Lognorm: 0.6185997724533081\n",
      "2018-11-26 12:56:22,382 DEBUG Layer 211: Lognorm: 0.6431679129600525\n",
      "2018-11-26 12:56:22,387 DEBUG Layer 218: Lognorm: 0.6612580418586731\n",
      "2018-11-26 12:56:22,389 DEBUG Layer 225: Lognorm: 0.6408177614212036\n",
      "2018-11-26 12:56:22,393 DEBUG Layer 232: Lognorm: 0.7037506699562073\n",
      "2018-11-26 12:56:22,396 DEBUG Layer 239: Lognorm: 0.6707753539085388\n",
      "2018-11-26 12:56:22,400 DEBUG Layer 246: Lognorm: 0.7297888398170471\n",
      "2018-11-26 12:56:22,403 DEBUG Layer 253: Lognorm: 0.7284191250801086\n",
      "2018-11-26 12:56:22,406 DEBUG Layer 260: Lognorm: 0.7068647742271423\n",
      "2018-11-26 12:56:22,409 DEBUG Layer 267: Lognorm: 0.6702701449394226\n",
      "2018-11-26 12:56:22,413 DEBUG Layer 274: Lognorm: 0.6986064910888672\n",
      "2018-11-26 12:56:22,415 DEBUG Layer 281: Lognorm: 0.773578941822052\n",
      "2018-11-26 12:56:22,420 DEBUG Layer 288: Lognorm: 0.7320337891578674\n",
      "2018-11-26 12:56:22,424 DEBUG Layer 295: Lognorm: 0.748719334602356\n",
      "2018-11-26 12:56:22,427 DEBUG Layer 302: Lognorm: 0.7782529592514038\n",
      "2018-11-26 12:56:22,430 DEBUG Layer 309: Lognorm: 0.7889545559883118\n",
      "2018-11-26 12:56:22,433 DEBUG Layer 316: Lognorm: 0.7701826691627502\n",
      "2018-11-26 12:56:22,436 DEBUG Layer 323: Lognorm: 0.7718908190727234\n",
      "2018-11-26 12:56:22,443 DEBUG Layer 330: Lognorm: 0.8019099235534668\n",
      "2018-11-26 12:56:22,445 DEBUG Layer 337: Lognorm: 0.7833647727966309\n",
      "2018-11-26 12:56:22,448 DEBUG Layer 344: Lognorm: 0.8105090260505676\n",
      "2018-11-26 12:56:22,450 DEBUG Layer 351: Lognorm: 0.8009234666824341\n",
      "2018-11-26 12:56:22,453 DEBUG Layer 358: Lognorm: 0.8085119128227234\n",
      "2018-11-26 12:56:22,457 DEBUG Layer 365: Lognorm: 0.8089067935943604\n",
      "2018-11-26 12:56:22,460 DEBUG Layer 378: Lognorm: 0.739496111869812\n",
      "2018-11-26 12:56:22,466 DEBUG Layer 385: Lognorm: 0.6991075277328491\n",
      "2018-11-26 12:56:22,475 DEBUG Layer 392: Lognorm: 0.7276461720466614\n",
      "2018-11-26 12:56:22,479 DEBUG Layer 399: Lognorm: 0.7221860885620117\n",
      "2018-11-26 12:56:22,484 DEBUG Layer 406: Lognorm: 0.7436009049415588\n",
      "2018-11-26 12:56:22,490 DEBUG Layer 413: Lognorm: 0.7478145956993103\n",
      "2018-11-26 12:56:22,494 DEBUG Layer 420: Lognorm: 0.7609472870826721\n",
      "2018-11-26 12:56:22,497 DEBUG Layer 427: Lognorm: 0.7696356177330017\n",
      "2018-11-26 12:56:22,500 DEBUG Layer 434: Lognorm: 0.7776841521263123\n",
      "2018-11-26 12:56:22,504 DEBUG Layer 441: Lognorm: 0.7810474038124084\n",
      "2018-11-26 12:56:22,507 DEBUG Layer 448: Lognorm: 0.7935295701026917\n",
      "2018-11-26 12:56:22,510 DEBUG Layer 455: Lognorm: 0.7822313904762268\n",
      "2018-11-26 12:56:22,514 DEBUG Layer 462: Lognorm: 0.8083719611167908\n",
      "2018-11-26 12:56:22,517 DEBUG Layer 469: Lognorm: 0.7893091440200806\n",
      "2018-11-26 12:56:22,521 DEBUG Layer 476: Lognorm: 0.7734553813934326\n",
      "2018-11-26 12:56:22,526 DEBUG Layer 483: Lognorm: 0.7729695439338684\n",
      "2018-11-26 12:56:22,530 DEBUG Layer 490: Lognorm: 0.7895529866218567\n",
      "2018-11-26 12:56:22,535 DEBUG Layer 497: Lognorm: 0.7633913159370422\n",
      "2018-11-26 12:56:22,539 DEBUG Layer 504: Lognorm: 0.7765175104141235\n",
      "2018-11-26 12:56:22,542 DEBUG Layer 511: Lognorm: 0.7685816287994385\n",
      "2018-11-26 12:56:22,545 DEBUG Layer 518: Lognorm: 0.7704346776008606\n",
      "2018-11-26 12:56:22,549 DEBUG Layer 525: Lognorm: 0.7728348970413208\n",
      "2018-11-26 12:56:22,552 DEBUG Layer 532: Lognorm: 0.7745780348777771\n",
      "2018-11-26 12:56:22,554 DEBUG Layer 539: Lognorm: 0.7745174765586853\n",
      "2018-11-26 12:56:22,556 DEBUG Layer 546: Lognorm: 0.7881466150283813\n",
      "2018-11-26 12:56:22,559 DEBUG Layer 553: Lognorm: 0.766076385974884\n",
      "2018-11-26 12:56:22,562 DEBUG Layer 560: Lognorm: 0.7647428512573242\n",
      "2018-11-26 12:56:22,565 DEBUG Layer 567: Lognorm: 0.7859439253807068\n",
      "2018-11-26 12:56:22,568 DEBUG Layer 574: Lognorm: 0.7857402563095093\n",
      "2018-11-26 12:56:22,571 DEBUG Layer 581: Lognorm: 0.7838059067726135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:22,574 DEBUG Layer 588: Lognorm: 0.7579707503318787\n",
      "2018-11-26 12:56:22,577 DEBUG Layer 595: Lognorm: 0.8180046677589417\n",
      "2018-11-26 12:56:22,583 INFO LogNorm: min: 0.384185254573822, max: 1.1360725164413452, avg: 0.7227750420570374\n",
      "2018-11-26 12:56:22,587 INFO LogNorm compound: min: 0.384185254573822, max: 1.1360725164413452, avg: 0.7227750966946284\n",
      "2018-11-26 12:56:22,590 DEBUG Layer 10: Alpha: 17.103577541465995\n",
      "2018-11-26 12:56:22,594 DEBUG Layer 17: Alpha: 2.5770547449291823\n",
      "2018-11-26 12:56:22,597 DEBUG Layer 24: Alpha: 13.92533794559396\n",
      "2018-11-26 12:56:22,601 DEBUG Layer 31: Alpha: 3.9763399815253497\n",
      "2018-11-26 12:56:22,605 DEBUG Layer 38: Alpha: 1.5424511829232852\n",
      "2018-11-26 12:56:22,608 DEBUG Layer 45: Alpha: 1.4873554350229614\n",
      "2018-11-26 12:56:22,612 DEBUG Layer 52: Alpha: 4.598715274857987\n",
      "2018-11-26 12:56:22,616 DEBUG Layer 58: Alpha: 1.9712193042565547\n",
      "2018-11-26 12:56:22,619 DEBUG Layer 65: Alpha: 1.9371152997133256\n",
      "2018-11-26 12:56:22,622 DEBUG Layer 72: Alpha: 2.291997430505141\n",
      "2018-11-26 12:56:22,626 DEBUG Layer 79: Alpha: 1.7220053448508905\n",
      "2018-11-26 12:56:22,630 DEBUG Layer 86: Alpha: 1.6464272811928575\n",
      "2018-11-26 12:56:22,633 DEBUG Layer 93: Alpha: 3.7824280637991103\n",
      "2018-11-26 12:56:22,638 DEBUG Layer 100: Alpha: 1.6903296572405917\n",
      "2018-11-26 12:56:22,642 DEBUG Layer 107: Alpha: 8.054599596017644\n",
      "2018-11-26 12:56:22,644 DEBUG Layer 114: Alpha: 1.6742162004816419\n",
      "2018-11-26 12:56:22,647 DEBUG Layer 121: Alpha: 2.3860073484654256\n",
      "2018-11-26 12:56:22,649 DEBUG Layer 128: Alpha: 2.1487801908422233\n",
      "2018-11-26 12:56:22,653 DEBUG Layer 135: Alpha: 2.109053590730394\n",
      "2018-11-26 12:56:22,656 DEBUG Layer 142: Alpha: 2.930404259481442\n",
      "2018-11-26 12:56:22,659 DEBUG Layer 148: Alpha: 2.370546853032188\n",
      "2018-11-26 12:56:22,664 DEBUG Layer 155: Alpha: 2.237817976337199\n",
      "2018-11-26 12:56:22,667 DEBUG Layer 162: Alpha: 2.1334286817035837\n",
      "2018-11-26 12:56:22,672 DEBUG Layer 169: Alpha: 4.631142116291371\n",
      "2018-11-26 12:56:22,675 DEBUG Layer 176: Alpha: 1.8324645180252213\n",
      "2018-11-26 12:56:22,678 DEBUG Layer 183: Alpha: 1.8128510924692096\n",
      "2018-11-26 12:56:22,681 DEBUG Layer 190: Alpha: 1.7344639556903467\n",
      "2018-11-26 12:56:22,684 DEBUG Layer 197: Alpha: 2.77118198862717\n",
      "2018-11-26 12:56:22,686 DEBUG Layer 204: Alpha: 1.7758665373130913\n",
      "2018-11-26 12:56:22,689 DEBUG Layer 211: Alpha: 2.1814484760652944\n",
      "2018-11-26 12:56:22,691 DEBUG Layer 218: Alpha: 5.139587084626642\n",
      "2018-11-26 12:56:22,694 DEBUG Layer 225: Alpha: 3.9001065377244726\n",
      "2018-11-26 12:56:22,697 DEBUG Layer 232: Alpha: 2.7682997796422084\n",
      "2018-11-26 12:56:22,699 DEBUG Layer 239: Alpha: 1.8649098205426444\n",
      "2018-11-26 12:56:22,702 DEBUG Layer 246: Alpha: 3.849618067722745\n",
      "2018-11-26 12:56:22,705 DEBUG Layer 253: Alpha: 3.91888744628046\n",
      "2018-11-26 12:56:22,708 DEBUG Layer 260: Alpha: 4.573183163100828\n",
      "2018-11-26 12:56:22,711 DEBUG Layer 267: Alpha: 4.496461274862021\n",
      "2018-11-26 12:56:22,715 DEBUG Layer 274: Alpha: 2.377113316388721\n",
      "2018-11-26 12:56:22,717 DEBUG Layer 281: Alpha: 3.3235660068940804\n",
      "2018-11-26 12:56:22,720 DEBUG Layer 288: Alpha: 3.5660532001570937\n",
      "2018-11-26 12:56:22,723 DEBUG Layer 295: Alpha: 3.0088890263357095\n",
      "2018-11-26 12:56:22,725 DEBUG Layer 302: Alpha: 4.546142259618181\n",
      "2018-11-26 12:56:22,730 DEBUG Layer 309: Alpha: 2.2651019171568993\n",
      "2018-11-26 12:56:22,733 DEBUG Layer 316: Alpha: 3.1643338858880683\n",
      "2018-11-26 12:56:22,736 DEBUG Layer 323: Alpha: 3.787828819460362\n",
      "2018-11-26 12:56:22,739 DEBUG Layer 330: Alpha: 2.9537739049687133\n",
      "2018-11-26 12:56:22,742 DEBUG Layer 337: Alpha: 5.620526974227303\n",
      "2018-11-26 12:56:22,746 DEBUG Layer 344: Alpha: 5.2220533783932135\n",
      "2018-11-26 12:56:22,749 DEBUG Layer 351: Alpha: 2.662632585983574\n",
      "2018-11-26 12:56:22,754 DEBUG Layer 358: Alpha: 2.4890896159198523\n",
      "2018-11-26 12:56:22,759 DEBUG Layer 365: Alpha: 6.6501287828896\n",
      "2018-11-26 12:56:22,763 DEBUG Layer 378: Alpha: 5.576862638712635\n",
      "2018-11-26 12:56:22,766 DEBUG Layer 385: Alpha: 3.1695034044766\n",
      "2018-11-26 12:56:22,771 DEBUG Layer 392: Alpha: 3.954030150296511\n",
      "2018-11-26 12:56:22,774 DEBUG Layer 399: Alpha: 5.8970533753497\n",
      "2018-11-26 12:56:22,777 DEBUG Layer 406: Alpha: 2.553047680007487\n",
      "2018-11-26 12:56:22,781 DEBUG Layer 413: Alpha: 2.318132044392585\n",
      "2018-11-26 12:56:22,784 DEBUG Layer 420: Alpha: 5.251685003689215\n",
      "2018-11-26 12:56:22,788 DEBUG Layer 427: Alpha: 5.620612197900111\n",
      "2018-11-26 12:56:22,793 DEBUG Layer 434: Alpha: 5.024479294679638\n",
      "2018-11-26 12:56:22,796 DEBUG Layer 441: Alpha: 5.265628891024189\n",
      "2018-11-26 12:56:22,799 DEBUG Layer 448: Alpha: 6.274368980969305\n",
      "2018-11-26 12:56:22,802 DEBUG Layer 455: Alpha: 5.901525643862882\n",
      "2018-11-26 12:56:22,806 DEBUG Layer 462: Alpha: 5.2015988484870155\n",
      "2018-11-26 12:56:22,810 DEBUG Layer 469: Alpha: 4.801889880619714\n",
      "2018-11-26 12:56:22,813 DEBUG Layer 476: Alpha: 5.4384505767453435\n",
      "2018-11-26 12:56:22,816 DEBUG Layer 483: Alpha: 6.687288648287833\n",
      "2018-11-26 12:56:22,820 DEBUG Layer 490: Alpha: 4.746577580267603\n",
      "2018-11-26 12:56:22,823 DEBUG Layer 497: Alpha: 5.767821478832888\n",
      "2018-11-26 12:56:22,826 DEBUG Layer 504: Alpha: 6.117059992623959\n",
      "2018-11-26 12:56:22,829 DEBUG Layer 511: Alpha: 6.374530963840121\n",
      "2018-11-26 12:56:22,831 DEBUG Layer 518: Alpha: 5.37342772196484\n",
      "2018-11-26 12:56:22,835 DEBUG Layer 525: Alpha: 5.944022077178415\n",
      "2018-11-26 12:56:22,837 DEBUG Layer 532: Alpha: 6.019460606000521\n",
      "2018-11-26 12:56:22,840 DEBUG Layer 539: Alpha: 6.059853838577711\n",
      "2018-11-26 12:56:22,843 DEBUG Layer 546: Alpha: 6.205969898510956\n",
      "2018-11-26 12:56:22,845 DEBUG Layer 553: Alpha: 6.11444232053226\n",
      "2018-11-26 12:56:22,848 DEBUG Layer 560: Alpha: 5.746970288496086\n",
      "2018-11-26 12:56:22,851 DEBUG Layer 567: Alpha: 6.077917878785389\n",
      "2018-11-26 12:56:22,854 DEBUG Layer 574: Alpha: 6.120409643070594\n",
      "2018-11-26 12:56:22,857 DEBUG Layer 581: Alpha: 6.821124202164396\n",
      "2018-11-26 12:56:22,859 DEBUG Layer 588: Alpha: 6.184561773224755\n",
      "2018-11-26 12:56:22,862 DEBUG Layer 595: Alpha: 6.222120705592499\n",
      "2018-11-26 12:56:22,866 INFO Alpha: min: 1.4873554350229614, max: 17.103577541465995, avg: 4.285920749373783\n",
      "2018-11-26 12:56:22,869 INFO Alpha compound: min: 1.4873554350229614, max: 17.103577541465995, avg: 4.285920749373783\n",
      "2018-11-26 12:56:22,873 DEBUG Layer 10: Alpha Weigthed: 4.0523294356593516\n",
      "2018-11-26 12:56:22,875 DEBUG Layer 17: Alpha Weigthed: 0.8674491604046812\n",
      "2018-11-26 12:56:22,878 DEBUG Layer 24: Alpha Weigthed: 2.370643720226937\n",
      "2018-11-26 12:56:22,882 DEBUG Layer 31: Alpha Weigthed: 0.6322501222086847\n",
      "2018-11-26 12:56:22,884 DEBUG Layer 38: Alpha Weigthed: 0.16623169301817434\n",
      "2018-11-26 12:56:22,889 DEBUG Layer 45: Alpha Weigthed: 0.28358131469354203\n",
      "2018-11-26 12:56:22,891 DEBUG Layer 52: Alpha Weigthed: 3.4545075877594966\n",
      "2018-11-26 12:56:22,894 DEBUG Layer 58: Alpha Weigthed: -0.19721177208001575\n",
      "2018-11-26 12:56:22,896 DEBUG Layer 65: Alpha Weigthed: 0.05932468760761852\n",
      "2018-11-26 12:56:22,899 DEBUG Layer 72: Alpha Weigthed: -0.09743981021976622\n",
      "2018-11-26 12:56:22,902 DEBUG Layer 79: Alpha Weigthed: -0.0770388029273832\n",
      "2018-11-26 12:56:22,905 DEBUG Layer 86: Alpha Weigthed: -0.022197763931461834\n",
      "2018-11-26 12:56:22,909 DEBUG Layer 93: Alpha Weigthed: 0.2663167799720304\n",
      "2018-11-26 12:56:22,912 DEBUG Layer 100: Alpha Weigthed: -0.011966826172071057\n",
      "2018-11-26 12:56:22,915 DEBUG Layer 107: Alpha Weigthed: 1.0135056634346233\n",
      "2018-11-26 12:56:22,919 DEBUG Layer 114: Alpha Weigthed: 0.4466364524337585\n",
      "2018-11-26 12:56:22,925 DEBUG Layer 121: Alpha Weigthed: 0.43304402087389215\n",
      "2018-11-26 12:56:22,928 DEBUG Layer 128: Alpha Weigthed: 0.693710478854593\n",
      "2018-11-26 12:56:22,931 DEBUG Layer 135: Alpha Weigthed: 0.35002852563181314\n",
      "2018-11-26 12:56:22,936 DEBUG Layer 142: Alpha Weigthed: 1.5519769252807962\n",
      "2018-11-26 12:56:22,939 DEBUG Layer 148: Alpha Weigthed: -0.26177928228183267\n",
      "2018-11-26 12:56:22,941 DEBUG Layer 155: Alpha Weigthed: -0.3042498589335454\n",
      "2018-11-26 12:56:22,943 DEBUG Layer 162: Alpha Weigthed: -0.3658363129775079\n",
      "2018-11-26 12:56:22,946 DEBUG Layer 169: Alpha Weigthed: -0.16362688300048991\n",
      "2018-11-26 12:56:22,950 DEBUG Layer 176: Alpha Weigthed: -0.24409468593629502\n",
      "2018-11-26 12:56:22,952 DEBUG Layer 183: Alpha Weigthed: -0.2032502777195054\n",
      "2018-11-26 12:56:22,956 DEBUG Layer 190: Alpha Weigthed: -0.09099536776729306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:22,959 DEBUG Layer 197: Alpha Weigthed: 0.9319157582881287\n",
      "2018-11-26 12:56:22,963 DEBUG Layer 204: Alpha Weigthed: -0.2284501899832328\n",
      "2018-11-26 12:56:22,968 DEBUG Layer 211: Alpha Weigthed: -0.13552175759341295\n",
      "2018-11-26 12:56:22,971 DEBUG Layer 218: Alpha Weigthed: -0.40373966518121546\n",
      "2018-11-26 12:56:22,974 DEBUG Layer 225: Alpha Weigthed: -0.28090291094244824\n",
      "2018-11-26 12:56:22,977 DEBUG Layer 232: Alpha Weigthed: 0.052118219660074266\n",
      "2018-11-26 12:56:22,980 DEBUG Layer 239: Alpha Weigthed: -0.04985549191352576\n",
      "2018-11-26 12:56:22,983 DEBUG Layer 246: Alpha Weigthed: 0.4107771194073228\n",
      "2018-11-26 12:56:22,985 DEBUG Layer 253: Alpha Weigthed: 0.38408383662447926\n",
      "2018-11-26 12:56:22,987 DEBUG Layer 260: Alpha Weigthed: 0.7787243983248218\n",
      "2018-11-26 12:56:22,990 DEBUG Layer 267: Alpha Weigthed: -0.19570798749494742\n",
      "2018-11-26 12:56:22,993 DEBUG Layer 274: Alpha Weigthed: 0.18669310714933413\n",
      "2018-11-26 12:56:22,995 DEBUG Layer 281: Alpha Weigthed: 0.6615994264110525\n",
      "2018-11-26 12:56:22,998 DEBUG Layer 288: Alpha Weigthed: 0.2805621116240357\n",
      "2018-11-26 12:56:23,001 DEBUG Layer 295: Alpha Weigthed: 0.16619307762261698\n",
      "2018-11-26 12:56:23,003 DEBUG Layer 302: Alpha Weigthed: 0.7973839533217886\n",
      "2018-11-26 12:56:23,006 DEBUG Layer 309: Alpha Weigthed: 0.5139195855845606\n",
      "2018-11-26 12:56:23,008 DEBUG Layer 316: Alpha Weigthed: 0.29748148974096456\n",
      "2018-11-26 12:56:23,011 DEBUG Layer 323: Alpha Weigthed: 0.357817004593928\n",
      "2018-11-26 12:56:23,014 DEBUG Layer 330: Alpha Weigthed: 0.5365945292544382\n",
      "2018-11-26 12:56:23,016 DEBUG Layer 337: Alpha Weigthed: 0.5060469459464658\n",
      "2018-11-26 12:56:23,019 DEBUG Layer 344: Alpha Weigthed: 1.3639966636082295\n",
      "2018-11-26 12:56:23,022 DEBUG Layer 351: Alpha Weigthed: 0.680148413712937\n",
      "2018-11-26 12:56:23,024 DEBUG Layer 358: Alpha Weigthed: 0.6251885195587166\n",
      "2018-11-26 12:56:23,027 DEBUG Layer 365: Alpha Weigthed: 1.4605934698852678\n",
      "2018-11-26 12:56:23,031 DEBUG Layer 378: Alpha Weigthed: 0.2596385757927139\n",
      "2018-11-26 12:56:23,033 DEBUG Layer 385: Alpha Weigthed: -0.018888748816430705\n",
      "2018-11-26 12:56:23,036 DEBUG Layer 392: Alpha Weigthed: 0.23067528341581398\n",
      "2018-11-26 12:56:23,039 DEBUG Layer 399: Alpha Weigthed: -0.1145734112224207\n",
      "2018-11-26 12:56:23,042 DEBUG Layer 406: Alpha Weigthed: 0.3239665392690146\n",
      "2018-11-26 12:56:23,045 DEBUG Layer 413: Alpha Weigthed: 0.1945933806671906\n",
      "2018-11-26 12:56:23,048 DEBUG Layer 420: Alpha Weigthed: 0.00311210283937652\n",
      "2018-11-26 12:56:23,051 DEBUG Layer 427: Alpha Weigthed: 0.4650241255345615\n",
      "2018-11-26 12:56:23,054 DEBUG Layer 434: Alpha Weigthed: 0.5807368038528061\n",
      "2018-11-26 12:56:23,056 DEBUG Layer 441: Alpha Weigthed: 0.6968058518813457\n",
      "2018-11-26 12:56:23,059 DEBUG Layer 448: Alpha Weigthed: 0.958617704324638\n",
      "2018-11-26 12:56:23,061 DEBUG Layer 455: Alpha Weigthed: 0.6385142443841765\n",
      "2018-11-26 12:56:23,064 DEBUG Layer 462: Alpha Weigthed: 1.2021673548369314\n",
      "2018-11-26 12:56:23,066 DEBUG Layer 469: Alpha Weigthed: 0.6390876235423372\n",
      "2018-11-26 12:56:23,070 DEBUG Layer 476: Alpha Weigthed: 0.4284860884163996\n",
      "2018-11-26 12:56:23,073 DEBUG Layer 483: Alpha Weigthed: 0.6184760044737043\n",
      "2018-11-26 12:56:23,076 DEBUG Layer 490: Alpha Weigthed: 1.0612107587824118\n",
      "2018-11-26 12:56:23,078 DEBUG Layer 497: Alpha Weigthed: 0.7663555057280247\n",
      "2018-11-26 12:56:23,081 DEBUG Layer 504: Alpha Weigthed: 0.892883650050567\n",
      "2018-11-26 12:56:23,083 DEBUG Layer 511: Alpha Weigthed: 1.0196932558964709\n",
      "2018-11-26 12:56:23,087 DEBUG Layer 518: Alpha Weigthed: 0.8523937178697979\n",
      "2018-11-26 12:56:23,090 DEBUG Layer 525: Alpha Weigthed: 0.8246195234677595\n",
      "2018-11-26 12:56:23,093 DEBUG Layer 532: Alpha Weigthed: 0.9370589530711309\n",
      "2018-11-26 12:56:23,098 DEBUG Layer 539: Alpha Weigthed: 0.9501155630369605\n",
      "2018-11-26 12:56:23,103 DEBUG Layer 546: Alpha Weigthed: 1.273347865795932\n",
      "2018-11-26 12:56:23,106 DEBUG Layer 553: Alpha Weigthed: 0.8546578864160052\n",
      "2018-11-26 12:56:23,108 DEBUG Layer 560: Alpha Weigthed: 0.7676605045497156\n",
      "2018-11-26 12:56:23,112 DEBUG Layer 567: Alpha Weigthed: 1.0356239139952625\n",
      "2018-11-26 12:56:23,116 DEBUG Layer 574: Alpha Weigthed: 1.0988566653330947\n",
      "2018-11-26 12:56:23,121 DEBUG Layer 581: Alpha Weigthed: 1.0316514633970493\n",
      "2018-11-26 12:56:23,124 DEBUG Layer 588: Alpha Weigthed: 0.9565473698775306\n",
      "2018-11-26 12:56:23,129 DEBUG Layer 595: Alpha Weigthed: 1.2686475424296686\n",
      "2018-11-26 12:56:23,133 INFO Alpha Weighted: min: -0.40373966518121546, max: 4.0523294356593516, avg: 0.559491335883485\n",
      "2018-11-26 12:56:23,137 INFO Alpha Weighted compound: min: -0.40373966518121546, max: 4.0523294356593516, avg: 0.559491335883485\n",
      "/Users/charlesmartin14/anaconda3/envs/py3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "2018-11-26 12:56:26,847 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 12:56:26,850 INFO Analyzing model\n",
      "2018-11-26 12:56:26,888 INFO Layer 0: DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer25): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer26): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer27): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer28): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer29): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer30): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer31): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer32): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer33): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer34): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer35): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer36): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer37): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer38): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer39): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer40): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer41): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer42): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer43): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer44): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer45): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer46): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer47): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer48): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer25): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer26): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer27): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer28): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer29): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer30): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer31): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer32): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1920, out_features=1000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:26,899 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:26,937 INFO Layer 1: Sequential(\n",
      "  (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu0): ReLU(inplace)\n",
      "  (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (denseblock1): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition1): _Transition(\n",
      "    (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock2): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition2): _Transition(\n",
      "    (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock3): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer13): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer14): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer15): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer16): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer17): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer18): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer19): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer20): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer21): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer22): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer23): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer24): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer25): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer26): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer27): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer28): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer29): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer30): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer31): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer32): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer33): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer34): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer35): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer36): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer37): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer38): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer39): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer40): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer41): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer42): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer43): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer44): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer45): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer46): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer47): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer48): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (transition3): _Transition(\n",
      "    (norm): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (denseblock4): _DenseBlock(\n",
      "    (denselayer1): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer2): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer3): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer4): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer5): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer6): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer7): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer8): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer9): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer10): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer11): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer12): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer13): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer14): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer15): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer16): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer17): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer18): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer19): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer20): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer21): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer22): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer23): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer24): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer25): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer26): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer27): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer28): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer29): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer30): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer31): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (denselayer32): _DenseLayer(\n",
      "      (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace)\n",
      "      (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (norm5): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:26,942 INFO Layer 1: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:26,946 INFO Layer 2: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "2018-11-26 12:56:26,949 INFO Pytorch tensor shape detected: 64x3 (NxM), 7x7 (i,j)\n",
      "2018-11-26 12:56:26,952 INFO Layer 2: Analyzing 49 weight matrices...\n",
      "2018-11-26 12:56:26,956 INFO     Weight matrix 1/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:26,960 INFO     Weight matrix 2/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:26,967 INFO     Weight matrix 3/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:26,971 INFO     Weight matrix 4/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:26,984 INFO     Weight matrix 5/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:26,987 INFO     Weight matrix 6/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:26,990 INFO     Weight matrix 7/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:26,993 INFO     Weight matrix 8/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:26,997 INFO     Weight matrix 9/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,002 INFO     Weight matrix 10/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,005 INFO     Weight matrix 11/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,009 INFO     Weight matrix 12/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,012 INFO     Weight matrix 13/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,015 INFO     Weight matrix 14/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,018 INFO     Weight matrix 15/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,022 INFO     Weight matrix 16/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,024 INFO     Weight matrix 17/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,028 INFO     Weight matrix 18/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,032 INFO     Weight matrix 19/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,036 INFO     Weight matrix 20/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,040 INFO     Weight matrix 21/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,043 INFO     Weight matrix 22/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,047 INFO     Weight matrix 23/49 (3,64): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:27,052 INFO     Weight matrix 24/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,057 INFO     Weight matrix 25/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,064 INFO     Weight matrix 26/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,078 INFO     Weight matrix 27/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,085 INFO     Weight matrix 28/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,089 INFO     Weight matrix 29/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,094 INFO     Weight matrix 30/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,098 INFO     Weight matrix 31/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,106 INFO     Weight matrix 32/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,109 INFO     Weight matrix 33/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,113 INFO     Weight matrix 34/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,117 INFO     Weight matrix 35/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,122 INFO     Weight matrix 36/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,126 INFO     Weight matrix 37/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,133 INFO     Weight matrix 38/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,137 INFO     Weight matrix 39/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,142 INFO     Weight matrix 40/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,146 INFO     Weight matrix 41/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,149 INFO     Weight matrix 42/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,154 INFO     Weight matrix 43/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,158 INFO     Weight matrix 44/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,162 INFO     Weight matrix 45/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,165 INFO     Weight matrix 46/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,171 INFO     Weight matrix 47/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,178 INFO     Weight matrix 48/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,181 INFO     Weight matrix 49/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:56:27,185 INFO Layer 3: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:27,188 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:27,191 INFO Layer 4: ReLU(inplace)\n",
      "2018-11-26 12:56:27,194 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:27,197 INFO Layer 5: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:56:27,200 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:27,206 INFO Layer 6: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:56:27,209 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:27,213 INFO Layer 7: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:27,217 INFO Layer 7: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:27,221 INFO Layer 8: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:27,224 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:27,227 INFO Layer 9: ReLU(inplace)\n",
      "2018-11-26 12:56:27,232 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:27,236 INFO Layer 10: Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:27,239 INFO Pytorch tensor shape detected: 128x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:27,244 INFO Layer 10: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:27,248 INFO     Weight matrix 1/1 (64,128): Analyzing ...\n",
      "2018-11-26 12:56:28,042 INFO     Weight matrix 1/1 (64,128): Alpha: 2.5829017726958545, Alpha Weighted: 0.7117965808304216, D: 0.2016111660120573\n",
      "2018-11-26 12:56:28,045 INFO     Weight matrix 1/1 (64,128): Lognorm: 0.6749588251113892\n",
      "2018-11-26 12:56:28,048 INFO Layer 11: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:28,052 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:28,054 INFO Layer 12: ReLU(inplace)\n",
      "2018-11-26 12:56:28,056 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:28,059 INFO Layer 13: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:28,063 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:28,067 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:28,072 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:28,074 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:28,078 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:28,085 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:28,088 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:28,091 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:28,094 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:28,097 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:28,102 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:28,106 INFO Layer 14: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:28,109 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:28,112 INFO Layer 15: BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:28,116 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:28,119 INFO Layer 16: ReLU(inplace)\n",
      "2018-11-26 12:56:28,123 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:28,126 INFO Layer 17: Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:28,130 INFO Pytorch tensor shape detected: 128x96 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:28,132 INFO Layer 17: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:28,136 INFO     Weight matrix 1/1 (96,128): Analyzing ...\n",
      "2018-11-26 12:56:29,298 INFO     Weight matrix 1/1 (96,128): Alpha: 1.8080375574947736, Alpha Weighted: 0.5953473001441335, D: 0.20567635262836947\n",
      "2018-11-26 12:56:29,301 INFO     Weight matrix 1/1 (96,128): Lognorm: 0.695601224899292\n",
      "2018-11-26 12:56:29,303 INFO Layer 18: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:29,308 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:29,310 INFO Layer 19: ReLU(inplace)\n",
      "2018-11-26 12:56:29,312 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:29,315 INFO Layer 20: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:29,318 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:29,325 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:29,327 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:29,330 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:29,333 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:29,335 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:29,339 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:29,343 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:29,346 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:29,349 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:29,353 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:29,356 INFO Layer 21: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:29,359 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:29,361 INFO Layer 22: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:29,365 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:29,368 INFO Layer 23: ReLU(inplace)\n",
      "2018-11-26 12:56:29,373 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:29,376 INFO Layer 24: Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:29,381 INFO Pytorch tensor shape detected: 128x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:29,384 INFO Layer 24: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:29,387 INFO     Weight matrix 1/1 (128,128): Analyzing ...\n",
      "2018-11-26 12:56:30,698 INFO     Weight matrix 1/1 (128,128): Alpha: 3.157632327704465, Alpha Weighted: 0.9838929180738292, D: 0.12841039223377293\n",
      "2018-11-26 12:56:30,701 INFO     Weight matrix 1/1 (128,128): Lognorm: 0.681190013885498\n",
      "2018-11-26 12:56:30,704 INFO Layer 25: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:30,706 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:30,708 INFO Layer 26: ReLU(inplace)\n",
      "2018-11-26 12:56:30,711 INFO Layer 26: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:30,715 INFO Layer 27: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:30,718 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:30,721 INFO Layer 27: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:30,724 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:30,728 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:30,731 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:30,736 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:30,740 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:30,743 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:30,747 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:30,750 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:30,753 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:30,758 INFO Layer 28: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:30,761 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:30,765 INFO Layer 29: BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:30,769 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:30,773 INFO Layer 30: ReLU(inplace)\n",
      "2018-11-26 12:56:30,775 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:30,778 INFO Layer 31: Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:30,783 INFO Pytorch tensor shape detected: 128x160 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:30,786 INFO Layer 31: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:30,790 INFO     Weight matrix 1/1 (128,160): Analyzing ...\n",
      "2018-11-26 12:56:32,255 INFO     Weight matrix 1/1 (128,160): Alpha: 5.399741104735045, Alpha Weighted: 1.1562916982824438, D: 0.19135518675122964\n",
      "2018-11-26 12:56:32,259 INFO     Weight matrix 1/1 (128,160): Alpha 5.399741104735045 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:32,261 INFO     Weight matrix 1/1 (128,160): Lognorm: 0.6703627109527588\n",
      "2018-11-26 12:56:32,264 INFO Layer 32: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:32,267 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:32,271 INFO Layer 33: ReLU(inplace)\n",
      "2018-11-26 12:56:32,275 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:32,278 INFO Layer 34: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:32,283 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:32,286 INFO Layer 34: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:32,290 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:32,293 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:32,296 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:32,299 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:32,302 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:32,306 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:32,310 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:32,313 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:32,316 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:32,319 INFO Layer 35: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:32,322 INFO Layer 35: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:32,328 INFO Layer 36: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:32,334 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:32,337 INFO Layer 37: ReLU(inplace)\n",
      "2018-11-26 12:56:32,341 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:32,344 INFO Layer 38: Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:32,348 INFO Pytorch tensor shape detected: 128x192 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:32,350 INFO Layer 38: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:32,355 INFO     Weight matrix 1/1 (128,192): Analyzing ...\n",
      "2018-11-26 12:56:33,891 INFO     Weight matrix 1/1 (128,192): Alpha: 1.6222642558442866, Alpha Weighted: 0.15717790017423475, D: 0.18939786691753502\n",
      "2018-11-26 12:56:33,894 INFO     Weight matrix 1/1 (128,192): Lognorm: 0.6274871230125427\n",
      "2018-11-26 12:56:33,898 INFO Layer 39: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:33,904 INFO Layer 39: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:33,908 INFO Layer 40: ReLU(inplace)\n",
      "2018-11-26 12:56:33,911 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:33,915 INFO Layer 41: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:33,925 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:33,932 INFO Layer 41: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:33,937 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:33,942 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:33,948 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:33,952 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:33,959 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:33,963 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:33,971 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:33,976 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:33,980 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:33,985 INFO Layer 42: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:33,991 INFO Layer 42: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:33,994 INFO Layer 43: BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:33,997 INFO Layer 43: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:34,001 INFO Layer 44: ReLU(inplace)\n",
      "2018-11-26 12:56:34,003 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:34,007 INFO Layer 45: Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:34,016 INFO Pytorch tensor shape detected: 128x224 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:34,020 INFO Layer 45: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:34,025 INFO     Weight matrix 1/1 (128,224): Analyzing ...\n",
      "2018-11-26 12:56:35,324 INFO     Weight matrix 1/1 (128,224): Alpha: 1.5521604079296467, Alpha Weighted: 0.311997502677867, D: 0.18545798638327998\n",
      "2018-11-26 12:56:35,328 INFO     Weight matrix 1/1 (128,224): Lognorm: 0.7079291343688965\n",
      "2018-11-26 12:56:35,331 INFO Layer 46: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:35,335 INFO Layer 46: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:35,339 INFO Layer 47: ReLU(inplace)\n",
      "2018-11-26 12:56:35,342 INFO Layer 47: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:35,344 INFO Layer 48: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:35,349 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:35,352 INFO Layer 48: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:35,357 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:35,359 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:35,362 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:35,365 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:35,369 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:35,373 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:35,377 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:35,381 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:35,385 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:35,389 INFO Layer 49: _Transition(\n",
      "  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "2018-11-26 12:56:35,391 INFO Layer 49: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:35,396 INFO Layer 50: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:35,399 INFO Layer 50: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:35,402 INFO Layer 51: ReLU(inplace)\n",
      "2018-11-26 12:56:35,404 INFO Layer 51: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:35,408 INFO Layer 52: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:35,411 INFO Pytorch tensor shape detected: 128x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:35,414 INFO Layer 52: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:35,417 INFO     Weight matrix 1/1 (128,256): Analyzing ...\n",
      "2018-11-26 12:56:36,701 INFO     Weight matrix 1/1 (128,256): Alpha: 4.431730352382717, Alpha Weighted: 3.608953501171657, D: 0.0970281980193004\n",
      "2018-11-26 12:56:36,704 INFO     Weight matrix 1/1 (128,256): Alpha 4.431730352382717 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:36,707 INFO     Weight matrix 1/1 (128,256): Lognorm: 1.0040216445922852\n",
      "2018-11-26 12:56:36,710 INFO Layer 53: AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "2018-11-26 12:56:36,714 INFO Layer 53: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:36,720 INFO Layer 54: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer7): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer8): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer9): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer10): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer11): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer12): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:36,723 INFO Layer 54: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:36,727 INFO Layer 55: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:36,733 INFO Layer 55: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:36,736 INFO Layer 56: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:36,741 INFO Layer 56: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:36,744 INFO Layer 57: ReLU(inplace)\n",
      "2018-11-26 12:56:36,747 INFO Layer 57: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:36,750 INFO Layer 58: Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:36,754 INFO Pytorch tensor shape detected: 128x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:36,757 INFO Layer 58: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:36,760 INFO     Weight matrix 1/1 (128,128): Analyzing ...\n",
      "2018-11-26 12:56:38,079 INFO     Weight matrix 1/1 (128,128): Alpha: 1.586015608967225, Alpha Weighted: -0.13864186531935546, D: 0.20391046895542392\n",
      "2018-11-26 12:56:38,083 INFO     Weight matrix 1/1 (128,128): Lognorm: 0.49563485383987427\n",
      "2018-11-26 12:56:38,086 INFO Layer 59: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:38,090 INFO Layer 59: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:38,093 INFO Layer 60: ReLU(inplace)\n",
      "2018-11-26 12:56:38,097 INFO Layer 60: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:38,100 INFO Layer 61: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:38,104 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:38,107 INFO Layer 61: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:38,111 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:38,116 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:38,123 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:38,127 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:38,131 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:38,134 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:38,139 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:38,143 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:38,146 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:38,149 INFO Layer 62: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:38,152 INFO Layer 62: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:38,155 INFO Layer 63: BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:38,158 INFO Layer 63: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:38,161 INFO Layer 64: ReLU(inplace)\n",
      "2018-11-26 12:56:38,165 INFO Layer 64: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:38,170 INFO Layer 65: Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:38,174 INFO Pytorch tensor shape detected: 128x160 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:38,177 INFO Layer 65: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:38,182 INFO     Weight matrix 1/1 (128,160): Analyzing ...\n",
      "2018-11-26 12:56:39,531 INFO     Weight matrix 1/1 (128,160): Alpha: 1.5951542118451156, Alpha Weighted: 0.027189199433767464, D: 0.1900124066841103\n",
      "2018-11-26 12:56:39,535 INFO     Weight matrix 1/1 (128,160): Lognorm: 0.41292110085487366\n",
      "2018-11-26 12:56:39,539 INFO Layer 66: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:39,543 INFO Layer 66: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:39,546 INFO Layer 67: ReLU(inplace)\n",
      "2018-11-26 12:56:39,550 INFO Layer 67: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:39,554 INFO Layer 68: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:39,558 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:39,561 INFO Layer 68: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:39,564 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:39,567 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:39,572 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:39,576 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:39,582 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:39,584 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:39,589 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:39,592 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:39,596 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:39,599 INFO Layer 69: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:39,602 INFO Layer 69: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:39,605 INFO Layer 70: BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:39,609 INFO Layer 70: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:39,612 INFO Layer 71: ReLU(inplace)\n",
      "2018-11-26 12:56:39,615 INFO Layer 71: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:39,619 INFO Layer 72: Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:39,624 INFO Pytorch tensor shape detected: 128x192 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:39,630 INFO Layer 72: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:39,635 INFO     Weight matrix 1/1 (128,192): Analyzing ...\n",
      "2018-11-26 12:56:41,052 INFO     Weight matrix 1/1 (128,192): Alpha: 3.705744796635297, Alpha Weighted: 0.22362586735112147, D: 0.13490667428916703\n",
      "2018-11-26 12:56:41,055 INFO     Weight matrix 1/1 (128,192): Alpha 3.705744796635297 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:41,059 INFO     Weight matrix 1/1 (128,192): Lognorm: 0.5833907127380371\n",
      "2018-11-26 12:56:41,063 INFO Layer 73: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:41,066 INFO Layer 73: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:41,069 INFO Layer 74: ReLU(inplace)\n",
      "2018-11-26 12:56:41,072 INFO Layer 74: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:41,076 INFO Layer 75: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:41,080 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:41,083 INFO Layer 75: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:41,088 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:41,091 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:41,095 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:41,098 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:41,101 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:41,104 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:41,107 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:41,110 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:41,114 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:41,118 INFO Layer 76: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:41,122 INFO Layer 76: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:41,124 INFO Layer 77: BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:41,127 INFO Layer 77: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:41,130 INFO Layer 78: ReLU(inplace)\n",
      "2018-11-26 12:56:41,133 INFO Layer 78: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:41,138 INFO Layer 79: Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:41,142 INFO Pytorch tensor shape detected: 128x224 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:41,145 INFO Layer 79: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:41,149 INFO     Weight matrix 1/1 (128,224): Analyzing ...\n",
      "2018-11-26 12:56:42,543 INFO     Weight matrix 1/1 (128,224): Alpha: 3.781191463840778, Alpha Weighted: 0.07791293519080601, D: 0.13174273897744504\n",
      "2018-11-26 12:56:42,545 INFO     Weight matrix 1/1 (128,224): Alpha 3.781191463840778 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:42,550 INFO     Weight matrix 1/1 (128,224): Lognorm: 0.6160895824432373\n",
      "2018-11-26 12:56:42,554 INFO Layer 80: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:42,557 INFO Layer 80: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:42,560 INFO Layer 81: ReLU(inplace)\n",
      "2018-11-26 12:56:42,564 INFO Layer 81: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:42,566 INFO Layer 82: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:42,570 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:42,576 INFO Layer 82: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:42,579 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:42,588 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:42,592 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:42,595 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:42,599 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:42,602 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:42,606 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:42,610 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:42,613 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:42,617 INFO Layer 83: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:42,623 INFO Layer 83: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:42,627 INFO Layer 84: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:42,631 INFO Layer 84: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:42,634 INFO Layer 85: ReLU(inplace)\n",
      "2018-11-26 12:56:42,636 INFO Layer 85: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:42,639 INFO Layer 86: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:42,644 INFO Pytorch tensor shape detected: 128x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:42,646 INFO Layer 86: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:42,649 INFO     Weight matrix 1/1 (128,256): Analyzing ...\n",
      "2018-11-26 12:56:44,045 INFO     Weight matrix 1/1 (128,256): Alpha: 8.45027960423436, Alpha Weighted: -0.042060838377636224, D: 0.1452196302592791\n",
      "2018-11-26 12:56:44,047 INFO     Weight matrix 1/1 (128,256): Alpha 8.45027960423436 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:44,051 INFO     Weight matrix 1/1 (128,256): Lognorm: 0.5941256880760193\n",
      "2018-11-26 12:56:44,054 INFO Layer 87: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:44,056 INFO Layer 87: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:44,059 INFO Layer 88: ReLU(inplace)\n",
      "2018-11-26 12:56:44,062 INFO Layer 88: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:44,064 INFO Layer 89: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:44,068 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:44,072 INFO Layer 89: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:44,077 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:44,080 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:44,083 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:44,086 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:44,089 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:44,093 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:44,095 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:44,099 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:44,103 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:44,106 INFO Layer 90: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:44,110 INFO Layer 90: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:44,114 INFO Layer 91: BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:44,121 INFO Layer 91: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:44,126 INFO Layer 92: ReLU(inplace)\n",
      "2018-11-26 12:56:44,129 INFO Layer 92: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:44,131 INFO Layer 93: Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:44,134 INFO Pytorch tensor shape detected: 128x288 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:44,137 INFO Layer 93: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:44,140 INFO     Weight matrix 1/1 (128,288): Analyzing ...\n",
      "2018-11-26 12:56:45,553 INFO     Weight matrix 1/1 (128,288): Alpha: 3.623104509490679, Alpha Weighted: 0.5855936525648835, D: 0.17008045724309306\n",
      "2018-11-26 12:56:45,556 INFO     Weight matrix 1/1 (128,288): Alpha 3.623104509490679 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:45,559 INFO     Weight matrix 1/1 (128,288): Lognorm: 0.6284042596817017\n",
      "2018-11-26 12:56:45,564 INFO Layer 94: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:45,568 INFO Layer 94: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:45,571 INFO Layer 95: ReLU(inplace)\n",
      "2018-11-26 12:56:45,575 INFO Layer 95: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:45,581 INFO Layer 96: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:45,586 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:45,589 INFO Layer 96: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:45,592 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:45,596 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:45,599 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:45,601 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:45,604 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:45,608 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:45,612 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:45,615 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:45,618 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:45,622 INFO Layer 97: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:45,625 INFO Layer 97: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:45,628 INFO Layer 98: BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:45,632 INFO Layer 98: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:45,635 INFO Layer 99: ReLU(inplace)\n",
      "2018-11-26 12:56:45,639 INFO Layer 99: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:45,642 INFO Layer 100: Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:45,646 INFO Pytorch tensor shape detected: 128x320 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:45,649 INFO Layer 100: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:45,652 INFO     Weight matrix 1/1 (128,320): Analyzing ...\n",
      "2018-11-26 12:56:47,041 INFO     Weight matrix 1/1 (128,320): Alpha: 5.717689393729436, Alpha Weighted: 0.5005110269601135, D: 0.1585322730416897\n",
      "2018-11-26 12:56:47,044 INFO     Weight matrix 1/1 (128,320): Alpha 5.717689393729436 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:47,048 INFO     Weight matrix 1/1 (128,320): Lognorm: 0.6488050222396851\n",
      "2018-11-26 12:56:47,051 INFO Layer 101: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:47,058 INFO Layer 101: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:47,063 INFO Layer 102: ReLU(inplace)\n",
      "2018-11-26 12:56:47,067 INFO Layer 102: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:47,073 INFO Layer 103: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:47,084 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:47,089 INFO Layer 103: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:47,092 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:47,098 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:47,102 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:47,106 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:47,114 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:47,130 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:47,134 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:47,137 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:47,141 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:47,145 INFO Layer 104: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:47,148 INFO Layer 104: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:47,151 INFO Layer 105: BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:47,155 INFO Layer 105: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:47,158 INFO Layer 106: ReLU(inplace)\n",
      "2018-11-26 12:56:47,162 INFO Layer 106: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:47,168 INFO Layer 107: Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:47,174 INFO Pytorch tensor shape detected: 128x352 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:47,177 INFO Layer 107: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:47,181 INFO     Weight matrix 1/1 (128,352): Analyzing ...\n",
      "2018-11-26 12:56:48,552 INFO     Weight matrix 1/1 (128,352): Alpha: 3.149973977725962, Alpha Weighted: 0.10839425354339485, D: 0.18419107575345162\n",
      "2018-11-26 12:56:48,555 INFO     Weight matrix 1/1 (128,352): Lognorm: 0.6654196381568909\n",
      "2018-11-26 12:56:48,560 INFO Layer 108: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:48,562 INFO Layer 108: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:48,565 INFO Layer 109: ReLU(inplace)\n",
      "2018-11-26 12:56:48,568 INFO Layer 109: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:48,572 INFO Layer 110: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:48,582 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:48,587 INFO Layer 110: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:48,591 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:48,594 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:48,598 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:48,601 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:48,606 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:48,609 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:48,612 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:48,618 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:48,624 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:48,628 INFO Layer 111: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:48,633 INFO Layer 111: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:48,638 INFO Layer 112: BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:48,641 INFO Layer 112: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:48,649 INFO Layer 113: ReLU(inplace)\n",
      "2018-11-26 12:56:48,652 INFO Layer 113: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:48,656 INFO Layer 114: Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:48,662 INFO Pytorch tensor shape detected: 128x384 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:48,670 INFO Layer 114: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:48,677 INFO     Weight matrix 1/1 (128,384): Analyzing ...\n",
      "2018-11-26 12:56:50,007 INFO     Weight matrix 1/1 (128,384): Alpha: 2.832963605098768, Alpha Weighted: 0.8884886550828026, D: 0.10791145144341915\n",
      "2018-11-26 12:56:50,011 INFO     Weight matrix 1/1 (128,384): Lognorm: 0.6997446417808533\n",
      "2018-11-26 12:56:50,014 INFO Layer 115: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:50,017 INFO Layer 115: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:50,023 INFO Layer 116: ReLU(inplace)\n",
      "2018-11-26 12:56:50,026 INFO Layer 116: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:50,030 INFO Layer 117: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:50,040 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:50,043 INFO Layer 117: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:50,047 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:50,050 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:50,054 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:50,057 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:50,061 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:50,063 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:50,068 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:50,071 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:50,076 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:50,080 INFO Layer 118: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:50,084 INFO Layer 118: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:50,087 INFO Layer 119: BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:50,090 INFO Layer 119: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:50,093 INFO Layer 120: ReLU(inplace)\n",
      "2018-11-26 12:56:50,096 INFO Layer 120: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:50,099 INFO Layer 121: Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:50,103 INFO Pytorch tensor shape detected: 128x416 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:50,107 INFO Layer 121: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:50,111 INFO     Weight matrix 1/1 (128,416): Analyzing ...\n",
      "2018-11-26 12:56:51,442 INFO     Weight matrix 1/1 (128,416): Alpha: 1.9367811344788302, Alpha Weighted: 0.150834441767218, D: 0.18027328270481746\n",
      "2018-11-26 12:56:51,445 INFO     Weight matrix 1/1 (128,416): Lognorm: 0.6738100051879883\n",
      "2018-11-26 12:56:51,449 INFO Layer 122: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:51,451 INFO Layer 122: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:51,454 INFO Layer 123: ReLU(inplace)\n",
      "2018-11-26 12:56:51,457 INFO Layer 123: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:51,460 INFO Layer 124: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:51,464 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:51,467 INFO Layer 124: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:51,479 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:51,488 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:51,491 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:51,495 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:51,499 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:51,502 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:51,506 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:51,511 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:51,514 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:51,516 INFO Layer 125: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:51,519 INFO Layer 125: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:51,521 INFO Layer 126: BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:51,524 INFO Layer 126: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:51,527 INFO Layer 127: ReLU(inplace)\n",
      "2018-11-26 12:56:51,531 INFO Layer 127: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:51,534 INFO Layer 128: Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:51,538 INFO Pytorch tensor shape detected: 128x448 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:51,542 INFO Layer 128: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:51,545 INFO     Weight matrix 1/1 (128,448): Analyzing ...\n",
      "2018-11-26 12:56:52,922 INFO     Weight matrix 1/1 (128,448): Alpha: 5.8120739704295605, Alpha Weighted: 0.6215564484764577, D: 0.1587961444607282\n",
      "2018-11-26 12:56:52,925 INFO     Weight matrix 1/1 (128,448): Alpha 5.8120739704295605 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:56:52,929 INFO     Weight matrix 1/1 (128,448): Lognorm: 0.7169743776321411\n",
      "2018-11-26 12:56:52,931 INFO Layer 129: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:52,935 INFO Layer 129: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:52,940 INFO Layer 130: ReLU(inplace)\n",
      "2018-11-26 12:56:52,946 INFO Layer 130: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:52,949 INFO Layer 131: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:52,953 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:52,956 INFO Layer 131: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:52,960 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:52,964 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:52,969 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:52,973 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:52,976 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:52,980 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:52,985 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:52,988 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:52,995 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:52,998 INFO Layer 132: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:53,001 INFO Layer 132: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:53,005 INFO Layer 133: BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:53,009 INFO Layer 133: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:53,013 INFO Layer 134: ReLU(inplace)\n",
      "2018-11-26 12:56:53,016 INFO Layer 134: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:53,020 INFO Layer 135: Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:53,025 INFO Pytorch tensor shape detected: 128x480 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:53,029 INFO Layer 135: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:53,034 INFO     Weight matrix 1/1 (128,480): Analyzing ...\n",
      "2018-11-26 12:56:54,478 INFO     Weight matrix 1/1 (128,480): Alpha: 2.1222122397018737, Alpha Weighted: 0.7374792446844336, D: 0.14115002810755561\n",
      "2018-11-26 12:56:54,483 INFO     Weight matrix 1/1 (128,480): Lognorm: 0.7770052552223206\n",
      "2018-11-26 12:56:54,486 INFO Layer 136: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:54,489 INFO Layer 136: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:54,492 INFO Layer 137: ReLU(inplace)\n",
      "2018-11-26 12:56:54,494 INFO Layer 137: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:54,498 INFO Layer 138: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:54,506 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:54,512 INFO Layer 138: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:54,516 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:54,519 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:54,525 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:54,529 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:54,533 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:54,538 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:54,541 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:54,544 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:54,547 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:54,553 INFO Layer 139: _Transition(\n",
      "  (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "2018-11-26 12:56:54,558 INFO Layer 139: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:54,565 INFO Layer 140: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:54,569 INFO Layer 140: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:54,573 INFO Layer 141: ReLU(inplace)\n",
      "2018-11-26 12:56:54,576 INFO Layer 141: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:54,581 INFO Layer 142: Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:54,591 INFO Pytorch tensor shape detected: 256x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:54,599 INFO Layer 142: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:54,603 INFO     Weight matrix 1/1 (256,512): Analyzing ...\n",
      "2018-11-26 12:56:58,052 INFO     Weight matrix 1/1 (256,512): Alpha: 3.045263829760049, Alpha Weighted: 1.6483738989814758, D: 0.1541695093550386\n",
      "2018-11-26 12:56:58,055 INFO     Weight matrix 1/1 (256,512): Lognorm: 1.133549690246582\n",
      "2018-11-26 12:56:58,057 INFO Layer 143: AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "2018-11-26 12:56:58,061 INFO Layer 143: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:58,081 INFO Layer 144: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer7): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer8): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer9): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer10): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer11): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer12): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer13): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer14): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer15): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer16): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer17): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer18): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer19): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer20): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer21): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer22): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer23): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer24): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer25): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer26): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer27): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer28): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer29): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer30): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer31): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer32): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer33): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer34): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer35): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer36): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer37): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer38): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer39): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer40): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer41): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer42): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer43): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer44): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer45): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer46): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer47): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer48): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:56:58,086 INFO Layer 144: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:58,090 INFO Layer 145: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:58,094 INFO Layer 145: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:58,097 INFO Layer 146: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:58,100 INFO Layer 146: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:58,103 INFO Layer 147: ReLU(inplace)\n",
      "2018-11-26 12:56:58,106 INFO Layer 147: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:58,109 INFO Layer 148: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:58,114 INFO Pytorch tensor shape detected: 128x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:58,121 INFO Layer 148: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:58,127 INFO     Weight matrix 1/1 (128,256): Analyzing ...\n",
      "2018-11-26 12:56:59,519 INFO     Weight matrix 1/1 (128,256): Alpha: 1.583846847746102, Alpha Weighted: -0.09800457814708281, D: 0.16503907691969733\n",
      "2018-11-26 12:56:59,523 INFO     Weight matrix 1/1 (128,256): Lognorm: 0.4658624827861786\n",
      "2018-11-26 12:56:59,526 INFO Layer 149: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:59,530 INFO Layer 149: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:59,534 INFO Layer 150: ReLU(inplace)\n",
      "2018-11-26 12:56:59,537 INFO Layer 150: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:59,541 INFO Layer 151: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:56:59,546 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:56:59,549 INFO Layer 151: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:56:59,552 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:59,555 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:59,558 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:59,562 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:59,566 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:59,570 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:59,574 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:59,578 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:59,581 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:56:59,584 INFO Layer 152: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:56:59,588 INFO Layer 152: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:59,594 INFO Layer 153: BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:56:59,598 INFO Layer 153: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:59,600 INFO Layer 154: ReLU(inplace)\n",
      "2018-11-26 12:56:59,603 INFO Layer 154: Skipping (Layer not supported)\n",
      "2018-11-26 12:56:59,607 INFO Layer 155: Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:56:59,611 INFO Pytorch tensor shape detected: 128x288 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:56:59,614 INFO Layer 155: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:56:59,618 INFO     Weight matrix 1/1 (128,288): Analyzing ...\n",
      "2018-11-26 12:57:01,103 INFO     Weight matrix 1/1 (128,288): Alpha: 2.408390723678167, Alpha Weighted: -0.05616942418913428, D: 0.14849799221512505\n",
      "2018-11-26 12:57:01,107 INFO     Weight matrix 1/1 (128,288): Lognorm: 0.5752851366996765\n",
      "2018-11-26 12:57:01,113 INFO Layer 156: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:01,118 INFO Layer 156: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:01,122 INFO Layer 157: ReLU(inplace)\n",
      "2018-11-26 12:57:01,127 INFO Layer 157: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:01,136 INFO Layer 158: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:01,143 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:01,153 INFO Layer 158: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:01,158 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:01,162 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:01,170 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:01,178 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:01,185 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:01,189 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:01,198 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:01,202 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:01,207 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:01,210 INFO Layer 159: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:01,214 INFO Layer 159: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:01,228 INFO Layer 160: BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:01,234 INFO Layer 160: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:01,241 INFO Layer 161: ReLU(inplace)\n",
      "2018-11-26 12:57:01,244 INFO Layer 161: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:01,247 INFO Layer 162: Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:01,253 INFO Pytorch tensor shape detected: 128x320 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:01,256 INFO Layer 162: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:01,260 INFO     Weight matrix 1/1 (128,320): Analyzing ...\n",
      "2018-11-26 12:57:02,623 INFO     Weight matrix 1/1 (128,320): Alpha: 2.221219270021453, Alpha Weighted: -0.1171287680137998, D: 0.15095340327936957\n",
      "2018-11-26 12:57:02,628 INFO     Weight matrix 1/1 (128,320): Lognorm: 0.5068046450614929\n",
      "2018-11-26 12:57:02,631 INFO Layer 163: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:02,634 INFO Layer 163: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:02,638 INFO Layer 164: ReLU(inplace)\n",
      "2018-11-26 12:57:02,641 INFO Layer 164: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:02,645 INFO Layer 165: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:02,649 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:02,653 INFO Layer 165: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:02,657 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:02,660 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:02,664 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:02,668 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:02,672 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:02,676 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:02,679 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:02,683 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:02,686 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:02,692 INFO Layer 166: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:02,695 INFO Layer 166: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:02,699 INFO Layer 167: BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:02,702 INFO Layer 167: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:02,709 INFO Layer 168: ReLU(inplace)\n",
      "2018-11-26 12:57:02,713 INFO Layer 168: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:02,716 INFO Layer 169: Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:02,721 INFO Pytorch tensor shape detected: 128x352 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:02,725 INFO Layer 169: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:02,732 INFO     Weight matrix 1/1 (128,352): Analyzing ...\n",
      "2018-11-26 12:57:04,146 INFO     Weight matrix 1/1 (128,352): Alpha: 1.6011513269268436, Alpha Weighted: -0.3082384911214438, D: 0.1837704253190045\n",
      "2018-11-26 12:57:04,151 INFO     Weight matrix 1/1 (128,352): Lognorm: 0.44901636242866516\n",
      "2018-11-26 12:57:04,154 INFO Layer 170: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:04,158 INFO Layer 170: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:04,161 INFO Layer 171: ReLU(inplace)\n",
      "2018-11-26 12:57:04,166 INFO Layer 171: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:04,170 INFO Layer 172: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:04,174 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:04,178 INFO Layer 172: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:04,184 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:04,186 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:04,189 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:04,193 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:04,196 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:04,201 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:04,205 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:04,208 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:04,211 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:04,216 INFO Layer 173: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:04,222 INFO Layer 173: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:04,225 INFO Layer 174: BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:04,232 INFO Layer 174: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:04,236 INFO Layer 175: ReLU(inplace)\n",
      "2018-11-26 12:57:04,239 INFO Layer 175: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:04,241 INFO Layer 176: Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:04,245 INFO Pytorch tensor shape detected: 128x384 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:04,248 INFO Layer 176: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:04,251 INFO     Weight matrix 1/1 (128,384): Analyzing ...\n",
      "2018-11-26 12:57:05,607 INFO     Weight matrix 1/1 (128,384): Alpha: 1.5985232651364778, Alpha Weighted: -0.17844673725325422, D: 0.1651416106407353\n",
      "2018-11-26 12:57:05,610 INFO     Weight matrix 1/1 (128,384): Lognorm: 0.4808567464351654\n",
      "2018-11-26 12:57:05,613 INFO Layer 177: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:05,616 INFO Layer 177: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:05,620 INFO Layer 178: ReLU(inplace)\n",
      "2018-11-26 12:57:05,626 INFO Layer 178: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:05,630 INFO Layer 179: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:05,635 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:05,640 INFO Layer 179: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:05,644 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:05,647 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:05,650 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:05,653 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:05,657 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:05,661 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:05,666 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:05,670 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:05,674 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:05,682 INFO Layer 180: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:05,687 INFO Layer 180: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:05,690 INFO Layer 181: BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:05,693 INFO Layer 181: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:05,697 INFO Layer 182: ReLU(inplace)\n",
      "2018-11-26 12:57:05,700 INFO Layer 182: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:05,703 INFO Layer 183: Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:05,707 INFO Pytorch tensor shape detected: 128x416 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:05,712 INFO Layer 183: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:05,716 INFO     Weight matrix 1/1 (128,416): Analyzing ...\n",
      "2018-11-26 12:57:06,981 INFO     Weight matrix 1/1 (128,416): Alpha: 3.7180725040685934, Alpha Weighted: 0.07798634653231735, D: 0.12640722276385125\n",
      "2018-11-26 12:57:06,984 INFO     Weight matrix 1/1 (128,416): Alpha 3.7180725040685934 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:06,987 INFO     Weight matrix 1/1 (128,416): Lognorm: 0.58819979429245\n",
      "2018-11-26 12:57:06,990 INFO Layer 184: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:06,993 INFO Layer 184: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:06,996 INFO Layer 185: ReLU(inplace)\n",
      "2018-11-26 12:57:06,999 INFO Layer 185: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:07,003 INFO Layer 186: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:07,007 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:07,009 INFO Layer 186: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:07,011 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:07,014 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:07,018 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:07,021 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:07,024 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:07,027 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:07,031 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:07,034 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:07,037 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:07,040 INFO Layer 187: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:07,042 INFO Layer 187: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:07,045 INFO Layer 188: BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:07,048 INFO Layer 188: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:07,050 INFO Layer 189: ReLU(inplace)\n",
      "2018-11-26 12:57:07,052 INFO Layer 189: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:07,054 INFO Layer 190: Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:07,058 INFO Pytorch tensor shape detected: 128x448 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:07,060 INFO Layer 190: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:07,064 INFO     Weight matrix 1/1 (128,448): Analyzing ...\n",
      "2018-11-26 12:57:08,371 INFO     Weight matrix 1/1 (128,448): Alpha: 3.296320111514852, Alpha Weighted: -0.11356279026957729, D: 0.12051931405731997\n",
      "2018-11-26 12:57:08,374 INFO     Weight matrix 1/1 (128,448): Lognorm: 0.5794326066970825\n",
      "2018-11-26 12:57:08,378 INFO Layer 191: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:08,382 INFO Layer 191: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:08,385 INFO Layer 192: ReLU(inplace)\n",
      "2018-11-26 12:57:08,389 INFO Layer 192: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:08,392 INFO Layer 193: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:08,397 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:08,400 INFO Layer 193: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:08,403 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:08,406 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:08,410 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:08,413 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:08,417 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:08,421 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:08,424 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:08,429 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:08,438 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:08,442 INFO Layer 194: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:08,445 INFO Layer 194: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:08,449 INFO Layer 195: BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:08,452 INFO Layer 195: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:08,456 INFO Layer 196: ReLU(inplace)\n",
      "2018-11-26 12:57:08,461 INFO Layer 196: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:08,465 INFO Layer 197: Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:08,469 INFO Pytorch tensor shape detected: 128x480 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:08,474 INFO Layer 197: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:08,480 INFO     Weight matrix 1/1 (128,480): Analyzing ...\n",
      "2018-11-26 12:57:09,658 INFO     Weight matrix 1/1 (128,480): Alpha: 4.930400614527592, Alpha Weighted: -0.5553586030436635, D: 0.1238838192163425\n",
      "2018-11-26 12:57:09,661 INFO     Weight matrix 1/1 (128,480): Alpha 4.930400614527592 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:09,664 INFO     Weight matrix 1/1 (128,480): Lognorm: 0.5141971707344055\n",
      "2018-11-26 12:57:09,667 INFO Layer 198: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:09,671 INFO Layer 198: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:09,678 INFO Layer 199: ReLU(inplace)\n",
      "2018-11-26 12:57:09,682 INFO Layer 199: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:09,685 INFO Layer 200: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:09,689 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:09,692 INFO Layer 200: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:09,695 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:09,699 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:09,701 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:09,704 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:09,707 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:09,709 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:09,712 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:09,716 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:09,718 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:09,721 INFO Layer 201: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:09,724 INFO Layer 201: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:09,727 INFO Layer 202: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:09,731 INFO Layer 202: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:09,733 INFO Layer 203: ReLU(inplace)\n",
      "2018-11-26 12:57:09,736 INFO Layer 203: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:09,740 INFO Layer 204: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:09,745 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:09,748 INFO Layer 204: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:09,796 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 12:57:10,928 INFO     Weight matrix 1/1 (128,512): Alpha: 3.653804064481247, Alpha Weighted: 0.15751756885954404, D: 0.09851365417116986\n",
      "2018-11-26 12:57:10,930 INFO     Weight matrix 1/1 (128,512): Alpha 3.653804064481247 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:10,936 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.6384378671646118\n",
      "2018-11-26 12:57:10,940 INFO Layer 205: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:10,942 INFO Layer 205: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:10,945 INFO Layer 206: ReLU(inplace)\n",
      "2018-11-26 12:57:10,949 INFO Layer 206: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:10,952 INFO Layer 207: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:10,956 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:10,959 INFO Layer 207: Analyzing 9 weight matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:10,962 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:10,965 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:10,968 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:10,973 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:10,978 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:10,981 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:10,991 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:10,993 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:10,998 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:11,005 INFO Layer 208: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:11,009 INFO Layer 208: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:11,013 INFO Layer 209: BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:11,016 INFO Layer 209: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:11,021 INFO Layer 210: ReLU(inplace)\n",
      "2018-11-26 12:57:11,024 INFO Layer 210: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:11,027 INFO Layer 211: Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:11,035 INFO Pytorch tensor shape detected: 128x544 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:11,039 INFO Layer 211: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:11,041 INFO     Weight matrix 1/1 (128,544): Analyzing ...\n",
      "2018-11-26 12:57:12,459 INFO     Weight matrix 1/1 (128,544): Alpha: 1.593179031310073, Alpha Weighted: -0.27672048647651315, D: 0.17331663503963263\n",
      "2018-11-26 12:57:12,462 INFO     Weight matrix 1/1 (128,544): Lognorm: 0.5537497401237488\n",
      "2018-11-26 12:57:12,466 INFO Layer 212: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:12,469 INFO Layer 212: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:12,472 INFO Layer 213: ReLU(inplace)\n",
      "2018-11-26 12:57:12,475 INFO Layer 213: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:12,480 INFO Layer 214: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:12,486 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:12,493 INFO Layer 214: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:12,496 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:12,499 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:12,502 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:12,505 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:12,509 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:12,512 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:12,515 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:12,519 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:12,523 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:12,528 INFO Layer 215: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:12,534 INFO Layer 215: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:12,537 INFO Layer 216: BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:12,539 INFO Layer 216: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:12,542 INFO Layer 217: ReLU(inplace)\n",
      "2018-11-26 12:57:12,544 INFO Layer 217: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:12,547 INFO Layer 218: Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:12,553 INFO Pytorch tensor shape detected: 128x576 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:12,555 INFO Layer 218: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:12,559 INFO     Weight matrix 1/1 (128,576): Analyzing ...\n",
      "2018-11-26 12:57:13,892 INFO     Weight matrix 1/1 (128,576): Alpha: 1.7559188664728833, Alpha Weighted: -0.24383948306700126, D: 0.15950278163212517\n",
      "2018-11-26 12:57:13,895 INFO     Weight matrix 1/1 (128,576): Lognorm: 0.5662946701049805\n",
      "2018-11-26 12:57:13,902 INFO Layer 219: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:13,905 INFO Layer 219: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:13,907 INFO Layer 220: ReLU(inplace)\n",
      "2018-11-26 12:57:13,909 INFO Layer 220: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:13,912 INFO Layer 221: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:13,922 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:13,930 INFO Layer 221: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:13,934 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:13,937 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:13,940 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:13,943 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:13,946 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:13,949 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:13,952 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:13,956 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:13,961 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:13,964 INFO Layer 222: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:13,968 INFO Layer 222: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:13,971 INFO Layer 223: BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:13,976 INFO Layer 223: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:13,981 INFO Layer 224: ReLU(inplace)\n",
      "2018-11-26 12:57:13,987 INFO Layer 224: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:13,991 INFO Layer 225: Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:13,997 INFO Pytorch tensor shape detected: 128x608 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:14,000 INFO Layer 225: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:14,003 INFO     Weight matrix 1/1 (128,608): Analyzing ...\n",
      "2018-11-26 12:57:15,180 INFO     Weight matrix 1/1 (128,608): Alpha: 1.9028857819457574, Alpha Weighted: -0.24604568030776583, D: 0.1584407339648427\n",
      "2018-11-26 12:57:15,183 INFO     Weight matrix 1/1 (128,608): Lognorm: 0.5766661763191223\n",
      "2018-11-26 12:57:15,187 INFO Layer 226: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:15,190 INFO Layer 226: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:15,194 INFO Layer 227: ReLU(inplace)\n",
      "2018-11-26 12:57:15,197 INFO Layer 227: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:15,200 INFO Layer 228: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:15,205 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:15,208 INFO Layer 228: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:15,211 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:15,213 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:15,217 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:15,222 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:15,227 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:15,230 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:15,234 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:15,238 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:15,245 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:15,249 INFO Layer 229: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:15,252 INFO Layer 229: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:15,255 INFO Layer 230: BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:15,264 INFO Layer 230: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:15,270 INFO Layer 231: ReLU(inplace)\n",
      "2018-11-26 12:57:15,273 INFO Layer 231: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:15,276 INFO Layer 232: Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:15,282 INFO Pytorch tensor shape detected: 128x640 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:15,285 INFO Layer 232: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:15,289 INFO     Weight matrix 1/1 (128,640): Analyzing ...\n",
      "2018-11-26 12:57:16,494 INFO     Weight matrix 1/1 (128,640): Alpha: 1.9614650789509442, Alpha Weighted: 0.6057853765488723, D: 0.10000530682140801\n",
      "2018-11-26 12:57:16,497 INFO     Weight matrix 1/1 (128,640): Lognorm: 0.6218957901000977\n",
      "2018-11-26 12:57:16,500 INFO Layer 233: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:16,506 INFO Layer 233: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:16,510 INFO Layer 234: ReLU(inplace)\n",
      "2018-11-26 12:57:16,512 INFO Layer 234: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:16,515 INFO Layer 235: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:16,519 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:16,521 INFO Layer 235: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:16,524 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:16,526 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:16,529 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:16,532 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:16,535 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:16,539 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:16,546 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:16,548 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:16,551 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:16,554 INFO Layer 236: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:16,558 INFO Layer 236: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:16,561 INFO Layer 237: BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:16,563 INFO Layer 237: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:16,572 INFO Layer 238: ReLU(inplace)\n",
      "2018-11-26 12:57:16,575 INFO Layer 238: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:16,578 INFO Layer 239: Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:16,583 INFO Pytorch tensor shape detected: 128x672 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:16,585 INFO Layer 239: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:16,589 INFO     Weight matrix 1/1 (128,672): Analyzing ...\n",
      "2018-11-26 12:57:17,791 INFO     Weight matrix 1/1 (128,672): Alpha: 4.411436032420086, Alpha Weighted: 0.05163540662268631, D: 0.08664420939650264\n",
      "2018-11-26 12:57:17,794 INFO     Weight matrix 1/1 (128,672): Alpha 4.411436032420086 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:17,797 INFO     Weight matrix 1/1 (128,672): Lognorm: 0.6364011168479919\n",
      "2018-11-26 12:57:17,800 INFO Layer 240: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:17,802 INFO Layer 240: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:17,805 INFO Layer 241: ReLU(inplace)\n",
      "2018-11-26 12:57:17,809 INFO Layer 241: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:17,812 INFO Layer 242: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:17,815 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:17,819 INFO Layer 242: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:17,824 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:17,828 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:17,831 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:17,834 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:17,838 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:17,844 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:17,846 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:17,850 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:17,852 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:17,855 INFO Layer 243: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:17,858 INFO Layer 243: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:17,860 INFO Layer 244: BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:17,862 INFO Layer 244: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:17,866 INFO Layer 245: ReLU(inplace)\n",
      "2018-11-26 12:57:17,869 INFO Layer 245: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:17,873 INFO Layer 246: Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:17,879 INFO Pytorch tensor shape detected: 128x704 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:17,882 INFO Layer 246: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:17,888 INFO     Weight matrix 1/1 (128,704): Analyzing ...\n",
      "2018-11-26 12:57:19,124 INFO     Weight matrix 1/1 (128,704): Alpha: 4.459959878440559, Alpha Weighted: 0.9721339931367186, D: 0.09348469122334879\n",
      "2018-11-26 12:57:19,128 INFO     Weight matrix 1/1 (128,704): Alpha 4.459959878440559 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:19,131 INFO     Weight matrix 1/1 (128,704): Lognorm: 0.6225210428237915\n",
      "2018-11-26 12:57:19,134 INFO Layer 247: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:19,136 INFO Layer 247: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:19,139 INFO Layer 248: ReLU(inplace)\n",
      "2018-11-26 12:57:19,141 INFO Layer 248: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:19,143 INFO Layer 249: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:19,146 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:19,149 INFO Layer 249: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:19,151 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:19,153 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:19,156 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:19,159 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:19,162 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:19,164 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:19,167 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:19,169 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:19,174 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:19,177 INFO Layer 250: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:19,180 INFO Layer 250: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:19,182 INFO Layer 251: BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:19,185 INFO Layer 251: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:19,187 INFO Layer 252: ReLU(inplace)\n",
      "2018-11-26 12:57:19,190 INFO Layer 252: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:19,193 INFO Layer 253: Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:19,197 INFO Pytorch tensor shape detected: 128x736 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:19,199 INFO Layer 253: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:19,202 INFO     Weight matrix 1/1 (128,736): Analyzing ...\n",
      "2018-11-26 12:57:20,531 INFO     Weight matrix 1/1 (128,736): Alpha: 3.9503800216517964, Alpha Weighted: 0.571019997966772, D: 0.10114323351838911\n",
      "2018-11-26 12:57:20,533 INFO     Weight matrix 1/1 (128,736): Alpha 3.9503800216517964 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:20,537 INFO     Weight matrix 1/1 (128,736): Lognorm: 0.735187828540802\n",
      "2018-11-26 12:57:20,543 INFO Layer 254: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:20,545 INFO Layer 254: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:20,548 INFO Layer 255: ReLU(inplace)\n",
      "2018-11-26 12:57:20,550 INFO Layer 255: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:20,552 INFO Layer 256: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:20,555 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:20,557 INFO Layer 256: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:20,561 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:20,564 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:20,576 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:20,583 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:20,586 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:20,589 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:20,596 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:20,606 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:20,610 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:20,614 INFO Layer 257: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:20,625 INFO Layer 257: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:20,629 INFO Layer 258: BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:20,635 INFO Layer 258: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:20,638 INFO Layer 259: ReLU(inplace)\n",
      "2018-11-26 12:57:20,642 INFO Layer 259: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:20,645 INFO Layer 260: Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:20,651 INFO Pytorch tensor shape detected: 128x768 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:20,657 INFO Layer 260: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:20,660 INFO     Weight matrix 1/1 (128,768): Analyzing ...\n",
      "2018-11-26 12:57:21,996 INFO     Weight matrix 1/1 (128,768): Alpha: 1.9869152848096587, Alpha Weighted: -0.16863190470296716, D: 0.1619889002829391\n",
      "2018-11-26 12:57:22,001 INFO     Weight matrix 1/1 (128,768): Lognorm: 0.6321976780891418\n",
      "2018-11-26 12:57:22,004 INFO Layer 261: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:22,008 INFO Layer 261: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:22,012 INFO Layer 262: ReLU(inplace)\n",
      "2018-11-26 12:57:22,016 INFO Layer 262: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:22,023 INFO Layer 263: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:22,030 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:22,035 INFO Layer 263: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:22,041 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:22,044 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:22,048 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:22,051 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:22,054 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:22,057 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:22,061 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:22,063 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:22,066 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:22,073 INFO Layer 264: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:22,083 INFO Layer 264: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:22,090 INFO Layer 265: BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:22,094 INFO Layer 265: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:22,097 INFO Layer 266: ReLU(inplace)\n",
      "2018-11-26 12:57:22,100 INFO Layer 266: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:22,104 INFO Layer 267: Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:22,111 INFO Pytorch tensor shape detected: 128x800 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:22,113 INFO Layer 267: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:22,123 INFO     Weight matrix 1/1 (128,800): Analyzing ...\n",
      "2018-11-26 12:57:23,475 INFO     Weight matrix 1/1 (128,800): Alpha: 4.990165032332616, Alpha Weighted: -0.3332681730049541, D: 0.10153273365070414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:23,478 INFO     Weight matrix 1/1 (128,800): Alpha 4.990165032332616 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:23,482 INFO     Weight matrix 1/1 (128,800): Lognorm: 0.6371203660964966\n",
      "2018-11-26 12:57:23,486 INFO Layer 268: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:23,489 INFO Layer 268: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:23,493 INFO Layer 269: ReLU(inplace)\n",
      "2018-11-26 12:57:23,496 INFO Layer 269: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:23,499 INFO Layer 270: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:23,503 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:23,506 INFO Layer 270: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:23,509 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:23,514 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:23,518 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:23,522 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:23,525 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:23,529 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:23,532 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:23,536 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:23,541 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:23,545 INFO Layer 271: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:23,548 INFO Layer 271: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:23,551 INFO Layer 272: BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:23,554 INFO Layer 272: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:23,557 INFO Layer 273: ReLU(inplace)\n",
      "2018-11-26 12:57:23,562 INFO Layer 273: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:23,565 INFO Layer 274: Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:23,571 INFO Pytorch tensor shape detected: 128x832 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:23,574 INFO Layer 274: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:23,577 INFO     Weight matrix 1/1 (128,832): Analyzing ...\n",
      "2018-11-26 12:57:24,733 INFO     Weight matrix 1/1 (128,832): Alpha: 1.8763474497531378, Alpha Weighted: -0.22647533612445825, D: 0.17735013471624855\n",
      "2018-11-26 12:57:24,737 INFO     Weight matrix 1/1 (128,832): Lognorm: 0.6352325677871704\n",
      "2018-11-26 12:57:24,741 INFO Layer 275: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:24,744 INFO Layer 275: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:24,747 INFO Layer 276: ReLU(inplace)\n",
      "2018-11-26 12:57:24,750 INFO Layer 276: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:24,753 INFO Layer 277: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:24,757 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:24,760 INFO Layer 277: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:24,763 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:24,766 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:24,769 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:24,774 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:24,779 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:24,785 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:24,789 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:24,793 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:24,795 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:24,798 INFO Layer 278: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:24,801 INFO Layer 278: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:24,803 INFO Layer 279: BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:24,805 INFO Layer 279: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:24,809 INFO Layer 280: ReLU(inplace)\n",
      "2018-11-26 12:57:24,811 INFO Layer 280: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:24,814 INFO Layer 281: Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:24,824 INFO Pytorch tensor shape detected: 128x864 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:24,827 INFO Layer 281: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:24,830 INFO     Weight matrix 1/1 (128,864): Analyzing ...\n",
      "2018-11-26 12:57:26,136 INFO     Weight matrix 1/1 (128,864): Alpha: 1.9229077848257754, Alpha Weighted: -0.0033152042244700545, D: 0.1473221920908499\n",
      "2018-11-26 12:57:26,139 INFO     Weight matrix 1/1 (128,864): Lognorm: 0.6629010438919067\n",
      "2018-11-26 12:57:26,146 INFO Layer 282: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:26,149 INFO Layer 282: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:26,152 INFO Layer 283: ReLU(inplace)\n",
      "2018-11-26 12:57:26,154 INFO Layer 283: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:26,157 INFO Layer 284: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:26,162 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:26,165 INFO Layer 284: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:26,169 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:26,173 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:26,177 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:26,181 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:26,184 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:26,186 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:26,190 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:26,193 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:26,195 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:26,199 INFO Layer 285: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:26,203 INFO Layer 285: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:26,205 INFO Layer 286: BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:26,208 INFO Layer 286: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:26,210 INFO Layer 287: ReLU(inplace)\n",
      "2018-11-26 12:57:26,214 INFO Layer 287: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:26,217 INFO Layer 288: Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:26,223 INFO Pytorch tensor shape detected: 128x896 (NxM), 1x1 (i,j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:26,226 INFO Layer 288: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:26,230 INFO     Weight matrix 1/1 (128,896): Analyzing ...\n",
      "2018-11-26 12:57:27,469 INFO     Weight matrix 1/1 (128,896): Alpha: 4.449403537898187, Alpha Weighted: 0.24144794347566012, D: 0.12787809523442206\n",
      "2018-11-26 12:57:27,472 INFO     Weight matrix 1/1 (128,896): Alpha 4.449403537898187 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:27,476 INFO     Weight matrix 1/1 (128,896): Lognorm: 0.6812089681625366\n",
      "2018-11-26 12:57:27,480 INFO Layer 289: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:27,485 INFO Layer 289: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:27,488 INFO Layer 290: ReLU(inplace)\n",
      "2018-11-26 12:57:27,492 INFO Layer 290: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:27,494 INFO Layer 291: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:27,497 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:27,499 INFO Layer 291: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:27,502 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:27,505 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:27,509 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:27,513 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:27,517 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:27,520 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:27,530 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:27,537 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:27,542 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:27,546 INFO Layer 292: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:27,551 INFO Layer 292: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:27,554 INFO Layer 293: BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:27,556 INFO Layer 293: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:27,558 INFO Layer 294: ReLU(inplace)\n",
      "2018-11-26 12:57:27,561 INFO Layer 294: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:27,563 INFO Layer 295: Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:27,569 INFO Pytorch tensor shape detected: 128x928 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:27,572 INFO Layer 295: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:27,575 INFO     Weight matrix 1/1 (128,928): Analyzing ...\n",
      "2018-11-26 12:57:28,717 INFO     Weight matrix 1/1 (128,928): Alpha: 1.949804317513989, Alpha Weighted: -0.006765395827168592, D: 0.15652817036633737\n",
      "2018-11-26 12:57:28,721 INFO     Weight matrix 1/1 (128,928): Lognorm: 0.6947890520095825\n",
      "2018-11-26 12:57:28,724 INFO Layer 296: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:28,727 INFO Layer 296: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:28,730 INFO Layer 297: ReLU(inplace)\n",
      "2018-11-26 12:57:28,733 INFO Layer 297: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:28,736 INFO Layer 298: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:28,741 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:28,743 INFO Layer 298: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:28,746 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:28,748 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:28,751 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:28,754 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:28,757 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:28,759 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:28,762 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:28,764 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:28,767 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:28,770 INFO Layer 299: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:28,772 INFO Layer 299: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:28,776 INFO Layer 300: BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:28,779 INFO Layer 300: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:28,783 INFO Layer 301: ReLU(inplace)\n",
      "2018-11-26 12:57:28,786 INFO Layer 301: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:28,789 INFO Layer 302: Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:28,794 INFO Pytorch tensor shape detected: 128x960 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:28,797 INFO Layer 302: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:28,801 INFO     Weight matrix 1/1 (128,960): Analyzing ...\n",
      "2018-11-26 12:57:29,908 INFO     Weight matrix 1/1 (128,960): Alpha: 2.338110712611456, Alpha Weighted: -0.16066700243022122, D: 0.15353687131613925\n",
      "2018-11-26 12:57:29,911 INFO     Weight matrix 1/1 (128,960): Lognorm: 0.6657415628433228\n",
      "2018-11-26 12:57:29,914 INFO Layer 303: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:29,917 INFO Layer 303: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:29,921 INFO Layer 304: ReLU(inplace)\n",
      "2018-11-26 12:57:29,924 INFO Layer 304: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:29,927 INFO Layer 305: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:29,930 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:29,933 INFO Layer 305: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:29,937 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:29,939 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:29,942 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:29,945 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:29,948 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:29,952 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:29,955 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:29,958 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:29,961 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:29,963 INFO Layer 306: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:29,966 INFO Layer 306: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:29,968 INFO Layer 307: BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:29,970 INFO Layer 307: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:29,973 INFO Layer 308: ReLU(inplace)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:29,976 INFO Layer 308: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:29,978 INFO Layer 309: Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:29,982 INFO Pytorch tensor shape detected: 128x992 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:29,984 INFO Layer 309: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:29,988 INFO     Weight matrix 1/1 (128,992): Analyzing ...\n",
      "2018-11-26 12:57:31,120 INFO     Weight matrix 1/1 (128,992): Alpha: 2.569899377338251, Alpha Weighted: 0.004463096259073948, D: 0.1439208315426832\n",
      "2018-11-26 12:57:31,123 INFO     Weight matrix 1/1 (128,992): Lognorm: 0.7128458619117737\n",
      "2018-11-26 12:57:31,126 INFO Layer 310: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:31,129 INFO Layer 310: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:31,132 INFO Layer 311: ReLU(inplace)\n",
      "2018-11-26 12:57:31,135 INFO Layer 311: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:31,138 INFO Layer 312: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:31,141 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:31,144 INFO Layer 312: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:31,147 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:31,149 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:31,152 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:31,154 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:31,157 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:31,160 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:31,163 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:31,166 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:31,169 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:31,172 INFO Layer 313: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:31,177 INFO Layer 313: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:31,180 INFO Layer 314: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:31,184 INFO Layer 314: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:31,187 INFO Layer 315: ReLU(inplace)\n",
      "2018-11-26 12:57:31,190 INFO Layer 315: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:31,193 INFO Layer 316: Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:31,197 INFO Pytorch tensor shape detected: 128x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:31,200 INFO Layer 316: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:31,204 INFO     Weight matrix 1/1 (128,1024): Analyzing ...\n",
      "2018-11-26 12:57:32,348 INFO     Weight matrix 1/1 (128,1024): Alpha: 3.2421375305452065, Alpha Weighted: 0.2840445833464272, D: 0.11800962467663378\n",
      "2018-11-26 12:57:32,352 INFO     Weight matrix 1/1 (128,1024): Lognorm: 0.7273784875869751\n",
      "2018-11-26 12:57:32,354 INFO Layer 317: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:32,357 INFO Layer 317: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:32,360 INFO Layer 318: ReLU(inplace)\n",
      "2018-11-26 12:57:32,363 INFO Layer 318: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:32,366 INFO Layer 319: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:32,369 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:32,372 INFO Layer 319: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:32,377 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:32,381 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:32,384 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:32,388 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:32,391 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:32,393 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:32,396 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:32,399 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:32,402 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:32,405 INFO Layer 320: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:32,408 INFO Layer 320: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:32,410 INFO Layer 321: BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:32,413 INFO Layer 321: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:32,416 INFO Layer 322: ReLU(inplace)\n",
      "2018-11-26 12:57:32,419 INFO Layer 322: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:32,422 INFO Layer 323: Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:32,427 INFO Pytorch tensor shape detected: 128x1056 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:32,431 INFO Layer 323: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:32,435 INFO     Weight matrix 1/1 (128,1056): Analyzing ...\n",
      "2018-11-26 12:57:33,552 INFO     Weight matrix 1/1 (128,1056): Alpha: 2.232946893567359, Alpha Weighted: 0.009706960765243309, D: 0.14915479142437377\n",
      "2018-11-26 12:57:33,555 INFO     Weight matrix 1/1 (128,1056): Lognorm: 0.6755932569503784\n",
      "2018-11-26 12:57:33,558 INFO Layer 324: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:33,560 INFO Layer 324: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:33,563 INFO Layer 325: ReLU(inplace)\n",
      "2018-11-26 12:57:33,565 INFO Layer 325: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:33,568 INFO Layer 326: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:33,572 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:33,574 INFO Layer 326: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:33,578 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:33,582 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:33,585 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:33,589 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:33,597 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:33,599 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:33,602 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:33,604 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:33,606 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:33,609 INFO Layer 327: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:33,612 INFO Layer 327: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:33,615 INFO Layer 328: BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:33,617 INFO Layer 328: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:33,621 INFO Layer 329: ReLU(inplace)\n",
      "2018-11-26 12:57:33,625 INFO Layer 329: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:33,627 INFO Layer 330: Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:33,630 INFO Pytorch tensor shape detected: 128x1088 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:33,637 INFO Layer 330: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:33,641 INFO     Weight matrix 1/1 (128,1088): Analyzing ...\n",
      "2018-11-26 12:57:34,814 INFO     Weight matrix 1/1 (128,1088): Alpha: 2.0233796395047245, Alpha Weighted: 0.008478215571232921, D: 0.14962645764538984\n",
      "2018-11-26 12:57:34,818 INFO     Weight matrix 1/1 (128,1088): Lognorm: 0.6841879487037659\n",
      "2018-11-26 12:57:34,820 INFO Layer 331: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:34,823 INFO Layer 331: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:34,826 INFO Layer 332: ReLU(inplace)\n",
      "2018-11-26 12:57:34,828 INFO Layer 332: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:34,830 INFO Layer 333: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:34,834 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:34,841 INFO Layer 333: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:34,845 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:34,850 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:34,852 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:34,854 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:34,857 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:34,861 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:34,865 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:34,868 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:34,872 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:34,877 INFO Layer 334: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:34,880 INFO Layer 334: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:34,884 INFO Layer 335: BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:34,887 INFO Layer 335: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:34,891 INFO Layer 336: ReLU(inplace)\n",
      "2018-11-26 12:57:34,894 INFO Layer 336: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:34,897 INFO Layer 337: Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:34,901 INFO Pytorch tensor shape detected: 128x1120 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:34,903 INFO Layer 337: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:34,907 INFO     Weight matrix 1/1 (128,1120): Analyzing ...\n",
      "2018-11-26 12:57:36,012 INFO     Weight matrix 1/1 (128,1120): Alpha: 3.561015092571958, Alpha Weighted: 0.7630452732284676, D: 0.08778512656131232\n",
      "2018-11-26 12:57:36,015 INFO     Weight matrix 1/1 (128,1120): Alpha 3.561015092571958 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:36,018 INFO     Weight matrix 1/1 (128,1120): Lognorm: 0.749965488910675\n",
      "2018-11-26 12:57:36,021 INFO Layer 338: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:36,025 INFO Layer 338: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:36,029 INFO Layer 339: ReLU(inplace)\n",
      "2018-11-26 12:57:36,032 INFO Layer 339: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:36,035 INFO Layer 340: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:36,040 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:36,043 INFO Layer 340: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:36,046 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:36,048 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:36,051 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:36,053 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:36,057 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:36,060 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:36,063 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:36,066 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:36,070 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:36,074 INFO Layer 341: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:36,078 INFO Layer 341: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:36,081 INFO Layer 342: BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:36,084 INFO Layer 342: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:36,087 INFO Layer 343: ReLU(inplace)\n",
      "2018-11-26 12:57:36,090 INFO Layer 343: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:36,093 INFO Layer 344: Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:36,098 INFO Pytorch tensor shape detected: 128x1152 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:36,102 INFO Layer 344: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:36,104 INFO     Weight matrix 1/1 (128,1152): Analyzing ...\n",
      "2018-11-26 12:57:37,236 INFO     Weight matrix 1/1 (128,1152): Alpha: 3.1388436815376353, Alpha Weighted: 0.17072858979362598, D: 0.14660127097059117\n",
      "2018-11-26 12:57:37,239 INFO     Weight matrix 1/1 (128,1152): Lognorm: 0.7406067848205566\n",
      "2018-11-26 12:57:37,246 INFO Layer 345: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:37,248 INFO Layer 345: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:37,250 INFO Layer 346: ReLU(inplace)\n",
      "2018-11-26 12:57:37,253 INFO Layer 346: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:37,258 INFO Layer 347: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:37,261 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:37,263 INFO Layer 347: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:37,266 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:37,270 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:37,273 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:37,276 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:37,279 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:37,282 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:37,285 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:37,293 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:37,296 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:37,299 INFO Layer 348: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:37,302 INFO Layer 348: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:37,305 INFO Layer 349: BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:37,307 INFO Layer 349: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:37,310 INFO Layer 350: ReLU(inplace)\n",
      "2018-11-26 12:57:37,313 INFO Layer 350: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:37,317 INFO Layer 351: Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:37,327 INFO Pytorch tensor shape detected: 128x1184 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:37,330 INFO Layer 351: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:37,334 INFO     Weight matrix 1/1 (128,1184): Analyzing ...\n",
      "2018-11-26 12:57:38,441 INFO     Weight matrix 1/1 (128,1184): Alpha: 2.198257136050932, Alpha Weighted: -0.1627496623439139, D: 0.15151041863058667\n",
      "2018-11-26 12:57:38,444 INFO     Weight matrix 1/1 (128,1184): Lognorm: 0.7148630619049072\n",
      "2018-11-26 12:57:38,447 INFO Layer 352: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:38,450 INFO Layer 352: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:38,452 INFO Layer 353: ReLU(inplace)\n",
      "2018-11-26 12:57:38,455 INFO Layer 353: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:38,458 INFO Layer 354: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:38,461 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:38,464 INFO Layer 354: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:38,466 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:38,468 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:38,471 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:38,473 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:38,477 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:38,484 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:38,486 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:38,490 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:38,493 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:38,499 INFO Layer 355: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:38,502 INFO Layer 355: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:38,505 INFO Layer 356: BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:38,508 INFO Layer 356: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:38,511 INFO Layer 357: ReLU(inplace)\n",
      "2018-11-26 12:57:38,514 INFO Layer 357: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:38,517 INFO Layer 358: Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:38,523 INFO Pytorch tensor shape detected: 128x1216 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:38,526 INFO Layer 358: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:38,529 INFO     Weight matrix 1/1 (128,1216): Analyzing ...\n",
      "2018-11-26 12:57:39,666 INFO     Weight matrix 1/1 (128,1216): Alpha: 3.1104971875642824, Alpha Weighted: 0.17075427316223535, D: 0.128619454202744\n",
      "2018-11-26 12:57:39,670 INFO     Weight matrix 1/1 (128,1216): Lognorm: 0.7356852889060974\n",
      "2018-11-26 12:57:39,673 INFO Layer 359: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:39,676 INFO Layer 359: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:39,678 INFO Layer 360: ReLU(inplace)\n",
      "2018-11-26 12:57:39,681 INFO Layer 360: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:39,685 INFO Layer 361: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:39,688 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:39,693 INFO Layer 361: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:39,696 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:39,698 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:39,701 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:39,704 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:39,707 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:39,709 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:39,712 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:39,715 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:39,718 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:39,721 INFO Layer 362: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:39,725 INFO Layer 362: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:39,728 INFO Layer 363: BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:39,731 INFO Layer 363: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:39,734 INFO Layer 364: ReLU(inplace)\n",
      "2018-11-26 12:57:39,738 INFO Layer 364: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:39,741 INFO Layer 365: Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:39,746 INFO Pytorch tensor shape detected: 128x1248 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:39,750 INFO Layer 365: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:39,755 INFO     Weight matrix 1/1 (128,1248): Analyzing ...\n",
      "2018-11-26 12:57:40,924 INFO     Weight matrix 1/1 (128,1248): Alpha: 3.069971426823827, Alpha Weighted: -0.07296624694112736, D: 0.1353631585912397\n",
      "2018-11-26 12:57:40,928 INFO     Weight matrix 1/1 (128,1248): Lognorm: 0.7214874029159546\n",
      "2018-11-26 12:57:40,932 INFO Layer 366: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:40,935 INFO Layer 366: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:40,938 INFO Layer 367: ReLU(inplace)\n",
      "2018-11-26 12:57:40,941 INFO Layer 367: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:40,943 INFO Layer 368: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:40,948 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:40,950 INFO Layer 368: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:40,953 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:40,956 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:40,960 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:40,963 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:40,966 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:40,970 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:40,973 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:40,977 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:40,980 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:40,984 INFO Layer 369: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:40,987 INFO Layer 369: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:40,990 INFO Layer 370: BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:40,996 INFO Layer 370: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:40,998 INFO Layer 371: ReLU(inplace)\n",
      "2018-11-26 12:57:41,002 INFO Layer 371: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:41,005 INFO Layer 372: Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:41,009 INFO Pytorch tensor shape detected: 128x1280 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:41,014 INFO Layer 372: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:41,018 INFO     Weight matrix 1/1 (128,1280): Analyzing ...\n",
      "2018-11-26 12:57:42,254 INFO     Weight matrix 1/1 (128,1280): Alpha: 2.236870798676037, Alpha Weighted: 0.5026357099931635, D: 0.10801491555972059\n",
      "2018-11-26 12:57:42,259 INFO     Weight matrix 1/1 (128,1280): Lognorm: 0.772777259349823\n",
      "2018-11-26 12:57:42,262 INFO Layer 373: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:42,265 INFO Layer 373: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:42,268 INFO Layer 374: ReLU(inplace)\n",
      "2018-11-26 12:57:42,272 INFO Layer 374: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:42,275 INFO Layer 375: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:42,279 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:42,282 INFO Layer 375: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:42,286 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:42,291 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:42,294 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:42,297 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:42,300 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:42,303 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:42,307 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:42,309 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:42,312 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:42,316 INFO Layer 376: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:42,320 INFO Layer 376: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:42,324 INFO Layer 377: BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:42,326 INFO Layer 377: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:42,330 INFO Layer 378: ReLU(inplace)\n",
      "2018-11-26 12:57:42,336 INFO Layer 378: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:42,339 INFO Layer 379: Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:42,344 INFO Pytorch tensor shape detected: 128x1312 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:42,347 INFO Layer 379: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:42,349 INFO     Weight matrix 1/1 (128,1312): Analyzing ...\n",
      "2018-11-26 12:57:43,657 INFO     Weight matrix 1/1 (128,1312): Alpha: 2.2033994484111923, Alpha Weighted: 0.4494840559392094, D: 0.125158934021668\n",
      "2018-11-26 12:57:43,660 INFO     Weight matrix 1/1 (128,1312): Lognorm: 0.7553160190582275\n",
      "2018-11-26 12:57:43,662 INFO Layer 380: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:43,666 INFO Layer 380: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:43,670 INFO Layer 381: ReLU(inplace)\n",
      "2018-11-26 12:57:43,674 INFO Layer 381: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:43,678 INFO Layer 382: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:43,684 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:43,687 INFO Layer 382: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:43,692 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:43,695 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:43,698 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:43,702 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:43,705 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:43,708 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:43,711 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:43,715 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:43,718 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:43,721 INFO Layer 383: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:43,724 INFO Layer 383: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:43,727 INFO Layer 384: BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:43,731 INFO Layer 384: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:43,734 INFO Layer 385: ReLU(inplace)\n",
      "2018-11-26 12:57:43,738 INFO Layer 385: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:43,741 INFO Layer 386: Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:43,748 INFO Pytorch tensor shape detected: 128x1344 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:43,751 INFO Layer 386: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:43,754 INFO     Weight matrix 1/1 (128,1344): Analyzing ...\n",
      "2018-11-26 12:57:44,962 INFO     Weight matrix 1/1 (128,1344): Alpha: 3.9745173235477975, Alpha Weighted: 0.6475066195279954, D: 0.09619323654802914\n",
      "2018-11-26 12:57:44,966 INFO     Weight matrix 1/1 (128,1344): Alpha 3.9745173235477975 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:44,974 INFO     Weight matrix 1/1 (128,1344): Lognorm: 0.7722168564796448\n",
      "2018-11-26 12:57:44,978 INFO Layer 387: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:44,985 INFO Layer 387: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:44,989 INFO Layer 388: ReLU(inplace)\n",
      "2018-11-26 12:57:44,993 INFO Layer 388: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:44,996 INFO Layer 389: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:44,999 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:45,002 INFO Layer 389: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:45,005 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:45,009 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:45,012 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:45,016 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:45,019 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:45,023 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:45,025 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:45,030 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:45,033 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:45,036 INFO Layer 390: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:45,040 INFO Layer 390: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:45,043 INFO Layer 391: BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:45,046 INFO Layer 391: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:45,050 INFO Layer 392: ReLU(inplace)\n",
      "2018-11-26 12:57:45,052 INFO Layer 392: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:45,054 INFO Layer 393: Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:45,059 INFO Pytorch tensor shape detected: 128x1376 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:45,061 INFO Layer 393: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:45,064 INFO     Weight matrix 1/1 (128,1376): Analyzing ...\n",
      "2018-11-26 12:57:46,472 INFO     Weight matrix 1/1 (128,1376): Alpha: 5.680001854853063, Alpha Weighted: 0.3353344376213078, D: 0.12101504550507047\n",
      "2018-11-26 12:57:46,475 INFO     Weight matrix 1/1 (128,1376): Alpha 5.680001854853063 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:46,481 INFO     Weight matrix 1/1 (128,1376): Lognorm: 0.7412845492362976\n",
      "2018-11-26 12:57:46,484 INFO Layer 394: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:46,490 INFO Layer 394: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:46,493 INFO Layer 395: ReLU(inplace)\n",
      "2018-11-26 12:57:46,496 INFO Layer 395: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:46,499 INFO Layer 396: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:46,505 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:46,512 INFO Layer 396: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:46,520 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:46,523 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:46,528 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:46,539 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:46,545 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:46,549 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:46,554 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:46,560 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:46,564 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:46,567 INFO Layer 397: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:46,574 INFO Layer 397: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:46,577 INFO Layer 398: BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:46,583 INFO Layer 398: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:46,588 INFO Layer 399: ReLU(inplace)\n",
      "2018-11-26 12:57:46,595 INFO Layer 399: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:46,599 INFO Layer 400: Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:46,606 INFO Pytorch tensor shape detected: 128x1408 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:46,610 INFO Layer 400: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:46,613 INFO     Weight matrix 1/1 (128,1408): Analyzing ...\n",
      "2018-11-26 12:57:47,950 INFO     Weight matrix 1/1 (128,1408): Alpha: 4.296300273065496, Alpha Weighted: 0.04364132022653738, D: 0.14732966465451036\n",
      "2018-11-26 12:57:47,953 INFO     Weight matrix 1/1 (128,1408): Alpha 4.296300273065496 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:47,956 INFO     Weight matrix 1/1 (128,1408): Lognorm: 0.7412115335464478\n",
      "2018-11-26 12:57:47,959 INFO Layer 401: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:47,961 INFO Layer 401: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:47,964 INFO Layer 402: ReLU(inplace)\n",
      "2018-11-26 12:57:47,970 INFO Layer 402: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:47,972 INFO Layer 403: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:47,977 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:47,982 INFO Layer 403: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:47,985 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:47,988 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:47,993 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:47,995 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:47,999 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:48,003 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:48,005 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:48,008 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:48,010 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:48,013 INFO Layer 404: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:48,017 INFO Layer 404: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:48,020 INFO Layer 405: BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:48,024 INFO Layer 405: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:48,027 INFO Layer 406: ReLU(inplace)\n",
      "2018-11-26 12:57:48,031 INFO Layer 406: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:48,036 INFO Layer 407: Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:48,042 INFO Pytorch tensor shape detected: 128x1440 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:48,047 INFO Layer 407: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:48,051 INFO     Weight matrix 1/1 (128,1440): Analyzing ...\n",
      "2018-11-26 12:57:49,310 INFO     Weight matrix 1/1 (128,1440): Alpha: 2.4485418986076093, Alpha Weighted: 0.26695241193328434, D: 0.1145168699358845\n",
      "2018-11-26 12:57:49,313 INFO     Weight matrix 1/1 (128,1440): Lognorm: 0.7664781808853149\n",
      "2018-11-26 12:57:49,315 INFO Layer 408: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:49,319 INFO Layer 408: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:49,322 INFO Layer 409: ReLU(inplace)\n",
      "2018-11-26 12:57:49,326 INFO Layer 409: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:49,330 INFO Layer 410: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:49,334 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:49,336 INFO Layer 410: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:49,340 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:49,343 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:49,346 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:49,349 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:49,352 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:49,355 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:49,357 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:49,359 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:49,362 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:49,365 INFO Layer 411: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:49,368 INFO Layer 411: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:49,370 INFO Layer 412: BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:49,373 INFO Layer 412: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:49,376 INFO Layer 413: ReLU(inplace)\n",
      "2018-11-26 12:57:49,379 INFO Layer 413: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:49,383 INFO Layer 414: Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:49,388 INFO Pytorch tensor shape detected: 128x1472 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:49,394 INFO Layer 414: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:49,397 INFO     Weight matrix 1/1 (128,1472): Analyzing ...\n",
      "2018-11-26 12:57:50,538 INFO     Weight matrix 1/1 (128,1472): Alpha: 3.1500770991353, Alpha Weighted: 0.31536548981362367, D: 0.11819646251302085\n",
      "2018-11-26 12:57:50,541 INFO     Weight matrix 1/1 (128,1472): Lognorm: 0.7630085945129395\n",
      "2018-11-26 12:57:50,544 INFO Layer 415: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:50,547 INFO Layer 415: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:50,550 INFO Layer 416: ReLU(inplace)\n",
      "2018-11-26 12:57:50,556 INFO Layer 416: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:50,559 INFO Layer 417: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:50,562 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:50,565 INFO Layer 417: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:50,568 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:50,571 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:50,574 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:50,577 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:50,580 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:50,586 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:50,591 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:50,599 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:50,602 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:50,605 INFO Layer 418: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:50,608 INFO Layer 418: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:50,612 INFO Layer 419: BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:50,614 INFO Layer 419: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:50,618 INFO Layer 420: ReLU(inplace)\n",
      "2018-11-26 12:57:50,621 INFO Layer 420: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:50,624 INFO Layer 421: Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:50,628 INFO Pytorch tensor shape detected: 128x1504 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:50,630 INFO Layer 421: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:50,633 INFO     Weight matrix 1/1 (128,1504): Analyzing ...\n",
      "2018-11-26 12:57:51,771 INFO     Weight matrix 1/1 (128,1504): Alpha: 7.285787245702748, Alpha Weighted: 0.33077936311659883, D: 0.11997307591277329\n",
      "2018-11-26 12:57:51,773 INFO     Weight matrix 1/1 (128,1504): Alpha 7.285787245702748 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:51,776 INFO     Weight matrix 1/1 (128,1504): Lognorm: 0.7728256583213806\n",
      "2018-11-26 12:57:51,778 INFO Layer 422: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:51,781 INFO Layer 422: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:51,783 INFO Layer 423: ReLU(inplace)\n",
      "2018-11-26 12:57:51,785 INFO Layer 423: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:51,788 INFO Layer 424: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:51,791 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:51,794 INFO Layer 424: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:51,796 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:51,799 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:51,802 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:51,805 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:51,808 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:51,810 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:51,814 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:51,820 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:51,823 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:51,826 INFO Layer 425: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:51,828 INFO Layer 425: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:51,831 INFO Layer 426: BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:51,835 INFO Layer 426: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:51,838 INFO Layer 427: ReLU(inplace)\n",
      "2018-11-26 12:57:51,841 INFO Layer 427: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:51,844 INFO Layer 428: Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:51,849 INFO Pytorch tensor shape detected: 128x1536 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:51,851 INFO Layer 428: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:51,855 INFO     Weight matrix 1/1 (128,1536): Analyzing ...\n",
      "2018-11-26 12:57:53,011 INFO     Weight matrix 1/1 (128,1536): Alpha: 6.012495369277081, Alpha Weighted: 0.9861401152647151, D: 0.07692307692307676\n",
      "2018-11-26 12:57:53,013 INFO     Weight matrix 1/1 (128,1536): Alpha 6.012495369277081 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:53,017 INFO     Weight matrix 1/1 (128,1536): Lognorm: 0.7890831232070923\n",
      "2018-11-26 12:57:53,019 INFO Layer 429: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:53,022 INFO Layer 429: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:53,025 INFO Layer 430: ReLU(inplace)\n",
      "2018-11-26 12:57:53,027 INFO Layer 430: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:53,031 INFO Layer 431: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:53,037 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:53,040 INFO Layer 431: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:53,043 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:53,045 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:53,048 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:53,050 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:53,053 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:53,055 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:53,058 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:53,061 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:53,063 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:53,065 INFO Layer 432: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:53,069 INFO Layer 432: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:53,072 INFO Layer 433: BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:53,075 INFO Layer 433: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:53,077 INFO Layer 434: ReLU(inplace)\n",
      "2018-11-26 12:57:53,080 INFO Layer 434: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:53,084 INFO Layer 435: Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:53,091 INFO Pytorch tensor shape detected: 128x1568 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:53,094 INFO Layer 435: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:53,097 INFO     Weight matrix 1/1 (128,1568): Analyzing ...\n",
      "2018-11-26 12:57:54,294 INFO     Weight matrix 1/1 (128,1568): Alpha: 5.785933792828196, Alpha Weighted: 0.9265330998912238, D: 0.08333333333333315\n",
      "2018-11-26 12:57:54,298 INFO     Weight matrix 1/1 (128,1568): Alpha 5.785933792828196 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:54,301 INFO     Weight matrix 1/1 (128,1568): Lognorm: 0.7760552167892456\n",
      "2018-11-26 12:57:54,303 INFO Layer 436: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:54,306 INFO Layer 436: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:54,308 INFO Layer 437: ReLU(inplace)\n",
      "2018-11-26 12:57:54,310 INFO Layer 437: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:54,313 INFO Layer 438: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:54,317 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:54,320 INFO Layer 438: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:54,323 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:54,325 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:54,328 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:54,331 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:54,334 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:54,338 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:54,340 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:54,342 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:54,346 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:54,349 INFO Layer 439: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:54,353 INFO Layer 439: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:54,357 INFO Layer 440: BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:54,360 INFO Layer 440: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:54,363 INFO Layer 441: ReLU(inplace)\n",
      "2018-11-26 12:57:54,366 INFO Layer 441: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:54,371 INFO Layer 442: Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:54,375 INFO Pytorch tensor shape detected: 128x1600 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:54,377 INFO Layer 442: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:54,381 INFO     Weight matrix 1/1 (128,1600): Analyzing ...\n",
      "2018-11-26 12:57:55,563 INFO     Weight matrix 1/1 (128,1600): Alpha: 6.108008317538168, Alpha Weighted: 0.8129195862514182, D: 0.08333333333333315\n",
      "2018-11-26 12:57:55,565 INFO     Weight matrix 1/1 (128,1600): Alpha 6.108008317538168 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:55,569 INFO     Weight matrix 1/1 (128,1600): Lognorm: 0.782757580280304\n",
      "2018-11-26 12:57:55,571 INFO Layer 443: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:55,574 INFO Layer 443: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:55,577 INFO Layer 444: ReLU(inplace)\n",
      "2018-11-26 12:57:55,580 INFO Layer 444: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:55,582 INFO Layer 445: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:55,585 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:55,589 INFO Layer 445: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:55,591 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:55,593 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:55,596 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:55,599 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:55,602 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:55,605 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:55,608 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:55,612 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:55,615 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:55,618 INFO Layer 446: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:55,620 INFO Layer 446: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:55,623 INFO Layer 447: BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:55,625 INFO Layer 447: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:55,628 INFO Layer 448: ReLU(inplace)\n",
      "2018-11-26 12:57:55,630 INFO Layer 448: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:55,634 INFO Layer 449: Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:55,641 INFO Pytorch tensor shape detected: 128x1632 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:55,644 INFO Layer 449: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:55,646 INFO     Weight matrix 1/1 (128,1632): Analyzing ...\n",
      "2018-11-26 12:57:56,817 INFO     Weight matrix 1/1 (128,1632): Alpha: 2.635781032381538, Alpha Weighted: 0.782700394827319, D: 0.09615200843656535\n",
      "2018-11-26 12:57:56,821 INFO     Weight matrix 1/1 (128,1632): Lognorm: 0.7759987115859985\n",
      "2018-11-26 12:57:56,824 INFO Layer 450: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:56,826 INFO Layer 450: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:56,829 INFO Layer 451: ReLU(inplace)\n",
      "2018-11-26 12:57:56,831 INFO Layer 451: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:56,838 INFO Layer 452: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:56,841 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:56,844 INFO Layer 452: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:56,848 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:56,851 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:56,853 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:56,856 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:56,858 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:56,862 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:56,864 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:56,867 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:56,871 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:56,875 INFO Layer 453: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:57:56,878 INFO Layer 453: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:56,881 INFO Layer 454: BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:56,883 INFO Layer 454: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:56,887 INFO Layer 455: ReLU(inplace)\n",
      "2018-11-26 12:57:56,890 INFO Layer 455: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:56,892 INFO Layer 456: Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:56,898 INFO Pytorch tensor shape detected: 128x1664 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:56,900 INFO Layer 456: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:56,902 INFO     Weight matrix 1/1 (128,1664): Analyzing ...\n",
      "2018-11-26 12:57:58,052 INFO     Weight matrix 1/1 (128,1664): Alpha: 4.846493435353816, Alpha Weighted: 0.6129859977157626, D: 0.11641419514783136\n",
      "2018-11-26 12:57:58,055 INFO     Weight matrix 1/1 (128,1664): Alpha 4.846493435353816 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:58,058 INFO     Weight matrix 1/1 (128,1664): Lognorm: 0.7648581862449646\n",
      "2018-11-26 12:57:58,060 INFO Layer 457: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:58,063 INFO Layer 457: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:58,067 INFO Layer 458: ReLU(inplace)\n",
      "2018-11-26 12:57:58,070 INFO Layer 458: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:58,073 INFO Layer 459: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:58,076 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:58,078 INFO Layer 459: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:58,082 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:58,084 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:58,089 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:58,092 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:58,095 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:58,098 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:58,101 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:58,104 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:58,109 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:58,112 INFO Layer 460: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:58,116 INFO Layer 460: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:58,119 INFO Layer 461: BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:58,122 INFO Layer 461: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:58,127 INFO Layer 462: ReLU(inplace)\n",
      "2018-11-26 12:57:58,130 INFO Layer 462: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:58,132 INFO Layer 463: Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:58,138 INFO Pytorch tensor shape detected: 128x1696 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:58,141 INFO Layer 463: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:58,144 INFO     Weight matrix 1/1 (128,1696): Analyzing ...\n",
      "2018-11-26 12:57:59,314 INFO     Weight matrix 1/1 (128,1696): Alpha: 4.8643011116139405, Alpha Weighted: 0.7991777554262778, D: 0.08786638740431985\n",
      "2018-11-26 12:57:59,316 INFO     Weight matrix 1/1 (128,1696): Alpha 4.8643011116139405 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:57:59,320 INFO     Weight matrix 1/1 (128,1696): Lognorm: 0.7842831611633301\n",
      "2018-11-26 12:57:59,324 INFO Layer 464: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:59,327 INFO Layer 464: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:59,330 INFO Layer 465: ReLU(inplace)\n",
      "2018-11-26 12:57:59,334 INFO Layer 465: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:59,338 INFO Layer 466: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:57:59,342 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:57:59,345 INFO Layer 466: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:57:59,349 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:59,351 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:59,355 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:59,357 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:59,360 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:59,363 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:59,365 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:59,368 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:59,371 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:57:59,375 INFO Layer 467: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:57:59,379 INFO Layer 467: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:59,383 INFO Layer 468: BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:57:59,386 INFO Layer 468: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:59,392 INFO Layer 469: ReLU(inplace)\n",
      "2018-11-26 12:57:59,395 INFO Layer 469: Skipping (Layer not supported)\n",
      "2018-11-26 12:57:59,399 INFO Layer 470: Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:57:59,402 INFO Pytorch tensor shape detected: 128x1728 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:57:59,405 INFO Layer 470: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:57:59,407 INFO     Weight matrix 1/1 (128,1728): Analyzing ...\n",
      "2018-11-26 12:58:00,574 INFO     Weight matrix 1/1 (128,1728): Alpha: 3.613576798062647, Alpha Weighted: 0.5548297135053051, D: 0.11255991155468675\n",
      "2018-11-26 12:58:00,577 INFO     Weight matrix 1/1 (128,1728): Alpha 3.613576798062647 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:00,580 INFO     Weight matrix 1/1 (128,1728): Lognorm: 0.7816086411476135\n",
      "2018-11-26 12:58:00,590 INFO Layer 471: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:00,595 INFO Layer 471: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:00,599 INFO Layer 472: ReLU(inplace)\n",
      "2018-11-26 12:58:00,602 INFO Layer 472: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:00,604 INFO Layer 473: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:00,608 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:00,611 INFO Layer 473: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:00,614 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:00,617 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:00,620 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:00,622 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:00,625 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:00,628 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:00,631 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:00,634 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:00,637 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:00,639 INFO Layer 474: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:00,642 INFO Layer 474: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:00,645 INFO Layer 475: BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:00,648 INFO Layer 475: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:00,650 INFO Layer 476: ReLU(inplace)\n",
      "2018-11-26 12:58:00,653 INFO Layer 476: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:00,656 INFO Layer 477: Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:00,663 INFO Pytorch tensor shape detected: 128x1760 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:00,665 INFO Layer 477: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:00,669 INFO     Weight matrix 1/1 (128,1760): Analyzing ...\n",
      "2018-11-26 12:58:02,064 INFO     Weight matrix 1/1 (128,1760): Alpha: 4.958305922700012, Alpha Weighted: 0.9568900379124826, D: 0.08829997186997107\n",
      "2018-11-26 12:58:02,067 INFO     Weight matrix 1/1 (128,1760): Alpha 4.958305922700012 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:02,070 INFO     Weight matrix 1/1 (128,1760): Lognorm: 0.7886970639228821\n",
      "2018-11-26 12:58:02,073 INFO Layer 478: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:02,075 INFO Layer 478: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:02,078 INFO Layer 479: ReLU(inplace)\n",
      "2018-11-26 12:58:02,080 INFO Layer 479: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:02,083 INFO Layer 480: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:02,087 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:02,089 INFO Layer 480: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:02,093 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:02,096 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:02,098 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:02,101 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:02,104 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:02,106 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:02,109 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:02,112 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:02,114 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:02,118 INFO Layer 481: _Transition(\n",
      "  (norm): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv): Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "2018-11-26 12:58:02,121 INFO Layer 481: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:02,128 INFO Layer 482: BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:02,133 INFO Layer 482: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:02,137 INFO Layer 483: ReLU(inplace)\n",
      "2018-11-26 12:58:02,139 INFO Layer 483: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:02,143 INFO Layer 484: Conv2d(1792, 896, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:02,177 INFO Pytorch tensor shape detected: 896x1792 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:02,180 INFO Layer 484: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:02,185 INFO     Weight matrix 1/1 (896,1792): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:58:02,188 INFO Layer 485: AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "2018-11-26 12:58:02,192 INFO Layer 485: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:02,201 INFO Layer 486: _DenseBlock(\n",
      "  (denselayer1): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer7): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer8): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer9): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer10): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer11): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer12): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer13): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer14): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer15): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer16): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer17): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer18): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer19): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer20): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer21): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer22): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer23): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer24): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer25): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer26): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer27): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer28): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer29): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer30): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer31): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer32): _DenseLayer(\n",
      "    (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU(inplace)\n",
      "    (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:02,204 INFO Layer 486: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:02,210 INFO Layer 487: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:02,213 INFO Layer 487: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:02,216 INFO Layer 488: BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:02,220 INFO Layer 488: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:02,224 INFO Layer 489: ReLU(inplace)\n",
      "2018-11-26 12:58:02,227 INFO Layer 489: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:02,230 INFO Layer 490: Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:02,236 INFO Pytorch tensor shape detected: 128x896 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:02,243 INFO Layer 490: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:02,246 INFO     Weight matrix 1/1 (128,896): Analyzing ...\n",
      "2018-11-26 12:58:03,551 INFO     Weight matrix 1/1 (128,896): Alpha: 3.1967187087811455, Alpha Weighted: -0.3594671481493354, D: 0.1638545368285267\n",
      "2018-11-26 12:58:03,554 INFO     Weight matrix 1/1 (128,896): Lognorm: 0.7102020978927612\n",
      "2018-11-26 12:58:03,556 INFO Layer 491: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:03,559 INFO Layer 491: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:03,562 INFO Layer 492: ReLU(inplace)\n",
      "2018-11-26 12:58:03,566 INFO Layer 492: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:03,569 INFO Layer 493: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:03,573 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:03,575 INFO Layer 493: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:03,579 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:03,581 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:03,585 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:03,588 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:03,590 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:03,593 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:03,597 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:03,600 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:03,602 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:03,605 INFO Layer 494: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:03,608 INFO Layer 494: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:03,610 INFO Layer 495: BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:03,613 INFO Layer 495: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:03,616 INFO Layer 496: ReLU(inplace)\n",
      "2018-11-26 12:58:03,620 INFO Layer 496: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:03,623 INFO Layer 497: Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:03,628 INFO Pytorch tensor shape detected: 128x928 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:03,632 INFO Layer 497: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:03,635 INFO     Weight matrix 1/1 (128,928): Analyzing ...\n",
      "2018-11-26 12:58:04,984 INFO     Weight matrix 1/1 (128,928): Alpha: 4.087275832100719, Alpha Weighted: -0.3668515488712201, D: 0.15673358303635565\n",
      "2018-11-26 12:58:04,986 INFO     Weight matrix 1/1 (128,928): Alpha 4.087275832100719 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:04,991 INFO     Weight matrix 1/1 (128,928): Lognorm: 0.6968818306922913\n",
      "2018-11-26 12:58:04,994 INFO Layer 498: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:04,997 INFO Layer 498: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:05,000 INFO Layer 499: ReLU(inplace)\n",
      "2018-11-26 12:58:05,003 INFO Layer 499: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:05,006 INFO Layer 500: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:05,010 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:05,013 INFO Layer 500: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:05,016 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:05,019 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:05,022 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:05,027 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:05,031 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:05,038 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:05,043 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:05,046 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:05,049 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:05,053 INFO Layer 501: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:05,057 INFO Layer 501: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:05,060 INFO Layer 502: BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:05,062 INFO Layer 502: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:05,065 INFO Layer 503: ReLU(inplace)\n",
      "2018-11-26 12:58:05,068 INFO Layer 503: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:05,080 INFO Layer 504: Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:05,087 INFO Pytorch tensor shape detected: 128x960 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:05,090 INFO Layer 504: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:05,094 INFO     Weight matrix 1/1 (128,960): Analyzing ...\n",
      "2018-11-26 12:58:06,418 INFO     Weight matrix 1/1 (128,960): Alpha: 4.539249315051804, Alpha Weighted: 0.0702731536354072, D: 0.11502591984426264\n",
      "2018-11-26 12:58:06,421 INFO     Weight matrix 1/1 (128,960): Alpha 4.539249315051804 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:06,428 INFO     Weight matrix 1/1 (128,960): Lognorm: 0.7062215805053711\n",
      "2018-11-26 12:58:06,431 INFO Layer 505: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:06,434 INFO Layer 505: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:06,437 INFO Layer 506: ReLU(inplace)\n",
      "2018-11-26 12:58:06,441 INFO Layer 506: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:06,445 INFO Layer 507: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:06,448 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:06,451 INFO Layer 507: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:06,454 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:06,457 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:06,461 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:06,465 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:06,468 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:06,471 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:06,477 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:06,480 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:06,483 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:06,488 INFO Layer 508: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:06,490 INFO Layer 508: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:06,494 INFO Layer 509: BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:06,497 INFO Layer 509: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:06,500 INFO Layer 510: ReLU(inplace)\n",
      "2018-11-26 12:58:06,503 INFO Layer 510: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:06,506 INFO Layer 511: Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:06,510 INFO Pytorch tensor shape detected: 128x992 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:06,514 INFO Layer 511: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:06,518 INFO     Weight matrix 1/1 (128,992): Analyzing ...\n",
      "2018-11-26 12:58:08,018 INFO     Weight matrix 1/1 (128,992): Alpha: 2.2740599302309104, Alpha Weighted: -0.2998432151044098, D: 0.18770691808823392\n",
      "2018-11-26 12:58:08,021 INFO     Weight matrix 1/1 (128,992): Lognorm: 0.7191216945648193\n",
      "2018-11-26 12:58:08,028 INFO Layer 512: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:08,034 INFO Layer 512: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:08,038 INFO Layer 513: ReLU(inplace)\n",
      "2018-11-26 12:58:08,042 INFO Layer 513: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:08,045 INFO Layer 514: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:08,057 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:08,061 INFO Layer 514: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:08,065 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:08,070 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:08,077 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:08,084 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:08,089 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:08,093 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:08,100 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:08,104 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:08,108 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:08,111 INFO Layer 515: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:08,116 INFO Layer 515: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:08,120 INFO Layer 516: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:08,125 INFO Layer 516: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:08,130 INFO Layer 517: ReLU(inplace)\n",
      "2018-11-26 12:58:08,144 INFO Layer 517: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:08,149 INFO Layer 518: Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:08,156 INFO Pytorch tensor shape detected: 128x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:08,160 INFO Layer 518: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:08,164 INFO     Weight matrix 1/1 (128,1024): Analyzing ...\n",
      "2018-11-26 12:58:09,556 INFO     Weight matrix 1/1 (128,1024): Alpha: 4.788876626359231, Alpha Weighted: 0.4865609914903658, D: 0.1237203346986151\n",
      "2018-11-26 12:58:09,558 INFO     Weight matrix 1/1 (128,1024): Alpha 4.788876626359231 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:09,561 INFO     Weight matrix 1/1 (128,1024): Lognorm: 0.722057044506073\n",
      "2018-11-26 12:58:09,564 INFO Layer 519: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:09,568 INFO Layer 519: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:09,572 INFO Layer 520: ReLU(inplace)\n",
      "2018-11-26 12:58:09,575 INFO Layer 520: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:09,578 INFO Layer 521: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:09,582 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:09,586 INFO Layer 521: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:09,590 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:09,593 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:09,597 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:09,608 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:09,613 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:09,617 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:09,620 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:09,627 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:09,631 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:09,635 INFO Layer 522: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:09,638 INFO Layer 522: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:09,642 INFO Layer 523: BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:09,645 INFO Layer 523: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:09,648 INFO Layer 524: ReLU(inplace)\n",
      "2018-11-26 12:58:09,651 INFO Layer 524: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:09,655 INFO Layer 525: Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:09,660 INFO Pytorch tensor shape detected: 128x1056 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:09,662 INFO Layer 525: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:09,667 INFO     Weight matrix 1/1 (128,1056): Analyzing ...\n",
      "2018-11-26 12:58:11,070 INFO     Weight matrix 1/1 (128,1056): Alpha: 5.231885513405296, Alpha Weighted: -0.014999514596075075, D: 0.09112033419092314\n",
      "2018-11-26 12:58:11,072 INFO     Weight matrix 1/1 (128,1056): Alpha 5.231885513405296 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:11,077 INFO     Weight matrix 1/1 (128,1056): Lognorm: 0.7418020963668823\n",
      "2018-11-26 12:58:11,081 INFO Layer 526: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:11,084 INFO Layer 526: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:11,088 INFO Layer 527: ReLU(inplace)\n",
      "2018-11-26 12:58:11,091 INFO Layer 527: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:11,094 INFO Layer 528: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:11,098 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:11,100 INFO Layer 528: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:11,104 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:11,107 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:11,111 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:11,118 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:11,121 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:11,125 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:11,130 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:11,134 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:11,137 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:11,142 INFO Layer 529: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:11,147 INFO Layer 529: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:11,153 INFO Layer 530: BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:11,156 INFO Layer 530: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:11,161 INFO Layer 531: ReLU(inplace)\n",
      "2018-11-26 12:58:11,167 INFO Layer 531: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:11,181 INFO Layer 532: Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:11,186 INFO Pytorch tensor shape detected: 128x1088 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:11,197 INFO Layer 532: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:11,206 INFO     Weight matrix 1/1 (128,1088): Analyzing ...\n",
      "2018-11-26 12:58:12,549 INFO     Weight matrix 1/1 (128,1088): Alpha: 7.450872986952545, Alpha Weighted: 0.4957275392215457, D: 0.11111111111111094\n",
      "2018-11-26 12:58:12,552 INFO     Weight matrix 1/1 (128,1088): Alpha 7.450872986952545 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:12,555 INFO     Weight matrix 1/1 (128,1088): Lognorm: 0.7736302614212036\n",
      "2018-11-26 12:58:12,558 INFO Layer 533: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:12,561 INFO Layer 533: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:12,564 INFO Layer 534: ReLU(inplace)\n",
      "2018-11-26 12:58:12,569 INFO Layer 534: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:12,573 INFO Layer 535: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:12,577 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:12,581 INFO Layer 535: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:12,587 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:12,593 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:12,598 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:12,601 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:12,605 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:12,610 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:12,614 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:12,617 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:12,622 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:12,629 INFO Layer 536: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:12,638 INFO Layer 536: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:12,642 INFO Layer 537: BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:12,645 INFO Layer 537: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:12,649 INFO Layer 538: ReLU(inplace)\n",
      "2018-11-26 12:58:12,652 INFO Layer 538: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:12,655 INFO Layer 539: Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:12,661 INFO Pytorch tensor shape detected: 128x1120 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:12,664 INFO Layer 539: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:12,667 INFO     Weight matrix 1/1 (128,1120): Analyzing ...\n",
      "2018-11-26 12:58:14,051 INFO     Weight matrix 1/1 (128,1120): Alpha: 5.042886646120866, Alpha Weighted: 0.5212087036311616, D: 0.08460025787445102\n",
      "2018-11-26 12:58:14,053 INFO     Weight matrix 1/1 (128,1120): Alpha 5.042886646120866 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:14,056 INFO     Weight matrix 1/1 (128,1120): Lognorm: 0.7669708132743835\n",
      "2018-11-26 12:58:14,060 INFO Layer 540: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:14,063 INFO Layer 540: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:14,066 INFO Layer 541: ReLU(inplace)\n",
      "2018-11-26 12:58:14,069 INFO Layer 541: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:14,074 INFO Layer 542: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:14,078 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:14,080 INFO Layer 542: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:14,083 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:14,087 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:14,089 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:14,092 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:14,096 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:14,099 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:14,102 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:14,105 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:14,109 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:14,113 INFO Layer 543: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:14,115 INFO Layer 543: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:14,118 INFO Layer 544: BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:14,121 INFO Layer 544: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:14,124 INFO Layer 545: ReLU(inplace)\n",
      "2018-11-26 12:58:14,127 INFO Layer 545: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:14,129 INFO Layer 546: Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:14,133 INFO Pytorch tensor shape detected: 128x1152 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:14,136 INFO Layer 546: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:14,139 INFO     Weight matrix 1/1 (128,1152): Analyzing ...\n",
      "2018-11-26 12:58:15,402 INFO     Weight matrix 1/1 (128,1152): Alpha: 4.637329497216912, Alpha Weighted: 0.9199176697067997, D: 0.08863318813097398\n",
      "2018-11-26 12:58:15,405 INFO     Weight matrix 1/1 (128,1152): Alpha 4.637329497216912 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:15,409 INFO     Weight matrix 1/1 (128,1152): Lognorm: 0.7952290773391724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:15,413 INFO Layer 547: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:15,417 INFO Layer 547: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:15,420 INFO Layer 548: ReLU(inplace)\n",
      "2018-11-26 12:58:15,424 INFO Layer 548: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:15,427 INFO Layer 549: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:15,432 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:15,435 INFO Layer 549: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:15,440 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:15,444 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:15,448 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:15,452 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:15,455 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:15,458 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:15,462 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:15,466 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:15,470 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:15,474 INFO Layer 550: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:15,478 INFO Layer 550: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:15,482 INFO Layer 551: BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:15,485 INFO Layer 551: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:15,490 INFO Layer 552: ReLU(inplace)\n",
      "2018-11-26 12:58:15,493 INFO Layer 552: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:15,497 INFO Layer 553: Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:15,502 INFO Pytorch tensor shape detected: 128x1184 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:15,505 INFO Layer 553: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:15,507 INFO     Weight matrix 1/1 (128,1184): Analyzing ...\n",
      "2018-11-26 12:58:16,762 INFO     Weight matrix 1/1 (128,1184): Alpha: 5.627413362964799, Alpha Weighted: 0.7663161546351969, D: 0.07692307692307676\n",
      "2018-11-26 12:58:16,765 INFO     Weight matrix 1/1 (128,1184): Alpha 5.627413362964799 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:16,769 INFO     Weight matrix 1/1 (128,1184): Lognorm: 0.7446065545082092\n",
      "2018-11-26 12:58:16,772 INFO Layer 554: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:16,776 INFO Layer 554: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:16,778 INFO Layer 555: ReLU(inplace)\n",
      "2018-11-26 12:58:16,781 INFO Layer 555: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:16,784 INFO Layer 556: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:16,787 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:16,789 INFO Layer 556: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:16,791 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:16,794 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:16,797 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:16,799 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:16,802 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:16,805 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:16,808 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:16,811 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:16,814 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:16,817 INFO Layer 557: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:16,820 INFO Layer 557: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:16,823 INFO Layer 558: BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:16,827 INFO Layer 558: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:16,831 INFO Layer 559: ReLU(inplace)\n",
      "2018-11-26 12:58:16,834 INFO Layer 559: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:16,838 INFO Layer 560: Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:16,844 INFO Pytorch tensor shape detected: 128x1216 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:16,847 INFO Layer 560: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:16,850 INFO     Weight matrix 1/1 (128,1216): Analyzing ...\n",
      "2018-11-26 12:58:18,185 INFO     Weight matrix 1/1 (128,1216): Alpha: 4.7197548918147785, Alpha Weighted: 1.1173393382677734, D: 0.09596361601847281\n",
      "2018-11-26 12:58:18,187 INFO     Weight matrix 1/1 (128,1216): Alpha 4.7197548918147785 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:18,190 INFO     Weight matrix 1/1 (128,1216): Lognorm: 0.7870555520057678\n",
      "2018-11-26 12:58:18,193 INFO Layer 561: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:18,196 INFO Layer 561: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:18,198 INFO Layer 562: ReLU(inplace)\n",
      "2018-11-26 12:58:18,201 INFO Layer 562: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:18,204 INFO Layer 563: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:18,209 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:18,211 INFO Layer 563: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:18,214 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:18,217 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:18,220 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:18,222 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:18,226 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:18,228 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:18,231 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:18,234 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:18,238 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:18,242 INFO Layer 564: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:18,244 INFO Layer 564: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:18,247 INFO Layer 565: BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:18,250 INFO Layer 565: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:18,252 INFO Layer 566: ReLU(inplace)\n",
      "2018-11-26 12:58:18,254 INFO Layer 566: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:18,257 INFO Layer 567: Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:18,262 INFO Pytorch tensor shape detected: 128x1248 (NxM), 1x1 (i,j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:18,264 INFO Layer 567: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:18,267 INFO     Weight matrix 1/1 (128,1248): Analyzing ...\n",
      "2018-11-26 12:58:19,500 INFO     Weight matrix 1/1 (128,1248): Alpha: 6.68830698687418, Alpha Weighted: 0.13605061196555687, D: 0.10657696949730056\n",
      "2018-11-26 12:58:19,502 INFO     Weight matrix 1/1 (128,1248): Alpha 6.68830698687418 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:19,506 INFO     Weight matrix 1/1 (128,1248): Lognorm: 0.7566502690315247\n",
      "2018-11-26 12:58:19,508 INFO Layer 568: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:19,511 INFO Layer 568: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:19,513 INFO Layer 569: ReLU(inplace)\n",
      "2018-11-26 12:58:19,516 INFO Layer 569: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:19,518 INFO Layer 570: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:19,522 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:19,524 INFO Layer 570: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:19,527 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:19,529 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:19,532 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:19,535 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:19,538 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:19,540 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:19,543 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:19,546 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:19,549 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:19,552 INFO Layer 571: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:19,555 INFO Layer 571: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:19,557 INFO Layer 572: BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:19,560 INFO Layer 572: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:19,563 INFO Layer 573: ReLU(inplace)\n",
      "2018-11-26 12:58:19,567 INFO Layer 573: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:19,570 INFO Layer 574: Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:19,575 INFO Pytorch tensor shape detected: 128x1280 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:19,577 INFO Layer 574: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:19,580 INFO     Weight matrix 1/1 (128,1280): Analyzing ...\n",
      "2018-11-26 12:58:20,818 INFO     Weight matrix 1/1 (128,1280): Alpha: 5.928652128622533, Alpha Weighted: 0.7675963177688083, D: 0.07692307692307676\n",
      "2018-11-26 12:58:20,822 INFO     Weight matrix 1/1 (128,1280): Alpha 5.928652128622533 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:20,826 INFO     Weight matrix 1/1 (128,1280): Lognorm: 0.7474079132080078\n",
      "2018-11-26 12:58:20,830 INFO Layer 575: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:20,833 INFO Layer 575: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:20,837 INFO Layer 576: ReLU(inplace)\n",
      "2018-11-26 12:58:20,840 INFO Layer 576: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:20,844 INFO Layer 577: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:20,849 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:20,853 INFO Layer 577: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:20,856 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:20,860 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:20,863 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:20,866 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:20,869 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:20,873 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:20,876 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:20,881 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:20,884 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:20,888 INFO Layer 578: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:20,891 INFO Layer 578: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:20,895 INFO Layer 579: BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:20,898 INFO Layer 579: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:20,901 INFO Layer 580: ReLU(inplace)\n",
      "2018-11-26 12:58:20,905 INFO Layer 580: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:20,907 INFO Layer 581: Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:20,912 INFO Pytorch tensor shape detected: 128x1312 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:20,914 INFO Layer 581: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:20,917 INFO     Weight matrix 1/1 (128,1312): Analyzing ...\n",
      "2018-11-26 12:58:22,137 INFO     Weight matrix 1/1 (128,1312): Alpha: 6.247611217123068, Alpha Weighted: 0.3870862610807112, D: 0.07692307692307676\n",
      "2018-11-26 12:58:22,140 INFO     Weight matrix 1/1 (128,1312): Alpha 6.247611217123068 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:22,143 INFO     Weight matrix 1/1 (128,1312): Lognorm: 0.7349714636802673\n",
      "2018-11-26 12:58:22,146 INFO Layer 582: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:22,148 INFO Layer 582: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:22,151 INFO Layer 583: ReLU(inplace)\n",
      "2018-11-26 12:58:22,155 INFO Layer 583: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:22,158 INFO Layer 584: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:22,161 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:22,164 INFO Layer 584: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:22,166 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:22,170 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:22,174 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:22,177 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:22,181 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:22,184 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:22,187 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:22,190 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:22,193 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:22,196 INFO Layer 585: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:22,199 INFO Layer 585: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:22,202 INFO Layer 586: BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:22,205 INFO Layer 586: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:22,208 INFO Layer 587: ReLU(inplace)\n",
      "2018-11-26 12:58:22,210 INFO Layer 587: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:22,213 INFO Layer 588: Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:22,217 INFO Pytorch tensor shape detected: 128x1344 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:22,230 INFO Layer 588: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:22,233 INFO     Weight matrix 1/1 (128,1344): Analyzing ...\n",
      "2018-11-26 12:58:24,024 INFO     Weight matrix 1/1 (128,1344): Alpha: 7.62478331544314, Alpha Weighted: 0.5294041658912931, D: 0.09999999999999987\n",
      "2018-11-26 12:58:24,043 INFO     Weight matrix 1/1 (128,1344): Alpha 7.62478331544314 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:24,050 INFO     Weight matrix 1/1 (128,1344): Lognorm: 0.760839581489563\n",
      "2018-11-26 12:58:24,055 INFO Layer 589: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:24,060 INFO Layer 589: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:24,063 INFO Layer 590: ReLU(inplace)\n",
      "2018-11-26 12:58:24,067 INFO Layer 590: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:24,071 INFO Layer 591: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:24,075 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:24,079 INFO Layer 591: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:24,082 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:24,086 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:24,091 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:24,094 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:24,098 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:24,102 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:24,105 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:24,108 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:24,111 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:24,114 INFO Layer 592: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:24,119 INFO Layer 592: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:24,122 INFO Layer 593: BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:24,125 INFO Layer 593: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:24,128 INFO Layer 594: ReLU(inplace)\n",
      "2018-11-26 12:58:24,132 INFO Layer 594: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:24,135 INFO Layer 595: Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:24,142 INFO Pytorch tensor shape detected: 128x1376 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:24,145 INFO Layer 595: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:24,148 INFO     Weight matrix 1/1 (128,1376): Analyzing ...\n",
      "2018-11-26 12:58:25,604 INFO     Weight matrix 1/1 (128,1376): Alpha: 6.608290999977355, Alpha Weighted: 0.4096857986832565, D: 0.07692307692307676\n",
      "2018-11-26 12:58:25,606 INFO     Weight matrix 1/1 (128,1376): Alpha 6.608290999977355 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:25,610 INFO     Weight matrix 1/1 (128,1376): Lognorm: 0.7599263787269592\n",
      "2018-11-26 12:58:25,612 INFO Layer 596: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:25,615 INFO Layer 596: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:25,619 INFO Layer 597: ReLU(inplace)\n",
      "2018-11-26 12:58:25,622 INFO Layer 597: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:25,625 INFO Layer 598: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:25,629 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:25,634 INFO Layer 598: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:25,638 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:25,643 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:25,646 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:25,649 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:25,653 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:25,657 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:25,659 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:25,663 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:25,666 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:25,670 INFO Layer 599: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:25,677 INFO Layer 599: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:25,681 INFO Layer 600: BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:25,684 INFO Layer 600: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:25,690 INFO Layer 601: ReLU(inplace)\n",
      "2018-11-26 12:58:25,694 INFO Layer 601: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:25,698 INFO Layer 602: Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:25,706 INFO Pytorch tensor shape detected: 128x1408 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:25,709 INFO Layer 602: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:25,713 INFO     Weight matrix 1/1 (128,1408): Analyzing ...\n",
      "2018-11-26 12:58:27,121 INFO     Weight matrix 1/1 (128,1408): Alpha: 7.1522035218275555, Alpha Weighted: 0.7324846313653267, D: 0.09090909090909083\n",
      "2018-11-26 12:58:27,124 INFO     Weight matrix 1/1 (128,1408): Alpha 7.1522035218275555 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:27,128 INFO     Weight matrix 1/1 (128,1408): Lognorm: 0.7551909685134888\n",
      "2018-11-26 12:58:27,131 INFO Layer 603: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:27,133 INFO Layer 603: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:27,135 INFO Layer 604: ReLU(inplace)\n",
      "2018-11-26 12:58:27,138 INFO Layer 604: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:27,141 INFO Layer 605: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:27,144 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:27,147 INFO Layer 605: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:27,150 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:27,152 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:27,155 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:27,157 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:27,159 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:27,162 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:27,165 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:27,168 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:27,170 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:27,172 INFO Layer 606: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:27,175 INFO Layer 606: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:27,178 INFO Layer 607: BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:27,187 INFO Layer 607: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:27,190 INFO Layer 608: ReLU(inplace)\n",
      "2018-11-26 12:58:27,193 INFO Layer 608: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:27,196 INFO Layer 609: Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:27,201 INFO Pytorch tensor shape detected: 128x1440 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:27,203 INFO Layer 609: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:27,206 INFO     Weight matrix 1/1 (128,1440): Analyzing ...\n",
      "2018-11-26 12:58:28,319 INFO     Weight matrix 1/1 (128,1440): Alpha: 6.828787840477588, Alpha Weighted: 0.751519958229239, D: 0.07142857142857129\n",
      "2018-11-26 12:58:28,322 INFO     Weight matrix 1/1 (128,1440): Alpha 6.828787840477588 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:28,325 INFO     Weight matrix 1/1 (128,1440): Lognorm: 0.7610861659049988\n",
      "2018-11-26 12:58:28,328 INFO Layer 610: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:28,331 INFO Layer 610: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:28,336 INFO Layer 611: ReLU(inplace)\n",
      "2018-11-26 12:58:28,340 INFO Layer 611: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:28,344 INFO Layer 612: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:28,348 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:28,350 INFO Layer 612: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:28,352 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:28,355 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:28,358 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:28,362 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:28,364 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:28,368 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:28,371 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:28,374 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:28,378 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:28,381 INFO Layer 613: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:28,384 INFO Layer 613: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:28,390 INFO Layer 614: BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:28,393 INFO Layer 614: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:28,396 INFO Layer 615: ReLU(inplace)\n",
      "2018-11-26 12:58:28,400 INFO Layer 615: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:28,403 INFO Layer 616: Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:28,407 INFO Pytorch tensor shape detected: 128x1472 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:28,410 INFO Layer 616: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:28,412 INFO     Weight matrix 1/1 (128,1472): Analyzing ...\n",
      "2018-11-26 12:58:29,560 INFO     Weight matrix 1/1 (128,1472): Alpha: 6.643342114860862, Alpha Weighted: 0.6177186716843218, D: 0.09108954955592019\n",
      "2018-11-26 12:58:29,563 INFO     Weight matrix 1/1 (128,1472): Alpha 6.643342114860862 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:29,567 INFO     Weight matrix 1/1 (128,1472): Lognorm: 0.7322724461555481\n",
      "2018-11-26 12:58:29,571 INFO Layer 617: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:29,574 INFO Layer 617: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:29,577 INFO Layer 618: ReLU(inplace)\n",
      "2018-11-26 12:58:29,582 INFO Layer 618: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:29,585 INFO Layer 619: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:29,589 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:29,595 INFO Layer 619: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:29,599 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:29,603 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:29,607 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:29,611 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:29,615 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:29,619 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:29,623 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:29,626 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:29,631 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:29,635 INFO Layer 620: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:29,638 INFO Layer 620: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:29,641 INFO Layer 621: BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:29,644 INFO Layer 621: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:29,647 INFO Layer 622: ReLU(inplace)\n",
      "2018-11-26 12:58:29,651 INFO Layer 622: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:29,653 INFO Layer 623: Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:29,657 INFO Pytorch tensor shape detected: 128x1504 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:29,669 INFO Layer 623: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:29,675 INFO     Weight matrix 1/1 (128,1504): Analyzing ...\n",
      "2018-11-26 12:58:31,298 INFO     Weight matrix 1/1 (128,1504): Alpha: 6.233372909226046, Alpha Weighted: 0.5599427038686712, D: 0.09271677976740816\n",
      "2018-11-26 12:58:31,301 INFO     Weight matrix 1/1 (128,1504): Alpha 6.233372909226046 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:31,303 INFO     Weight matrix 1/1 (128,1504): Lognorm: 0.7674457430839539\n",
      "2018-11-26 12:58:31,307 INFO Layer 624: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:31,309 INFO Layer 624: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:31,313 INFO Layer 625: ReLU(inplace)\n",
      "2018-11-26 12:58:31,316 INFO Layer 625: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:31,319 INFO Layer 626: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:31,326 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:31,331 INFO Layer 626: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:31,339 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:31,342 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:31,346 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:31,349 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:31,352 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:31,355 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:31,359 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:31,364 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:31,366 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:31,370 INFO Layer 627: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:31,373 INFO Layer 627: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:31,376 INFO Layer 628: BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:31,381 INFO Layer 628: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:31,385 INFO Layer 629: ReLU(inplace)\n",
      "2018-11-26 12:58:31,388 INFO Layer 629: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:31,394 INFO Layer 630: Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:31,399 INFO Pytorch tensor shape detected: 128x1536 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:31,403 INFO Layer 630: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:31,406 INFO     Weight matrix 1/1 (128,1536): Analyzing ...\n",
      "2018-11-26 12:58:33,152 INFO     Weight matrix 1/1 (128,1536): Alpha: 6.706991745405565, Alpha Weighted: 0.6901682791087871, D: 0.09425828573192274\n",
      "2018-11-26 12:58:33,155 INFO     Weight matrix 1/1 (128,1536): Alpha 6.706991745405565 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:33,161 INFO     Weight matrix 1/1 (128,1536): Lognorm: 0.7697627544403076\n",
      "2018-11-26 12:58:33,168 INFO Layer 631: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:33,171 INFO Layer 631: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:33,180 INFO Layer 632: ReLU(inplace)\n",
      "2018-11-26 12:58:33,184 INFO Layer 632: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:33,189 INFO Layer 633: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:33,198 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:33,203 INFO Layer 633: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:33,208 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:33,212 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:33,216 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:33,222 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:33,230 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:33,235 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:33,238 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:33,242 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:33,249 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:33,253 INFO Layer 634: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:33,257 INFO Layer 634: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:33,262 INFO Layer 635: BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:33,274 INFO Layer 635: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:33,277 INFO Layer 636: ReLU(inplace)\n",
      "2018-11-26 12:58:33,283 INFO Layer 636: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:33,286 INFO Layer 637: Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:33,295 INFO Pytorch tensor shape detected: 128x1568 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:33,298 INFO Layer 637: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:33,302 INFO     Weight matrix 1/1 (128,1568): Analyzing ...\n",
      "2018-11-26 12:58:34,782 INFO     Weight matrix 1/1 (128,1568): Alpha: 5.793228809606808, Alpha Weighted: 0.5880162897774346, D: 0.0825632029100184\n",
      "2018-11-26 12:58:34,784 INFO     Weight matrix 1/1 (128,1568): Alpha 5.793228809606808 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:34,792 INFO     Weight matrix 1/1 (128,1568): Lognorm: 0.7493795156478882\n",
      "2018-11-26 12:58:34,796 INFO Layer 638: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:34,799 INFO Layer 638: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:34,803 INFO Layer 639: ReLU(inplace)\n",
      "2018-11-26 12:58:34,807 INFO Layer 639: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:34,809 INFO Layer 640: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:34,815 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:34,820 INFO Layer 640: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:34,838 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:34,843 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:34,846 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:34,849 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:34,854 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:34,857 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:34,860 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:34,863 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:34,866 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:34,869 INFO Layer 641: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:34,873 INFO Layer 641: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:34,876 INFO Layer 642: BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:34,879 INFO Layer 642: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:34,882 INFO Layer 643: ReLU(inplace)\n",
      "2018-11-26 12:58:34,884 INFO Layer 643: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:34,887 INFO Layer 644: Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:34,893 INFO Pytorch tensor shape detected: 128x1600 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:34,896 INFO Layer 644: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:34,899 INFO     Weight matrix 1/1 (128,1600): Analyzing ...\n",
      "2018-11-26 12:58:36,247 INFO     Weight matrix 1/1 (128,1600): Alpha: 5.825000946001141, Alpha Weighted: 0.6220716771451509, D: 0.0860562300524707\n",
      "2018-11-26 12:58:36,250 INFO     Weight matrix 1/1 (128,1600): Alpha 5.825000946001141 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:36,255 INFO     Weight matrix 1/1 (128,1600): Lognorm: 0.7441933751106262\n",
      "2018-11-26 12:58:36,257 INFO Layer 645: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:36,261 INFO Layer 645: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:36,265 INFO Layer 646: ReLU(inplace)\n",
      "2018-11-26 12:58:36,278 INFO Layer 646: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:36,282 INFO Layer 647: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:36,286 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:36,289 INFO Layer 647: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:36,293 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:36,299 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:36,307 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:36,315 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:36,322 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:36,326 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:36,331 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:36,337 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:36,343 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:36,351 INFO Layer 648: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:36,356 INFO Layer 648: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:36,358 INFO Layer 649: BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:36,361 INFO Layer 649: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:36,364 INFO Layer 650: ReLU(inplace)\n",
      "2018-11-26 12:58:36,370 INFO Layer 650: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:36,374 INFO Layer 651: Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:36,380 INFO Pytorch tensor shape detected: 128x1632 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:36,383 INFO Layer 651: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:36,387 INFO     Weight matrix 1/1 (128,1632): Analyzing ...\n",
      "2018-11-26 12:58:37,712 INFO     Weight matrix 1/1 (128,1632): Alpha: 6.5742193155537425, Alpha Weighted: 1.0107111953982117, D: 0.07142857142857129\n",
      "2018-11-26 12:58:37,715 INFO     Weight matrix 1/1 (128,1632): Alpha 6.5742193155537425 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:37,718 INFO     Weight matrix 1/1 (128,1632): Lognorm: 0.7744452953338623\n",
      "2018-11-26 12:58:37,720 INFO Layer 652: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:37,722 INFO Layer 652: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:37,725 INFO Layer 653: ReLU(inplace)\n",
      "2018-11-26 12:58:37,728 INFO Layer 653: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:37,731 INFO Layer 654: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:37,740 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:37,744 INFO Layer 654: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:37,747 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:37,751 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:37,754 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:37,756 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:37,759 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:37,761 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:37,764 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:37,767 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:37,769 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:37,772 INFO Layer 655: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:37,775 INFO Layer 655: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:37,777 INFO Layer 656: BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:37,779 INFO Layer 656: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:37,782 INFO Layer 657: ReLU(inplace)\n",
      "2018-11-26 12:58:37,785 INFO Layer 657: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:37,787 INFO Layer 658: Conv2d(1664, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:37,791 INFO Pytorch tensor shape detected: 128x1664 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:37,793 INFO Layer 658: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:37,797 INFO     Weight matrix 1/1 (128,1664): Analyzing ...\n",
      "2018-11-26 12:58:39,085 INFO     Weight matrix 1/1 (128,1664): Alpha: 5.9412210479453655, Alpha Weighted: 0.5781682795883173, D: 0.09895642170688862\n",
      "2018-11-26 12:58:39,088 INFO     Weight matrix 1/1 (128,1664): Alpha 5.9412210479453655 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:39,091 INFO     Weight matrix 1/1 (128,1664): Lognorm: 0.7371182441711426\n",
      "2018-11-26 12:58:39,093 INFO Layer 659: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:39,097 INFO Layer 659: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:39,100 INFO Layer 660: ReLU(inplace)\n",
      "2018-11-26 12:58:39,103 INFO Layer 660: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:39,106 INFO Layer 661: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:39,109 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:39,111 INFO Layer 661: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:39,115 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:39,118 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:39,121 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:39,124 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:39,127 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:39,130 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:39,134 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:39,140 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:39,143 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:39,149 INFO Layer 662: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:39,152 INFO Layer 662: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:39,155 INFO Layer 663: BatchNorm2d(1696, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:39,158 INFO Layer 663: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:39,160 INFO Layer 664: ReLU(inplace)\n",
      "2018-11-26 12:58:39,163 INFO Layer 664: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:39,166 INFO Layer 665: Conv2d(1696, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:39,170 INFO Pytorch tensor shape detected: 128x1696 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:39,173 INFO Layer 665: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:39,177 INFO     Weight matrix 1/1 (128,1696): Analyzing ...\n",
      "2018-11-26 12:58:40,500 INFO     Weight matrix 1/1 (128,1696): Alpha: 5.05888578740579, Alpha Weighted: 0.475689368834146, D: 0.0963991604871568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:40,503 INFO     Weight matrix 1/1 (128,1696): Alpha 5.05888578740579 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:40,506 INFO     Weight matrix 1/1 (128,1696): Lognorm: 0.7460304498672485\n",
      "2018-11-26 12:58:40,508 INFO Layer 666: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:40,511 INFO Layer 666: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:40,513 INFO Layer 667: ReLU(inplace)\n",
      "2018-11-26 12:58:40,516 INFO Layer 667: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:40,518 INFO Layer 668: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:40,522 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:40,524 INFO Layer 668: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:40,526 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:40,529 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:40,532 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:40,535 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:40,538 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:40,541 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:40,543 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:40,546 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:40,550 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:40,552 INFO Layer 669: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:40,555 INFO Layer 669: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:40,558 INFO Layer 670: BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:40,561 INFO Layer 670: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:40,563 INFO Layer 671: ReLU(inplace)\n",
      "2018-11-26 12:58:40,566 INFO Layer 671: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:40,568 INFO Layer 672: Conv2d(1728, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:40,572 INFO Pytorch tensor shape detected: 128x1728 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:40,581 INFO Layer 672: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:40,584 INFO     Weight matrix 1/1 (128,1728): Analyzing ...\n",
      "2018-11-26 12:58:41,736 INFO     Weight matrix 1/1 (128,1728): Alpha: 6.301428040744418, Alpha Weighted: 0.64341279765429, D: 0.08095447042256917\n",
      "2018-11-26 12:58:41,738 INFO     Weight matrix 1/1 (128,1728): Alpha 6.301428040744418 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:41,745 INFO     Weight matrix 1/1 (128,1728): Lognorm: 0.7652871608734131\n",
      "2018-11-26 12:58:41,748 INFO Layer 673: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:41,750 INFO Layer 673: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:41,753 INFO Layer 674: ReLU(inplace)\n",
      "2018-11-26 12:58:41,755 INFO Layer 674: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:41,758 INFO Layer 675: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:41,761 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:41,763 INFO Layer 675: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:41,766 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:41,768 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:41,771 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:41,774 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:41,776 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:41,779 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:41,781 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:41,784 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:41,787 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:41,790 INFO Layer 676: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:41,793 INFO Layer 676: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:41,796 INFO Layer 677: BatchNorm2d(1760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:41,799 INFO Layer 677: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:41,802 INFO Layer 678: ReLU(inplace)\n",
      "2018-11-26 12:58:41,804 INFO Layer 678: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:41,807 INFO Layer 679: Conv2d(1760, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:41,812 INFO Pytorch tensor shape detected: 128x1760 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:41,815 INFO Layer 679: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:41,818 INFO     Weight matrix 1/1 (128,1760): Analyzing ...\n",
      "2018-11-26 12:58:42,944 INFO     Weight matrix 1/1 (128,1760): Alpha: 6.911490149679013, Alpha Weighted: 0.705735956183951, D: 0.08333333333333315\n",
      "2018-11-26 12:58:42,947 INFO     Weight matrix 1/1 (128,1760): Alpha 6.911490149679013 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:42,950 INFO     Weight matrix 1/1 (128,1760): Lognorm: 0.7563068866729736\n",
      "2018-11-26 12:58:42,954 INFO Layer 680: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:42,956 INFO Layer 680: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:42,959 INFO Layer 681: ReLU(inplace)\n",
      "2018-11-26 12:58:42,962 INFO Layer 681: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:42,965 INFO Layer 682: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:42,972 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:42,976 INFO Layer 682: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:42,984 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:42,987 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:42,991 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:42,994 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:42,997 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:42,999 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:43,002 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:43,005 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:43,007 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:43,011 INFO Layer 683: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:43,013 INFO Layer 683: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:43,017 INFO Layer 684: BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:43,020 INFO Layer 684: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:43,023 INFO Layer 685: ReLU(inplace)\n",
      "2018-11-26 12:58:43,026 INFO Layer 685: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:43,030 INFO Layer 686: Conv2d(1792, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:43,035 INFO Pytorch tensor shape detected: 128x1792 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:43,038 INFO Layer 686: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:43,042 INFO     Weight matrix 1/1 (128,1792): Analyzing ...\n",
      "2018-11-26 12:58:44,187 INFO     Weight matrix 1/1 (128,1792): Alpha: 5.925426326141596, Alpha Weighted: 0.8060060077981605, D: 0.07142857142857129\n",
      "2018-11-26 12:58:44,189 INFO     Weight matrix 1/1 (128,1792): Alpha 5.925426326141596 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:44,195 INFO     Weight matrix 1/1 (128,1792): Lognorm: 0.7579418420791626\n",
      "2018-11-26 12:58:44,198 INFO Layer 687: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:44,200 INFO Layer 687: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:44,202 INFO Layer 688: ReLU(inplace)\n",
      "2018-11-26 12:58:44,205 INFO Layer 688: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:44,207 INFO Layer 689: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:44,211 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:44,213 INFO Layer 689: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:44,217 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:44,220 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:44,223 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:44,226 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:44,229 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:44,233 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:44,236 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:44,238 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:44,242 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:44,246 INFO Layer 690: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:44,248 INFO Layer 690: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:44,251 INFO Layer 691: BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:44,254 INFO Layer 691: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:44,257 INFO Layer 692: ReLU(inplace)\n",
      "2018-11-26 12:58:44,260 INFO Layer 692: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:44,263 INFO Layer 693: Conv2d(1824, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:44,267 INFO Pytorch tensor shape detected: 128x1824 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:44,269 INFO Layer 693: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:44,272 INFO     Weight matrix 1/1 (128,1824): Analyzing ...\n",
      "2018-11-26 12:58:45,403 INFO     Weight matrix 1/1 (128,1824): Alpha: 7.218109223466672, Alpha Weighted: 0.8124304451615545, D: 0.09090909090909083\n",
      "2018-11-26 12:58:45,406 INFO     Weight matrix 1/1 (128,1824): Alpha 7.218109223466672 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:45,409 INFO     Weight matrix 1/1 (128,1824): Lognorm: 0.7575539946556091\n",
      "2018-11-26 12:58:45,413 INFO Layer 694: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:45,419 INFO Layer 694: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:45,423 INFO Layer 695: ReLU(inplace)\n",
      "2018-11-26 12:58:45,427 INFO Layer 695: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:45,429 INFO Layer 696: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:45,435 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:45,438 INFO Layer 696: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:45,443 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:45,446 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:45,448 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:45,451 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:45,455 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:45,457 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:45,461 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:45,466 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:45,470 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:45,479 INFO Layer 697: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n",
      "2018-11-26 12:58:45,483 INFO Layer 697: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:45,489 INFO Layer 698: BatchNorm2d(1856, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:45,497 INFO Layer 698: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:45,501 INFO Layer 699: ReLU(inplace)\n",
      "2018-11-26 12:58:45,504 INFO Layer 699: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:45,506 INFO Layer 700: Conv2d(1856, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:45,511 INFO Pytorch tensor shape detected: 128x1856 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:45,513 INFO Layer 700: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:45,515 INFO     Weight matrix 1/1 (128,1856): Analyzing ...\n",
      "2018-11-26 12:58:46,623 INFO     Weight matrix 1/1 (128,1856): Alpha: 5.525587760965482, Alpha Weighted: 0.7688612122816274, D: 0.08242198553881774\n",
      "2018-11-26 12:58:46,625 INFO     Weight matrix 1/1 (128,1856): Alpha 5.525587760965482 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:46,630 INFO     Weight matrix 1/1 (128,1856): Lognorm: 0.7620581984519958\n",
      "2018-11-26 12:58:46,634 INFO Layer 701: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:46,637 INFO Layer 701: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:46,639 INFO Layer 702: ReLU(inplace)\n",
      "2018-11-26 12:58:46,643 INFO Layer 702: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:46,646 INFO Layer 703: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:46,648 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:46,651 INFO Layer 703: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:46,656 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:46,657 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:46,660 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:46,663 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:46,666 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:46,669 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:46,673 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:46,675 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:46,678 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:46,681 INFO Layer 704: _DenseLayer(\n",
      "  (norm1): BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU(inplace)\n",
      "  (conv1): Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:46,684 INFO Layer 704: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:46,686 INFO Layer 705: BatchNorm2d(1888, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:46,689 INFO Layer 705: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:46,691 INFO Layer 706: ReLU(inplace)\n",
      "2018-11-26 12:58:46,694 INFO Layer 706: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:46,696 INFO Layer 707: Conv2d(1888, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 12:58:46,705 INFO Pytorch tensor shape detected: 128x1888 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:58:46,708 INFO Layer 707: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:46,712 INFO     Weight matrix 1/1 (128,1888): Analyzing ...\n",
      "2018-11-26 12:58:47,839 INFO     Weight matrix 1/1 (128,1888): Alpha: 4.957605707415748, Alpha Weighted: 0.5726402269280143, D: 0.09314997931958191\n",
      "2018-11-26 12:58:47,842 INFO     Weight matrix 1/1 (128,1888): Alpha 4.957605707415748 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:58:47,846 INFO     Weight matrix 1/1 (128,1888): Lognorm: 0.7691556215286255\n",
      "2018-11-26 12:58:47,848 INFO Layer 708: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:47,851 INFO Layer 708: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:47,854 INFO Layer 709: ReLU(inplace)\n",
      "2018-11-26 12:58:47,856 INFO Layer 709: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:47,862 INFO Layer 710: Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:47,864 INFO Pytorch tensor shape detected: 32x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:47,867 INFO Layer 710: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:47,869 INFO     Weight matrix 1/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:47,871 INFO     Weight matrix 2/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:47,874 INFO     Weight matrix 3/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:47,878 INFO     Weight matrix 4/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:47,880 INFO     Weight matrix 5/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:47,883 INFO     Weight matrix 6/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:47,887 INFO     Weight matrix 7/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:47,890 INFO     Weight matrix 8/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:47,893 INFO     Weight matrix 9/9 (32,128): Skipping: too small (<50)\n",
      "2018-11-26 12:58:47,897 INFO Layer 711: BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:47,900 INFO Layer 711: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:47,903 INFO Layer 712: Linear(in_features=1920, out_features=1000, bias=True)\n",
      "2018-11-26 12:58:47,952 INFO Layer 712: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:58:47,955 INFO     Weight matrix 1/1 (1000,1920): Skipping: too big (testing) (>256)\n",
      "2018-11-26 12:58:47,958 INFO ### Printing results ###\n",
      "2018-11-26 12:58:47,961 DEBUG Layer 10: Lognorm: 0.6749588251113892\n",
      "2018-11-26 12:58:47,964 DEBUG Layer 17: Lognorm: 0.695601224899292\n",
      "2018-11-26 12:58:47,968 DEBUG Layer 24: Lognorm: 0.681190013885498\n",
      "2018-11-26 12:58:47,972 DEBUG Layer 31: Lognorm: 0.6703627109527588\n",
      "2018-11-26 12:58:47,976 DEBUG Layer 38: Lognorm: 0.6274871230125427\n",
      "2018-11-26 12:58:47,980 DEBUG Layer 45: Lognorm: 0.7079291343688965\n",
      "2018-11-26 12:58:47,984 DEBUG Layer 52: Lognorm: 1.0040216445922852\n",
      "2018-11-26 12:58:47,987 DEBUG Layer 58: Lognorm: 0.49563485383987427\n",
      "2018-11-26 12:58:47,989 DEBUG Layer 65: Lognorm: 0.41292110085487366\n",
      "2018-11-26 12:58:47,992 DEBUG Layer 72: Lognorm: 0.5833907127380371\n",
      "2018-11-26 12:58:47,995 DEBUG Layer 79: Lognorm: 0.6160895824432373\n",
      "2018-11-26 12:58:47,998 DEBUG Layer 86: Lognorm: 0.5941256880760193\n",
      "2018-11-26 12:58:48,001 DEBUG Layer 93: Lognorm: 0.6284042596817017\n",
      "2018-11-26 12:58:48,004 DEBUG Layer 100: Lognorm: 0.6488050222396851\n",
      "2018-11-26 12:58:48,006 DEBUG Layer 107: Lognorm: 0.6654196381568909\n",
      "2018-11-26 12:58:48,009 DEBUG Layer 114: Lognorm: 0.6997446417808533\n",
      "2018-11-26 12:58:48,011 DEBUG Layer 121: Lognorm: 0.6738100051879883\n",
      "2018-11-26 12:58:48,014 DEBUG Layer 128: Lognorm: 0.7169743776321411\n",
      "2018-11-26 12:58:48,017 DEBUG Layer 135: Lognorm: 0.7770052552223206\n",
      "2018-11-26 12:58:48,020 DEBUG Layer 142: Lognorm: 1.133549690246582\n",
      "2018-11-26 12:58:48,026 DEBUG Layer 148: Lognorm: 0.4658624827861786\n",
      "2018-11-26 12:58:48,028 DEBUG Layer 155: Lognorm: 0.5752851366996765\n",
      "2018-11-26 12:58:48,030 DEBUG Layer 162: Lognorm: 0.5068046450614929\n",
      "2018-11-26 12:58:48,033 DEBUG Layer 169: Lognorm: 0.44901636242866516\n",
      "2018-11-26 12:58:48,035 DEBUG Layer 176: Lognorm: 0.4808567464351654\n",
      "2018-11-26 12:58:48,038 DEBUG Layer 183: Lognorm: 0.58819979429245\n",
      "2018-11-26 12:58:48,041 DEBUG Layer 190: Lognorm: 0.5794326066970825\n",
      "2018-11-26 12:58:48,044 DEBUG Layer 197: Lognorm: 0.5141971707344055\n",
      "2018-11-26 12:58:48,048 DEBUG Layer 204: Lognorm: 0.6384378671646118\n",
      "2018-11-26 12:58:48,051 DEBUG Layer 211: Lognorm: 0.5537497401237488\n",
      "2018-11-26 12:58:48,055 DEBUG Layer 218: Lognorm: 0.5662946701049805\n",
      "2018-11-26 12:58:48,059 DEBUG Layer 225: Lognorm: 0.5766661763191223\n",
      "2018-11-26 12:58:48,062 DEBUG Layer 232: Lognorm: 0.6218957901000977\n",
      "2018-11-26 12:58:48,066 DEBUG Layer 239: Lognorm: 0.6364011168479919\n",
      "2018-11-26 12:58:48,069 DEBUG Layer 246: Lognorm: 0.6225210428237915\n",
      "2018-11-26 12:58:48,072 DEBUG Layer 253: Lognorm: 0.735187828540802\n",
      "2018-11-26 12:58:48,075 DEBUG Layer 260: Lognorm: 0.6321976780891418\n",
      "2018-11-26 12:58:48,078 DEBUG Layer 267: Lognorm: 0.6371203660964966\n",
      "2018-11-26 12:58:48,081 DEBUG Layer 274: Lognorm: 0.6352325677871704\n",
      "2018-11-26 12:58:48,084 DEBUG Layer 281: Lognorm: 0.6629010438919067\n",
      "2018-11-26 12:58:48,086 DEBUG Layer 288: Lognorm: 0.6812089681625366\n",
      "2018-11-26 12:58:48,088 DEBUG Layer 295: Lognorm: 0.6947890520095825\n",
      "2018-11-26 12:58:48,092 DEBUG Layer 302: Lognorm: 0.6657415628433228\n",
      "2018-11-26 12:58:48,094 DEBUG Layer 309: Lognorm: 0.7128458619117737\n",
      "2018-11-26 12:58:48,096 DEBUG Layer 316: Lognorm: 0.7273784875869751\n",
      "2018-11-26 12:58:48,099 DEBUG Layer 323: Lognorm: 0.6755932569503784\n",
      "2018-11-26 12:58:48,102 DEBUG Layer 330: Lognorm: 0.6841879487037659\n",
      "2018-11-26 12:58:48,105 DEBUG Layer 337: Lognorm: 0.749965488910675\n",
      "2018-11-26 12:58:48,107 DEBUG Layer 344: Lognorm: 0.7406067848205566\n",
      "2018-11-26 12:58:48,110 DEBUG Layer 351: Lognorm: 0.7148630619049072\n",
      "2018-11-26 12:58:48,112 DEBUG Layer 358: Lognorm: 0.7356852889060974\n",
      "2018-11-26 12:58:48,115 DEBUG Layer 365: Lognorm: 0.7214874029159546\n",
      "2018-11-26 12:58:48,117 DEBUG Layer 372: Lognorm: 0.772777259349823\n",
      "2018-11-26 12:58:48,120 DEBUG Layer 379: Lognorm: 0.7553160190582275\n",
      "2018-11-26 12:58:48,123 DEBUG Layer 386: Lognorm: 0.7722168564796448\n",
      "2018-11-26 12:58:48,125 DEBUG Layer 393: Lognorm: 0.7412845492362976\n",
      "2018-11-26 12:58:48,128 DEBUG Layer 400: Lognorm: 0.7412115335464478\n",
      "2018-11-26 12:58:48,132 DEBUG Layer 407: Lognorm: 0.7664781808853149\n",
      "2018-11-26 12:58:48,137 DEBUG Layer 414: Lognorm: 0.7630085945129395\n",
      "2018-11-26 12:58:48,141 DEBUG Layer 421: Lognorm: 0.7728256583213806\n",
      "2018-11-26 12:58:48,145 DEBUG Layer 428: Lognorm: 0.7890831232070923\n",
      "2018-11-26 12:58:48,148 DEBUG Layer 435: Lognorm: 0.7760552167892456\n",
      "2018-11-26 12:58:48,151 DEBUG Layer 442: Lognorm: 0.782757580280304\n",
      "2018-11-26 12:58:48,156 DEBUG Layer 449: Lognorm: 0.7759987115859985\n",
      "2018-11-26 12:58:48,159 DEBUG Layer 456: Lognorm: 0.7648581862449646\n",
      "2018-11-26 12:58:48,164 DEBUG Layer 463: Lognorm: 0.7842831611633301\n",
      "2018-11-26 12:58:48,167 DEBUG Layer 470: Lognorm: 0.7816086411476135\n",
      "2018-11-26 12:58:48,170 DEBUG Layer 477: Lognorm: 0.7886970639228821\n",
      "2018-11-26 12:58:48,173 DEBUG Layer 490: Lognorm: 0.7102020978927612\n",
      "2018-11-26 12:58:48,176 DEBUG Layer 497: Lognorm: 0.6968818306922913\n",
      "2018-11-26 12:58:48,179 DEBUG Layer 504: Lognorm: 0.7062215805053711\n",
      "2018-11-26 12:58:48,183 DEBUG Layer 511: Lognorm: 0.7191216945648193\n",
      "2018-11-26 12:58:48,185 DEBUG Layer 518: Lognorm: 0.722057044506073\n",
      "2018-11-26 12:58:48,189 DEBUG Layer 525: Lognorm: 0.7418020963668823\n",
      "2018-11-26 12:58:48,193 DEBUG Layer 532: Lognorm: 0.7736302614212036\n",
      "2018-11-26 12:58:48,198 DEBUG Layer 539: Lognorm: 0.7669708132743835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:48,201 DEBUG Layer 546: Lognorm: 0.7952290773391724\n",
      "2018-11-26 12:58:48,203 DEBUG Layer 553: Lognorm: 0.7446065545082092\n",
      "2018-11-26 12:58:48,206 DEBUG Layer 560: Lognorm: 0.7870555520057678\n",
      "2018-11-26 12:58:48,209 DEBUG Layer 567: Lognorm: 0.7566502690315247\n",
      "2018-11-26 12:58:48,212 DEBUG Layer 574: Lognorm: 0.7474079132080078\n",
      "2018-11-26 12:58:48,214 DEBUG Layer 581: Lognorm: 0.7349714636802673\n",
      "2018-11-26 12:58:48,218 DEBUG Layer 588: Lognorm: 0.760839581489563\n",
      "2018-11-26 12:58:48,221 DEBUG Layer 595: Lognorm: 0.7599263787269592\n",
      "2018-11-26 12:58:48,224 DEBUG Layer 602: Lognorm: 0.7551909685134888\n",
      "2018-11-26 12:58:48,229 DEBUG Layer 609: Lognorm: 0.7610861659049988\n",
      "2018-11-26 12:58:48,232 DEBUG Layer 616: Lognorm: 0.7322724461555481\n",
      "2018-11-26 12:58:48,237 DEBUG Layer 623: Lognorm: 0.7674457430839539\n",
      "2018-11-26 12:58:48,241 DEBUG Layer 630: Lognorm: 0.7697627544403076\n",
      "2018-11-26 12:58:48,244 DEBUG Layer 637: Lognorm: 0.7493795156478882\n",
      "2018-11-26 12:58:48,247 DEBUG Layer 644: Lognorm: 0.7441933751106262\n",
      "2018-11-26 12:58:48,250 DEBUG Layer 651: Lognorm: 0.7744452953338623\n",
      "2018-11-26 12:58:48,253 DEBUG Layer 658: Lognorm: 0.7371182441711426\n",
      "2018-11-26 12:58:48,256 DEBUG Layer 665: Lognorm: 0.7460304498672485\n",
      "2018-11-26 12:58:48,260 DEBUG Layer 672: Lognorm: 0.7652871608734131\n",
      "2018-11-26 12:58:48,263 DEBUG Layer 679: Lognorm: 0.7563068866729736\n",
      "2018-11-26 12:58:48,267 DEBUG Layer 686: Lognorm: 0.7579418420791626\n",
      "2018-11-26 12:58:48,272 DEBUG Layer 693: Lognorm: 0.7575539946556091\n",
      "2018-11-26 12:58:48,275 DEBUG Layer 700: Lognorm: 0.7620581984519958\n",
      "2018-11-26 12:58:48,279 DEBUG Layer 707: Lognorm: 0.7691556215286255\n",
      "2018-11-26 12:58:48,284 INFO LogNorm: min: 0.41292110085487366, max: 1.133549690246582, avg: 0.702472984790802\n",
      "2018-11-26 12:58:48,287 INFO LogNorm compound: min: 0.41292110085487366, max: 1.133549690246582, avg: 0.7024730271100998\n",
      "2018-11-26 12:58:48,291 DEBUG Layer 10: Alpha: 2.5829017726958545\n",
      "2018-11-26 12:58:48,294 DEBUG Layer 17: Alpha: 1.8080375574947736\n",
      "2018-11-26 12:58:48,297 DEBUG Layer 24: Alpha: 3.157632327704465\n",
      "2018-11-26 12:58:48,301 DEBUG Layer 31: Alpha: 5.399741104735045\n",
      "2018-11-26 12:58:48,303 DEBUG Layer 38: Alpha: 1.6222642558442866\n",
      "2018-11-26 12:58:48,306 DEBUG Layer 45: Alpha: 1.5521604079296467\n",
      "2018-11-26 12:58:48,308 DEBUG Layer 52: Alpha: 4.431730352382717\n",
      "2018-11-26 12:58:48,311 DEBUG Layer 58: Alpha: 1.586015608967225\n",
      "2018-11-26 12:58:48,314 DEBUG Layer 65: Alpha: 1.5951542118451156\n",
      "2018-11-26 12:58:48,317 DEBUG Layer 72: Alpha: 3.705744796635297\n",
      "2018-11-26 12:58:48,319 DEBUG Layer 79: Alpha: 3.781191463840778\n",
      "2018-11-26 12:58:48,322 DEBUG Layer 86: Alpha: 8.45027960423436\n",
      "2018-11-26 12:58:48,324 DEBUG Layer 93: Alpha: 3.623104509490679\n",
      "2018-11-26 12:58:48,329 DEBUG Layer 100: Alpha: 5.717689393729436\n",
      "2018-11-26 12:58:48,331 DEBUG Layer 107: Alpha: 3.149973977725962\n",
      "2018-11-26 12:58:48,334 DEBUG Layer 114: Alpha: 2.832963605098768\n",
      "2018-11-26 12:58:48,338 DEBUG Layer 121: Alpha: 1.9367811344788302\n",
      "2018-11-26 12:58:48,342 DEBUG Layer 128: Alpha: 5.8120739704295605\n",
      "2018-11-26 12:58:48,345 DEBUG Layer 135: Alpha: 2.1222122397018737\n",
      "2018-11-26 12:58:48,348 DEBUG Layer 142: Alpha: 3.045263829760049\n",
      "2018-11-26 12:58:48,350 DEBUG Layer 148: Alpha: 1.583846847746102\n",
      "2018-11-26 12:58:48,353 DEBUG Layer 155: Alpha: 2.408390723678167\n",
      "2018-11-26 12:58:48,355 DEBUG Layer 162: Alpha: 2.221219270021453\n",
      "2018-11-26 12:58:48,357 DEBUG Layer 169: Alpha: 1.6011513269268436\n",
      "2018-11-26 12:58:48,362 DEBUG Layer 176: Alpha: 1.5985232651364778\n",
      "2018-11-26 12:58:48,364 DEBUG Layer 183: Alpha: 3.7180725040685934\n",
      "2018-11-26 12:58:48,367 DEBUG Layer 190: Alpha: 3.296320111514852\n",
      "2018-11-26 12:58:48,370 DEBUG Layer 197: Alpha: 4.930400614527592\n",
      "2018-11-26 12:58:48,373 DEBUG Layer 204: Alpha: 3.653804064481247\n",
      "2018-11-26 12:58:48,375 DEBUG Layer 211: Alpha: 1.593179031310073\n",
      "2018-11-26 12:58:48,378 DEBUG Layer 218: Alpha: 1.7559188664728833\n",
      "2018-11-26 12:58:48,382 DEBUG Layer 225: Alpha: 1.9028857819457574\n",
      "2018-11-26 12:58:48,385 DEBUG Layer 232: Alpha: 1.9614650789509442\n",
      "2018-11-26 12:58:48,387 DEBUG Layer 239: Alpha: 4.411436032420086\n",
      "2018-11-26 12:58:48,390 DEBUG Layer 246: Alpha: 4.459959878440559\n",
      "2018-11-26 12:58:48,394 DEBUG Layer 253: Alpha: 3.9503800216517964\n",
      "2018-11-26 12:58:48,397 DEBUG Layer 260: Alpha: 1.9869152848096587\n",
      "2018-11-26 12:58:48,400 DEBUG Layer 267: Alpha: 4.990165032332616\n",
      "2018-11-26 12:58:48,403 DEBUG Layer 274: Alpha: 1.8763474497531378\n",
      "2018-11-26 12:58:48,405 DEBUG Layer 281: Alpha: 1.9229077848257754\n",
      "2018-11-26 12:58:48,409 DEBUG Layer 288: Alpha: 4.449403537898187\n",
      "2018-11-26 12:58:48,411 DEBUG Layer 295: Alpha: 1.949804317513989\n",
      "2018-11-26 12:58:48,415 DEBUG Layer 302: Alpha: 2.338110712611456\n",
      "2018-11-26 12:58:48,419 DEBUG Layer 309: Alpha: 2.569899377338251\n",
      "2018-11-26 12:58:48,423 DEBUG Layer 316: Alpha: 3.2421375305452065\n",
      "2018-11-26 12:58:48,427 DEBUG Layer 323: Alpha: 2.232946893567359\n",
      "2018-11-26 12:58:48,429 DEBUG Layer 330: Alpha: 2.0233796395047245\n",
      "2018-11-26 12:58:48,433 DEBUG Layer 337: Alpha: 3.561015092571958\n",
      "2018-11-26 12:58:48,437 DEBUG Layer 344: Alpha: 3.1388436815376353\n",
      "2018-11-26 12:58:48,440 DEBUG Layer 351: Alpha: 2.198257136050932\n",
      "2018-11-26 12:58:48,444 DEBUG Layer 358: Alpha: 3.1104971875642824\n",
      "2018-11-26 12:58:48,447 DEBUG Layer 365: Alpha: 3.069971426823827\n",
      "2018-11-26 12:58:48,449 DEBUG Layer 372: Alpha: 2.236870798676037\n",
      "2018-11-26 12:58:48,452 DEBUG Layer 379: Alpha: 2.2033994484111923\n",
      "2018-11-26 12:58:48,454 DEBUG Layer 386: Alpha: 3.9745173235477975\n",
      "2018-11-26 12:58:48,456 DEBUG Layer 393: Alpha: 5.680001854853063\n",
      "2018-11-26 12:58:48,460 DEBUG Layer 400: Alpha: 4.296300273065496\n",
      "2018-11-26 12:58:48,463 DEBUG Layer 407: Alpha: 2.4485418986076093\n",
      "2018-11-26 12:58:48,466 DEBUG Layer 414: Alpha: 3.1500770991353\n",
      "2018-11-26 12:58:48,469 DEBUG Layer 421: Alpha: 7.285787245702748\n",
      "2018-11-26 12:58:48,472 DEBUG Layer 428: Alpha: 6.012495369277081\n",
      "2018-11-26 12:58:48,474 DEBUG Layer 435: Alpha: 5.785933792828196\n",
      "2018-11-26 12:58:48,477 DEBUG Layer 442: Alpha: 6.108008317538168\n",
      "2018-11-26 12:58:48,480 DEBUG Layer 449: Alpha: 2.635781032381538\n",
      "2018-11-26 12:58:48,482 DEBUG Layer 456: Alpha: 4.846493435353816\n",
      "2018-11-26 12:58:48,485 DEBUG Layer 463: Alpha: 4.8643011116139405\n",
      "2018-11-26 12:58:48,487 DEBUG Layer 470: Alpha: 3.613576798062647\n",
      "2018-11-26 12:58:48,490 DEBUG Layer 477: Alpha: 4.958305922700012\n",
      "2018-11-26 12:58:48,493 DEBUG Layer 490: Alpha: 3.1967187087811455\n",
      "2018-11-26 12:58:48,496 DEBUG Layer 497: Alpha: 4.087275832100719\n",
      "2018-11-26 12:58:48,498 DEBUG Layer 504: Alpha: 4.539249315051804\n",
      "2018-11-26 12:58:48,501 DEBUG Layer 511: Alpha: 2.2740599302309104\n",
      "2018-11-26 12:58:48,504 DEBUG Layer 518: Alpha: 4.788876626359231\n",
      "2018-11-26 12:58:48,507 DEBUG Layer 525: Alpha: 5.231885513405296\n",
      "2018-11-26 12:58:48,509 DEBUG Layer 532: Alpha: 7.450872986952545\n",
      "2018-11-26 12:58:48,512 DEBUG Layer 539: Alpha: 5.042886646120866\n",
      "2018-11-26 12:58:48,515 DEBUG Layer 546: Alpha: 4.637329497216912\n",
      "2018-11-26 12:58:48,517 DEBUG Layer 553: Alpha: 5.627413362964799\n",
      "2018-11-26 12:58:48,520 DEBUG Layer 560: Alpha: 4.7197548918147785\n",
      "2018-11-26 12:58:48,522 DEBUG Layer 567: Alpha: 6.68830698687418\n",
      "2018-11-26 12:58:48,526 DEBUG Layer 574: Alpha: 5.928652128622533\n",
      "2018-11-26 12:58:48,529 DEBUG Layer 581: Alpha: 6.247611217123068\n",
      "2018-11-26 12:58:48,532 DEBUG Layer 588: Alpha: 7.62478331544314\n",
      "2018-11-26 12:58:48,534 DEBUG Layer 595: Alpha: 6.608290999977355\n",
      "2018-11-26 12:58:48,537 DEBUG Layer 602: Alpha: 7.1522035218275555\n",
      "2018-11-26 12:58:48,540 DEBUG Layer 609: Alpha: 6.828787840477588\n",
      "2018-11-26 12:58:48,542 DEBUG Layer 616: Alpha: 6.643342114860862\n",
      "2018-11-26 12:58:48,545 DEBUG Layer 623: Alpha: 6.233372909226046\n",
      "2018-11-26 12:58:48,548 DEBUG Layer 630: Alpha: 6.706991745405565\n",
      "2018-11-26 12:58:48,550 DEBUG Layer 637: Alpha: 5.793228809606808\n",
      "2018-11-26 12:58:48,553 DEBUG Layer 644: Alpha: 5.825000946001141\n",
      "2018-11-26 12:58:48,556 DEBUG Layer 651: Alpha: 6.5742193155537425\n",
      "2018-11-26 12:58:48,558 DEBUG Layer 658: Alpha: 5.9412210479453655\n",
      "2018-11-26 12:58:48,561 DEBUG Layer 665: Alpha: 5.05888578740579\n",
      "2018-11-26 12:58:48,563 DEBUG Layer 672: Alpha: 6.301428040744418\n",
      "2018-11-26 12:58:48,566 DEBUG Layer 679: Alpha: 6.911490149679013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:48,568 DEBUG Layer 686: Alpha: 5.925426326141596\n",
      "2018-11-26 12:58:48,570 DEBUG Layer 693: Alpha: 7.218109223466672\n",
      "2018-11-26 12:58:48,573 DEBUG Layer 700: Alpha: 5.525587760965482\n",
      "2018-11-26 12:58:48,575 DEBUG Layer 707: Alpha: 4.957605707415748\n",
      "2018-11-26 12:58:48,578 INFO Alpha: min: 1.5521604079296467, max: 8.45027960423436, avg: 4.120117325567844\n",
      "2018-11-26 12:58:48,580 INFO Alpha compound: min: 1.5521604079296467, max: 8.45027960423436, avg: 4.120117325567844\n",
      "2018-11-26 12:58:48,584 DEBUG Layer 10: Alpha Weigthed: 0.7117965808304216\n",
      "2018-11-26 12:58:48,587 DEBUG Layer 17: Alpha Weigthed: 0.5953473001441335\n",
      "2018-11-26 12:58:48,591 DEBUG Layer 24: Alpha Weigthed: 0.9838929180738292\n",
      "2018-11-26 12:58:48,595 DEBUG Layer 31: Alpha Weigthed: 1.1562916982824438\n",
      "2018-11-26 12:58:48,598 DEBUG Layer 38: Alpha Weigthed: 0.15717790017423475\n",
      "2018-11-26 12:58:48,602 DEBUG Layer 45: Alpha Weigthed: 0.311997502677867\n",
      "2018-11-26 12:58:48,606 DEBUG Layer 52: Alpha Weigthed: 3.608953501171657\n",
      "2018-11-26 12:58:48,609 DEBUG Layer 58: Alpha Weigthed: -0.13864186531935546\n",
      "2018-11-26 12:58:48,612 DEBUG Layer 65: Alpha Weigthed: 0.027189199433767464\n",
      "2018-11-26 12:58:48,615 DEBUG Layer 72: Alpha Weigthed: 0.22362586735112147\n",
      "2018-11-26 12:58:48,619 DEBUG Layer 79: Alpha Weigthed: 0.07791293519080601\n",
      "2018-11-26 12:58:48,624 DEBUG Layer 86: Alpha Weigthed: -0.042060838377636224\n",
      "2018-11-26 12:58:48,627 DEBUG Layer 93: Alpha Weigthed: 0.5855936525648835\n",
      "2018-11-26 12:58:48,632 DEBUG Layer 100: Alpha Weigthed: 0.5005110269601135\n",
      "2018-11-26 12:58:48,636 DEBUG Layer 107: Alpha Weigthed: 0.10839425354339485\n",
      "2018-11-26 12:58:48,640 DEBUG Layer 114: Alpha Weigthed: 0.8884886550828026\n",
      "2018-11-26 12:58:48,645 DEBUG Layer 121: Alpha Weigthed: 0.150834441767218\n",
      "2018-11-26 12:58:48,648 DEBUG Layer 128: Alpha Weigthed: 0.6215564484764577\n",
      "2018-11-26 12:58:48,650 DEBUG Layer 135: Alpha Weigthed: 0.7374792446844336\n",
      "2018-11-26 12:58:48,653 DEBUG Layer 142: Alpha Weigthed: 1.6483738989814758\n",
      "2018-11-26 12:58:48,656 DEBUG Layer 148: Alpha Weigthed: -0.09800457814708281\n",
      "2018-11-26 12:58:48,658 DEBUG Layer 155: Alpha Weigthed: -0.05616942418913428\n",
      "2018-11-26 12:58:48,662 DEBUG Layer 162: Alpha Weigthed: -0.1171287680137998\n",
      "2018-11-26 12:58:48,667 DEBUG Layer 169: Alpha Weigthed: -0.3082384911214438\n",
      "2018-11-26 12:58:48,670 DEBUG Layer 176: Alpha Weigthed: -0.17844673725325422\n",
      "2018-11-26 12:58:48,674 DEBUG Layer 183: Alpha Weigthed: 0.07798634653231735\n",
      "2018-11-26 12:58:48,679 DEBUG Layer 190: Alpha Weigthed: -0.11356279026957729\n",
      "2018-11-26 12:58:48,684 DEBUG Layer 197: Alpha Weigthed: -0.5553586030436635\n",
      "2018-11-26 12:58:48,689 DEBUG Layer 204: Alpha Weigthed: 0.15751756885954404\n",
      "2018-11-26 12:58:48,693 DEBUG Layer 211: Alpha Weigthed: -0.27672048647651315\n",
      "2018-11-26 12:58:48,697 DEBUG Layer 218: Alpha Weigthed: -0.24383948306700126\n",
      "2018-11-26 12:58:48,699 DEBUG Layer 225: Alpha Weigthed: -0.24604568030776583\n",
      "2018-11-26 12:58:48,703 DEBUG Layer 232: Alpha Weigthed: 0.6057853765488723\n",
      "2018-11-26 12:58:48,706 DEBUG Layer 239: Alpha Weigthed: 0.05163540662268631\n",
      "2018-11-26 12:58:48,712 DEBUG Layer 246: Alpha Weigthed: 0.9721339931367186\n",
      "2018-11-26 12:58:48,716 DEBUG Layer 253: Alpha Weigthed: 0.571019997966772\n",
      "2018-11-26 12:58:48,720 DEBUG Layer 260: Alpha Weigthed: -0.16863190470296716\n",
      "2018-11-26 12:58:48,723 DEBUG Layer 267: Alpha Weigthed: -0.3332681730049541\n",
      "2018-11-26 12:58:48,726 DEBUG Layer 274: Alpha Weigthed: -0.22647533612445825\n",
      "2018-11-26 12:58:48,730 DEBUG Layer 281: Alpha Weigthed: -0.0033152042244700545\n",
      "2018-11-26 12:58:48,733 DEBUG Layer 288: Alpha Weigthed: 0.24144794347566012\n",
      "2018-11-26 12:58:48,738 DEBUG Layer 295: Alpha Weigthed: -0.006765395827168592\n",
      "2018-11-26 12:58:48,741 DEBUG Layer 302: Alpha Weigthed: -0.16066700243022122\n",
      "2018-11-26 12:58:48,743 DEBUG Layer 309: Alpha Weigthed: 0.004463096259073948\n",
      "2018-11-26 12:58:48,746 DEBUG Layer 316: Alpha Weigthed: 0.2840445833464272\n",
      "2018-11-26 12:58:48,749 DEBUG Layer 323: Alpha Weigthed: 0.009706960765243309\n",
      "2018-11-26 12:58:48,752 DEBUG Layer 330: Alpha Weigthed: 0.008478215571232921\n",
      "2018-11-26 12:58:48,756 DEBUG Layer 337: Alpha Weigthed: 0.7630452732284676\n",
      "2018-11-26 12:58:48,759 DEBUG Layer 344: Alpha Weigthed: 0.17072858979362598\n",
      "2018-11-26 12:58:48,762 DEBUG Layer 351: Alpha Weigthed: -0.1627496623439139\n",
      "2018-11-26 12:58:48,765 DEBUG Layer 358: Alpha Weigthed: 0.17075427316223535\n",
      "2018-11-26 12:58:48,769 DEBUG Layer 365: Alpha Weigthed: -0.07296624694112736\n",
      "2018-11-26 12:58:48,773 DEBUG Layer 372: Alpha Weigthed: 0.5026357099931635\n",
      "2018-11-26 12:58:48,776 DEBUG Layer 379: Alpha Weigthed: 0.4494840559392094\n",
      "2018-11-26 12:58:48,779 DEBUG Layer 386: Alpha Weigthed: 0.6475066195279954\n",
      "2018-11-26 12:58:48,782 DEBUG Layer 393: Alpha Weigthed: 0.3353344376213078\n",
      "2018-11-26 12:58:48,788 DEBUG Layer 400: Alpha Weigthed: 0.04364132022653738\n",
      "2018-11-26 12:58:48,791 DEBUG Layer 407: Alpha Weigthed: 0.26695241193328434\n",
      "2018-11-26 12:58:48,793 DEBUG Layer 414: Alpha Weigthed: 0.31536548981362367\n",
      "2018-11-26 12:58:48,797 DEBUG Layer 421: Alpha Weigthed: 0.33077936311659883\n",
      "2018-11-26 12:58:48,800 DEBUG Layer 428: Alpha Weigthed: 0.9861401152647151\n",
      "2018-11-26 12:58:48,802 DEBUG Layer 435: Alpha Weigthed: 0.9265330998912238\n",
      "2018-11-26 12:58:48,805 DEBUG Layer 442: Alpha Weigthed: 0.8129195862514182\n",
      "2018-11-26 12:58:48,808 DEBUG Layer 449: Alpha Weigthed: 0.782700394827319\n",
      "2018-11-26 12:58:48,811 DEBUG Layer 456: Alpha Weigthed: 0.6129859977157626\n",
      "2018-11-26 12:58:48,813 DEBUG Layer 463: Alpha Weigthed: 0.7991777554262778\n",
      "2018-11-26 12:58:48,816 DEBUG Layer 470: Alpha Weigthed: 0.5548297135053051\n",
      "2018-11-26 12:58:48,818 DEBUG Layer 477: Alpha Weigthed: 0.9568900379124826\n",
      "2018-11-26 12:58:48,821 DEBUG Layer 490: Alpha Weigthed: -0.3594671481493354\n",
      "2018-11-26 12:58:48,824 DEBUG Layer 497: Alpha Weigthed: -0.3668515488712201\n",
      "2018-11-26 12:58:48,827 DEBUG Layer 504: Alpha Weigthed: 0.0702731536354072\n",
      "2018-11-26 12:58:48,829 DEBUG Layer 511: Alpha Weigthed: -0.2998432151044098\n",
      "2018-11-26 12:58:48,833 DEBUG Layer 518: Alpha Weigthed: 0.4865609914903658\n",
      "2018-11-26 12:58:48,835 DEBUG Layer 525: Alpha Weigthed: -0.014999514596075075\n",
      "2018-11-26 12:58:48,839 DEBUG Layer 532: Alpha Weigthed: 0.4957275392215457\n",
      "2018-11-26 12:58:48,843 DEBUG Layer 539: Alpha Weigthed: 0.5212087036311616\n",
      "2018-11-26 12:58:48,846 DEBUG Layer 546: Alpha Weigthed: 0.9199176697067997\n",
      "2018-11-26 12:58:48,849 DEBUG Layer 553: Alpha Weigthed: 0.7663161546351969\n",
      "2018-11-26 12:58:48,852 DEBUG Layer 560: Alpha Weigthed: 1.1173393382677734\n",
      "2018-11-26 12:58:48,857 DEBUG Layer 567: Alpha Weigthed: 0.13605061196555687\n",
      "2018-11-26 12:58:48,860 DEBUG Layer 574: Alpha Weigthed: 0.7675963177688083\n",
      "2018-11-26 12:58:48,862 DEBUG Layer 581: Alpha Weigthed: 0.3870862610807112\n",
      "2018-11-26 12:58:48,865 DEBUG Layer 588: Alpha Weigthed: 0.5294041658912931\n",
      "2018-11-26 12:58:48,870 DEBUG Layer 595: Alpha Weigthed: 0.4096857986832565\n",
      "2018-11-26 12:58:48,873 DEBUG Layer 602: Alpha Weigthed: 0.7324846313653267\n",
      "2018-11-26 12:58:48,877 DEBUG Layer 609: Alpha Weigthed: 0.751519958229239\n",
      "2018-11-26 12:58:48,881 DEBUG Layer 616: Alpha Weigthed: 0.6177186716843218\n",
      "2018-11-26 12:58:48,887 DEBUG Layer 623: Alpha Weigthed: 0.5599427038686712\n",
      "2018-11-26 12:58:48,890 DEBUG Layer 630: Alpha Weigthed: 0.6901682791087871\n",
      "2018-11-26 12:58:48,895 DEBUG Layer 637: Alpha Weigthed: 0.5880162897774346\n",
      "2018-11-26 12:58:48,899 DEBUG Layer 644: Alpha Weigthed: 0.6220716771451509\n",
      "2018-11-26 12:58:48,902 DEBUG Layer 651: Alpha Weigthed: 1.0107111953982117\n",
      "2018-11-26 12:58:48,905 DEBUG Layer 658: Alpha Weigthed: 0.5781682795883173\n",
      "2018-11-26 12:58:48,907 DEBUG Layer 665: Alpha Weigthed: 0.475689368834146\n",
      "2018-11-26 12:58:48,910 DEBUG Layer 672: Alpha Weigthed: 0.64341279765429\n",
      "2018-11-26 12:58:48,912 DEBUG Layer 679: Alpha Weigthed: 0.705735956183951\n",
      "2018-11-26 12:58:48,915 DEBUG Layer 686: Alpha Weigthed: 0.8060060077981605\n",
      "2018-11-26 12:58:48,920 DEBUG Layer 693: Alpha Weigthed: 0.8124304451615545\n",
      "2018-11-26 12:58:48,923 DEBUG Layer 700: Alpha Weigthed: 0.7688612122816274\n",
      "2018-11-26 12:58:48,928 DEBUG Layer 707: Alpha Weigthed: 0.5726402269280143\n",
      "2018-11-26 12:58:48,932 INFO Alpha Weighted: min: -0.5553586030436635, max: 3.608953501171657, avg: 0.3950056706870469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:48,936 INFO Alpha Weighted compound: min: -0.5553586030436635, max: 3.608953501171657, avg: 0.3950056706870469\n",
      "2018-11-26 12:58:50,690 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 12:58:50,693 INFO Analyzing model\n",
      "2018-11-26 12:58:50,697 INFO Layer 0: ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "2018-11-26 12:58:50,700 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:50,702 INFO Layer 1: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "2018-11-26 12:58:50,705 INFO Pytorch tensor shape detected: 64x3 (NxM), 7x7 (i,j)\n",
      "2018-11-26 12:58:50,708 INFO Layer 1: Analyzing 49 weight matrices...\n",
      "2018-11-26 12:58:50,710 INFO     Weight matrix 1/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,713 INFO     Weight matrix 2/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,715 INFO     Weight matrix 3/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,718 INFO     Weight matrix 4/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,722 INFO     Weight matrix 5/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,725 INFO     Weight matrix 6/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,727 INFO     Weight matrix 7/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,730 INFO     Weight matrix 8/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,732 INFO     Weight matrix 9/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,737 INFO     Weight matrix 10/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,741 INFO     Weight matrix 11/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,745 INFO     Weight matrix 12/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,748 INFO     Weight matrix 13/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,751 INFO     Weight matrix 14/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,753 INFO     Weight matrix 15/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,757 INFO     Weight matrix 16/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,760 INFO     Weight matrix 17/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,763 INFO     Weight matrix 18/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,767 INFO     Weight matrix 19/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,770 INFO     Weight matrix 20/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,773 INFO     Weight matrix 21/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,775 INFO     Weight matrix 22/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,778 INFO     Weight matrix 23/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,781 INFO     Weight matrix 24/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,784 INFO     Weight matrix 25/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,787 INFO     Weight matrix 26/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,790 INFO     Weight matrix 27/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,792 INFO     Weight matrix 28/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,795 INFO     Weight matrix 29/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,798 INFO     Weight matrix 30/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,801 INFO     Weight matrix 31/49 (3,64): Skipping: too small (<50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:50,804 INFO     Weight matrix 32/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,807 INFO     Weight matrix 33/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,809 INFO     Weight matrix 34/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,812 INFO     Weight matrix 35/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,815 INFO     Weight matrix 36/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,817 INFO     Weight matrix 37/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,819 INFO     Weight matrix 38/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,822 INFO     Weight matrix 39/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,824 INFO     Weight matrix 40/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,827 INFO     Weight matrix 41/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,829 INFO     Weight matrix 42/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,832 INFO     Weight matrix 43/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,835 INFO     Weight matrix 44/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,838 INFO     Weight matrix 45/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,841 INFO     Weight matrix 46/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,847 INFO     Weight matrix 47/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,850 INFO     Weight matrix 48/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,854 INFO     Weight matrix 49/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 12:58:50,857 INFO Layer 2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:50,861 INFO Layer 2: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:50,863 INFO Layer 3: ReLU(inplace)\n",
      "2018-11-26 12:58:50,866 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:50,870 INFO Layer 4: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "2018-11-26 12:58:50,873 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:50,876 INFO Layer 5: Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:58:50,879 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:50,882 INFO Layer 6: BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 12:58:50,885 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:50,889 INFO Layer 7: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:58:50,893 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:50,895 INFO Layer 7: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:50,898 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:51,555 INFO     Weight matrix 1/9 (64,64): Alpha: 2.08592594176104, Alpha Weighted: 0.39401361835208437, D: 0.0917883820756541\n",
      "2018-11-26 12:58:51,558 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.3994942307472229\n",
      "2018-11-26 12:58:51,561 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:52,229 INFO     Weight matrix 2/9 (64,64): Alpha: 1.6477266027880735, Alpha Weighted: 0.25997470484726026, D: 0.17097268173225638\n",
      "2018-11-26 12:58:52,234 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.4928339719772339\n",
      "2018-11-26 12:58:52,237 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:52,653 INFO     Weight matrix 3/9 (64,64): Alpha: 2.049003611283939, Alpha Weighted: 0.22997093243417127, D: 0.1271845443649853\n",
      "2018-11-26 12:58:52,656 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.4090757668018341\n",
      "2018-11-26 12:58:52,659 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:53,082 INFO     Weight matrix 4/9 (64,64): Alpha: 1.6126754330146316, Alpha Weighted: 0.276544755341337, D: 0.18636535908073415\n",
      "2018-11-26 12:58:53,085 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.5110701322555542\n",
      "2018-11-26 12:58:53,088 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:53,490 INFO     Weight matrix 5/9 (64,64): Alpha: 1.8541381259886434, Alpha Weighted: 1.6780320840945113, D: 0.17552306188898775\n",
      "2018-11-26 12:58:53,493 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.7587662935256958\n",
      "2018-11-26 12:58:53,498 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:53,925 INFO     Weight matrix 6/9 (64,64): Alpha: 1.5558698219039537, Alpha Weighted: 0.467075807464634, D: 0.20450911144829353\n",
      "2018-11-26 12:58:53,927 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.5628993511199951\n",
      "2018-11-26 12:58:53,930 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:54,357 INFO     Weight matrix 7/9 (64,64): Alpha: 1.9982102352675373, Alpha Weighted: 0.32408377328464194, D: 0.14336205824979886\n",
      "2018-11-26 12:58:54,360 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.4178236126899719\n",
      "2018-11-26 12:58:54,363 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:54,777 INFO     Weight matrix 8/9 (64,64): Alpha: 2.144014638873454, Alpha Weighted: 0.41370802967363873, D: 0.20389368929833485\n",
      "2018-11-26 12:58:54,780 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.5255467295646667\n",
      "2018-11-26 12:58:54,783 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:55,224 INFO     Weight matrix 9/9 (64,64): Alpha: 2.308094819764403, Alpha Weighted: 0.4494764875385992, D: 0.13252627726981842\n",
      "2018-11-26 12:58:55,227 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.45166245102882385\n",
      "2018-11-26 12:58:55,229 INFO Layer 8: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:55,232 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:55,234 INFO Layer 9: ReLU(inplace)\n",
      "2018-11-26 12:58:55,237 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:55,241 INFO Layer 10: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:55,244 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:55,248 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:55,251 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:55,701 INFO     Weight matrix 1/9 (64,64): Alpha: 2.7272638775246403, Alpha Weighted: -0.6492226839853398, D: 0.15893219777602552\n",
      "2018-11-26 12:58:55,704 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.35071104764938354\n",
      "2018-11-26 12:58:55,706 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:56,158 INFO     Weight matrix 2/9 (64,64): Alpha: 2.667925102238509, Alpha Weighted: 0.07123445322490425, D: 0.12432890571675403\n",
      "2018-11-26 12:58:56,161 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.4201262593269348\n",
      "2018-11-26 12:58:56,163 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:56,621 INFO     Weight matrix 3/9 (64,64): Alpha: 2.1774033055433883, Alpha Weighted: -0.37201518155730795, D: 0.17140329336718102\n",
      "2018-11-26 12:58:56,624 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.3746475279331207\n",
      "2018-11-26 12:58:56,627 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:57,065 INFO     Weight matrix 4/9 (64,64): Alpha: 2.3680438808172903, Alpha Weighted: 0.08582508290073897, D: 0.1595927794382428\n",
      "2018-11-26 12:58:57,069 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.43538808822631836\n",
      "2018-11-26 12:58:57,072 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:57,515 INFO     Weight matrix 5/9 (64,64): Alpha: 2.1095837374457944, Alpha Weighted: 0.6466639661384544, D: 0.18722932095976974\n",
      "2018-11-26 12:58:57,518 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.6097316145896912\n",
      "2018-11-26 12:58:57,522 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:57,959 INFO     Weight matrix 6/9 (64,64): Alpha: 2.914289596538548, Alpha Weighted: 0.6377155488652788, D: 0.13204310965615296\n",
      "2018-11-26 12:58:57,962 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.5146217942237854\n",
      "2018-11-26 12:58:57,965 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:58,394 INFO     Weight matrix 7/9 (64,64): Alpha: 2.785020365807717, Alpha Weighted: -0.5272297966295281, D: 0.13569568172398982\n",
      "2018-11-26 12:58:58,397 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.37113213539123535\n",
      "2018-11-26 12:58:58,400 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:58,833 INFO     Weight matrix 8/9 (64,64): Alpha: 2.6792811678075594, Alpha Weighted: 0.42148133782458386, D: 0.14351965916903242\n",
      "2018-11-26 12:58:58,836 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.4947205185890198\n",
      "2018-11-26 12:58:58,840 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:59,286 INFO     Weight matrix 9/9 (64,64): Alpha: 2.977173310795038, Alpha Weighted: 0.06435212924241958, D: 0.13678175283944727\n",
      "2018-11-26 12:58:59,289 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.44592392444610596\n",
      "2018-11-26 12:58:59,291 INFO Layer 11: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:58:59,295 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:59,298 INFO Layer 12: BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 12:58:59,301 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 12:58:59,303 INFO Layer 13: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:58:59,307 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:58:59,309 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:58:59,312 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:58:59,766 INFO     Weight matrix 1/9 (64,64): Alpha: 2.7401393098858633, Alpha Weighted: 0.7322267783228449, D: 0.10544436989049583\n",
      "2018-11-26 12:58:59,768 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.4528571665287018\n",
      "2018-11-26 12:58:59,771 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:00,209 INFO     Weight matrix 2/9 (64,64): Alpha: 1.961805646228927, Alpha Weighted: 0.5995529215151225, D: 0.14161587709338253\n",
      "2018-11-26 12:59:00,211 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.5070993900299072\n",
      "2018-11-26 12:59:00,214 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:00,702 INFO     Weight matrix 3/9 (64,64): Alpha: 2.3643355531976695, Alpha Weighted: 0.3616508505936895, D: 0.14629658439452575\n",
      "2018-11-26 12:59:00,705 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.45500725507736206\n",
      "2018-11-26 12:59:00,708 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:59:01,210 INFO     Weight matrix 4/9 (64,64): Alpha: 1.9094160750513196, Alpha Weighted: 0.2513366152659846, D: 0.1635302651813334\n",
      "2018-11-26 12:59:01,213 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.49615415930747986\n",
      "2018-11-26 12:59:01,216 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:01,776 INFO     Weight matrix 5/9 (64,64): Alpha: 1.9257722650363789, Alpha Weighted: 0.8715621185161369, D: 0.15857330576904188\n",
      "2018-11-26 12:59:01,781 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.6064251065254211\n",
      "2018-11-26 12:59:01,787 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:02,250 INFO     Weight matrix 6/9 (64,64): Alpha: 1.6844287128710171, Alpha Weighted: 0.3179072785105674, D: 0.1779014823208619\n",
      "2018-11-26 12:59:02,252 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.5429444313049316\n",
      "2018-11-26 12:59:02,256 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:02,821 INFO     Weight matrix 7/9 (64,64): Alpha: 2.401080605574829, Alpha Weighted: 0.6422420084585768, D: 0.10713146633912984\n",
      "2018-11-26 12:59:02,824 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.4680757224559784\n",
      "2018-11-26 12:59:02,828 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:03,260 INFO     Weight matrix 8/9 (64,64): Alpha: 1.7104410377316275, Alpha Weighted: 0.5743044580169748, D: 0.13806114259956737\n",
      "2018-11-26 12:59:03,263 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.5512226223945618\n",
      "2018-11-26 12:59:03,265 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:03,704 INFO     Weight matrix 9/9 (64,64): Alpha: 2.701095364009727, Alpha Weighted: 0.6168866095887858, D: 0.13131251702267094\n",
      "2018-11-26 12:59:03,707 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.4851316213607788\n",
      "2018-11-26 12:59:03,710 INFO Layer 14: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:59:03,712 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:03,715 INFO Layer 15: ReLU(inplace)\n",
      "2018-11-26 12:59:03,717 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:03,720 INFO Layer 16: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:59:03,727 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:59:03,730 INFO Layer 16: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:59:03,733 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:04,192 INFO     Weight matrix 1/9 (64,64): Alpha: 4.403902421463419, Alpha Weighted: -1.73548113014596, D: 0.19961674767868598\n",
      "2018-11-26 12:59:04,194 INFO     Weight matrix 1/9 (64,64): Alpha 4.403902421463419 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:04,197 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.33790627121925354\n",
      "2018-11-26 12:59:04,200 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:04,689 INFO     Weight matrix 2/9 (64,64): Alpha: 2.160413566623768, Alpha Weighted: -0.2918452325658962, D: 0.18937108613809517\n",
      "2018-11-26 12:59:04,692 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.42357760667800903\n",
      "2018-11-26 12:59:04,695 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:05,197 INFO     Weight matrix 3/9 (64,64): Alpha: 3.536847014582524, Alpha Weighted: -0.8437060271753453, D: 0.16350353504014653\n",
      "2018-11-26 12:59:05,200 INFO     Weight matrix 3/9 (64,64): Alpha 3.536847014582524 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:05,202 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.39023399353027344\n",
      "2018-11-26 12:59:05,205 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:05,811 INFO     Weight matrix 4/9 (64,64): Alpha: 2.1024176814609983, Alpha Weighted: -0.16687603314972696, D: 0.1765880520304881\n",
      "2018-11-26 12:59:05,814 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.4403513967990875\n",
      "2018-11-26 12:59:05,820 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:06,269 INFO     Weight matrix 5/9 (64,64): Alpha: 2.5506482641240265, Alpha Weighted: 0.12566035923945634, D: 0.18393653545589417\n",
      "2018-11-26 12:59:06,274 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.5332736372947693\n",
      "2018-11-26 12:59:06,278 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:06,815 INFO     Weight matrix 6/9 (64,64): Alpha: 6.862387149412229, Alpha Weighted: -0.009502683474065849, D: 0.2000000000000005\n",
      "2018-11-26 12:59:06,817 INFO     Weight matrix 6/9 (64,64): Alpha 6.862387149412229 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:06,822 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.49840793013572693\n",
      "2018-11-26 12:59:06,826 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:07,314 INFO     Weight matrix 7/9 (64,64): Alpha: 2.141528398547382, Alpha Weighted: -0.5682163607852232, D: 0.18870268705313942\n",
      "2018-11-26 12:59:07,316 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.3829489052295685\n",
      "2018-11-26 12:59:07,320 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:07,862 INFO     Weight matrix 8/9 (64,64): Alpha: 2.3953463301437035, Alpha Weighted: 0.11177610100217641, D: 0.18063910954386786\n",
      "2018-11-26 12:59:07,865 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.5002455711364746\n",
      "2018-11-26 12:59:07,867 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 12:59:08,294 INFO     Weight matrix 9/9 (64,64): Alpha: 2.5992513537470403, Alpha Weighted: -0.2485913632803745, D: 0.18522716680550144\n",
      "2018-11-26 12:59:08,297 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.4651367962360382\n",
      "2018-11-26 12:59:08,299 INFO Layer 17: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:59:08,303 INFO Layer 17: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:08,306 INFO Layer 18: Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:59:08,308 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:08,310 INFO Layer 19: BasicBlock(\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:59:08,313 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:08,316 INFO Layer 20: Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:59:08,324 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:59:08,326 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:59:08,329 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:59:08,794 INFO     Weight matrix 1/9 (64,128): Alpha: 2.5293731889975053, Alpha Weighted: -0.5081092077980445, D: 0.191544871713766\n",
      "2018-11-26 12:59:08,798 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.4721699655056\n",
      "2018-11-26 12:59:08,801 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:59:09,236 INFO     Weight matrix 2/9 (64,128): Alpha: 2.5648619898470892, Alpha Weighted: 0.15602537251060725, D: 0.17825218773425305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:59:09,240 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.5599187016487122\n",
      "2018-11-26 12:59:09,243 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:59:09,671 INFO     Weight matrix 3/9 (64,128): Alpha: 2.5053498939110037, Alpha Weighted: -0.11694826693892993, D: 0.1905477400276258\n",
      "2018-11-26 12:59:09,675 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.5322392582893372\n",
      "2018-11-26 12:59:09,678 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:59:10,111 INFO     Weight matrix 4/9 (64,128): Alpha: 2.053407510916492, Alpha Weighted: 0.07086261444339159, D: 0.19107137872983032\n",
      "2018-11-26 12:59:10,115 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.5582053065299988\n",
      "2018-11-26 12:59:10,117 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:59:10,554 INFO     Weight matrix 5/9 (64,128): Alpha: 1.8260881577354446, Alpha Weighted: 0.4689316491195188, D: 0.1888685533786313\n",
      "2018-11-26 12:59:10,558 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.6406477093696594\n",
      "2018-11-26 12:59:10,561 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:59:11,011 INFO     Weight matrix 6/9 (64,128): Alpha: 2.542851845879057, Alpha Weighted: 0.546948423941486, D: 0.17498654572722416\n",
      "2018-11-26 12:59:11,015 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.6191611886024475\n",
      "2018-11-26 12:59:11,018 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:59:11,474 INFO     Weight matrix 7/9 (64,128): Alpha: 2.2992747554343524, Alpha Weighted: -0.08531568108460758, D: 0.2013838456722732\n",
      "2018-11-26 12:59:11,478 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.53813236951828\n",
      "2018-11-26 12:59:11,480 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:59:11,913 INFO     Weight matrix 8/9 (64,128): Alpha: 2.4941905410164384, Alpha Weighted: 0.452477163480532, D: 0.19053653722949931\n",
      "2018-11-26 12:59:11,917 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.6194336414337158\n",
      "2018-11-26 12:59:11,919 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 12:59:12,368 INFO     Weight matrix 9/9 (64,128): Alpha: 3.8374589699967037, Alpha Weighted: 0.4648528372826212, D: 0.180884793604976\n",
      "2018-11-26 12:59:12,370 INFO     Weight matrix 9/9 (64,128): Alpha 3.8374589699967037 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:12,374 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.5925993323326111\n",
      "2018-11-26 12:59:12,377 INFO Layer 21: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:59:12,380 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:12,386 INFO Layer 22: ReLU(inplace)\n",
      "2018-11-26 12:59:12,388 INFO Layer 22: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:12,390 INFO Layer 23: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:59:12,395 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:59:12,398 INFO Layer 23: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:59:12,401 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:13,365 INFO     Weight matrix 1/9 (128,128): Alpha: 3.53146696411832, Alpha Weighted: -0.9100874397477879, D: 0.13170802954575633\n",
      "2018-11-26 12:59:13,368 INFO     Weight matrix 1/9 (128,128): Alpha 3.53146696411832 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:13,372 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.46447765827178955\n",
      "2018-11-26 12:59:13,375 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:14,324 INFO     Weight matrix 2/9 (128,128): Alpha: 4.157932721133518, Alpha Weighted: 0.03847720410592404, D: 0.12650682623312176\n",
      "2018-11-26 12:59:14,327 INFO     Weight matrix 2/9 (128,128): Alpha 4.157932721133518 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:14,330 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.5795437097549438\n",
      "2018-11-26 12:59:14,333 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:15,290 INFO     Weight matrix 3/9 (128,128): Alpha: 3.05790764187955, Alpha Weighted: -0.6512204103255013, D: 0.15924917020314078\n",
      "2018-11-26 12:59:15,294 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.5137226581573486\n",
      "2018-11-26 12:59:15,297 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:16,245 INFO     Weight matrix 4/9 (128,128): Alpha: 3.2804223317901084, Alpha Weighted: -0.08630092327415993, D: 0.1460778571359757\n",
      "2018-11-26 12:59:16,249 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.5825978517532349\n",
      "2018-11-26 12:59:16,252 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:17,433 INFO     Weight matrix 5/9 (128,128): Alpha: 1.5712668426012941, Alpha Weighted: 0.8406896141691256, D: 0.18680708886310804\n",
      "2018-11-26 12:59:17,437 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.8435519933700562\n",
      "2018-11-26 12:59:17,439 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:18,504 INFO     Weight matrix 6/9 (128,128): Alpha: 1.7173765385466075, Alpha Weighted: 0.3082081800640937, D: 0.18912551534370142\n",
      "2018-11-26 12:59:18,508 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.6928181052207947\n",
      "2018-11-26 12:59:18,511 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:19,676 INFO     Weight matrix 7/9 (128,128): Alpha: 3.8386534503265537, Alpha Weighted: -0.376699542815365, D: 0.11931985945901513\n",
      "2018-11-26 12:59:19,679 INFO     Weight matrix 7/9 (128,128): Alpha 3.8386534503265537 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:19,683 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.5187480449676514\n",
      "2018-11-26 12:59:19,688 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:21,125 INFO     Weight matrix 8/9 (128,128): Alpha: 2.0796595296859035, Alpha Weighted: 0.3468238203817548, D: 0.19860599135234175\n",
      "2018-11-26 12:59:21,132 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.6849531531333923\n",
      "2018-11-26 12:59:21,136 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:22,217 INFO     Weight matrix 9/9 (128,128): Alpha: 2.9849909202907385, Alpha Weighted: -0.0698174607190755, D: 0.1568250031816641\n",
      "2018-11-26 12:59:22,221 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.592700719833374\n",
      "2018-11-26 12:59:22,224 INFO Layer 24: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:59:22,227 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:22,230 INFO Layer 25: Sequential(\n",
      "  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 12:59:22,233 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:22,236 INFO Layer 26: Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 12:59:22,240 INFO Pytorch tensor shape detected: 128x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 12:59:22,245 INFO Layer 26: Analyzing 1 weight matrices...\n",
      "2018-11-26 12:59:22,249 INFO     Weight matrix 1/1 (64,128): Analyzing ...\n",
      "2018-11-26 12:59:22,797 INFO     Weight matrix 1/1 (64,128): Alpha: 3.863360435314098, Alpha Weighted: 2.17809643703869, D: 0.1497992768283014\n",
      "2018-11-26 12:59:22,800 INFO     Weight matrix 1/1 (64,128): Alpha 3.863360435314098 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:22,804 INFO     Weight matrix 1/1 (64,128): Lognorm: 0.8058925271034241\n",
      "2018-11-26 12:59:22,806 INFO Layer 27: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:59:22,809 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:22,811 INFO Layer 28: BasicBlock(\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 12:59:22,814 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:22,816 INFO Layer 29: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:59:22,821 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:59:22,823 INFO Layer 29: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:59:22,826 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:23,876 INFO     Weight matrix 1/9 (128,128): Alpha: 2.698435627742879, Alpha Weighted: -0.22365775845349858, D: 0.13881931441485063\n",
      "2018-11-26 12:59:23,879 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.5598830580711365\n",
      "2018-11-26 12:59:23,882 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:24,952 INFO     Weight matrix 2/9 (128,128): Alpha: 2.5391904007170467, Alpha Weighted: 0.36020514425240524, D: 0.14939826875213436\n",
      "2018-11-26 12:59:24,955 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.6348187327384949\n",
      "2018-11-26 12:59:24,959 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:26,227 INFO     Weight matrix 3/9 (128,128): Alpha: 3.0591061541081137, Alpha Weighted: 0.04981914029650317, D: 0.15273421945269816\n",
      "2018-11-26 12:59:26,232 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.58717942237854\n",
      "2018-11-26 12:59:26,235 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:27,419 INFO     Weight matrix 4/9 (128,128): Alpha: 3.3577331942843838, Alpha Weighted: 0.6296837981470953, D: 0.14048182615312133\n",
      "2018-11-26 12:59:27,432 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.6349189877510071\n",
      "2018-11-26 12:59:27,436 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:28,621 INFO     Weight matrix 5/9 (128,128): Alpha: 1.958280738869209, Alpha Weighted: 0.5785790672004059, D: 0.15431958888576314\n",
      "2018-11-26 12:59:28,624 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.716701090335846\n",
      "2018-11-26 12:59:28,629 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:29,833 INFO     Weight matrix 6/9 (128,128): Alpha: 1.7851325719270574, Alpha Weighted: 0.5166822386260741, D: 0.15489728668016733\n",
      "2018-11-26 12:59:29,837 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.6905273199081421\n",
      "2018-11-26 12:59:29,842 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:31,070 INFO     Weight matrix 7/9 (128,128): Alpha: 2.4338916911919353, Alpha Weighted: -0.1500681926025223, D: 0.15440140462495544\n",
      "2018-11-26 12:59:31,074 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.5879391431808472\n",
      "2018-11-26 12:59:31,077 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:32,262 INFO     Weight matrix 8/9 (128,128): Alpha: 1.9392472199093342, Alpha Weighted: 0.4176133384483507, D: 0.16489230382710096\n",
      "2018-11-26 12:59:32,266 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.6831360459327698\n",
      "2018-11-26 12:59:32,269 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:33,425 INFO     Weight matrix 9/9 (128,128): Alpha: 2.40718075198194, Alpha Weighted: 0.13223101570858634, D: 0.15577700446635329\n",
      "2018-11-26 12:59:33,428 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.6248815059661865\n",
      "2018-11-26 12:59:33,433 INFO Layer 30: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:59:33,438 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:33,442 INFO Layer 31: ReLU(inplace)\n",
      "2018-11-26 12:59:33,446 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:33,450 INFO Layer 32: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:59:33,456 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:59:33,458 INFO Layer 32: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:59:33,460 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:34,568 INFO     Weight matrix 1/9 (128,128): Alpha: 3.8277046633819034, Alpha Weighted: -0.33602788005454176, D: 0.09175820464495776\n",
      "2018-11-26 12:59:34,571 INFO     Weight matrix 1/9 (128,128): Alpha 3.8277046633819034 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:34,576 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.5170747637748718\n",
      "2018-11-26 12:59:34,578 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:35,690 INFO     Weight matrix 2/9 (128,128): Alpha: 2.8999652866489427, Alpha Weighted: 0.2706342376259387, D: 0.09076896413140534\n",
      "2018-11-26 12:59:35,694 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.5698797702789307\n",
      "2018-11-26 12:59:35,698 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:36,734 INFO     Weight matrix 3/9 (128,128): Alpha: 3.200868502540824, Alpha Weighted: -0.2170035748372955, D: 0.11394492754219188\n",
      "2018-11-26 12:59:36,740 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.5404695868492126\n",
      "2018-11-26 12:59:36,743 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:37,848 INFO     Weight matrix 4/9 (128,128): Alpha: 3.10434178961397, Alpha Weighted: 0.17414665783821198, D: 0.10250621001804983\n",
      "2018-11-26 12:59:37,854 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.5641091465950012\n",
      "2018-11-26 12:59:37,857 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:38,890 INFO     Weight matrix 5/9 (128,128): Alpha: 2.2514481528610997, Alpha Weighted: 1.2863589489538734, D: 0.09423457802661006\n",
      "2018-11-26 12:59:38,895 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.695960521697998\n",
      "2018-11-26 12:59:38,898 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:39,969 INFO     Weight matrix 6/9 (128,128): Alpha: 2.693857510458697, Alpha Weighted: 0.28326310932340554, D: 0.112180895568804\n",
      "2018-11-26 12:59:39,974 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.6077677607536316\n",
      "2018-11-26 12:59:39,977 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:40,983 INFO     Weight matrix 7/9 (128,128): Alpha: 3.802544094046315, Alpha Weighted: -0.33313221449211566, D: 0.10060046772739073\n",
      "2018-11-26 12:59:40,986 INFO     Weight matrix 7/9 (128,128): Alpha 3.802544094046315 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:40,992 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.5388143658638\n",
      "2018-11-26 12:59:40,995 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:42,082 INFO     Weight matrix 8/9 (128,128): Alpha: 3.107062510573358, Alpha Weighted: 0.3454031614517667, D: 0.109769158929928\n",
      "2018-11-26 12:59:42,086 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.6049209237098694\n",
      "2018-11-26 12:59:42,090 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 12:59:43,046 INFO     Weight matrix 9/9 (128,128): Alpha: 2.831552469125186, Alpha Weighted: -0.09577968523372847, D: 0.12289760772947156\n",
      "2018-11-26 12:59:43,050 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.5738546848297119\n",
      "2018-11-26 12:59:43,052 INFO Layer 33: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:59:43,055 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:43,059 INFO Layer 34: Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 12:59:43,061 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:43,064 INFO Layer 35: BasicBlock(\n",
      "  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 12:59:43,067 INFO Layer 35: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:43,069 INFO Layer 36: Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:59:43,079 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:59:43,082 INFO Layer 36: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:59:43,085 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:59:44,165 INFO     Weight matrix 1/9 (128,256): Alpha: 3.3668840108427855, Alpha Weighted: -0.36327617744581137, D: 0.10674542624143793\n",
      "2018-11-26 12:59:44,169 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.5896475911140442\n",
      "2018-11-26 12:59:44,171 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:59:45,149 INFO     Weight matrix 2/9 (128,256): Alpha: 4.142781557594516, Alpha Weighted: 0.09537340289890082, D: 0.1290766077382376\n",
      "2018-11-26 12:59:45,151 INFO     Weight matrix 2/9 (128,256): Alpha 4.142781557594516 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:45,157 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.6990422606468201\n",
      "2018-11-26 12:59:45,161 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:59:46,148 INFO     Weight matrix 3/9 (128,256): Alpha: 3.460525933915197, Alpha Weighted: -0.16018500916154077, D: 0.12362857593742943\n",
      "2018-11-26 12:59:46,152 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.6517252922058105\n",
      "2018-11-26 12:59:46,155 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:59:47,136 INFO     Weight matrix 4/9 (128,256): Alpha: 4.539788064314092, Alpha Weighted: 0.3339746447852371, D: 0.08879351314159423\n",
      "2018-11-26 12:59:47,138 INFO     Weight matrix 4/9 (128,256): Alpha 4.539788064314092 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:47,143 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.6918943524360657\n",
      "2018-11-26 12:59:47,147 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:59:48,137 INFO     Weight matrix 5/9 (128,256): Alpha: 7.30672054637901, Alpha Weighted: 1.5300806196962478, D: 0.12499999999999978\n",
      "2018-11-26 12:59:48,140 INFO     Weight matrix 5/9 (128,256): Alpha 7.30672054637901 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:48,145 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.7840527892112732\n",
      "2018-11-26 12:59:48,148 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:59:49,211 INFO     Weight matrix 6/9 (128,256): Alpha: 5.6700420750756315, Alpha Weighted: 1.0366199453749867, D: 0.13465212444948893\n",
      "2018-11-26 12:59:49,213 INFO     Weight matrix 6/9 (128,256): Alpha 5.6700420750756315 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:49,221 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.7913143038749695\n",
      "2018-11-26 12:59:49,224 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:59:50,359 INFO     Weight matrix 7/9 (128,256): Alpha: 5.053733532781327, Alpha Weighted: -0.1382539194727418, D: 0.11111111111111094\n",
      "2018-11-26 12:59:50,362 INFO     Weight matrix 7/9 (128,256): Alpha 5.053733532781327 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:50,365 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.6446924805641174\n",
      "2018-11-26 12:59:50,369 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:59:51,574 INFO     Weight matrix 8/9 (128,256): Alpha: 8.175033282986202, Alpha Weighted: 1.3797381333587764, D: 0.11683954528388457\n",
      "2018-11-26 12:59:51,576 INFO     Weight matrix 8/9 (128,256): Alpha 8.175033282986202 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:51,581 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.795989990234375\n",
      "2018-11-26 12:59:51,585 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 12:59:52,717 INFO     Weight matrix 9/9 (128,256): Alpha: 5.736895121702779, Alpha Weighted: 1.3798251943382505, D: 0.12499999999999978\n",
      "2018-11-26 12:59:52,720 INFO     Weight matrix 9/9 (128,256): Alpha 5.736895121702779 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:52,724 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.7467861175537109\n",
      "2018-11-26 12:59:52,728 INFO Layer 37: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 12:59:52,735 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:52,739 INFO Layer 38: ReLU(inplace)\n",
      "2018-11-26 12:59:52,743 INFO Layer 38: Skipping (Layer not supported)\n",
      "2018-11-26 12:59:52,746 INFO Layer 39: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 12:59:52,763 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 12:59:52,766 INFO Layer 39: Analyzing 9 weight matrices...\n",
      "2018-11-26 12:59:52,769 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:59:55,555 INFO     Weight matrix 1/9 (256,256): Alpha: 2.798952516983198, Alpha Weighted: 0.1185509712240624, D: 0.09466591527537283\n",
      "2018-11-26 12:59:55,558 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.6926036477088928\n",
      "2018-11-26 12:59:55,561 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 12:59:58,280 INFO     Weight matrix 2/9 (256,256): Alpha: 3.6982541525303585, Alpha Weighted: 0.7128818836878228, D: 0.11091609770980565\n",
      "2018-11-26 12:59:58,285 INFO     Weight matrix 2/9 (256,256): Alpha 3.6982541525303585 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 12:59:58,290 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7822263836860657\n",
      "2018-11-26 12:59:58,294 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:01,171 INFO     Weight matrix 3/9 (256,256): Alpha: 3.3496999213617626, Alpha Weighted: 0.05369227859206334, D: 0.09007901346600511\n",
      "2018-11-26 13:00:01,176 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.7386592030525208\n",
      "2018-11-26 13:00:01,182 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:03,937 INFO     Weight matrix 4/9 (256,256): Alpha: 2.8186144303421714, Alpha Weighted: 0.5187663463034651, D: 0.09273276604983338\n",
      "2018-11-26 13:00:03,942 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.7594506144523621\n",
      "2018-11-26 13:00:03,945 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:06,658 INFO     Weight matrix 5/9 (256,256): Alpha: 3.905787772007375, Alpha Weighted: 1.8534145636510253, D: 0.11329516533297074\n",
      "2018-11-26 13:00:06,661 INFO     Weight matrix 5/9 (256,256): Alpha 3.905787772007375 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:00:06,667 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.9088530540466309\n",
      "2018-11-26 13:00:06,671 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:09,295 INFO     Weight matrix 6/9 (256,256): Alpha: 5.024383235242583, Alpha Weighted: 1.3449762644747265, D: 0.15153053500523228\n",
      "2018-11-26 13:00:09,298 INFO     Weight matrix 6/9 (256,256): Alpha 5.024383235242583 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:00:09,303 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.8662769198417664\n",
      "2018-11-26 13:00:09,306 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:12,021 INFO     Weight matrix 7/9 (256,256): Alpha: 3.1648603718544672, Alpha Weighted: -0.1396225650163055, D: 0.1074272888248845\n",
      "2018-11-26 13:00:12,026 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.724816620349884\n",
      "2018-11-26 13:00:12,030 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:14,610 INFO     Weight matrix 8/9 (256,256): Alpha: 3.0546216411350864, Alpha Weighted: 0.8387815304594958, D: 0.14261992107021038\n",
      "2018-11-26 13:00:14,614 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.8678616881370544\n",
      "2018-11-26 13:00:14,618 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:17,016 INFO     Weight matrix 9/9 (256,256): Alpha: 3.377058136392842, Alpha Weighted: 0.3830815722003161, D: 0.1553249425525981\n",
      "2018-11-26 13:00:17,021 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.8219429850578308\n",
      "2018-11-26 13:00:17,023 INFO Layer 40: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:00:17,026 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 13:00:17,028 INFO Layer 41: Sequential(\n",
      "  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:00:17,030 INFO Layer 41: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:00:17,032 INFO Layer 42: Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 13:00:17,036 INFO Pytorch tensor shape detected: 256x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:00:17,038 INFO Layer 42: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:00:17,041 INFO     Weight matrix 1/1 (128,256): Analyzing ...\n",
      "2018-11-26 13:00:18,119 INFO     Weight matrix 1/1 (128,256): Alpha: 3.1061876766686587, Alpha Weighted: 0.525515448568861, D: 0.13632229574151633\n",
      "2018-11-26 13:00:18,122 INFO     Weight matrix 1/1 (128,256): Lognorm: 0.7762191891670227\n",
      "2018-11-26 13:00:18,126 INFO Layer 43: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:00:18,128 INFO Layer 43: Skipping (Layer not supported)\n",
      "2018-11-26 13:00:18,130 INFO Layer 44: BasicBlock(\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:00:18,133 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 13:00:18,135 INFO Layer 45: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:00:18,141 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:00:18,144 INFO Layer 45: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:00:18,146 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:20,981 INFO     Weight matrix 1/9 (256,256): Alpha: 2.9602887217717777, Alpha Weighted: 0.2885134713192996, D: 0.09702028108772165\n",
      "2018-11-26 13:00:20,988 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.7297214269638062\n",
      "2018-11-26 13:00:20,992 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:24,504 INFO     Weight matrix 2/9 (256,256): Alpha: 2.6888229233256338, Alpha Weighted: 0.29048910315268717, D: 0.1349660455411581\n",
      "2018-11-26 13:00:24,508 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7517711520195007\n",
      "2018-11-26 13:00:24,512 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:27,147 INFO     Weight matrix 3/9 (256,256): Alpha: 2.7852056749639327, Alpha Weighted: 0.3429352809206596, D: 0.11680933869742371\n",
      "2018-11-26 13:00:27,153 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.7470499277114868\n",
      "2018-11-26 13:00:27,156 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:29,606 INFO     Weight matrix 4/9 (256,256): Alpha: 2.182750749641156, Alpha Weighted: 0.3812062915222349, D: 0.1162682214247942\n",
      "2018-11-26 13:00:29,611 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.7485865950584412\n",
      "2018-11-26 13:00:29,614 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:32,065 INFO     Weight matrix 5/9 (256,256): Alpha: 3.4435525165546967, Alpha Weighted: 1.2004187132325301, D: 0.0998042234360208\n",
      "2018-11-26 13:00:32,069 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.7827379703521729\n",
      "2018-11-26 13:00:32,072 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:34,672 INFO     Weight matrix 6/9 (256,256): Alpha: 2.1704737839720734, Alpha Weighted: 0.4292255555432056, D: 0.12617391130901462\n",
      "2018-11-26 13:00:34,677 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7714142799377441\n",
      "2018-11-26 13:00:34,680 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:37,090 INFO     Weight matrix 7/9 (256,256): Alpha: 2.543918987450437, Alpha Weighted: 0.2365935123454127, D: 0.11396078702497037\n",
      "2018-11-26 13:00:37,093 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.749273419380188\n",
      "2018-11-26 13:00:37,096 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:39,607 INFO     Weight matrix 8/9 (256,256): Alpha: 2.7794463773949216, Alpha Weighted: 0.6602156291624789, D: 0.12049936846632386\n",
      "2018-11-26 13:00:39,613 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7785983085632324\n",
      "2018-11-26 13:00:39,619 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:42,229 INFO     Weight matrix 9/9 (256,256): Alpha: 2.9125345042711865, Alpha Weighted: 0.5865649967980797, D: 0.1048650558396429\n",
      "2018-11-26 13:00:42,233 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7656707763671875\n",
      "2018-11-26 13:00:42,237 INFO Layer 46: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:00:42,240 INFO Layer 46: Skipping (Layer not supported)\n",
      "2018-11-26 13:00:42,243 INFO Layer 47: ReLU(inplace)\n",
      "2018-11-26 13:00:42,245 INFO Layer 47: Skipping (Layer not supported)\n",
      "2018-11-26 13:00:42,249 INFO Layer 48: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:00:42,257 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:00:42,259 INFO Layer 48: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:00:42,263 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:44,672 INFO     Weight matrix 1/9 (256,256): Alpha: 3.053592894060549, Alpha Weighted: 0.2846965719474778, D: 0.07189138386965421\n",
      "2018-11-26 13:00:44,677 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.6883019804954529\n",
      "2018-11-26 13:00:44,682 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:47,046 INFO     Weight matrix 2/9 (256,256): Alpha: 3.142601871020403, Alpha Weighted: 0.7790628333584334, D: 0.05623428056362856\n",
      "2018-11-26 13:00:47,050 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7174637317657471\n",
      "2018-11-26 13:00:47,053 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:49,412 INFO     Weight matrix 3/9 (256,256): Alpha: 2.950022308466588, Alpha Weighted: 0.3277670273522997, D: 0.07138523615165504\n",
      "2018-11-26 13:00:49,416 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.7126033902168274\n",
      "2018-11-26 13:00:49,419 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:51,779 INFO     Weight matrix 4/9 (256,256): Alpha: 2.6904835808563767, Alpha Weighted: 0.6041381690373513, D: 0.07045151708720837\n",
      "2018-11-26 13:00:51,784 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.6951768398284912\n",
      "2018-11-26 13:00:51,786 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:54,567 INFO     Weight matrix 5/9 (256,256): Alpha: 2.5864663729321755, Alpha Weighted: 1.5020970997586152, D: 0.0654994892363876\n",
      "2018-11-26 13:00:54,572 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.7672772407531738\n",
      "2018-11-26 13:00:54,574 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:56,972 INFO     Weight matrix 6/9 (256,256): Alpha: 2.752277712382239, Alpha Weighted: 0.8325050587949274, D: 0.08572614143171875\n",
      "2018-11-26 13:00:56,979 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7355829477310181\n",
      "2018-11-26 13:00:56,982 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:00:59,449 INFO     Weight matrix 7/9 (256,256): Alpha: 2.8862690096618455, Alpha Weighted: 0.24996132059668585, D: 0.08156257222444163\n",
      "2018-11-26 13:00:59,454 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.7059727311134338\n",
      "2018-11-26 13:00:59,457 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:01:01,865 INFO     Weight matrix 8/9 (256,256): Alpha: 2.9122349917903803, Alpha Weighted: 0.8688865053631896, D: 0.07622082141749975\n",
      "2018-11-26 13:01:01,869 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7462247014045715\n",
      "2018-11-26 13:01:01,873 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:01:04,211 INFO     Weight matrix 9/9 (256,256): Alpha: 3.0989553212315837, Alpha Weighted: 0.4960618371788528, D: 0.07942797524066297\n",
      "2018-11-26 13:01:04,215 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.7406564950942993\n",
      "2018-11-26 13:01:04,219 INFO Layer 49: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:01:04,223 INFO Layer 49: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:04,226 INFO Layer 50: Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:01:04,229 INFO Layer 50: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:04,232 INFO Layer 51: BasicBlock(\n",
      "  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:01:04,235 INFO Layer 51: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:04,238 INFO Layer 52: Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:01:04,265 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:01:04,268 INFO Layer 52: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:01:04,271 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:01:06,746 INFO     Weight matrix 1/9 (256,512): Alpha: 3.7473339372160512, Alpha Weighted: 0.6268481148646156, D: 0.0450805382639996\n",
      "2018-11-26 13:01:06,749 INFO     Weight matrix 1/9 (256,512): Alpha 3.7473339372160512 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:06,756 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.7731038928031921\n",
      "2018-11-26 13:01:06,760 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:01:09,866 INFO     Weight matrix 2/9 (256,512): Alpha: 4.39313823110697, Alpha Weighted: 0.9474576679572684, D: 0.06993979363864467\n",
      "2018-11-26 13:01:09,869 INFO     Weight matrix 2/9 (256,512): Alpha 4.39313823110697 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:09,876 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.8470125198364258\n",
      "2018-11-26 13:01:09,880 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:01:12,797 INFO     Weight matrix 3/9 (256,512): Alpha: 3.7774656055103115, Alpha Weighted: 1.0045818322494509, D: 0.06759728179371371\n",
      "2018-11-26 13:01:12,799 INFO     Weight matrix 3/9 (256,512): Alpha 3.7774656055103115 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:12,805 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.8376678228378296\n",
      "2018-11-26 13:01:12,807 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:01:15,569 INFO     Weight matrix 4/9 (256,512): Alpha: 4.155565766528122, Alpha Weighted: 0.8192395392767408, D: 0.07128026416268607\n",
      "2018-11-26 13:01:15,572 INFO     Weight matrix 4/9 (256,512): Alpha 4.155565766528122 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:15,578 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.8037548065185547\n",
      "2018-11-26 13:01:15,581 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:01:18,352 INFO     Weight matrix 5/9 (256,512): Alpha: 4.045856868738285, Alpha Weighted: 1.6289588794322052, D: 0.039838628069269966\n",
      "2018-11-26 13:01:18,355 INFO     Weight matrix 5/9 (256,512): Alpha 4.045856868738285 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:18,359 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.8652359247207642\n",
      "2018-11-26 13:01:18,362 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:01:20,843 INFO     Weight matrix 6/9 (256,512): Alpha: 4.2456565916574185, Alpha Weighted: 1.5424600539602387, D: 0.09099771339865922\n",
      "2018-11-26 13:01:20,846 INFO     Weight matrix 6/9 (256,512): Alpha 4.2456565916574185 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:20,851 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.9049846529960632\n",
      "2018-11-26 13:01:20,857 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:01:23,358 INFO     Weight matrix 7/9 (256,512): Alpha: 3.808607727575218, Alpha Weighted: 0.8276029027419702, D: 0.06414771075634174\n",
      "2018-11-26 13:01:23,361 INFO     Weight matrix 7/9 (256,512): Alpha 3.808607727575218 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:23,366 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.8154228925704956\n",
      "2018-11-26 13:01:23,369 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:01:25,876 INFO     Weight matrix 8/9 (256,512): Alpha: 4.521467994236187, Alpha Weighted: 1.5984594414912292, D: 0.08955359132436214\n",
      "2018-11-26 13:01:25,879 INFO     Weight matrix 8/9 (256,512): Alpha 4.521467994236187 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:25,892 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.9199431538581848\n",
      "2018-11-26 13:01:25,895 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:01:28,350 INFO     Weight matrix 9/9 (256,512): Alpha: 4.388749898814993, Alpha Weighted: 1.8821818165902722, D: 0.08063667103412042\n",
      "2018-11-26 13:01:28,352 INFO     Weight matrix 9/9 (256,512): Alpha 4.388749898814993 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:28,362 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.910116970539093\n",
      "2018-11-26 13:01:28,365 INFO Layer 53: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:01:28,367 INFO Layer 53: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:28,370 INFO Layer 54: ReLU(inplace)\n",
      "2018-11-26 13:01:28,372 INFO Layer 54: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:28,376 INFO Layer 55: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:01:28,430 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:01:28,435 INFO Layer 55: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:01:28,439 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:28,445 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:28,449 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:28,453 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:28,457 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:28,460 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:28,464 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:28,468 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:28,471 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:28,474 INFO Layer 56: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:01:28,477 INFO Layer 56: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:28,480 INFO Layer 57: Sequential(\n",
      "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:01:28,483 INFO Layer 57: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:28,487 INFO Layer 58: Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 13:01:28,495 INFO Pytorch tensor shape detected: 512x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:01:28,498 INFO Layer 58: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:01:28,503 INFO     Weight matrix 1/1 (256,512): Analyzing ...\n",
      "2018-11-26 13:01:30,888 INFO     Weight matrix 1/1 (256,512): Alpha: 2.1973860329301758, Alpha Weighted: 1.3674615510782795, D: 0.1294276274022942\n",
      "2018-11-26 13:01:30,891 INFO     Weight matrix 1/1 (256,512): Lognorm: 1.07454252243042\n",
      "2018-11-26 13:01:30,897 INFO Layer 59: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:01:30,900 INFO Layer 59: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:30,904 INFO Layer 60: BasicBlock(\n",
      "  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:01:30,907 INFO Layer 60: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:30,909 INFO Layer 61: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:01:30,928 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:01:30,931 INFO Layer 61: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:01:30,934 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:30,937 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:30,940 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:30,943 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:30,946 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:30,949 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:30,954 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:30,959 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:30,962 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:30,964 INFO Layer 62: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:01:30,966 INFO Layer 62: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:30,968 INFO Layer 63: ReLU(inplace)\n",
      "2018-11-26 13:01:30,981 INFO Layer 63: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:30,991 INFO Layer 64: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:01:31,032 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:01:31,034 INFO Layer 64: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:01:31,038 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:31,044 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:31,049 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:31,051 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:31,054 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:31,057 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:31,061 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:31,063 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:31,066 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:31,070 INFO Layer 65: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:01:31,073 INFO Layer 65: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:31,075 INFO Layer 66: AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "2018-11-26 13:01:31,081 INFO Layer 66: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:31,084 INFO Layer 67: Linear(in_features=512, out_features=1000, bias=True)\n",
      "2018-11-26 13:01:31,109 INFO Layer 67: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:01:31,112 INFO     Weight matrix 1/1 (512,1000): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:01:31,115 INFO ### Printing results ###\n",
      "2018-11-26 13:01:31,117 DEBUG Layer 7: Lognorm compound: 0.5032413933012221\n",
      "2018-11-26 13:01:31,121 DEBUG Layer 10: Lognorm compound: 0.4463336567083995\n",
      "2018-11-26 13:01:31,132 DEBUG Layer 13: Lognorm compound: 0.5072130527761247\n",
      "2018-11-26 13:01:31,135 DEBUG Layer 16: Lognorm compound: 0.44134245647324455\n",
      "2018-11-26 13:01:31,140 DEBUG Layer 20: Lognorm compound: 0.5702786081367068\n",
      "2018-11-26 13:01:31,146 DEBUG Layer 23: Lognorm compound: 0.6081237660513984\n",
      "2018-11-26 13:01:31,152 DEBUG Layer 26: Lognorm: 0.8058925271034241\n",
      "2018-11-26 13:01:31,156 DEBUG Layer 29: Lognorm compound: 0.6355539229181077\n",
      "2018-11-26 13:01:31,160 DEBUG Layer 32: Lognorm compound: 0.5792057249281142\n",
      "2018-11-26 13:01:31,164 DEBUG Layer 36: Lognorm compound: 0.7105716864267985\n",
      "2018-11-26 13:01:31,167 DEBUG Layer 39: Lognorm compound: 0.7958545684814453\n",
      "2018-11-26 13:01:31,170 DEBUG Layer 42: Lognorm: 0.7762191891670227\n",
      "2018-11-26 13:01:31,174 DEBUG Layer 45: Lognorm compound: 0.7583137618170844\n",
      "2018-11-26 13:01:31,180 DEBUG Layer 48: Lognorm compound: 0.723251117600335\n",
      "2018-11-26 13:01:31,187 DEBUG Layer 52: Lognorm compound: 0.8530269596311781\n",
      "2018-11-26 13:01:31,190 DEBUG Layer 58: Lognorm: 1.07454252243042\n",
      "2018-11-26 13:01:31,200 INFO LogNorm: min: 0.33790627121925354, max: 1.07454252243042, avg: 0.6320620775222778\n",
      "2018-11-26 13:01:31,204 INFO LogNorm compound: min: 0.44134245647324455, max: 1.07454252243042, avg: 0.6743103071219392\n",
      "2018-11-26 13:01:31,210 DEBUG Layer 7: Alpha compound: 1.9172954700717417\n",
      "2018-11-26 13:01:31,222 DEBUG Layer 10: Alpha compound: 2.6006649271687206\n",
      "2018-11-26 13:01:31,228 DEBUG Layer 13: Alpha compound: 2.1553905077319286\n",
      "2018-11-26 13:01:31,232 DEBUG Layer 16: Alpha compound: 3.194749131122788\n",
      "2018-11-26 13:01:31,241 DEBUG Layer 20: Alpha compound: 2.516984094859343\n",
      "2018-11-26 13:01:31,244 DEBUG Layer 23: Alpha compound: 2.9132974378191765\n",
      "2018-11-26 13:01:31,247 DEBUG Layer 26: Alpha: 3.863360435314098\n",
      "2018-11-26 13:01:31,251 DEBUG Layer 29: Alpha compound: 2.4642442611924333\n",
      "2018-11-26 13:01:31,255 DEBUG Layer 32: Alpha compound: 3.079927219916699\n",
      "2018-11-26 13:01:31,258 DEBUG Layer 36: Alpha compound: 5.272489347287948\n",
      "2018-11-26 13:01:31,262 DEBUG Layer 39: Alpha compound: 3.4658035753166487\n",
      "2018-11-26 13:01:31,265 DEBUG Layer 42: Alpha: 3.1061876766686587\n",
      "2018-11-26 13:01:31,270 DEBUG Layer 45: Alpha compound: 2.7185549154828683\n",
      "2018-11-26 13:01:31,277 DEBUG Layer 48: Alpha compound: 2.896989340266904\n",
      "2018-11-26 13:01:31,287 DEBUG Layer 52: Alpha compound: 4.120426957931507\n",
      "2018-11-26 13:01:31,290 DEBUG Layer 58: Alpha: 2.1973860329301758\n",
      "2018-11-26 13:01:31,293 INFO Alpha: min: 1.5558698219039537, max: 8.175033282986202, avg: 3.0251524068369275\n",
      "2018-11-26 13:01:31,303 INFO Alpha compound: min: 1.9172954700717417, max: 5.272489347287948, avg: 3.030234458192602\n",
      "2018-11-26 13:01:31,308 DEBUG Layer 7: Alpha Weighted compound: 0.4992089103367643\n",
      "2018-11-26 13:01:31,310 DEBUG Layer 10: Alpha Weighted compound: 0.04208942844713379\n",
      "2018-11-26 13:01:31,313 DEBUG Layer 13: Alpha Weighted compound: 0.5519632931987426\n",
      "2018-11-26 13:01:31,315 DEBUG Layer 16: Alpha Weighted compound: -0.4029758189261065\n",
      "2018-11-26 13:01:31,317 DEBUG Layer 20: Alpha Weighted compound: 0.161080544995175\n",
      "2018-11-26 13:01:31,319 DEBUG Layer 23: Alpha Weighted compound: -0.0622141064623324\n",
      "2018-11-26 13:01:31,321 DEBUG Layer 26: Alpha Weigthed: 2.17809643703869\n",
      "2018-11-26 13:01:31,325 DEBUG Layer 29: Alpha Weighted compound: 0.25678753240260005\n",
      "2018-11-26 13:01:31,332 DEBUG Layer 32: Alpha Weighted compound: 0.15309586228616834\n",
      "2018-11-26 13:01:31,336 DEBUG Layer 36: Alpha Weighted compound: 0.5659885371524784\n",
      "2018-11-26 13:01:31,339 DEBUG Layer 39: Alpha Weighted compound: 0.6316136495085192\n",
      "2018-11-26 13:01:31,341 DEBUG Layer 42: Alpha Weigthed: 0.525515448568861\n",
      "2018-11-26 13:01:31,344 DEBUG Layer 45: Alpha Weighted compound: 0.4906847282218432\n",
      "2018-11-26 13:01:31,347 DEBUG Layer 48: Alpha Weighted compound: 0.6605751581542036\n",
      "2018-11-26 13:01:31,349 DEBUG Layer 52: Alpha Weighted compound: 1.2086433609515546\n",
      "2018-11-26 13:01:31,351 DEBUG Layer 58: Alpha Weigthed: 1.3674615510782795\n",
      "2018-11-26 13:01:31,354 INFO Alpha Weighted: min: -1.73548113014596, max: 2.17809643703869, avg: 0.3906661929923877\n",
      "2018-11-26 13:01:31,357 INFO Alpha Weighted compound: min: -0.4029758189261065, max: 2.17809643703869, avg: 0.551725907309536\n",
      "2018-11-26 13:01:33,968 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 13:01:33,971 INFO Analyzing model\n",
      "2018-11-26 13:01:33,977 INFO Layer 0: ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:01:33,980 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:33,984 INFO Layer 1: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "2018-11-26 13:01:33,987 INFO Pytorch tensor shape detected: 64x3 (NxM), 7x7 (i,j)\n",
      "2018-11-26 13:01:33,993 INFO Layer 1: Analyzing 49 weight matrices...\n",
      "2018-11-26 13:01:33,997 INFO     Weight matrix 1/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,000 INFO     Weight matrix 2/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,003 INFO     Weight matrix 3/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,006 INFO     Weight matrix 4/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,009 INFO     Weight matrix 5/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,011 INFO     Weight matrix 6/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,014 INFO     Weight matrix 7/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,017 INFO     Weight matrix 8/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,019 INFO     Weight matrix 9/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,022 INFO     Weight matrix 10/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,025 INFO     Weight matrix 11/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,034 INFO     Weight matrix 12/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,037 INFO     Weight matrix 13/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,042 INFO     Weight matrix 14/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,047 INFO     Weight matrix 15/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,050 INFO     Weight matrix 16/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,052 INFO     Weight matrix 17/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,055 INFO     Weight matrix 18/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,057 INFO     Weight matrix 19/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,060 INFO     Weight matrix 20/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,063 INFO     Weight matrix 21/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,066 INFO     Weight matrix 22/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,068 INFO     Weight matrix 23/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,072 INFO     Weight matrix 24/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,076 INFO     Weight matrix 25/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,079 INFO     Weight matrix 26/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,083 INFO     Weight matrix 27/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,087 INFO     Weight matrix 28/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,090 INFO     Weight matrix 29/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,093 INFO     Weight matrix 30/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,099 INFO     Weight matrix 31/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,102 INFO     Weight matrix 32/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,106 INFO     Weight matrix 33/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,109 INFO     Weight matrix 34/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,112 INFO     Weight matrix 35/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,115 INFO     Weight matrix 36/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,118 INFO     Weight matrix 37/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,121 INFO     Weight matrix 38/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,124 INFO     Weight matrix 39/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,127 INFO     Weight matrix 40/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,131 INFO     Weight matrix 41/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,135 INFO     Weight matrix 42/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,138 INFO     Weight matrix 43/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,140 INFO     Weight matrix 44/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,144 INFO     Weight matrix 45/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,146 INFO     Weight matrix 46/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,150 INFO     Weight matrix 47/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,153 INFO     Weight matrix 48/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,156 INFO     Weight matrix 49/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:01:34,159 INFO Layer 2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:01:34,162 INFO Layer 2: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:34,164 INFO Layer 3: ReLU(inplace)\n",
      "2018-11-26 13:01:34,167 INFO Layer 3: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:01:34,169 INFO Layer 4: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "2018-11-26 13:01:34,172 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:34,175 INFO Layer 5: Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:01:34,178 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:34,181 INFO Layer 6: BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:01:34,184 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:34,187 INFO Layer 7: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:01:34,190 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:01:34,193 INFO Layer 7: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:01:34,195 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:34,908 INFO     Weight matrix 1/9 (64,64): Alpha: 2.1498617870430614, Alpha Weighted: -0.4749954795891825, D: 0.17240833851549486\n",
      "2018-11-26 13:01:34,911 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.2720319926738739\n",
      "2018-11-26 13:01:34,914 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:35,478 INFO     Weight matrix 2/9 (64,64): Alpha: 1.7272754641828443, Alpha Weighted: -0.13408535426118207, D: 0.20401942641364623\n",
      "2018-11-26 13:01:35,481 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.37870973348617554\n",
      "2018-11-26 13:01:35,484 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:35,927 INFO     Weight matrix 3/9 (64,64): Alpha: 2.1393772980632404, Alpha Weighted: -0.436847390321472, D: 0.1703264156041645\n",
      "2018-11-26 13:01:35,930 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.29398345947265625\n",
      "2018-11-26 13:01:35,932 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:36,365 INFO     Weight matrix 4/9 (64,64): Alpha: 1.5998908730206585, Alpha Weighted: -0.08257680550959298, D: 0.20130341867233437\n",
      "2018-11-26 13:01:36,367 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.40192314982414246\n",
      "2018-11-26 13:01:36,371 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:36,795 INFO     Weight matrix 5/9 (64,64): Alpha: 1.8874445033524867, Alpha Weighted: 1.4608867499140248, D: 0.17152566758314736\n",
      "2018-11-26 13:01:36,798 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.6825634241104126\n",
      "2018-11-26 13:01:36,801 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:37,233 INFO     Weight matrix 6/9 (64,64): Alpha: 1.5795685343427133, Alpha Weighted: 0.09714553295266028, D: 0.21222279803647948\n",
      "2018-11-26 13:01:37,236 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.4472293555736542\n",
      "2018-11-26 13:01:37,239 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:37,677 INFO     Weight matrix 7/9 (64,64): Alpha: 1.9701191419381208, Alpha Weighted: -0.32002316286644716, D: 0.15884869702406024\n",
      "2018-11-26 13:01:37,680 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.3086911141872406\n",
      "2018-11-26 13:01:37,682 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:38,120 INFO     Weight matrix 8/9 (64,64): Alpha: 1.6689184176313838, Alpha Weighted: 0.013673881058207833, D: 0.1993555273397309\n",
      "2018-11-26 13:01:38,124 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.44637802243232727\n",
      "2018-11-26 13:01:38,127 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:38,561 INFO     Weight matrix 9/9 (64,64): Alpha: 1.8130979665808877, Alpha Weighted: -0.19864033473126674, D: 0.1682573773933862\n",
      "2018-11-26 13:01:38,563 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.3329903781414032\n",
      "2018-11-26 13:01:38,566 INFO Layer 8: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:01:38,569 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:38,572 INFO Layer 9: ReLU(inplace)\n",
      "2018-11-26 13:01:38,574 INFO Layer 9: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:38,577 INFO Layer 10: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:01:38,581 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:01:38,583 INFO Layer 10: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:01:38,586 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:39,063 INFO     Weight matrix 1/9 (64,64): Alpha: 2.5394243429029255, Alpha Weighted: -0.8686539560839006, D: 0.11704333017384372\n",
      "2018-11-26 13:01:39,066 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.23161980509757996\n",
      "2018-11-26 13:01:39,069 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:39,531 INFO     Weight matrix 2/9 (64,64): Alpha: 1.8163003641114, Alpha Weighted: -0.47959255384605887, D: 0.1736525612799168\n",
      "2018-11-26 13:01:39,534 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.3122708201408386\n",
      "2018-11-26 13:01:39,537 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:39,983 INFO     Weight matrix 3/9 (64,64): Alpha: 2.995367278976609, Alpha Weighted: -1.023506428502919, D: 0.13175120264024598\n",
      "2018-11-26 13:01:39,986 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.25686219334602356\n",
      "2018-11-26 13:01:39,989 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:40,421 INFO     Weight matrix 4/9 (64,64): Alpha: 1.97607317291481, Alpha Weighted: -0.1416574432763022, D: 0.1401788114913246\n",
      "2018-11-26 13:01:40,426 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.33228883147239685\n",
      "2018-11-26 13:01:40,429 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:40,877 INFO     Weight matrix 5/9 (64,64): Alpha: 2.2898100658876337, Alpha Weighted: 0.3330448806377161, D: 0.18221738248909258\n",
      "2018-11-26 13:01:40,882 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.5054314136505127\n",
      "2018-11-26 13:01:40,886 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:41,317 INFO     Weight matrix 6/9 (64,64): Alpha: 2.6943437945159943, Alpha Weighted: -0.22128992870637923, D: 0.1705428345207552\n",
      "2018-11-26 13:01:41,319 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.3817022442817688\n",
      "2018-11-26 13:01:41,322 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:41,773 INFO     Weight matrix 7/9 (64,64): Alpha: 3.1394805199155624, Alpha Weighted: -0.9290485937922899, D: 0.1468810682408742\n",
      "2018-11-26 13:01:41,776 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.26378437876701355\n",
      "2018-11-26 13:01:41,779 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:42,217 INFO     Weight matrix 8/9 (64,64): Alpha: 2.7821519132051726, Alpha Weighted: 0.11182602420376953, D: 0.1527531620401434\n",
      "2018-11-26 13:01:42,219 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.3957526385784149\n",
      "2018-11-26 13:01:42,223 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:01:42,673 INFO     Weight matrix 9/9 (64,64): Alpha: 3.628762369149484, Alpha Weighted: -0.8792290747157351, D: 0.1520219163412656\n",
      "2018-11-26 13:01:42,675 INFO     Weight matrix 9/9 (64,64): Alpha 3.628762369149484 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:42,679 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.3095843195915222\n",
      "2018-11-26 13:01:42,682 INFO Layer 11: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:01:42,684 INFO Layer 11: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:42,690 INFO Layer 12: BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:01:42,692 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:42,695 INFO Layer 13: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:01:42,698 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:01:42,701 INFO Layer 13: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:01:42,704 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:43,168 INFO     Weight matrix 1/9 (64,64): Alpha: 3.1206982882330054, Alpha Weighted: -1.2822629231206781, D: 0.16721429750738415\n",
      "2018-11-26 13:01:43,171 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.264235258102417\n",
      "2018-11-26 13:01:43,173 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:43,613 INFO     Weight matrix 2/9 (64,64): Alpha: 1.948181240581929, Alpha Weighted: -0.42544760135858867, D: 0.18081107662058352\n",
      "2018-11-26 13:01:43,616 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.36786478757858276\n",
      "2018-11-26 13:01:43,619 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:44,069 INFO     Weight matrix 3/9 (64,64): Alpha: 2.5163649031364077, Alpha Weighted: -1.035831320034359, D: 0.2019837089548\n",
      "2018-11-26 13:01:44,072 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.28624042868614197\n",
      "2018-11-26 13:01:44,075 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:44,520 INFO     Weight matrix 4/9 (64,64): Alpha: 1.6646165721239283, Alpha Weighted: -0.3600311822972849, D: 0.20011683535996744\n",
      "2018-11-26 13:01:44,523 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.361628919839859\n",
      "2018-11-26 13:01:44,526 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:44,972 INFO     Weight matrix 5/9 (64,64): Alpha: 1.780114931187097, Alpha Weighted: 0.6658145732976604, D: 0.1492143345731346\n",
      "2018-11-26 13:01:44,975 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.5506614446640015\n",
      "2018-11-26 13:01:44,980 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:45,419 INFO     Weight matrix 6/9 (64,64): Alpha: 1.6555624562106694, Alpha Weighted: -0.18594354599774948, D: 0.19547395119130428\n",
      "2018-11-26 13:01:45,422 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.4043586552143097\n",
      "2018-11-26 13:01:45,425 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:45,860 INFO     Weight matrix 7/9 (64,64): Alpha: 1.9042921960190786, Alpha Weighted: -0.8597239639026528, D: 0.21666837677817574\n",
      "2018-11-26 13:01:45,863 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.28646010160446167\n",
      "2018-11-26 13:01:45,866 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:46,308 INFO     Weight matrix 8/9 (64,64): Alpha: 1.7030953813026768, Alpha Weighted: -0.15603221564075367, D: 0.1777661456588343\n",
      "2018-11-26 13:01:46,311 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.4054296910762787\n",
      "2018-11-26 13:01:46,313 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:46,758 INFO     Weight matrix 9/9 (64,64): Alpha: 2.2520268555096665, Alpha Weighted: -0.8049888976393422, D: 0.19421164481860753\n",
      "2018-11-26 13:01:46,761 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.3123728930950165\n",
      "2018-11-26 13:01:46,763 INFO Layer 14: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:01:46,766 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:46,769 INFO Layer 15: ReLU(inplace)\n",
      "2018-11-26 13:01:46,771 INFO Layer 15: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:46,778 INFO Layer 16: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:01:46,781 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:01:46,788 INFO Layer 16: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:01:46,790 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:47,259 INFO     Weight matrix 1/9 (64,64): Alpha: 2.52031350461671, Alpha Weighted: -1.3945440509985285, D: 0.17140007880796038\n",
      "2018-11-26 13:01:47,262 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.20187431573867798\n",
      "2018-11-26 13:01:47,265 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:47,702 INFO     Weight matrix 2/9 (64,64): Alpha: 2.058616805388587, Alpha Weighted: -0.821269306149207, D: 0.2139832961012752\n",
      "2018-11-26 13:01:47,705 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.2986585795879364\n",
      "2018-11-26 13:01:47,707 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:48,147 INFO     Weight matrix 3/9 (64,64): Alpha: 6.183048236602318, Alpha Weighted: -2.908473493614272, D: 0.17489590548226008\n",
      "2018-11-26 13:01:48,150 INFO     Weight matrix 3/9 (64,64): Alpha 6.183048236602318 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:48,153 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.26348355412483215\n",
      "2018-11-26 13:01:48,155 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:48,606 INFO     Weight matrix 4/9 (64,64): Alpha: 1.9438474039694085, Alpha Weighted: -0.6230608818602549, D: 0.1833321500235391\n",
      "2018-11-26 13:01:48,609 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.2951812744140625\n",
      "2018-11-26 13:01:48,613 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:49,067 INFO     Weight matrix 5/9 (64,64): Alpha: 2.1961145658774237, Alpha Weighted: -0.14764506282158782, D: 0.2224382241535861\n",
      "2018-11-26 13:01:49,069 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.4589180648326874\n",
      "2018-11-26 13:01:49,074 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:49,522 INFO     Weight matrix 6/9 (64,64): Alpha: 2.298844418615727, Alpha Weighted: -0.3660760865194886, D: 0.16646396540379538\n",
      "2018-11-26 13:01:49,525 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.3849697411060333\n",
      "2018-11-26 13:01:49,528 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:49,985 INFO     Weight matrix 7/9 (64,64): Alpha: 2.009360707310279, Alpha Weighted: -0.9979628491924432, D: 0.20923910479562924\n",
      "2018-11-26 13:01:49,988 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.26280295848846436\n",
      "2018-11-26 13:01:49,992 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:50,452 INFO     Weight matrix 8/9 (64,64): Alpha: 3.69219360689631, Alpha Weighted: -0.04869919238634815, D: 0.17755363695530557\n",
      "2018-11-26 13:01:50,454 INFO     Weight matrix 8/9 (64,64): Alpha 3.69219360689631 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:50,457 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.3932937979698181\n",
      "2018-11-26 13:01:50,460 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:50,911 INFO     Weight matrix 9/9 (64,64): Alpha: 1.9358170566304413, Alpha Weighted: -0.609548543179488, D: 0.20246766926290216\n",
      "2018-11-26 13:01:50,915 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.3438940942287445\n",
      "2018-11-26 13:01:50,917 INFO Layer 17: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:01:50,920 INFO Layer 17: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:50,925 INFO Layer 18: BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:01:50,928 INFO Layer 18: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:50,931 INFO Layer 19: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:01:50,941 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:01:50,946 INFO Layer 19: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:01:50,950 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:51,410 INFO     Weight matrix 1/9 (64,64): Alpha: 2.3708907418817295, Alpha Weighted: -1.1032709770715599, D: 0.1852082211124828\n",
      "2018-11-26 13:01:51,413 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.27308499813079834\n",
      "2018-11-26 13:01:51,416 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:51,848 INFO     Weight matrix 2/9 (64,64): Alpha: 3.3464697795539147, Alpha Weighted: -0.7338525048292563, D: 0.1898849984121241\n",
      "2018-11-26 13:01:51,850 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.3538312613964081\n",
      "2018-11-26 13:01:51,853 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:52,304 INFO     Weight matrix 3/9 (64,64): Alpha: 3.1783217016509617, Alpha Weighted: -1.350506101676809, D: 0.19322511852546798\n",
      "2018-11-26 13:01:52,306 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.2886953353881836\n",
      "2018-11-26 13:01:52,309 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:52,749 INFO     Weight matrix 4/9 (64,64): Alpha: 2.0740596781463387, Alpha Weighted: -0.5307961196854014, D: 0.18037940779739686\n",
      "2018-11-26 13:01:52,752 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.34147197008132935\n",
      "2018-11-26 13:01:52,755 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:53,199 INFO     Weight matrix 5/9 (64,64): Alpha: 1.8307929177225453, Alpha Weighted: 0.33410427520201064, D: 0.15576212208703388\n",
      "2018-11-26 13:01:53,202 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.4939362704753876\n",
      "2018-11-26 13:01:53,204 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:53,634 INFO     Weight matrix 6/9 (64,64): Alpha: 1.9816443852647345, Alpha Weighted: -0.2473876706001082, D: 0.17352907895247455\n",
      "2018-11-26 13:01:53,639 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.38428181409835815\n",
      "2018-11-26 13:01:53,642 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:54,109 INFO     Weight matrix 7/9 (64,64): Alpha: 2.0598280308763988, Alpha Weighted: -0.8283736653497948, D: 0.19715988497125314\n",
      "2018-11-26 13:01:54,112 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.3051455020904541\n",
      "2018-11-26 13:01:54,114 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:54,559 INFO     Weight matrix 8/9 (64,64): Alpha: 1.8852395689124581, Alpha Weighted: -0.06427596580100406, D: 0.17430863525018409\n",
      "2018-11-26 13:01:54,563 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.40714314579963684\n",
      "2018-11-26 13:01:54,565 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:54,998 INFO     Weight matrix 9/9 (64,64): Alpha: 2.778787253411958, Alpha Weighted: -0.6904257479447755, D: 0.1697640154564003\n",
      "2018-11-26 13:01:55,002 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.3266996443271637\n",
      "2018-11-26 13:01:55,005 INFO Layer 20: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:01:55,008 INFO Layer 20: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:55,013 INFO Layer 21: ReLU(inplace)\n",
      "2018-11-26 13:01:55,015 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:55,017 INFO Layer 22: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:01:55,021 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:01:55,025 INFO Layer 22: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:01:55,028 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:55,518 INFO     Weight matrix 1/9 (64,64): Alpha: 3.8454389851031516, Alpha Weighted: -2.4191148767738833, D: 0.19767719466190392\n",
      "2018-11-26 13:01:55,521 INFO     Weight matrix 1/9 (64,64): Alpha 3.8454389851031516 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:55,525 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.20001229643821716\n",
      "2018-11-26 13:01:55,528 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:55,973 INFO     Weight matrix 2/9 (64,64): Alpha: 4.4712730370012395, Alpha Weighted: -1.4626819065849634, D: 0.18625154231261243\n",
      "2018-11-26 13:01:55,975 INFO     Weight matrix 2/9 (64,64): Alpha 4.4712730370012395 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:55,980 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.2997560203075409\n",
      "2018-11-26 13:01:55,984 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:56,420 INFO     Weight matrix 3/9 (64,64): Alpha: 2.8945925385068563, Alpha Weighted: -1.509633502682855, D: 0.17059280512981634\n",
      "2018-11-26 13:01:56,423 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.2402837872505188\n",
      "2018-11-26 13:01:56,426 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:56,862 INFO     Weight matrix 4/9 (64,64): Alpha: 2.458403979360324, Alpha Weighted: -1.0284690093762823, D: 0.20093499079622712\n",
      "2018-11-26 13:01:56,866 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.2944088876247406\n",
      "2018-11-26 13:01:56,869 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:57,316 INFO     Weight matrix 5/9 (64,64): Alpha: 2.2519011703907594, Alpha Weighted: -0.232812067470012, D: 0.1893376792988023\n",
      "2018-11-26 13:01:57,319 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.434140145778656\n",
      "2018-11-26 13:01:57,322 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:57,761 INFO     Weight matrix 6/9 (64,64): Alpha: 2.485065817940259, Alpha Weighted: -0.7621651468541055, D: 0.16833864179883928\n",
      "2018-11-26 13:01:57,764 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.34509819746017456\n",
      "2018-11-26 13:01:57,767 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:58,223 INFO     Weight matrix 7/9 (64,64): Alpha: 2.675178948499668, Alpha Weighted: -1.5138659824511365, D: 0.1887742571073716\n",
      "2018-11-26 13:01:58,226 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.240924671292305\n",
      "2018-11-26 13:01:58,228 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:58,688 INFO     Weight matrix 8/9 (64,64): Alpha: 3.6235319239365924, Alpha Weighted: -0.7845660936730038, D: 0.13646690281756013\n",
      "2018-11-26 13:01:58,691 INFO     Weight matrix 8/9 (64,64): Alpha 3.6235319239365924 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:01:58,694 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.3525247275829315\n",
      "2018-11-26 13:01:58,697 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:01:59,159 INFO     Weight matrix 9/9 (64,64): Alpha: 3.3565407669875706, Alpha Weighted: -1.3880905965918604, D: 0.20679268521647276\n",
      "2018-11-26 13:01:59,161 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.3084239363670349\n",
      "2018-11-26 13:01:59,164 INFO Layer 23: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:01:59,166 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:59,169 INFO Layer 24: Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (3): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:01:59,171 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:59,174 INFO Layer 25: BasicBlock(\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:01:59,177 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 13:01:59,179 INFO Layer 26: Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:01:59,194 INFO Pytorch tensor shape detected: 128x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:01:59,197 INFO Layer 26: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:01:59,200 INFO     Weight matrix 1/9 (64,128): Analyzing ...\n",
      "2018-11-26 13:01:59,670 INFO     Weight matrix 1/9 (64,128): Alpha: 2.335291261500318, Alpha Weighted: -0.7051691923736586, D: 0.18512139717651066\n",
      "2018-11-26 13:01:59,674 INFO     Weight matrix 1/9 (64,128): Lognorm: 0.3909384310245514\n",
      "2018-11-26 13:01:59,677 INFO     Weight matrix 2/9 (64,128): Analyzing ...\n",
      "2018-11-26 13:02:00,123 INFO     Weight matrix 2/9 (64,128): Alpha: 2.0271674125537875, Alpha Weighted: -0.0024961068202118027, D: 0.17554488484432118\n",
      "2018-11-26 13:02:00,126 INFO     Weight matrix 2/9 (64,128): Lognorm: 0.4868176281452179\n",
      "2018-11-26 13:02:00,131 INFO     Weight matrix 3/9 (64,128): Analyzing ...\n",
      "2018-11-26 13:02:00,610 INFO     Weight matrix 3/9 (64,128): Alpha: 2.7052788167394475, Alpha Weighted: -0.4237030144638897, D: 0.18474018761811942\n",
      "2018-11-26 13:02:00,614 INFO     Weight matrix 3/9 (64,128): Lognorm: 0.45086023211479187\n",
      "2018-11-26 13:02:00,616 INFO     Weight matrix 4/9 (64,128): Analyzing ...\n",
      "2018-11-26 13:02:01,055 INFO     Weight matrix 4/9 (64,128): Alpha: 2.045910590425997, Alpha Weighted: -0.17327131739180457, D: 0.2023663083056101\n",
      "2018-11-26 13:02:01,059 INFO     Weight matrix 4/9 (64,128): Lognorm: 0.4822406470775604\n",
      "2018-11-26 13:02:01,061 INFO     Weight matrix 5/9 (64,128): Analyzing ...\n",
      "2018-11-26 13:02:01,500 INFO     Weight matrix 5/9 (64,128): Alpha: 1.7208922161296158, Alpha Weighted: 0.3197434423351413, D: 0.17614556229224287\n",
      "2018-11-26 13:02:01,504 INFO     Weight matrix 5/9 (64,128): Lognorm: 0.561602771282196\n",
      "2018-11-26 13:02:01,507 INFO     Weight matrix 6/9 (64,128): Analyzing ...\n",
      "2018-11-26 13:02:01,951 INFO     Weight matrix 6/9 (64,128): Alpha: 2.3669257686045415, Alpha Weighted: 0.3745995189203843, D: 0.17139053833972506\n",
      "2018-11-26 13:02:01,956 INFO     Weight matrix 6/9 (64,128): Lognorm: 0.5593247413635254\n",
      "2018-11-26 13:02:01,959 INFO     Weight matrix 7/9 (64,128): Analyzing ...\n",
      "2018-11-26 13:02:02,466 INFO     Weight matrix 7/9 (64,128): Alpha: 1.8301401723703488, Alpha Weighted: -0.2600882650579971, D: 0.19897455681835474\n",
      "2018-11-26 13:02:02,470 INFO     Weight matrix 7/9 (64,128): Lognorm: 0.4527641236782074\n",
      "2018-11-26 13:02:02,474 INFO     Weight matrix 8/9 (64,128): Analyzing ...\n",
      "2018-11-26 13:02:03,050 INFO     Weight matrix 8/9 (64,128): Alpha: 2.5295654854472405, Alpha Weighted: 0.42326984765194686, D: 0.14115781589414822\n",
      "2018-11-26 13:02:03,054 INFO     Weight matrix 8/9 (64,128): Lognorm: 0.5501151084899902\n",
      "2018-11-26 13:02:03,058 INFO     Weight matrix 9/9 (64,128): Analyzing ...\n",
      "2018-11-26 13:02:03,515 INFO     Weight matrix 9/9 (64,128): Alpha: 3.12709906258622, Alpha Weighted: 0.2760669680257053, D: 0.1602671430026137\n",
      "2018-11-26 13:02:03,520 INFO     Weight matrix 9/9 (64,128): Lognorm: 0.5293245911598206\n",
      "2018-11-26 13:02:03,523 INFO Layer 27: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:02:03,527 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:03,529 INFO Layer 28: ReLU(inplace)\n",
      "2018-11-26 13:02:03,532 INFO Layer 28: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:03,535 INFO Layer 29: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:02:03,539 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:02:03,541 INFO Layer 29: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:02:03,545 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:04,687 INFO     Weight matrix 1/9 (128,128): Alpha: 3.2246289942146973, Alpha Weighted: -1.5801390646736826, D: 0.1272770679473455\n",
      "2018-11-26 13:02:04,690 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.3466299772262573\n",
      "2018-11-26 13:02:04,696 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:05,927 INFO     Weight matrix 2/9 (128,128): Alpha: 2.3421543044629165, Alpha Weighted: -0.693819204160625, D: 0.1929654060081536\n",
      "2018-11-26 13:02:05,930 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.4715851843357086\n",
      "2018-11-26 13:02:05,933 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:06,967 INFO     Weight matrix 3/9 (128,128): Alpha: 2.5684917978463764, Alpha Weighted: -1.046090971274203, D: 0.17068817398957697\n",
      "2018-11-26 13:02:06,971 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.397930771112442\n",
      "2018-11-26 13:02:06,975 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:08,126 INFO     Weight matrix 4/9 (128,128): Alpha: 2.809045159160787, Alpha Weighted: -0.7145416837316724, D: 0.1697831943916937\n",
      "2018-11-26 13:02:08,129 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.47491952776908875\n",
      "2018-11-26 13:02:08,133 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:09,247 INFO     Weight matrix 5/9 (128,128): Alpha: 1.5824073751771839, Alpha Weighted: 0.669298392533895, D: 0.1786926089052665\n",
      "2018-11-26 13:02:09,251 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.7727354168891907\n",
      "2018-11-26 13:02:09,255 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:10,216 INFO     Weight matrix 6/9 (128,128): Alpha: 1.732661269300296, Alpha Weighted: -0.036261717750734286, D: 0.20498787531374396\n",
      "2018-11-26 13:02:10,219 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.6042481660842896\n",
      "2018-11-26 13:02:10,222 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:11,180 INFO     Weight matrix 7/9 (128,128): Alpha: 3.4061476494723832, Alpha Weighted: -1.5667211574923194, D: 0.17662273327590616\n",
      "2018-11-26 13:02:11,183 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.3901055157184601\n",
      "2018-11-26 13:02:11,186 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:12,135 INFO     Weight matrix 8/9 (128,128): Alpha: 2.339881669907017, Alpha Weighted: 0.06411717283230838, D: 0.1970358039246698\n",
      "2018-11-26 13:02:12,141 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.5947567224502563\n",
      "2018-11-26 13:02:12,143 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:13,340 INFO     Weight matrix 9/9 (128,128): Alpha: 5.262232694805015, Alpha Weighted: -1.2362770736396327, D: 0.17497278501490976\n",
      "2018-11-26 13:02:13,342 INFO     Weight matrix 9/9 (128,128): Alpha 5.262232694805015 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:02:13,350 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.4868180453777313\n",
      "2018-11-26 13:02:13,353 INFO Layer 30: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:02:13,358 INFO Layer 30: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:13,363 INFO Layer 31: Sequential(\n",
      "  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:02:13,365 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:13,368 INFO Layer 32: Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 13:02:13,371 INFO Pytorch tensor shape detected: 128x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:02:13,375 INFO Layer 32: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:02:13,378 INFO     Weight matrix 1/1 (64,128): Analyzing ...\n",
      "2018-11-26 13:02:13,842 INFO     Weight matrix 1/1 (64,128): Alpha: 1.7408908497937519, Alpha Weighted: 0.9822524070953985, D: 0.2057308870091905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:02:13,846 INFO     Weight matrix 1/1 (64,128): Lognorm: 0.80375075340271\n",
      "2018-11-26 13:02:13,851 INFO Layer 33: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:02:13,853 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:13,857 INFO Layer 34: BasicBlock(\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:02:13,860 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:13,862 INFO Layer 35: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:02:13,865 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:02:13,869 INFO Layer 35: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:02:13,871 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:14,851 INFO     Weight matrix 1/9 (128,128): Alpha: 2.81882371773255, Alpha Weighted: 0.16681536987807882, D: 0.0919489578808903\n",
      "2018-11-26 13:02:14,854 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.4613860249519348\n",
      "2018-11-26 13:02:14,857 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:15,801 INFO     Weight matrix 2/9 (128,128): Alpha: 1.9787158864712604, Alpha Weighted: 0.2172345285298985, D: 0.10111431892852538\n",
      "2018-11-26 13:02:15,805 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.510932207107544\n",
      "2018-11-26 13:02:15,807 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:16,743 INFO     Weight matrix 3/9 (128,128): Alpha: 2.30988845285132, Alpha Weighted: 0.13218711015320306, D: 0.10243043116012468\n",
      "2018-11-26 13:02:16,748 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.47349390387535095\n",
      "2018-11-26 13:02:16,750 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:17,710 INFO     Weight matrix 4/9 (128,128): Alpha: 2.1159379790801087, Alpha Weighted: 0.2028389318868783, D: 0.11181273117114421\n",
      "2018-11-26 13:02:17,714 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.5054808259010315\n",
      "2018-11-26 13:02:17,717 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:18,712 INFO     Weight matrix 5/9 (128,128): Alpha: 2.361107359933511, Alpha Weighted: 0.027830216590902904, D: 0.15127113936359976\n",
      "2018-11-26 13:02:18,715 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.523640513420105\n",
      "2018-11-26 13:02:18,718 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:19,715 INFO     Weight matrix 6/9 (128,128): Alpha: 2.069266015730961, Alpha Weighted: 0.2601285318302656, D: 0.11255018667273764\n",
      "2018-11-26 13:02:19,719 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.5180031657218933\n",
      "2018-11-26 13:02:19,722 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:20,710 INFO     Weight matrix 7/9 (128,128): Alpha: 2.1902148174349425, Alpha Weighted: 0.1335991318412344, D: 0.10406886600239662\n",
      "2018-11-26 13:02:20,714 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.46735891699790955\n",
      "2018-11-26 13:02:20,718 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:21,772 INFO     Weight matrix 8/9 (128,128): Alpha: 1.993279010404886, Alpha Weighted: 0.4672862997188982, D: 0.09053521333686942\n",
      "2018-11-26 13:02:21,776 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.5436110496520996\n",
      "2018-11-26 13:02:21,780 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:22,805 INFO     Weight matrix 9/9 (128,128): Alpha: 2.5897135307287114, Alpha Weighted: 0.2161758576004083, D: 0.11138085489915128\n",
      "2018-11-26 13:02:22,809 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.4836534857749939\n",
      "2018-11-26 13:02:22,811 INFO Layer 36: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:02:22,814 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:22,816 INFO Layer 37: ReLU(inplace)\n",
      "2018-11-26 13:02:22,818 INFO Layer 37: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:22,821 INFO Layer 38: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:02:22,826 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:02:22,830 INFO Layer 38: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:02:22,832 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:23,824 INFO     Weight matrix 1/9 (128,128): Alpha: 3.0977218241067064, Alpha Weighted: -1.4653193270528788, D: 0.1682609645788291\n",
      "2018-11-26 13:02:23,829 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.40733104944229126\n",
      "2018-11-26 13:02:23,831 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:24,781 INFO     Weight matrix 2/9 (128,128): Alpha: 2.1245822327796944, Alpha Weighted: -0.5147009310365547, D: 0.16663813958156531\n",
      "2018-11-26 13:02:24,784 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.47300708293914795\n",
      "2018-11-26 13:02:24,789 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:25,745 INFO     Weight matrix 3/9 (128,128): Alpha: 2.851108689140845, Alpha Weighted: -1.2431413928340838, D: 0.17350958592854826\n",
      "2018-11-26 13:02:25,749 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.42240312695503235\n",
      "2018-11-26 13:02:25,752 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:26,702 INFO     Weight matrix 4/9 (128,128): Alpha: 2.125995235798732, Alpha Weighted: -0.49260960799994435, D: 0.1503078756979318\n",
      "2018-11-26 13:02:26,706 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.46134692430496216\n",
      "2018-11-26 13:02:26,709 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:27,652 INFO     Weight matrix 5/9 (128,128): Alpha: 2.8956855226344373, Alpha Weighted: 1.0738361432345571, D: 0.11167657304704326\n",
      "2018-11-26 13:02:27,655 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.5925697088241577\n",
      "2018-11-26 13:02:27,657 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:28,598 INFO     Weight matrix 6/9 (128,128): Alpha: 2.3720663080346727, Alpha Weighted: -0.34013394551391646, D: 0.15680057163315897\n",
      "2018-11-26 13:02:28,601 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.5044435858726501\n",
      "2018-11-26 13:02:28,603 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:29,571 INFO     Weight matrix 7/9 (128,128): Alpha: 3.096561447152973, Alpha Weighted: -1.3657573230772286, D: 0.15598670507975804\n",
      "2018-11-26 13:02:29,574 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.4215879440307617\n",
      "2018-11-26 13:02:29,578 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:30,539 INFO     Weight matrix 8/9 (128,128): Alpha: 2.272860568581354, Alpha Weighted: -0.19644819512557932, D: 0.12594130906613027\n",
      "2018-11-26 13:02:30,543 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.4986790120601654\n",
      "2018-11-26 13:02:30,547 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:31,498 INFO     Weight matrix 9/9 (128,128): Alpha: 2.119963627182395, Alpha Weighted: -0.8894618908822146, D: 0.19083600493414854\n",
      "2018-11-26 13:02:31,502 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.4456374943256378\n",
      "2018-11-26 13:02:31,505 INFO Layer 39: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:02:31,507 INFO Layer 39: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:31,510 INFO Layer 40: BasicBlock(\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:02:31,513 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:31,515 INFO Layer 41: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:02:31,520 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:02:31,523 INFO Layer 41: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:02:31,526 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:32,509 INFO     Weight matrix 1/9 (128,128): Alpha: 2.527752063386629, Alpha Weighted: -1.0040401153985234, D: 0.16399645403320195\n",
      "2018-11-26 13:02:32,513 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.43350329995155334\n",
      "2018-11-26 13:02:32,517 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:33,477 INFO     Weight matrix 2/9 (128,128): Alpha: 1.9383459205831324, Alpha Weighted: -0.2527538131148693, D: 0.15695233640940043\n",
      "2018-11-26 13:02:33,481 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.5181934833526611\n",
      "2018-11-26 13:02:33,484 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:34,442 INFO     Weight matrix 3/9 (128,128): Alpha: 2.284962393921385, Alpha Weighted: -0.8886946977997695, D: 0.17502442509024563\n",
      "2018-11-26 13:02:34,446 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.4426705241203308\n",
      "2018-11-26 13:02:34,448 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:35,391 INFO     Weight matrix 4/9 (128,128): Alpha: 1.9644608935673955, Alpha Weighted: -0.26474800593233655, D: 0.14952236249171835\n",
      "2018-11-26 13:02:35,395 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.5204745531082153\n",
      "2018-11-26 13:02:35,399 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:36,342 INFO     Weight matrix 5/9 (128,128): Alpha: 1.653727607790546, Alpha Weighted: 0.3065017798617668, D: 0.1871090451606009\n",
      "2018-11-26 13:02:36,345 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.6592556238174438\n",
      "2018-11-26 13:02:36,348 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:37,288 INFO     Weight matrix 6/9 (128,128): Alpha: 1.7991569161214875, Alpha Weighted: -0.11962589328987895, D: 0.15065421830110104\n",
      "2018-11-26 13:02:37,292 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.5477105975151062\n",
      "2018-11-26 13:02:37,296 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:38,248 INFO     Weight matrix 7/9 (128,128): Alpha: 2.71536280176665, Alpha Weighted: -0.9941064154153431, D: 0.16652038507606315\n",
      "2018-11-26 13:02:38,252 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.45008108019828796\n",
      "2018-11-26 13:02:38,255 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:39,240 INFO     Weight matrix 8/9 (128,128): Alpha: 1.9003309475138035, Alpha Weighted: -0.10355983633620959, D: 0.1550362923920115\n",
      "2018-11-26 13:02:39,244 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.542788565158844\n",
      "2018-11-26 13:02:39,248 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:40,198 INFO     Weight matrix 9/9 (128,128): Alpha: 2.151322629652271, Alpha Weighted: -0.6719020324426574, D: 0.17478394784239393\n",
      "2018-11-26 13:02:40,203 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.47135522961616516\n",
      "2018-11-26 13:02:40,206 INFO Layer 42: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:02:40,208 INFO Layer 42: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:40,210 INFO Layer 43: ReLU(inplace)\n",
      "2018-11-26 13:02:40,213 INFO Layer 43: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:40,215 INFO Layer 44: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:02:40,219 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:02:40,222 INFO Layer 44: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:02:40,225 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:41,215 INFO     Weight matrix 1/9 (128,128): Alpha: 3.5575055510421953, Alpha Weighted: -1.5808575470666923, D: 0.12694117809485977\n",
      "2018-11-26 13:02:41,217 INFO     Weight matrix 1/9 (128,128): Alpha 3.5575055510421953 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:02:41,221 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.37426015734672546\n",
      "2018-11-26 13:02:41,223 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:42,188 INFO     Weight matrix 2/9 (128,128): Alpha: 3.010989151106563, Alpha Weighted: -0.9890222734585481, D: 0.1376938216639223\n",
      "2018-11-26 13:02:42,193 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.44311827421188354\n",
      "2018-11-26 13:02:42,195 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:43,163 INFO     Weight matrix 3/9 (128,128): Alpha: 4.19555511187616, Alpha Weighted: -1.798399406563615, D: 0.11414636743730366\n",
      "2018-11-26 13:02:43,166 INFO     Weight matrix 3/9 (128,128): Alpha 4.19555511187616 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:02:43,170 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.3968365788459778\n",
      "2018-11-26 13:02:43,173 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:44,155 INFO     Weight matrix 4/9 (128,128): Alpha: 2.8676655000650237, Alpha Weighted: -1.0052020143856941, D: 0.13563452315374736\n",
      "2018-11-26 13:02:44,159 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.4412573277950287\n",
      "2018-11-26 13:02:44,162 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:45,114 INFO     Weight matrix 5/9 (128,128): Alpha: 2.3143567540407464, Alpha Weighted: 0.8258410270381364, D: 0.10347058352327454\n",
      "2018-11-26 13:02:45,118 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.6054041981697083\n",
      "2018-11-26 13:02:45,120 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:46,079 INFO     Weight matrix 6/9 (128,128): Alpha: 3.081233721279809, Alpha Weighted: -0.8879871963050886, D: 0.14730178409454675\n",
      "2018-11-26 13:02:46,082 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.4823266267776489\n",
      "2018-11-26 13:02:46,086 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:47,049 INFO     Weight matrix 7/9 (128,128): Alpha: 3.6413977890537215, Alpha Weighted: -1.6658861346814986, D: 0.11398795485189361\n",
      "2018-11-26 13:02:47,051 INFO     Weight matrix 7/9 (128,128): Alpha 3.6413977890537215 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:02:47,055 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.39610782265663147\n",
      "2018-11-26 13:02:47,058 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:48,019 INFO     Weight matrix 8/9 (128,128): Alpha: 2.3864241982030094, Alpha Weighted: -0.5094079190417485, D: 0.14676409466387647\n",
      "2018-11-26 13:02:48,023 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.4892123341560364\n",
      "2018-11-26 13:02:48,027 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:49,001 INFO     Weight matrix 9/9 (128,128): Alpha: 4.1257060914815575, Alpha Weighted: -1.7101272990620884, D: 0.11735879631040247\n",
      "2018-11-26 13:02:49,004 INFO     Weight matrix 9/9 (128,128): Alpha 4.1257060914815575 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:02:49,009 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.4360447824001312\n",
      "2018-11-26 13:02:49,011 INFO Layer 45: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:02:49,014 INFO Layer 45: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:49,017 INFO Layer 46: BasicBlock(\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:02:49,019 INFO Layer 46: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:49,024 INFO Layer 47: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:02:49,027 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:02:49,034 INFO Layer 47: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:02:49,036 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:50,011 INFO     Weight matrix 1/9 (128,128): Alpha: 3.6022236131041008, Alpha Weighted: -1.4046131565271451, D: 0.1459009237260417\n",
      "2018-11-26 13:02:50,014 INFO     Weight matrix 1/9 (128,128): Alpha 3.6022236131041008 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:02:50,017 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.44137653708457947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:02:50,022 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:50,988 INFO     Weight matrix 2/9 (128,128): Alpha: 2.92337491197051, Alpha Weighted: -0.3280235947333959, D: 0.1553789154232506\n",
      "2018-11-26 13:02:50,991 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.5151178240776062\n",
      "2018-11-26 13:02:50,994 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:51,949 INFO     Weight matrix 3/9 (128,128): Alpha: 3.691569211152016, Alpha Weighted: -1.0937278818403366, D: 0.12552379526028867\n",
      "2018-11-26 13:02:51,952 INFO     Weight matrix 3/9 (128,128): Alpha 3.691569211152016 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:02:51,956 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.4519611597061157\n",
      "2018-11-26 13:02:51,959 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:52,908 INFO     Weight matrix 4/9 (128,128): Alpha: 2.0287596172637246, Alpha Weighted: -0.16393146444760182, D: 0.1631642338608737\n",
      "2018-11-26 13:02:52,911 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.5303599238395691\n",
      "2018-11-26 13:02:52,914 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:53,907 INFO     Weight matrix 5/9 (128,128): Alpha: 2.4729150722738944, Alpha Weighted: 0.6629866722565898, D: 0.15984743887581349\n",
      "2018-11-26 13:02:53,911 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.6827681064605713\n",
      "2018-11-26 13:02:53,915 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:54,884 INFO     Weight matrix 6/9 (128,128): Alpha: 1.9041233925637877, Alpha Weighted: 0.12427762091060308, D: 0.14594251417128012\n",
      "2018-11-26 13:02:54,887 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.5764028429985046\n",
      "2018-11-26 13:02:54,892 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:55,834 INFO     Weight matrix 7/9 (128,128): Alpha: 3.5145144083363196, Alpha Weighted: -0.8777628155286911, D: 0.14538932296038765\n",
      "2018-11-26 13:02:55,836 INFO     Weight matrix 7/9 (128,128): Alpha 3.5145144083363196 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:02:55,840 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.4651564359664917\n",
      "2018-11-26 13:02:55,846 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:56,815 INFO     Weight matrix 8/9 (128,128): Alpha: 2.175201680472488, Alpha Weighted: 0.047547384018031554, D: 0.156166371372241\n",
      "2018-11-26 13:02:56,818 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.5669155120849609\n",
      "2018-11-26 13:02:56,822 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:57,791 INFO     Weight matrix 9/9 (128,128): Alpha: 3.0483239977192906, Alpha Weighted: -0.6245204954541763, D: 0.13998052436959496\n",
      "2018-11-26 13:02:57,794 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.489760160446167\n",
      "2018-11-26 13:02:57,797 INFO Layer 48: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:02:57,799 INFO Layer 48: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:57,802 INFO Layer 49: ReLU(inplace)\n",
      "2018-11-26 13:02:57,805 INFO Layer 49: Skipping (Layer not supported)\n",
      "2018-11-26 13:02:57,807 INFO Layer 50: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:02:57,816 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:02:57,818 INFO Layer 50: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:02:57,822 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:58,805 INFO     Weight matrix 1/9 (128,128): Alpha: 4.1536660832989405, Alpha Weighted: -1.92978656443015, D: 0.10222522237312448\n",
      "2018-11-26 13:02:58,808 INFO     Weight matrix 1/9 (128,128): Alpha 4.1536660832989405 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:02:58,812 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.34988731145858765\n",
      "2018-11-26 13:02:58,816 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:02:59,776 INFO     Weight matrix 2/9 (128,128): Alpha: 5.490234054017404, Alpha Weighted: -2.2108454618374536, D: 0.12499999999999978\n",
      "2018-11-26 13:02:59,779 INFO     Weight matrix 2/9 (128,128): Alpha 5.490234054017404 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:02:59,787 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.40193161368370056\n",
      "2018-11-26 13:02:59,790 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:03:00,800 INFO     Weight matrix 3/9 (128,128): Alpha: 4.090447049745659, Alpha Weighted: -1.675560928353923, D: 0.10213741083638228\n",
      "2018-11-26 13:03:00,803 INFO     Weight matrix 3/9 (128,128): Alpha 4.090447049745659 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:03:00,807 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.3814607560634613\n",
      "2018-11-26 13:03:00,810 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:03:01,767 INFO     Weight matrix 4/9 (128,128): Alpha: 2.572643758424262, Alpha Weighted: -1.1148169824562273, D: 0.15695931803117036\n",
      "2018-11-26 13:03:01,772 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.4073147177696228\n",
      "2018-11-26 13:03:01,774 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:03:02,743 INFO     Weight matrix 5/9 (128,128): Alpha: 3.602359630502056, Alpha Weighted: 0.10379466331335589, D: 0.08333333333333315\n",
      "2018-11-26 13:03:02,746 INFO     Weight matrix 5/9 (128,128): Alpha 3.602359630502056 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:03:02,750 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.5243498086929321\n",
      "2018-11-26 13:03:02,755 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:03:03,746 INFO     Weight matrix 6/9 (128,128): Alpha: 3.4345055706107788, Alpha Weighted: -1.0586441034044176, D: 0.15706138794256286\n",
      "2018-11-26 13:03:03,751 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.4617268443107605\n",
      "2018-11-26 13:03:03,754 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:03:04,716 INFO     Weight matrix 7/9 (128,128): Alpha: 4.620128524231555, Alpha Weighted: -2.171502947264172, D: 0.08698170996829868\n",
      "2018-11-26 13:03:04,719 INFO     Weight matrix 7/9 (128,128): Alpha 4.620128524231555 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:03:04,725 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.373475044965744\n",
      "2018-11-26 13:03:04,728 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:03:05,686 INFO     Weight matrix 8/9 (128,128): Alpha: 3.318549519768552, Alpha Weighted: -0.9247141721296875, D: 0.11612567466569279\n",
      "2018-11-26 13:03:05,690 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.4598386585712433\n",
      "2018-11-26 13:03:05,692 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:03:06,650 INFO     Weight matrix 9/9 (128,128): Alpha: 4.299721153459281, Alpha Weighted: -1.7364090244477157, D: 0.12508244176448025\n",
      "2018-11-26 13:03:06,652 INFO     Weight matrix 9/9 (128,128): Alpha 4.299721153459281 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:03:06,655 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.42541414499282837\n",
      "2018-11-26 13:03:06,658 INFO Layer 51: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:03:06,660 INFO Layer 51: Skipping (Layer not supported)\n",
      "2018-11-26 13:03:06,664 INFO Layer 52: Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (3): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (4): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (5): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:03:06,667 INFO Layer 52: Skipping (Layer not supported)\n",
      "2018-11-26 13:03:06,671 INFO Layer 53: BasicBlock(\n",
      "  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:03:06,678 INFO Layer 53: Skipping (Layer not supported)\n",
      "2018-11-26 13:03:06,680 INFO Layer 54: Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:03:06,692 INFO Pytorch tensor shape detected: 256x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:03:06,695 INFO Layer 54: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:03:06,699 INFO     Weight matrix 1/9 (128,256): Analyzing ...\n",
      "2018-11-26 13:03:07,712 INFO     Weight matrix 1/9 (128,256): Alpha: 2.9526929289831996, Alpha Weighted: -1.1296107614519557, D: 0.14852610418708367\n",
      "2018-11-26 13:03:07,716 INFO     Weight matrix 1/9 (128,256): Lognorm: 0.5263813734054565\n",
      "2018-11-26 13:03:07,721 INFO     Weight matrix 2/9 (128,256): Analyzing ...\n",
      "2018-11-26 13:03:08,700 INFO     Weight matrix 2/9 (128,256): Alpha: 6.310838035436134, Alpha Weighted: -0.8882584836501123, D: 0.16184750141010096\n",
      "2018-11-26 13:03:08,703 INFO     Weight matrix 2/9 (128,256): Alpha 6.310838035436134 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:03:08,708 INFO     Weight matrix 2/9 (128,256): Lognorm: 0.6388680934906006\n",
      "2018-11-26 13:03:08,713 INFO     Weight matrix 3/9 (128,256): Analyzing ...\n",
      "2018-11-26 13:03:09,738 INFO     Weight matrix 3/9 (128,256): Alpha: 6.07462388128133, Alpha Weighted: -1.500545663026564, D: 0.15029702201094075\n",
      "2018-11-26 13:03:09,741 INFO     Weight matrix 3/9 (128,256): Alpha 6.07462388128133 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:03:09,746 INFO     Weight matrix 3/9 (128,256): Lognorm: 0.5956307649612427\n",
      "2018-11-26 13:03:09,749 INFO     Weight matrix 4/9 (128,256): Analyzing ...\n",
      "2018-11-26 13:03:10,748 INFO     Weight matrix 4/9 (128,256): Alpha: 6.075267879066814, Alpha Weighted: -1.0569315470007459, D: 0.14374330740120933\n",
      "2018-11-26 13:03:10,750 INFO     Weight matrix 4/9 (128,256): Alpha 6.075267879066814 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:03:10,754 INFO     Weight matrix 4/9 (128,256): Lognorm: 0.6253129839897156\n",
      "2018-11-26 13:03:10,757 INFO     Weight matrix 5/9 (128,256): Analyzing ...\n",
      "2018-11-26 13:03:11,765 INFO     Weight matrix 5/9 (128,256): Alpha: 3.330843621809623, Alpha Weighted: -0.36424823483671165, D: 0.15704144260263764\n",
      "2018-11-26 13:03:11,769 INFO     Weight matrix 5/9 (128,256): Lognorm: 0.6574724912643433\n",
      "2018-11-26 13:03:11,771 INFO     Weight matrix 6/9 (128,256): Analyzing ...\n",
      "2018-11-26 13:03:12,757 INFO     Weight matrix 6/9 (128,256): Alpha: 2.625155739245468, Alpha Weighted: 0.14639636503729556, D: 0.1878465636345213\n",
      "2018-11-26 13:03:12,761 INFO     Weight matrix 6/9 (128,256): Lognorm: 0.7364076375961304\n",
      "2018-11-26 13:03:12,764 INFO     Weight matrix 7/9 (128,256): Analyzing ...\n",
      "2018-11-26 13:03:13,747 INFO     Weight matrix 7/9 (128,256): Alpha: 2.6582192171263497, Alpha Weighted: -0.828162707896962, D: 0.1926782911774163\n",
      "2018-11-26 13:03:13,752 INFO     Weight matrix 7/9 (128,256): Lognorm: 0.5860468149185181\n",
      "2018-11-26 13:03:13,756 INFO     Weight matrix 8/9 (128,256): Analyzing ...\n",
      "2018-11-26 13:03:14,754 INFO     Weight matrix 8/9 (128,256): Alpha: 4.057651305752779, Alpha Weighted: 0.2842542596415174, D: 0.18819047257373944\n",
      "2018-11-26 13:03:14,757 INFO     Weight matrix 8/9 (128,256): Alpha 4.057651305752779 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:03:14,761 INFO     Weight matrix 8/9 (128,256): Lognorm: 0.7426738739013672\n",
      "2018-11-26 13:03:14,763 INFO     Weight matrix 9/9 (128,256): Analyzing ...\n",
      "2018-11-26 13:03:15,779 INFO     Weight matrix 9/9 (128,256): Alpha: 3.335815056345157, Alpha Weighted: 0.12214205851669856, D: 0.16410831791864422\n",
      "2018-11-26 13:03:15,784 INFO     Weight matrix 9/9 (128,256): Lognorm: 0.6961755156517029\n",
      "2018-11-26 13:03:15,786 INFO Layer 55: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:03:15,790 INFO Layer 55: Skipping (Layer not supported)\n",
      "2018-11-26 13:03:15,793 INFO Layer 56: ReLU(inplace)\n",
      "2018-11-26 13:03:15,797 INFO Layer 56: Skipping (Layer not supported)\n",
      "2018-11-26 13:03:15,799 INFO Layer 57: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:03:15,809 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:03:15,811 INFO Layer 57: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:03:15,814 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:18,194 INFO     Weight matrix 1/9 (256,256): Alpha: 2.816333073790122, Alpha Weighted: -0.5432301577734807, D: 0.09818302353406239\n",
      "2018-11-26 13:03:18,197 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.617645263671875\n",
      "2018-11-26 13:03:18,200 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:20,593 INFO     Weight matrix 2/9 (256,256): Alpha: 3.2016941154509166, Alpha Weighted: -0.09727573694015017, D: 0.12419473166272299\n",
      "2018-11-26 13:03:20,599 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.7231413125991821\n",
      "2018-11-26 13:03:20,601 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:23,136 INFO     Weight matrix 3/9 (256,256): Alpha: 3.1174983910427816, Alpha Weighted: -0.5310336588699242, D: 0.10530766767603533\n",
      "2018-11-26 13:03:23,141 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.6437622904777527\n",
      "2018-11-26 13:03:23,145 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:25,523 INFO     Weight matrix 4/9 (256,256): Alpha: 2.878278667901611, Alpha Weighted: 0.010187296252550786, D: 0.1253475564780141\n",
      "2018-11-26 13:03:25,529 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.7115628719329834\n",
      "2018-11-26 13:03:25,533 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:27,885 INFO     Weight matrix 5/9 (256,256): Alpha: 4.04577290535696, Alpha Weighted: 1.6028202030675573, D: 0.13320247179201217\n",
      "2018-11-26 13:03:27,888 INFO     Weight matrix 5/9 (256,256): Alpha 4.04577290535696 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:03:27,893 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.9030960202217102\n",
      "2018-11-26 13:03:27,896 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:30,286 INFO     Weight matrix 6/9 (256,256): Alpha: 2.8969696111144163, Alpha Weighted: 0.23454834539153283, D: 0.14551684049545677\n",
      "2018-11-26 13:03:30,289 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.776038408279419\n",
      "2018-11-26 13:03:30,294 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:32,662 INFO     Weight matrix 7/9 (256,256): Alpha: 2.9256295093942057, Alpha Weighted: -0.4518299946001975, D: 0.1149718894666708\n",
      "2018-11-26 13:03:32,666 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.6453627347946167\n",
      "2018-11-26 13:03:32,670 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:35,034 INFO     Weight matrix 8/9 (256,256): Alpha: 3.372144658361969, Alpha Weighted: 0.187520596465879, D: 0.13818583800375506\n",
      "2018-11-26 13:03:35,037 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7806337475776672\n",
      "2018-11-26 13:03:35,041 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:37,432 INFO     Weight matrix 9/9 (256,256): Alpha: 2.6268410475586625, Alpha Weighted: -0.2527924422911246, D: 0.1315047484465195\n",
      "2018-11-26 13:03:37,437 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6955782771110535\n",
      "2018-11-26 13:03:37,439 INFO Layer 58: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:03:37,445 INFO Layer 58: Skipping (Layer not supported)\n",
      "2018-11-26 13:03:37,448 INFO Layer 59: Sequential(\n",
      "  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:03:37,451 INFO Layer 59: Skipping (Layer not supported)\n",
      "2018-11-26 13:03:37,459 INFO Layer 60: Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 13:03:37,462 INFO Pytorch tensor shape detected: 256x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:03:37,465 INFO Layer 60: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:03:37,468 INFO     Weight matrix 1/1 (128,256): Analyzing ...\n",
      "2018-11-26 13:03:38,496 INFO     Weight matrix 1/1 (128,256): Alpha: 2.659050835548668, Alpha Weighted: 1.021444181607654, D: 0.15388576329439263\n",
      "2018-11-26 13:03:38,500 INFO     Weight matrix 1/1 (128,256): Lognorm: 0.8478102684020996\n",
      "2018-11-26 13:03:38,504 INFO Layer 61: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:03:38,507 INFO Layer 61: Skipping (Layer not supported)\n",
      "2018-11-26 13:03:38,510 INFO Layer 62: BasicBlock(\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:03:38,513 INFO Layer 62: Skipping (Layer not supported)\n",
      "2018-11-26 13:03:38,517 INFO Layer 63: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:03:38,521 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:03:38,527 INFO Layer 63: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:03:38,532 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:40,950 INFO     Weight matrix 1/9 (256,256): Alpha: 1.9624570080701087, Alpha Weighted: -0.5337129470382009, D: 0.16563990835493614\n",
      "2018-11-26 13:03:40,954 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.6056623458862305\n",
      "2018-11-26 13:03:40,957 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:43,310 INFO     Weight matrix 2/9 (256,256): Alpha: 2.1439296908778056, Alpha Weighted: 0.021572186140475944, D: 0.11073299434846556\n",
      "2018-11-26 13:03:43,314 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6517960429191589\n",
      "2018-11-26 13:03:43,317 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:45,686 INFO     Weight matrix 3/9 (256,256): Alpha: 2.591240373841665, Alpha Weighted: -0.6011635020589153, D: 0.16307544764768922\n",
      "2018-11-26 13:03:45,691 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.6205839514732361\n",
      "2018-11-26 13:03:45,693 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:48,007 INFO     Weight matrix 4/9 (256,256): Alpha: 2.120591451580701, Alpha Weighted: 0.06593037456881089, D: 0.1063511270205244\n",
      "2018-11-26 13:03:48,011 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.6490073800086975\n",
      "2018-11-26 13:03:48,014 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:50,383 INFO     Weight matrix 5/9 (256,256): Alpha: 3.6807709695624435, Alpha Weighted: 0.008947649567765253, D: 0.08000983042104748\n",
      "2018-11-26 13:03:50,386 INFO     Weight matrix 5/9 (256,256): Alpha 3.6807709695624435 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:03:50,390 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.643494188785553\n",
      "2018-11-26 13:03:50,393 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:52,724 INFO     Weight matrix 6/9 (256,256): Alpha: 2.09785153939145, Alpha Weighted: 0.11609925295585019, D: 0.09993367926256327\n",
      "2018-11-26 13:03:52,729 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6571266055107117\n",
      "2018-11-26 13:03:52,732 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:55,097 INFO     Weight matrix 7/9 (256,256): Alpha: 2.125191726998235, Alpha Weighted: -0.45445199714206647, D: 0.16083925609825866\n",
      "2018-11-26 13:03:55,102 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.6196172833442688\n",
      "2018-11-26 13:03:55,104 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:57,426 INFO     Weight matrix 8/9 (256,256): Alpha: 2.2032707141660772, Alpha Weighted: -0.08709827425348343, D: 0.12103120730992528\n",
      "2018-11-26 13:03:57,431 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6552371382713318\n",
      "2018-11-26 13:03:57,435 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:03:59,750 INFO     Weight matrix 9/9 (256,256): Alpha: 2.2713166207014344, Alpha Weighted: -0.40517708362260124, D: 0.1455904029797685\n",
      "2018-11-26 13:03:59,754 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6218225359916687\n",
      "2018-11-26 13:03:59,757 INFO Layer 64: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:03:59,760 INFO Layer 64: Skipping (Layer not supported)\n",
      "2018-11-26 13:03:59,762 INFO Layer 65: ReLU(inplace)\n",
      "2018-11-26 13:03:59,765 INFO Layer 65: Skipping (Layer not supported)\n",
      "2018-11-26 13:03:59,768 INFO Layer 66: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:03:59,778 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:03:59,781 INFO Layer 66: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:03:59,784 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:02,172 INFO     Weight matrix 1/9 (256,256): Alpha: 3.010701415225561, Alpha Weighted: -0.941619693161469, D: 0.118826721339368\n",
      "2018-11-26 13:04:02,177 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.5794655084609985\n",
      "2018-11-26 13:04:02,179 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:04,531 INFO     Weight matrix 2/9 (256,256): Alpha: 2.9698913433066108, Alpha Weighted: -0.31136343933275734, D: 0.09704721531112215\n",
      "2018-11-26 13:04:04,535 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6148586273193359\n",
      "2018-11-26 13:04:04,539 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:06,870 INFO     Weight matrix 3/9 (256,256): Alpha: 2.6042531124518833, Alpha Weighted: -0.7239374200049014, D: 0.12463871253767222\n",
      "2018-11-26 13:04:06,875 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.5939658284187317\n",
      "2018-11-26 13:04:06,878 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:09,235 INFO     Weight matrix 4/9 (256,256): Alpha: 2.468949674100143, Alpha Weighted: -0.23182840225678203, D: 0.09939473415279837\n",
      "2018-11-26 13:04:09,240 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.6036763191223145\n",
      "2018-11-26 13:04:09,243 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:11,575 INFO     Weight matrix 5/9 (256,256): Alpha: 2.3941671505757314, Alpha Weighted: 1.4914811451809895, D: 0.04963345078343506\n",
      "2018-11-26 13:04:11,579 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.7113441824913025\n",
      "2018-11-26 13:04:11,583 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:13,922 INFO     Weight matrix 6/9 (256,256): Alpha: 2.3301044922162433, Alpha Weighted: -0.03185098822963391, D: 0.09324948053619819\n",
      "2018-11-26 13:04:13,926 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6228676438331604\n",
      "2018-11-26 13:04:13,929 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:16,297 INFO     Weight matrix 7/9 (256,256): Alpha: 3.4454099050036584, Alpha Weighted: -1.111388837439114, D: 0.1308711011398287\n",
      "2018-11-26 13:04:16,302 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.5911714434623718\n",
      "2018-11-26 13:04:16,304 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:18,837 INFO     Weight matrix 8/9 (256,256): Alpha: 2.66310464064897, Alpha Weighted: -0.2822225197532038, D: 0.11232650559941809\n",
      "2018-11-26 13:04:18,842 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6313410997390747\n",
      "2018-11-26 13:04:18,846 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:21,700 INFO     Weight matrix 9/9 (256,256): Alpha: 2.7147741638687055, Alpha Weighted: -0.971772025776488, D: 0.14011985552655537\n",
      "2018-11-26 13:04:21,705 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.5989913940429688\n",
      "2018-11-26 13:04:21,710 INFO Layer 67: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:04:21,712 INFO Layer 67: Skipping (Layer not supported)\n",
      "2018-11-26 13:04:21,715 INFO Layer 68: BasicBlock(\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:04:21,717 INFO Layer 68: Skipping (Layer not supported)\n",
      "2018-11-26 13:04:21,720 INFO Layer 69: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:04:21,725 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:04:21,729 INFO Layer 69: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:04:21,732 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:24,209 INFO     Weight matrix 1/9 (256,256): Alpha: 2.5971225589704705, Alpha Weighted: -0.38207342024580426, D: 0.10547300482428434\n",
      "2018-11-26 13:04:24,214 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.5973016023635864\n",
      "2018-11-26 13:04:24,217 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:26,564 INFO     Weight matrix 2/9 (256,256): Alpha: 2.659635251753532, Alpha Weighted: -0.15760159180194996, D: 0.08947018220378866\n",
      "2018-11-26 13:04:26,568 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6338257789611816\n",
      "2018-11-26 13:04:26,570 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:28,996 INFO     Weight matrix 3/9 (256,256): Alpha: 2.918749310749436, Alpha Weighted: -0.519369112894806, D: 0.09667768029096968\n",
      "2018-11-26 13:04:29,000 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.6052584648132324\n",
      "2018-11-26 13:04:29,003 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:31,432 INFO     Weight matrix 4/9 (256,256): Alpha: 2.513760382340679, Alpha Weighted: -0.052903232789840465, D: 0.08690306998522757\n",
      "2018-11-26 13:04:31,437 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.6279725432395935\n",
      "2018-11-26 13:04:31,441 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:33,787 INFO     Weight matrix 5/9 (256,256): Alpha: 3.7129857838009084, Alpha Weighted: 0.5086192226686456, D: 0.10240209393729469\n",
      "2018-11-26 13:04:33,790 INFO     Weight matrix 5/9 (256,256): Alpha 3.7129857838009084 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:04:33,794 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.6842048168182373\n",
      "2018-11-26 13:04:33,798 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:36,139 INFO     Weight matrix 6/9 (256,256): Alpha: 2.3721665558595646, Alpha Weighted: 0.031176937023138993, D: 0.10348397990765482\n",
      "2018-11-26 13:04:36,143 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6493052244186401\n",
      "2018-11-26 13:04:36,146 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:38,481 INFO     Weight matrix 7/9 (256,256): Alpha: 2.743197320288566, Alpha Weighted: -0.44374197589988584, D: 0.08920011858442134\n",
      "2018-11-26 13:04:38,485 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.6028741598129272\n",
      "2018-11-26 13:04:38,489 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:40,841 INFO     Weight matrix 8/9 (256,256): Alpha: 2.6670482620487426, Alpha Weighted: -0.2073618229872534, D: 0.10874150260062865\n",
      "2018-11-26 13:04:40,848 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.644111156463623\n",
      "2018-11-26 13:04:40,851 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:43,220 INFO     Weight matrix 9/9 (256,256): Alpha: 2.7318854014123017, Alpha Weighted: -0.334650594695385, D: 0.09624764355342741\n",
      "2018-11-26 13:04:43,225 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6130622625350952\n",
      "2018-11-26 13:04:43,228 INFO Layer 70: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:04:43,230 INFO Layer 70: Skipping (Layer not supported)\n",
      "2018-11-26 13:04:43,232 INFO Layer 71: ReLU(inplace)\n",
      "2018-11-26 13:04:43,235 INFO Layer 71: Skipping (Layer not supported)\n",
      "2018-11-26 13:04:43,238 INFO Layer 72: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:04:43,244 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:04:43,247 INFO Layer 72: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:04:43,250 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:45,607 INFO     Weight matrix 1/9 (256,256): Alpha: 3.672396932485028, Alpha Weighted: -0.7520791829459141, D: 0.09455519863449358\n",
      "2018-11-26 13:04:45,610 INFO     Weight matrix 1/9 (256,256): Alpha 3.672396932485028 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:04:45,614 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.5755836963653564\n",
      "2018-11-26 13:04:45,617 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:47,954 INFO     Weight matrix 2/9 (256,256): Alpha: 2.974300863281424, Alpha Weighted: -0.38628308261147565, D: 0.09190311923701744\n",
      "2018-11-26 13:04:47,959 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6033255457878113\n",
      "2018-11-26 13:04:47,962 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:50,328 INFO     Weight matrix 3/9 (256,256): Alpha: 3.6852403646489824, Alpha Weighted: -0.7589713244821611, D: 0.08870186707576588\n",
      "2018-11-26 13:04:50,331 INFO     Weight matrix 3/9 (256,256): Alpha 3.6852403646489824 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:04:50,335 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.5804954171180725\n",
      "2018-11-26 13:04:50,338 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:52,707 INFO     Weight matrix 4/9 (256,256): Alpha: 3.1330403182200146, Alpha Weighted: -0.40393066419104184, D: 0.09582107641130055\n",
      "2018-11-26 13:04:52,712 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.591460645198822\n",
      "2018-11-26 13:04:52,715 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:55,063 INFO     Weight matrix 5/9 (256,256): Alpha: 3.0145077479094597, Alpha Weighted: 0.39831449115650175, D: 0.074664393078397\n",
      "2018-11-26 13:04:55,067 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.6468872427940369\n",
      "2018-11-26 13:04:55,069 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:57,431 INFO     Weight matrix 6/9 (256,256): Alpha: 2.9860197812115032, Alpha Weighted: -0.40355145327515957, D: 0.09927190338068875\n",
      "2018-11-26 13:04:57,435 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.603835940361023\n",
      "2018-11-26 13:04:57,439 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:04:59,810 INFO     Weight matrix 7/9 (256,256): Alpha: 3.49073168312675, Alpha Weighted: -0.8055452508172015, D: 0.07826572186018455\n",
      "2018-11-26 13:04:59,814 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.5768049955368042\n",
      "2018-11-26 13:04:59,817 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:02,478 INFO     Weight matrix 8/9 (256,256): Alpha: 3.0620764242536316, Alpha Weighted: -0.46582946668394304, D: 0.09749282005341137\n",
      "2018-11-26 13:05:02,483 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6107731461524963\n",
      "2018-11-26 13:05:02,486 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:04,874 INFO     Weight matrix 9/9 (256,256): Alpha: 3.450188220033512, Alpha Weighted: -0.829085575115271, D: 0.09104005124512993\n",
      "2018-11-26 13:05:04,879 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.5893150568008423\n",
      "2018-11-26 13:05:04,882 INFO Layer 73: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:05:04,884 INFO Layer 73: Skipping (Layer not supported)\n",
      "2018-11-26 13:05:04,887 INFO Layer 74: BasicBlock(\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:05:04,890 INFO Layer 74: Skipping (Layer not supported)\n",
      "2018-11-26 13:05:04,897 INFO Layer 75: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:05:04,906 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:05:04,911 INFO Layer 75: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:05:04,914 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:07,285 INFO     Weight matrix 1/9 (256,256): Alpha: 2.758175418724856, Alpha Weighted: -0.49732590004176963, D: 0.1036234207318883\n",
      "2018-11-26 13:05:07,289 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.5899627208709717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:05:07,295 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:09,662 INFO     Weight matrix 2/9 (256,256): Alpha: 2.6110384917191842, Alpha Weighted: -0.29710222487498417, D: 0.10802522916535273\n",
      "2018-11-26 13:05:09,666 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6206537485122681\n",
      "2018-11-26 13:05:09,669 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:12,039 INFO     Weight matrix 3/9 (256,256): Alpha: 2.833404957800362, Alpha Weighted: -0.341623837051566, D: 0.09324277291266608\n",
      "2018-11-26 13:05:12,043 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.6039031147956848\n",
      "2018-11-26 13:05:12,046 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:14,483 INFO     Weight matrix 4/9 (256,256): Alpha: 2.413587401079675, Alpha Weighted: -0.3265839359015231, D: 0.10499308462619406\n",
      "2018-11-26 13:05:14,487 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.60651695728302\n",
      "2018-11-26 13:05:14,489 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:16,844 INFO     Weight matrix 5/9 (256,256): Alpha: 4.709643350480892, Alpha Weighted: -0.21652571110803648, D: 0.13712537931399293\n",
      "2018-11-26 13:05:16,846 INFO     Weight matrix 5/9 (256,256): Alpha 4.709643350480892 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:05:16,850 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.6634628176689148\n",
      "2018-11-26 13:05:16,854 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:19,228 INFO     Weight matrix 6/9 (256,256): Alpha: 2.3998559117099743, Alpha Weighted: -0.2784166066642509, D: 0.11591559003604596\n",
      "2018-11-26 13:05:19,232 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6235886812210083\n",
      "2018-11-26 13:05:19,235 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:21,594 INFO     Weight matrix 7/9 (256,256): Alpha: 2.760476354732394, Alpha Weighted: -0.4893853758972057, D: 0.10501402219072176\n",
      "2018-11-26 13:05:21,598 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.5931430459022522\n",
      "2018-11-26 13:05:21,600 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:23,973 INFO     Weight matrix 8/9 (256,256): Alpha: 2.3645397062620117, Alpha Weighted: -0.41920105257887946, D: 0.13118876519788425\n",
      "2018-11-26 13:05:23,977 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6284019947052002\n",
      "2018-11-26 13:05:23,981 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:26,326 INFO     Weight matrix 9/9 (256,256): Alpha: 2.983678961372064, Alpha Weighted: -0.4567383342025439, D: 0.10373491044408245\n",
      "2018-11-26 13:05:26,331 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6089610457420349\n",
      "2018-11-26 13:05:26,334 INFO Layer 76: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:05:26,336 INFO Layer 76: Skipping (Layer not supported)\n",
      "2018-11-26 13:05:26,339 INFO Layer 77: ReLU(inplace)\n",
      "2018-11-26 13:05:26,341 INFO Layer 77: Skipping (Layer not supported)\n",
      "2018-11-26 13:05:26,344 INFO Layer 78: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:05:26,349 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:05:26,353 INFO Layer 78: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:05:26,356 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:28,760 INFO     Weight matrix 1/9 (256,256): Alpha: 2.9938660175435334, Alpha Weighted: -0.5905083784680547, D: 0.07919681747689777\n",
      "2018-11-26 13:05:28,765 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.5578444004058838\n",
      "2018-11-26 13:05:28,768 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:31,216 INFO     Weight matrix 2/9 (256,256): Alpha: 3.1199915969910403, Alpha Weighted: -0.5366959899067981, D: 0.08273340036681587\n",
      "2018-11-26 13:05:31,220 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.5752645134925842\n",
      "2018-11-26 13:05:31,223 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:33,587 INFO     Weight matrix 3/9 (256,256): Alpha: 3.0542903639399683, Alpha Weighted: -0.5655678917629593, D: 0.08003075025887196\n",
      "2018-11-26 13:05:33,591 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.5559898018836975\n",
      "2018-11-26 13:05:33,595 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:35,965 INFO     Weight matrix 4/9 (256,256): Alpha: 2.6572564067106135, Alpha Weighted: -0.5091939846673407, D: 0.09250068718688698\n",
      "2018-11-26 13:05:35,969 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5672746300697327\n",
      "2018-11-26 13:05:35,974 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:38,346 INFO     Weight matrix 5/9 (256,256): Alpha: 3.1374471371618475, Alpha Weighted: 0.2534473260534337, D: 0.07003082803115046\n",
      "2018-11-26 13:05:38,351 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.6057024002075195\n",
      "2018-11-26 13:05:38,355 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:40,718 INFO     Weight matrix 6/9 (256,256): Alpha: 2.7931734429473907, Alpha Weighted: -0.5892956947639113, D: 0.10087307536032258\n",
      "2018-11-26 13:05:40,723 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.5666442513465881\n",
      "2018-11-26 13:05:40,726 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:43,089 INFO     Weight matrix 7/9 (256,256): Alpha: 3.1023519619365487, Alpha Weighted: -0.5641300243972269, D: 0.0714858981647144\n",
      "2018-11-26 13:05:43,093 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.5606557726860046\n",
      "2018-11-26 13:05:43,096 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:45,465 INFO     Weight matrix 8/9 (256,256): Alpha: 2.877894947960083, Alpha Weighted: -0.7645694117134995, D: 0.10796866284906592\n",
      "2018-11-26 13:05:45,469 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.578876793384552\n",
      "2018-11-26 13:05:45,472 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:47,806 INFO     Weight matrix 9/9 (256,256): Alpha: 3.1445517781655203, Alpha Weighted: -0.7705117270391773, D: 0.08989834753819198\n",
      "2018-11-26 13:05:47,811 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.5649220943450928\n",
      "2018-11-26 13:05:47,814 INFO Layer 79: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:05:47,816 INFO Layer 79: Skipping (Layer not supported)\n",
      "2018-11-26 13:05:47,819 INFO Layer 80: BasicBlock(\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:05:47,823 INFO Layer 80: Skipping (Layer not supported)\n",
      "2018-11-26 13:05:47,825 INFO Layer 81: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:05:47,831 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:05:47,833 INFO Layer 81: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:05:47,836 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:50,221 INFO     Weight matrix 1/9 (256,256): Alpha: 3.2003253006741263, Alpha Weighted: -0.43102148996435147, D: 0.08980994777280848\n",
      "2018-11-26 13:05:50,225 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.6052650213241577\n",
      "2018-11-26 13:05:50,228 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:52,649 INFO     Weight matrix 2/9 (256,256): Alpha: 3.6486892367369883, Alpha Weighted: -0.37586452262145514, D: 0.11347916657227208\n",
      "2018-11-26 13:05:52,652 INFO     Weight matrix 2/9 (256,256): Alpha 3.6486892367369883 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:05:52,656 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6330474019050598\n",
      "2018-11-26 13:05:52,658 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:55,024 INFO     Weight matrix 3/9 (256,256): Alpha: 3.1092886358528067, Alpha Weighted: -0.3938018477799742, D: 0.07683617639749862\n",
      "2018-11-26 13:05:55,029 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.6109535098075867\n",
      "2018-11-26 13:05:55,032 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:57,392 INFO     Weight matrix 4/9 (256,256): Alpha: 3.004120056727352, Alpha Weighted: -0.41813663151077746, D: 0.08508852993633165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:05:57,397 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.6126210689544678\n",
      "2018-11-26 13:05:57,400 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:05:59,765 INFO     Weight matrix 5/9 (256,256): Alpha: 3.222438386564436, Alpha Weighted: 0.05615249760416159, D: 0.11945788892635578\n",
      "2018-11-26 13:05:59,769 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.6864863634109497\n",
      "2018-11-26 13:05:59,773 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:02,155 INFO     Weight matrix 6/9 (256,256): Alpha: 2.9584781559523403, Alpha Weighted: -0.23704719254153817, D: 0.10290599489475405\n",
      "2018-11-26 13:06:02,159 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6265990734100342\n",
      "2018-11-26 13:06:02,162 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:04,522 INFO     Weight matrix 7/9 (256,256): Alpha: 3.2726854273454005, Alpha Weighted: -0.5489188580023707, D: 0.08989623120589729\n",
      "2018-11-26 13:06:04,526 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.6064426302909851\n",
      "2018-11-26 13:06:04,529 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:06,886 INFO     Weight matrix 8/9 (256,256): Alpha: 2.7819759212990673, Alpha Weighted: -0.2969560839208116, D: 0.11657786817604754\n",
      "2018-11-26 13:06:06,891 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6377353668212891\n",
      "2018-11-26 13:06:06,894 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:09,309 INFO     Weight matrix 9/9 (256,256): Alpha: 3.120783661491238, Alpha Weighted: -0.3574509666931037, D: 0.07444535327409496\n",
      "2018-11-26 13:06:09,313 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6159132719039917\n",
      "2018-11-26 13:06:09,316 INFO Layer 82: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:06:09,318 INFO Layer 82: Skipping (Layer not supported)\n",
      "2018-11-26 13:06:09,322 INFO Layer 83: ReLU(inplace)\n",
      "2018-11-26 13:06:09,324 INFO Layer 83: Skipping (Layer not supported)\n",
      "2018-11-26 13:06:09,328 INFO Layer 84: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:06:09,332 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:06:09,340 INFO Layer 84: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:06:09,343 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:11,698 INFO     Weight matrix 1/9 (256,256): Alpha: 2.9188225767449483, Alpha Weighted: -0.6472573184509038, D: 0.08135749533234687\n",
      "2018-11-26 13:06:11,702 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.5532264709472656\n",
      "2018-11-26 13:06:11,704 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:14,072 INFO     Weight matrix 2/9 (256,256): Alpha: 3.331825253668641, Alpha Weighted: -0.30569507763998705, D: 0.0841415729391205\n",
      "2018-11-26 13:06:14,077 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.5769770741462708\n",
      "2018-11-26 13:06:14,081 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:16,444 INFO     Weight matrix 3/9 (256,256): Alpha: 3.1182800257249363, Alpha Weighted: -0.7434202535572536, D: 0.08679892731067873\n",
      "2018-11-26 13:06:16,447 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.5563429594039917\n",
      "2018-11-26 13:06:16,450 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:18,886 INFO     Weight matrix 4/9 (256,256): Alpha: 2.835849216717076, Alpha Weighted: -0.3430015787427376, D: 0.08807402212608723\n",
      "2018-11-26 13:06:18,895 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5622023940086365\n",
      "2018-11-26 13:06:18,901 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:21,535 INFO     Weight matrix 5/9 (256,256): Alpha: 3.2001601129296686, Alpha Weighted: 0.5862820226852035, D: 0.06059947164796553\n",
      "2018-11-26 13:06:21,539 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.6157693862915039\n",
      "2018-11-26 13:06:21,542 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:24,009 INFO     Weight matrix 6/9 (256,256): Alpha: 3.94553576385295, Alpha Weighted: -0.5937011246117339, D: 0.08257868921218825\n",
      "2018-11-26 13:06:24,012 INFO     Weight matrix 6/9 (256,256): Alpha 3.94553576385295 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:06:24,017 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.5716554522514343\n",
      "2018-11-26 13:06:24,020 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:26,522 INFO     Weight matrix 7/9 (256,256): Alpha: 3.05838153651755, Alpha Weighted: -0.773042693982267, D: 0.09221424696365066\n",
      "2018-11-26 13:06:26,527 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.5579208731651306\n",
      "2018-11-26 13:06:26,532 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:28,998 INFO     Weight matrix 8/9 (256,256): Alpha: 3.9955847962601716, Alpha Weighted: -0.7102833947665333, D: 0.09733306270271058\n",
      "2018-11-26 13:06:29,000 INFO     Weight matrix 8/9 (256,256): Alpha 3.9955847962601716 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:06:29,005 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.5884836912155151\n",
      "2018-11-26 13:06:29,012 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:31,431 INFO     Weight matrix 9/9 (256,256): Alpha: 2.797322494660504, Alpha Weighted: -0.546576639646521, D: 0.09837205684279016\n",
      "2018-11-26 13:06:31,435 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.5722842812538147\n",
      "2018-11-26 13:06:31,437 INFO Layer 85: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:06:31,442 INFO Layer 85: Skipping (Layer not supported)\n",
      "2018-11-26 13:06:31,444 INFO Layer 86: BasicBlock(\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:06:31,447 INFO Layer 86: Skipping (Layer not supported)\n",
      "2018-11-26 13:06:31,450 INFO Layer 87: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:06:31,457 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:06:31,461 INFO Layer 87: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:06:31,463 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:33,853 INFO     Weight matrix 1/9 (256,256): Alpha: 3.7412394665242847, Alpha Weighted: -0.7059840050733823, D: 0.08984926090533707\n",
      "2018-11-26 13:06:33,855 INFO     Weight matrix 1/9 (256,256): Alpha 3.7412394665242847 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:06:33,860 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.598693311214447\n",
      "2018-11-26 13:06:33,866 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:36,213 INFO     Weight matrix 2/9 (256,256): Alpha: 3.2471744794120645, Alpha Weighted: -0.5783355805454894, D: 0.10861658694236437\n",
      "2018-11-26 13:06:36,217 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6321144700050354\n",
      "2018-11-26 13:06:36,220 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:38,587 INFO     Weight matrix 3/9 (256,256): Alpha: 3.4825820604661852, Alpha Weighted: -0.5634736717090211, D: 0.09191929688613665\n",
      "2018-11-26 13:06:38,592 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.6063223481178284\n",
      "2018-11-26 13:06:38,594 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:40,955 INFO     Weight matrix 4/9 (256,256): Alpha: 3.342558055023006, Alpha Weighted: -0.7201739690490336, D: 0.1148501689178314\n",
      "2018-11-26 13:06:40,959 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.6109638214111328\n",
      "2018-11-26 13:06:40,961 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:43,303 INFO     Weight matrix 5/9 (256,256): Alpha: 3.000982302303427, Alpha Weighted: 0.42081656877899215, D: 0.11754788292600304\n",
      "2018-11-26 13:06:43,308 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.7218824625015259\n",
      "2018-11-26 13:06:43,311 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:45,681 INFO     Weight matrix 6/9 (256,256): Alpha: 2.7596517567182763, Alpha Weighted: -0.4909782387758855, D: 0.11387646327787293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:06:45,685 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6306362748146057\n",
      "2018-11-26 13:06:45,688 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:48,047 INFO     Weight matrix 7/9 (256,256): Alpha: 3.2410486748785154, Alpha Weighted: -0.6318616589550153, D: 0.11037718234580468\n",
      "2018-11-26 13:06:48,051 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.6172720789909363\n",
      "2018-11-26 13:06:48,055 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:50,435 INFO     Weight matrix 8/9 (256,256): Alpha: 3.1343854317945894, Alpha Weighted: -0.4215476012736938, D: 0.12112827328292186\n",
      "2018-11-26 13:06:50,440 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6618442535400391\n",
      "2018-11-26 13:06:50,443 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:52,821 INFO     Weight matrix 9/9 (256,256): Alpha: 3.189175913597828, Alpha Weighted: -0.556078943976008, D: 0.11044771546289528\n",
      "2018-11-26 13:06:52,826 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.625532865524292\n",
      "2018-11-26 13:06:52,828 INFO Layer 88: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:06:52,831 INFO Layer 88: Skipping (Layer not supported)\n",
      "2018-11-26 13:06:52,834 INFO Layer 89: ReLU(inplace)\n",
      "2018-11-26 13:06:52,836 INFO Layer 89: Skipping (Layer not supported)\n",
      "2018-11-26 13:06:52,839 INFO Layer 90: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:06:52,844 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:06:52,851 INFO Layer 90: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:06:52,854 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:55,213 INFO     Weight matrix 1/9 (256,256): Alpha: 2.8223467606411528, Alpha Weighted: -0.29713508135915284, D: 0.08553816317714841\n",
      "2018-11-26 13:06:55,218 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.5490716695785522\n",
      "2018-11-26 13:06:55,221 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:57,552 INFO     Weight matrix 2/9 (256,256): Alpha: 3.500911788474733, Alpha Weighted: 0.12602987148737965, D: 0.051076226703611005\n",
      "2018-11-26 13:06:57,555 INFO     Weight matrix 2/9 (256,256): Alpha 3.500911788474733 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:06:57,560 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.5848163962364197\n",
      "2018-11-26 13:06:57,564 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:06:59,930 INFO     Weight matrix 3/9 (256,256): Alpha: 3.418843427703174, Alpha Weighted: -0.45653142840535116, D: 0.086904950993405\n",
      "2018-11-26 13:06:59,935 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.5648597478866577\n",
      "2018-11-26 13:06:59,941 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:07:02,306 INFO     Weight matrix 4/9 (256,256): Alpha: 3.054865485631372, Alpha Weighted: -0.14323926801159315, D: 0.06907394340327055\n",
      "2018-11-26 13:07:02,311 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5597319006919861\n",
      "2018-11-26 13:07:02,314 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:07:04,652 INFO     Weight matrix 5/9 (256,256): Alpha: 2.956926787281578, Alpha Weighted: 0.9361888258892608, D: 0.07145201892098119\n",
      "2018-11-26 13:07:04,657 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.6342726349830627\n",
      "2018-11-26 13:07:04,660 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:07:07,097 INFO     Weight matrix 6/9 (256,256): Alpha: 3.116860322453788, Alpha Weighted: -0.05680130547003305, D: 0.07108388482262662\n",
      "2018-11-26 13:07:07,101 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.5858901739120483\n",
      "2018-11-26 13:07:07,104 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:07:09,621 INFO     Weight matrix 7/9 (256,256): Alpha: 3.507047050183034, Alpha Weighted: -0.6090752153400354, D: 0.08195587213934574\n",
      "2018-11-26 13:07:09,624 INFO     Weight matrix 7/9 (256,256): Alpha 3.507047050183034 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:09,629 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.5637637972831726\n",
      "2018-11-26 13:07:09,632 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:07:12,382 INFO     Weight matrix 8/9 (256,256): Alpha: 4.34445040071626, Alpha Weighted: 0.22922036214557762, D: 0.08333333333333293\n",
      "2018-11-26 13:07:12,384 INFO     Weight matrix 8/9 (256,256): Alpha 4.34445040071626 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:12,390 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6073956489562988\n",
      "2018-11-26 13:07:12,392 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:07:14,809 INFO     Weight matrix 9/9 (256,256): Alpha: 4.024105015505031, Alpha Weighted: -0.39408078097058324, D: 0.07286032171301926\n",
      "2018-11-26 13:07:14,811 INFO     Weight matrix 9/9 (256,256): Alpha 4.024105015505031 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:14,818 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.5858950614929199\n",
      "2018-11-26 13:07:14,821 INFO Layer 91: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:14,823 INFO Layer 91: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:14,826 INFO Layer 92: Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (2): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:07:14,828 INFO Layer 92: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:14,831 INFO Layer 93: BasicBlock(\n",
      "  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:07:14,833 INFO Layer 93: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:14,836 INFO Layer 94: Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:07:14,858 INFO Pytorch tensor shape detected: 512x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:07:14,861 INFO Layer 94: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:07:14,864 INFO     Weight matrix 1/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:07:17,319 INFO     Weight matrix 1/9 (256,512): Alpha: 5.710557318727829, Alpha Weighted: -0.9167605310678794, D: 0.06249999999999978\n",
      "2018-11-26 13:07:17,321 INFO     Weight matrix 1/9 (256,512): Alpha 5.710557318727829 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:17,327 INFO     Weight matrix 1/9 (256,512): Lognorm: 0.6880068778991699\n",
      "2018-11-26 13:07:17,330 INFO     Weight matrix 2/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:07:19,788 INFO     Weight matrix 2/9 (256,512): Alpha: 6.633113913265258, Alpha Weighted: -0.23471029912684455, D: 0.10241002394957432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:07:19,790 INFO     Weight matrix 2/9 (256,512): Alpha 6.633113913265258 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:19,795 INFO     Weight matrix 2/9 (256,512): Lognorm: 0.8051021695137024\n",
      "2018-11-26 13:07:19,799 INFO     Weight matrix 3/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:07:22,268 INFO     Weight matrix 3/9 (256,512): Alpha: 6.847373741493381, Alpha Weighted: -0.8791133927416847, D: 0.09138576254234071\n",
      "2018-11-26 13:07:22,271 INFO     Weight matrix 3/9 (256,512): Alpha 6.847373741493381 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:22,277 INFO     Weight matrix 3/9 (256,512): Lognorm: 0.7709341049194336\n",
      "2018-11-26 13:07:22,280 INFO     Weight matrix 4/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:07:24,720 INFO     Weight matrix 4/9 (256,512): Alpha: 4.663454448528239, Alpha Weighted: -0.6283792627546748, D: 0.082835842748741\n",
      "2018-11-26 13:07:24,722 INFO     Weight matrix 4/9 (256,512): Alpha 4.663454448528239 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:24,727 INFO     Weight matrix 4/9 (256,512): Lognorm: 0.745711624622345\n",
      "2018-11-26 13:07:24,729 INFO     Weight matrix 5/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:07:27,140 INFO     Weight matrix 5/9 (256,512): Alpha: 5.746826907726681, Alpha Weighted: 1.4099611360615592, D: 0.07656015363373792\n",
      "2018-11-26 13:07:27,143 INFO     Weight matrix 5/9 (256,512): Alpha 5.746826907726681 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:27,148 INFO     Weight matrix 5/9 (256,512): Lognorm: 0.8538184762001038\n",
      "2018-11-26 13:07:27,152 INFO     Weight matrix 6/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:07:29,568 INFO     Weight matrix 6/9 (256,512): Alpha: 2.6311953796816434, Alpha Weighted: 0.34856981303646944, D: 0.14726234653181058\n",
      "2018-11-26 13:07:29,573 INFO     Weight matrix 6/9 (256,512): Lognorm: 0.8912021517753601\n",
      "2018-11-26 13:07:29,576 INFO     Weight matrix 7/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:07:32,043 INFO     Weight matrix 7/9 (256,512): Alpha: 5.792567140389399, Alpha Weighted: -0.78285172740734, D: 0.07086446323625739\n",
      "2018-11-26 13:07:32,046 INFO     Weight matrix 7/9 (256,512): Alpha 5.792567140389399 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:32,051 INFO     Weight matrix 7/9 (256,512): Lognorm: 0.739857017993927\n",
      "2018-11-26 13:07:32,055 INFO     Weight matrix 8/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:07:34,461 INFO     Weight matrix 8/9 (256,512): Alpha: 3.1053022128051495, Alpha Weighted: 0.6858494152478165, D: 0.13571443067165628\n",
      "2018-11-26 13:07:34,465 INFO     Weight matrix 8/9 (256,512): Lognorm: 0.9103933572769165\n",
      "2018-11-26 13:07:34,468 INFO     Weight matrix 9/9 (256,512): Analyzing ...\n",
      "2018-11-26 13:07:36,885 INFO     Weight matrix 9/9 (256,512): Alpha: 5.972594925516773, Alpha Weighted: 0.8370952864686719, D: 0.11362599319229033\n",
      "2018-11-26 13:07:36,888 INFO     Weight matrix 9/9 (256,512): Alpha 5.972594925516773 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:36,892 INFO     Weight matrix 9/9 (256,512): Lognorm: 0.8703627586364746\n",
      "2018-11-26 13:07:36,895 INFO Layer 95: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:36,897 INFO Layer 95: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:36,900 INFO Layer 96: ReLU(inplace)\n",
      "2018-11-26 13:07:36,902 INFO Layer 96: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:36,905 INFO Layer 97: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:07:36,954 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:07:36,957 INFO Layer 97: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:07:36,960 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:36,963 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:36,968 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:36,972 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:36,974 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:36,977 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:36,980 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:36,982 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:36,984 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:36,987 INFO Layer 98: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:36,989 INFO Layer 98: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:36,991 INFO Layer 99: Sequential(\n",
      "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:07:36,993 INFO Layer 99: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:36,996 INFO Layer 100: Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 13:07:37,007 INFO Pytorch tensor shape detected: 512x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:07:37,009 INFO Layer 100: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:07:37,012 INFO     Weight matrix 1/1 (256,512): Analyzing ...\n",
      "2018-11-26 13:07:39,430 INFO     Weight matrix 1/1 (256,512): Alpha: 3.0692634911300725, Alpha Weighted: 1.1445346954537743, D: 0.10410065026576781\n",
      "2018-11-26 13:07:39,434 INFO     Weight matrix 1/1 (256,512): Lognorm: 0.9793840646743774\n",
      "2018-11-26 13:07:39,437 INFO Layer 101: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:39,441 INFO Layer 101: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:39,446 INFO Layer 102: BasicBlock(\n",
      "  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:07:39,448 INFO Layer 102: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:39,450 INFO Layer 103: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:07:39,471 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:07:39,474 INFO Layer 103: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:07:39,477 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,480 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,482 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,484 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,487 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,490 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,493 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,495 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,498 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,500 INFO Layer 104: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:39,502 INFO Layer 104: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:39,505 INFO Layer 105: ReLU(inplace)\n",
      "2018-11-26 13:07:39,507 INFO Layer 105: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:39,509 INFO Layer 106: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:07:39,534 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:07:39,540 INFO Layer 106: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:07:39,545 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,548 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,552 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:07:39,555 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,557 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,560 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,563 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,566 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,568 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,571 INFO Layer 107: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:39,573 INFO Layer 107: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:39,576 INFO Layer 108: BasicBlock(\n",
      "  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:07:39,579 INFO Layer 108: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:39,582 INFO Layer 109: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:07:39,601 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:07:39,604 INFO Layer 109: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:07:39,639 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,643 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,648 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,652 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,655 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,658 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,661 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,663 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,666 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,669 INFO Layer 110: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:39,671 INFO Layer 110: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:39,674 INFO Layer 111: ReLU(inplace)\n",
      "2018-11-26 13:07:39,676 INFO Layer 111: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:39,680 INFO Layer 112: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:07:39,702 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:07:39,705 INFO Layer 112: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:07:39,709 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,712 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,715 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,719 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,722 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,724 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,727 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,730 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,733 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,735 INFO Layer 113: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:39,738 INFO Layer 113: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:39,740 INFO Layer 114: AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "2018-11-26 13:07:39,743 INFO Layer 114: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:39,746 INFO Layer 115: Linear(in_features=512, out_features=1000, bias=True)\n",
      "2018-11-26 13:07:39,753 INFO Layer 115: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:07:39,756 INFO     Weight matrix 1/1 (512,1000): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:07:39,758 INFO ### Printing results ###\n",
      "2018-11-26 13:07:39,761 DEBUG Layer 7: Lognorm compound: 0.396055625544654\n",
      "2018-11-26 13:07:39,764 DEBUG Layer 10: Lognorm compound: 0.33214407165845233\n",
      "2018-11-26 13:07:39,769 DEBUG Layer 13: Lognorm compound: 0.35991690887345207\n",
      "2018-11-26 13:07:39,771 DEBUG Layer 16: Lognorm compound: 0.3225640422768063\n",
      "2018-11-26 13:07:39,775 DEBUG Layer 19: Lognorm compound: 0.35269888242085773\n",
      "2018-11-26 13:07:39,777 DEBUG Layer 22: Lognorm compound: 0.30173029667801327\n",
      "2018-11-26 13:07:39,780 DEBUG Layer 26: Lognorm compound: 0.49599869714842904\n",
      "2018-11-26 13:07:39,783 DEBUG Layer 29: Lognorm compound: 0.5044143696626028\n",
      "2018-11-26 13:07:39,786 DEBUG Layer 32: Lognorm: 0.80375075340271\n",
      "2018-11-26 13:07:39,788 DEBUG Layer 35: Lognorm compound: 0.4986177881558736\n",
      "2018-11-26 13:07:39,792 DEBUG Layer 38: Lognorm compound: 0.46966732541720074\n",
      "2018-11-26 13:07:39,795 DEBUG Layer 41: Lognorm compound: 0.509559217426512\n",
      "2018-11-26 13:07:39,797 DEBUG Layer 44: Lognorm compound: 0.45161867803997463\n",
      "2018-11-26 13:07:39,799 DEBUG Layer 47: Lognorm compound: 0.5244242780738406\n",
      "2018-11-26 13:07:39,801 DEBUG Layer 50: Lognorm compound: 0.42059987783432007\n",
      "2018-11-26 13:07:39,805 DEBUG Layer 54: Lognorm compound: 0.644996616575453\n",
      "2018-11-26 13:07:39,808 DEBUG Layer 57: Lognorm compound: 0.7218689918518066\n",
      "2018-11-26 13:07:39,810 DEBUG Layer 60: Lognorm: 0.8478102684020996\n",
      "2018-11-26 13:07:39,812 DEBUG Layer 63: Lognorm compound: 0.6360386080212064\n",
      "2018-11-26 13:07:39,814 DEBUG Layer 66: Lognorm compound: 0.6164091163211398\n",
      "2018-11-26 13:07:39,817 DEBUG Layer 69: Lognorm compound: 0.6286573343806796\n",
      "2018-11-26 13:07:39,820 DEBUG Layer 72: Lognorm compound: 0.5976090762350295\n",
      "2018-11-26 13:07:39,823 DEBUG Layer 75: Lognorm compound: 0.6153993474112617\n",
      "2018-11-26 13:07:39,826 DEBUG Layer 78: Lognorm compound: 0.5703527397579617\n",
      "2018-11-26 13:07:39,828 DEBUG Layer 81: Lognorm compound: 0.6261181897587247\n",
      "2018-11-26 13:07:39,831 DEBUG Layer 84: Lognorm compound: 0.5727625091870626\n",
      "2018-11-26 13:07:39,833 DEBUG Layer 87: Lognorm compound: 0.6339179873466492\n",
      "2018-11-26 13:07:39,836 DEBUG Layer 90: Lognorm compound: 0.581744114557902\n",
      "2018-11-26 13:07:39,838 DEBUG Layer 94: Lognorm compound: 0.8083765043152703\n",
      "2018-11-26 13:07:39,840 DEBUG Layer 100: Lognorm: 0.9793840646743774\n",
      "2018-11-26 13:07:39,844 INFO LogNorm: min: 0.20001229643821716, max: 0.9793840646743774, avg: 0.5299971699714661\n",
      "2018-11-26 13:07:39,846 INFO LogNorm compound: min: 0.30173029667801327, max: 0.9793840646743774, avg: 0.5608402093803442\n",
      "2018-11-26 13:07:39,850 DEBUG Layer 7: Alpha compound: 1.837283776239489\n",
      "2018-11-26 13:07:39,852 DEBUG Layer 10: Alpha compound: 2.651301535731066\n",
      "2018-11-26 13:07:39,857 DEBUG Layer 13: Alpha compound: 2.060550313811606\n",
      "2018-11-26 13:07:39,861 DEBUG Layer 16: Alpha compound: 2.7597951451008007\n",
      "2018-11-26 13:07:39,864 DEBUG Layer 19: Alpha compound: 2.3895593397134487\n",
      "2018-11-26 13:07:39,867 DEBUG Layer 22: Alpha compound: 3.1179919075251576\n",
      "2018-11-26 13:07:39,870 DEBUG Layer 26: Alpha compound: 2.2986967540397245\n",
      "2018-11-26 13:07:39,872 DEBUG Layer 29: Alpha compound: 2.807516768260742\n",
      "2018-11-26 13:07:39,874 DEBUG Layer 32: Alpha: 1.7408908497937519\n",
      "2018-11-26 13:07:39,877 DEBUG Layer 35: Alpha compound: 2.269660752263139\n",
      "2018-11-26 13:07:39,879 DEBUG Layer 38: Alpha compound: 2.550727272823534\n",
      "2018-11-26 13:07:39,882 DEBUG Layer 41: Alpha compound: 2.1039357971448114\n",
      "2018-11-26 13:07:39,884 DEBUG Layer 44: Alpha compound: 3.2423148742387538\n",
      "2018-11-26 13:07:39,886 DEBUG Layer 47: Alpha compound: 2.8178895449840144\n",
      "2018-11-26 13:07:39,888 DEBUG Layer 50: Alpha compound: 3.95358392711761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:07:39,890 DEBUG Layer 54: Alpha compound: 4.157900851671872\n",
      "2018-11-26 13:07:39,893 DEBUG Layer 57: Alpha compound: 3.097906886663516\n",
      "2018-11-26 13:07:39,895 DEBUG Layer 60: Alpha: 2.659050835548668\n",
      "2018-11-26 13:07:39,898 DEBUG Layer 63: Alpha compound: 2.355180010576658\n",
      "2018-11-26 13:07:39,900 DEBUG Layer 66: Alpha compound: 2.7334839885997226\n",
      "2018-11-26 13:07:39,903 DEBUG Layer 69: Alpha compound: 2.7685056474693557\n",
      "2018-11-26 13:07:39,906 DEBUG Layer 72: Alpha compound: 3.274278037241145\n",
      "2018-11-26 13:07:39,909 DEBUG Layer 75: Alpha compound: 2.870488950431268\n",
      "2018-11-26 13:07:39,912 DEBUG Layer 78: Alpha compound: 2.986758183706283\n",
      "2018-11-26 13:07:39,915 DEBUG Layer 81: Alpha compound: 3.146531642515973\n",
      "2018-11-26 13:07:39,919 DEBUG Layer 84: Alpha compound: 3.244640197452939\n",
      "2018-11-26 13:07:39,922 DEBUG Layer 87: Alpha compound: 3.2376442378575754\n",
      "2018-11-26 13:07:39,924 DEBUG Layer 90: Alpha compound: 3.4162618931766797\n",
      "2018-11-26 13:07:39,927 DEBUG Layer 94: Alpha compound: 5.233665109792707\n",
      "2018-11-26 13:07:39,930 DEBUG Layer 100: Alpha: 3.0692634911300725\n",
      "2018-11-26 13:07:39,933 INFO Alpha: min: 1.5795685343427133, max: 6.847373741493381, avg: 2.934657257283816\n",
      "2018-11-26 13:07:39,935 INFO Alpha compound: min: 1.7408908497937519, max: 5.233665109792707, avg: 2.8951086174207363\n",
      "2018-11-26 13:07:39,939 DEBUG Layer 7: Alpha Weighted compound: -0.008384707039361184\n",
      "2018-11-26 13:07:39,941 DEBUG Layer 10: Alpha Weighted compound: -0.45534523045356656\n",
      "2018-11-26 13:07:39,944 DEBUG Layer 13: Alpha Weighted compound: -0.49382745296597214\n",
      "2018-11-26 13:07:39,946 DEBUG Layer 16: Alpha Weighted compound: -0.8796977185246243\n",
      "2018-11-26 13:07:39,948 DEBUG Layer 19: Alpha Weighted compound: -0.579420497528522\n",
      "2018-11-26 13:07:39,951 DEBUG Layer 22: Alpha Weighted compound: -1.2334887980509002\n",
      "2018-11-26 13:07:39,955 DEBUG Layer 26: Alpha Weighted compound: -0.019005346574931557\n",
      "2018-11-26 13:07:39,957 DEBUG Layer 29: Alpha Weighted compound: -0.6822705897062963\n",
      "2018-11-26 13:07:39,959 DEBUG Layer 32: Alpha Weigthed: 0.9822524070953985\n",
      "2018-11-26 13:07:39,962 DEBUG Layer 35: Alpha Weighted compound: 0.20267733089219644\n",
      "2018-11-26 13:07:39,964 DEBUG Layer 38: Alpha Weighted compound: -0.6037484966986493\n",
      "2018-11-26 13:07:39,967 DEBUG Layer 41: Alpha Weighted compound: -0.4436587810964246\n",
      "2018-11-26 13:07:39,969 DEBUG Layer 44: Alpha Weighted compound: -1.0356720848363152\n",
      "2018-11-26 13:07:39,971 DEBUG Layer 47: Alpha Weighted compound: -0.4064186368162358\n",
      "2018-11-26 13:07:39,975 DEBUG Layer 50: Alpha Weighted compound: -1.4131650578900432\n",
      "2018-11-26 13:07:39,977 DEBUG Layer 54: Alpha Weighted compound: -0.5794405238519489\n",
      "2018-11-26 13:07:39,979 DEBUG Layer 57: Alpha Weighted compound: 0.017657161189182535\n",
      "2018-11-26 13:07:39,981 DEBUG Layer 60: Alpha Weigthed: 1.021444181607654\n",
      "2018-11-26 13:07:39,984 DEBUG Layer 63: Alpha Weighted compound: -0.207672704542485\n",
      "2018-11-26 13:07:39,987 DEBUG Layer 66: Alpha Weighted compound: -0.3460557978637067\n",
      "2018-11-26 13:07:39,989 DEBUG Layer 69: Alpha Weighted compound: -0.17310062129146006\n",
      "2018-11-26 13:07:39,991 DEBUG Layer 72: Alpha Weighted compound: -0.489662389885074\n",
      "2018-11-26 13:07:39,993 DEBUG Layer 75: Alpha Weighted compound: -0.36921144203563994\n",
      "2018-11-26 13:07:39,996 DEBUG Layer 78: Alpha Weighted compound: -0.5152250862961705\n",
      "2018-11-26 13:07:39,999 DEBUG Layer 81: Alpha Weighted compound: -0.33367167727002456\n",
      "2018-11-26 13:07:40,003 DEBUG Layer 84: Alpha Weighted compound: -0.4529662287458593\n",
      "2018-11-26 13:07:40,006 DEBUG Layer 87: Alpha Weighted compound: -0.4719574556198374\n",
      "2018-11-26 13:07:40,009 DEBUG Layer 90: Alpha Weighted compound: -0.07393600222605896\n",
      "2018-11-26 13:07:40,012 DEBUG Layer 94: Alpha Weighted compound: -0.01781550692043405\n",
      "2018-11-26 13:07:40,014 DEBUG Layer 100: Alpha Weigthed: 1.1445346954537743\n",
      "2018-11-26 13:07:40,017 INFO Alpha Weighted: min: -2.908473493614272, max: 1.6028202030675573, avg: -0.4285858853645758\n",
      "2018-11-26 13:07:40,020 INFO Alpha Weighted compound: min: -1.4131650578900432, max: 1.1445346954537743, avg: -0.2972084352830778\n",
      "2018-11-26 13:07:43,027 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 13:07:43,029 INFO Analyzing model\n",
      "2018-11-26 13:07:43,036 INFO Layer 0: ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:07:43,039 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:43,042 INFO Layer 1: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "2018-11-26 13:07:43,045 INFO Pytorch tensor shape detected: 64x3 (NxM), 7x7 (i,j)\n",
      "2018-11-26 13:07:43,048 INFO Layer 1: Analyzing 49 weight matrices...\n",
      "2018-11-26 13:07:43,051 INFO     Weight matrix 1/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,054 INFO     Weight matrix 2/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,058 INFO     Weight matrix 3/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,061 INFO     Weight matrix 4/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,064 INFO     Weight matrix 5/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,067 INFO     Weight matrix 6/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,070 INFO     Weight matrix 7/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,072 INFO     Weight matrix 8/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,075 INFO     Weight matrix 9/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,080 INFO     Weight matrix 10/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,082 INFO     Weight matrix 11/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,085 INFO     Weight matrix 12/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,087 INFO     Weight matrix 13/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,090 INFO     Weight matrix 14/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,093 INFO     Weight matrix 15/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,096 INFO     Weight matrix 16/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,099 INFO     Weight matrix 17/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,102 INFO     Weight matrix 18/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,105 INFO     Weight matrix 19/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,108 INFO     Weight matrix 20/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,110 INFO     Weight matrix 21/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,113 INFO     Weight matrix 22/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,116 INFO     Weight matrix 23/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,118 INFO     Weight matrix 24/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,121 INFO     Weight matrix 25/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,124 INFO     Weight matrix 26/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,127 INFO     Weight matrix 27/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,130 INFO     Weight matrix 28/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,132 INFO     Weight matrix 29/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,135 INFO     Weight matrix 30/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,138 INFO     Weight matrix 31/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,142 INFO     Weight matrix 32/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,145 INFO     Weight matrix 33/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,149 INFO     Weight matrix 34/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,151 INFO     Weight matrix 35/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,155 INFO     Weight matrix 36/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,159 INFO     Weight matrix 37/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,163 INFO     Weight matrix 38/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,166 INFO     Weight matrix 39/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,168 INFO     Weight matrix 40/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,171 INFO     Weight matrix 41/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,173 INFO     Weight matrix 42/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,176 INFO     Weight matrix 43/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,179 INFO     Weight matrix 44/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,181 INFO     Weight matrix 45/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,185 INFO     Weight matrix 46/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,188 INFO     Weight matrix 47/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,191 INFO     Weight matrix 48/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,193 INFO     Weight matrix 49/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:07:43,196 INFO Layer 2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:43,199 INFO Layer 2: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:43,202 INFO Layer 3: ReLU(inplace)\n",
      "2018-11-26 13:07:43,210 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:43,213 INFO Layer 4: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "2018-11-26 13:07:43,215 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:43,219 INFO Layer 5: Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:07:43,222 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:43,225 INFO Layer 6: Bottleneck(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:07:43,228 INFO Layer 6: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:07:43,231 INFO Layer 7: Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:07:43,234 INFO Pytorch tensor shape detected: 64x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:07:43,237 INFO Layer 7: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:07:43,241 INFO     Weight matrix 1/1 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:43,911 INFO     Weight matrix 1/1 (64,64): Alpha: 10.446010528952465, Alpha Weighted: 2.956207824751127, D: 0.18763205754786322\n",
      "2018-11-26 13:07:43,913 INFO     Weight matrix 1/1 (64,64): Alpha 10.446010528952465 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:43,917 INFO     Weight matrix 1/1 (64,64): Lognorm: 0.6571754217147827\n",
      "2018-11-26 13:07:43,920 INFO Layer 8: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:43,922 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:43,924 INFO Layer 9: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:07:43,929 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:07:43,931 INFO Layer 9: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:07:43,933 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:44,602 INFO     Weight matrix 1/9 (64,64): Alpha: 2.046145726523097, Alpha Weighted: -0.5533474183189713, D: 0.10459396807016441\n",
      "2018-11-26 13:07:44,607 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.1128871813416481\n",
      "2018-11-26 13:07:44,610 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:45,061 INFO     Weight matrix 2/9 (64,64): Alpha: 2.1174593413877605, Alpha Weighted: -0.06240196546401215, D: 0.13321019218320473\n",
      "2018-11-26 13:07:45,064 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.23285619914531708\n",
      "2018-11-26 13:07:45,067 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:45,469 INFO     Weight matrix 3/9 (64,64): Alpha: 2.283839700486803, Alpha Weighted: -0.36751972514677383, D: 0.10012238473531287\n",
      "2018-11-26 13:07:45,473 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.15300758183002472\n",
      "2018-11-26 13:07:45,475 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:45,896 INFO     Weight matrix 4/9 (64,64): Alpha: 1.9674268146161458, Alpha Weighted: -0.21295957190024145, D: 0.137334931614852\n",
      "2018-11-26 13:07:45,899 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.22994133830070496\n",
      "2018-11-26 13:07:45,902 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:46,322 INFO     Weight matrix 5/9 (64,64): Alpha: 1.4104423307007656, Alpha Weighted: 0.4567723455522228, D: 0.1573894776727801\n",
      "2018-11-26 13:07:46,325 INFO     Weight matrix 5/9 (64,64): Alpha 1.4104423307007656 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:46,329 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.4518630802631378\n",
      "2018-11-26 13:07:46,331 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:46,739 INFO     Weight matrix 6/9 (64,64): Alpha: 1.484105209287797, Alpha Weighted: 0.03482936097760814, D: 0.1926679350920399\n",
      "2018-11-26 13:07:46,741 INFO     Weight matrix 6/9 (64,64): Alpha 1.484105209287797 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:46,744 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.3103581666946411\n",
      "2018-11-26 13:07:46,747 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:47,159 INFO     Weight matrix 7/9 (64,64): Alpha: 2.0632486036657998, Alpha Weighted: -0.24660565511219312, D: 0.10224316857690882\n",
      "2018-11-26 13:07:47,162 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.16029702126979828\n",
      "2018-11-26 13:07:47,166 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:47,605 INFO     Weight matrix 8/9 (64,64): Alpha: 2.3983207270671247, Alpha Weighted: 0.2548869666372128, D: 0.16355122848566095\n",
      "2018-11-26 13:07:47,608 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.322370320558548\n",
      "2018-11-26 13:07:47,610 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:48,017 INFO     Weight matrix 9/9 (64,64): Alpha: 1.8606091348677583, Alpha Weighted: 0.0011372105798282777, D: 0.1418971214350766\n",
      "2018-11-26 13:07:48,020 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.2485942840576172\n",
      "2018-11-26 13:07:48,023 INFO Layer 10: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:48,027 INFO Layer 10: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:48,030 INFO Layer 11: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:07:48,035 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:07:48,038 INFO Layer 11: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:07:48,040 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:07:48,497 INFO     Weight matrix 1/1 (64,256): Alpha: 3.7837070383280946, Alpha Weighted: 1.995679611445936, D: 0.08333333333333359\n",
      "2018-11-26 13:07:48,499 INFO     Weight matrix 1/1 (64,256): Alpha 3.7837070383280946 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:48,505 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.6545941829681396\n",
      "2018-11-26 13:07:48,507 INFO Layer 12: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:48,511 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:48,516 INFO Layer 13: ReLU(inplace)\n",
      "2018-11-26 13:07:48,520 INFO Layer 13: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:48,522 INFO Layer 14: Sequential(\n",
      "  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:07:48,524 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:48,527 INFO Layer 15: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:07:48,532 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:07:48,535 INFO Layer 15: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:07:48,537 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:07:49,003 INFO     Weight matrix 1/1 (64,256): Alpha: 3.2753482641674876, Alpha Weighted: 2.41984151376588, D: 0.12981590171599378\n",
      "2018-11-26 13:07:49,007 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.8676601648330688\n",
      "2018-11-26 13:07:49,010 INFO Layer 16: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:49,014 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:49,017 INFO Layer 17: Bottleneck(\n",
      "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:07:49,022 INFO Layer 17: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:49,024 INFO Layer 18: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:07:49,028 INFO Pytorch tensor shape detected: 64x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:07:49,030 INFO Layer 18: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:07:49,033 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:07:49,487 INFO     Weight matrix 1/1 (64,256): Alpha: 5.157142466567017, Alpha Weighted: 0.9424509641742017, D: 0.169332121111759\n",
      "2018-11-26 13:07:49,489 INFO     Weight matrix 1/1 (64,256): Alpha 5.157142466567017 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:49,493 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.593684196472168\n",
      "2018-11-26 13:07:49,495 INFO Layer 19: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:49,498 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:49,501 INFO Layer 20: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:07:49,507 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:07:49,511 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:07:49,513 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:07:49,970 INFO     Weight matrix 1/9 (64,64): Alpha: 2.0614123558123216, Alpha Weighted: -1.373399006375133, D: 0.19020689685569675\n",
      "2018-11-26 13:07:49,973 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.1424606740474701\n",
      "2018-11-26 13:07:49,976 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:50,425 INFO     Weight matrix 2/9 (64,64): Alpha: 2.0011488888785376, Alpha Weighted: -0.5784562061081873, D: 0.15070869513192808\n",
      "2018-11-26 13:07:50,428 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.23141486942768097\n",
      "2018-11-26 13:07:50,433 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:50,859 INFO     Weight matrix 3/9 (64,64): Alpha: 2.539537148398047, Alpha Weighted: -1.4129076511069794, D: 0.1762999568026441\n",
      "2018-11-26 13:07:50,862 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.16783680021762848\n",
      "2018-11-26 13:07:50,864 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:51,291 INFO     Weight matrix 4/9 (64,64): Alpha: 1.9287313393673542, Alpha Weighted: -0.4044694245545195, D: 0.1259368106853515\n",
      "2018-11-26 13:07:51,295 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.24712525308132172\n",
      "2018-11-26 13:07:51,299 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:51,726 INFO     Weight matrix 5/9 (64,64): Alpha: 1.5709396152192694, Alpha Weighted: 0.3205999792787847, D: 0.13722991205342105\n",
      "2018-11-26 13:07:51,729 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.43896424770355225\n",
      "2018-11-26 13:07:51,733 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:52,155 INFO     Weight matrix 6/9 (64,64): Alpha: 1.904892606591337, Alpha Weighted: -0.08188362480103051, D: 0.1391483558238602\n",
      "2018-11-26 13:07:52,158 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.3186936676502228\n",
      "2018-11-26 13:07:52,160 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:52,597 INFO     Weight matrix 7/9 (64,64): Alpha: 2.404268278068937, Alpha Weighted: -1.620542512978525, D: 0.21520103713872024\n",
      "2018-11-26 13:07:52,601 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.15706436336040497\n",
      "2018-11-26 13:07:52,604 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:53,043 INFO     Weight matrix 8/9 (64,64): Alpha: 1.9294080127427322, Alpha Weighted: -0.23399670551252044, D: 0.12367836833844992\n",
      "2018-11-26 13:07:53,047 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.29591798782348633\n",
      "2018-11-26 13:07:53,050 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:53,501 INFO     Weight matrix 9/9 (64,64): Alpha: 2.0493370220739413, Alpha Weighted: -1.0058630291324417, D: 0.18173547284334401\n",
      "2018-11-26 13:07:53,504 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.20949126780033112\n",
      "2018-11-26 13:07:53,507 INFO Layer 21: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:53,513 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:53,516 INFO Layer 22: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:07:53,519 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:07:53,522 INFO Layer 22: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:07:53,524 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:07:53,998 INFO     Weight matrix 1/1 (64,256): Alpha: 6.066928198524358, Alpha Weighted: 0.8830111902366142, D: 0.15383109051125599\n",
      "2018-11-26 13:07:54,001 INFO     Weight matrix 1/1 (64,256): Alpha 6.066928198524358 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:54,005 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.6196277141571045\n",
      "2018-11-26 13:07:54,012 INFO Layer 23: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:54,015 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:54,017 INFO Layer 24: ReLU(inplace)\n",
      "2018-11-26 13:07:54,020 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:54,023 INFO Layer 25: Bottleneck(\n",
      "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:07:54,026 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:54,028 INFO Layer 26: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:07:54,033 INFO Pytorch tensor shape detected: 64x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:07:54,036 INFO Layer 26: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:07:54,040 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:07:54,512 INFO     Weight matrix 1/1 (64,256): Alpha: 1.778434394499036, Alpha Weighted: 0.286697964557169, D: 0.16768323926475437\n",
      "2018-11-26 13:07:54,515 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.5854821801185608\n",
      "2018-11-26 13:07:54,520 INFO Layer 27: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:54,523 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:54,525 INFO Layer 28: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:07:54,529 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:07:54,533 INFO Layer 28: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:07:54,535 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:55,003 INFO     Weight matrix 1/9 (64,64): Alpha: 2.2702189932219525, Alpha Weighted: -1.113124500991515, D: 0.17967035772172274\n",
      "2018-11-26 13:07:55,007 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.1987421214580536\n",
      "2018-11-26 13:07:55,010 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:55,438 INFO     Weight matrix 2/9 (64,64): Alpha: 1.8012187963703983, Alpha Weighted: -0.21534060032014748, D: 0.155994719547776\n",
      "2018-11-26 13:07:55,443 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.30759885907173157\n",
      "2018-11-26 13:07:55,445 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:55,883 INFO     Weight matrix 3/9 (64,64): Alpha: 1.7342629925745803, Alpha Weighted: -0.7101090132361657, D: 0.18717012653888665\n",
      "2018-11-26 13:07:55,886 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.232007697224617\n",
      "2018-11-26 13:07:55,888 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:56,319 INFO     Weight matrix 4/9 (64,64): Alpha: 1.6933524321289395, Alpha Weighted: -0.26261484443911437, D: 0.1343861829346663\n",
      "2018-11-26 13:07:56,321 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.31155675649642944\n",
      "2018-11-26 13:07:56,325 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:56,769 INFO     Weight matrix 5/9 (64,64): Alpha: 1.6435814739494137, Alpha Weighted: 0.21015400063697076, D: 0.15094221881749992\n",
      "2018-11-26 13:07:56,772 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.44244372844696045\n",
      "2018-11-26 13:07:56,775 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:57,200 INFO     Weight matrix 6/9 (64,64): Alpha: 1.6428029735070582, Alpha Weighted: -0.24745295942008325, D: 0.13402702930459232\n",
      "2018-11-26 13:07:57,203 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.3428919017314911\n",
      "2018-11-26 13:07:57,211 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:57,667 INFO     Weight matrix 7/9 (64,64): Alpha: 1.7497505376160807, Alpha Weighted: -0.8583933878772817, D: 0.18981806961446768\n",
      "2018-11-26 13:07:57,670 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.22087888419628143\n",
      "2018-11-26 13:07:57,673 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:58,097 INFO     Weight matrix 8/9 (64,64): Alpha: 1.647860843671732, Alpha Weighted: -0.21332436599556415, D: 0.1490334702889763\n",
      "2018-11-26 13:07:58,100 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.34753674268722534\n",
      "2018-11-26 13:07:58,103 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:07:58,544 INFO     Weight matrix 9/9 (64,64): Alpha: 1.8331260651794268, Alpha Weighted: -0.6219378930337176, D: 0.17115281718551745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:07:58,547 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.2575131952762604\n",
      "2018-11-26 13:07:58,549 INFO Layer 29: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:58,552 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:58,554 INFO Layer 30: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:07:58,559 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:07:58,561 INFO Layer 30: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:07:58,566 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:07:59,021 INFO     Weight matrix 1/1 (64,256): Alpha: 7.0701668469902685, Alpha Weighted: 0.04334644477657957, D: 0.24109906839829864\n",
      "2018-11-26 13:07:59,024 INFO     Weight matrix 1/1 (64,256): Alpha 7.0701668469902685 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:07:59,027 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.6012221574783325\n",
      "2018-11-26 13:07:59,031 INFO Layer 31: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:07:59,034 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:59,036 INFO Layer 32: ReLU(inplace)\n",
      "2018-11-26 13:07:59,039 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:59,044 INFO Layer 33: Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:07:59,047 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:59,052 INFO Layer 34: Bottleneck(\n",
      "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:07:59,053 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 13:07:59,056 INFO Layer 35: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:07:59,059 INFO Pytorch tensor shape detected: 128x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:07:59,062 INFO Layer 35: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:07:59,065 INFO     Weight matrix 1/1 (128,256): Analyzing ...\n",
      "2018-11-26 13:08:00,043 INFO     Weight matrix 1/1 (128,256): Alpha: 5.618319957177584, Alpha Weighted: 2.4762422214765127, D: 0.1375002786495364\n",
      "2018-11-26 13:08:00,045 INFO     Weight matrix 1/1 (128,256): Alpha 5.618319957177584 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:08:00,049 INFO     Weight matrix 1/1 (128,256): Lognorm: 0.8073619604110718\n",
      "2018-11-26 13:08:00,054 INFO Layer 36: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:08:00,057 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:00,060 INFO Layer 37: Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:08:00,066 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:08:00,068 INFO Layer 37: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:08:00,071 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:01,064 INFO     Weight matrix 1/9 (128,128): Alpha: 2.3529794221428935, Alpha Weighted: -0.8121890363197606, D: 0.1313014464846589\n",
      "2018-11-26 13:08:01,069 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.37251046299934387\n",
      "2018-11-26 13:08:01,071 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:02,036 INFO     Weight matrix 2/9 (128,128): Alpha: 1.9891082453545705, Alpha Weighted: -0.43598638521376043, D: 0.17175551320183713\n",
      "2018-11-26 13:08:02,040 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.44680657982826233\n",
      "2018-11-26 13:08:02,044 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:03,029 INFO     Weight matrix 3/9 (128,128): Alpha: 2.5568012574536105, Alpha Weighted: -0.649811123948942, D: 0.16043967552950067\n",
      "2018-11-26 13:08:03,032 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.4273532032966614\n",
      "2018-11-26 13:08:03,036 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:03,992 INFO     Weight matrix 4/9 (128,128): Alpha: 2.3930316181809683, Alpha Weighted: -0.4263877211466372, D: 0.15482465820878638\n",
      "2018-11-26 13:08:03,995 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.44282111525535583\n",
      "2018-11-26 13:08:04,001 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:04,959 INFO     Weight matrix 5/9 (128,128): Alpha: 2.1113893886932025, Alpha Weighted: -0.27319613657837793, D: 0.14238857161226853\n",
      "2018-11-26 13:08:04,962 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.45676061511039734\n",
      "2018-11-26 13:08:04,965 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:05,925 INFO     Weight matrix 6/9 (128,128): Alpha: 1.5646782947992521, Alpha Weighted: -0.12470945416759592, D: 0.18401964148409694\n",
      "2018-11-26 13:08:05,928 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.5106464624404907\n",
      "2018-11-26 13:08:05,930 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:06,893 INFO     Weight matrix 7/9 (128,128): Alpha: 2.432542152047458, Alpha Weighted: -0.6102273929357485, D: 0.12620937786135739\n",
      "2018-11-26 13:08:06,898 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.41971227526664734\n",
      "2018-11-26 13:08:06,903 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:07,878 INFO     Weight matrix 8/9 (128,128): Alpha: 2.5552307781967016, Alpha Weighted: -0.2352712879343758, D: 0.15700522005176287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:08:07,882 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.5039682984352112\n",
      "2018-11-26 13:08:07,884 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:09,001 INFO     Weight matrix 9/9 (128,128): Alpha: 2.410338939878314, Alpha Weighted: -0.27642815650041064, D: 0.14605310097580188\n",
      "2018-11-26 13:08:09,005 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.4838077127933502\n",
      "2018-11-26 13:08:09,008 INFO Layer 38: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:08:09,014 INFO Layer 38: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:09,017 INFO Layer 39: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:08:09,024 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:08:09,027 INFO Layer 39: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:08:09,030 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:08:10,331 INFO     Weight matrix 1/1 (128,512): Alpha: 4.894880010137086, Alpha Weighted: 1.2696346229573083, D: 0.2045049795431106\n",
      "2018-11-26 13:08:10,337 INFO     Weight matrix 1/1 (128,512): Alpha 4.894880010137086 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:08:10,343 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.856681764125824\n",
      "2018-11-26 13:08:10,348 INFO Layer 40: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:08:10,351 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:10,355 INFO Layer 41: ReLU(inplace)\n",
      "2018-11-26 13:08:10,364 INFO Layer 41: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:10,370 INFO Layer 42: Sequential(\n",
      "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:08:10,373 INFO Layer 42: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:10,377 INFO Layer 43: Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 13:08:10,387 INFO Pytorch tensor shape detected: 512x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:08:10,393 INFO Layer 43: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:08:10,398 INFO     Weight matrix 1/1 (256,512): Analyzing ...\n",
      "2018-11-26 13:08:13,350 INFO     Weight matrix 1/1 (256,512): Alpha: 1.6427641443311631, Alpha Weighted: 1.2899124078568749, D: 0.11605745216524793\n",
      "2018-11-26 13:08:13,353 INFO     Weight matrix 1/1 (256,512): Lognorm: 0.9226973056793213\n",
      "2018-11-26 13:08:13,357 INFO Layer 44: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:08:13,360 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:13,363 INFO Layer 45: Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:08:13,366 INFO Layer 45: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:13,369 INFO Layer 46: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:08:13,374 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:08:13,376 INFO Layer 46: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:08:13,379 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:08:14,594 INFO     Weight matrix 1/1 (128,512): Alpha: 1.6051311913613768, Alpha Weighted: 0.6235918972714211, D: 0.09141059761576287\n",
      "2018-11-26 13:08:14,597 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.6298876404762268\n",
      "2018-11-26 13:08:14,600 INFO Layer 47: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:08:14,603 INFO Layer 47: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:14,606 INFO Layer 48: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:08:14,612 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:08:14,617 INFO Layer 48: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:08:14,621 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:15,731 INFO     Weight matrix 1/9 (128,128): Alpha: 1.6345789732314082, Alpha Weighted: -0.5581335762646293, D: 0.1140138899627498\n",
      "2018-11-26 13:08:15,738 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.2436905950307846\n",
      "2018-11-26 13:08:15,741 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:16,950 INFO     Weight matrix 2/9 (128,128): Alpha: 1.5253708522878693, Alpha Weighted: 0.4245479657111094, D: 0.09163560076007998\n",
      "2018-11-26 13:08:16,957 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.4482283592224121\n",
      "2018-11-26 13:08:16,964 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:18,308 INFO     Weight matrix 3/9 (128,128): Alpha: 1.5916088032378892, Alpha Weighted: -0.22140753680943254, D: 0.09922952472615681\n",
      "2018-11-26 13:08:18,312 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.3045502007007599\n",
      "2018-11-26 13:08:18,316 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:19,589 INFO     Weight matrix 4/9 (128,128): Alpha: 1.5023212312822567, Alpha Weighted: 0.3661480511876928, D: 0.10122098171344907\n",
      "2018-11-26 13:08:19,592 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.43075186014175415\n",
      "2018-11-26 13:08:19,595 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:21,084 INFO     Weight matrix 5/9 (128,128): Alpha: 1.5511365615582895, Alpha Weighted: 0.2732906192431855, D: 0.10701662169615217\n",
      "2018-11-26 13:08:21,089 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.4253232479095459\n",
      "2018-11-26 13:08:21,093 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:22,786 INFO     Weight matrix 6/9 (128,128): Alpha: 1.4848413823418687, Alpha Weighted: 0.37842510201870483, D: 0.09124875852791692\n",
      "2018-11-26 13:08:22,791 INFO     Weight matrix 6/9 (128,128): Alpha 1.4848413823418687 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:08:22,798 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.4500580430030823\n",
      "2018-11-26 13:08:22,803 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:24,201 INFO     Weight matrix 7/9 (128,128): Alpha: 1.583636253828657, Alpha Weighted: -0.2862926542838403, D: 0.10869799352080178\n",
      "2018-11-26 13:08:24,204 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.28608909249305725\n",
      "2018-11-26 13:08:24,206 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:25,406 INFO     Weight matrix 8/9 (128,128): Alpha: 1.5003388090615148, Alpha Weighted: 0.4816931021883375, D: 0.09540051571645836\n",
      "2018-11-26 13:08:25,410 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.4704359471797943\n",
      "2018-11-26 13:08:25,414 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:26,590 INFO     Weight matrix 9/9 (128,128): Alpha: 1.5523106891686336, Alpha Weighted: 0.018091326732064306, D: 0.09656168628863138\n",
      "2018-11-26 13:08:26,594 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.3642394542694092\n",
      "2018-11-26 13:08:26,599 INFO Layer 49: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:08:26,604 INFO Layer 49: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:26,607 INFO Layer 50: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:08:26,612 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:08:26,615 INFO Layer 50: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:08:26,619 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:08:27,834 INFO     Weight matrix 1/1 (128,512): Alpha: 7.039391081203674, Alpha Weighted: 2.2407076834663644, D: 0.16312271238238085\n",
      "2018-11-26 13:08:27,837 INFO     Weight matrix 1/1 (128,512): Alpha 7.039391081203674 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:08:27,840 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.7524837255477905\n",
      "2018-11-26 13:08:27,844 INFO Layer 51: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:08:27,847 INFO Layer 51: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:27,850 INFO Layer 52: ReLU(inplace)\n",
      "2018-11-26 13:08:27,854 INFO Layer 52: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:27,857 INFO Layer 53: Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:08:27,863 INFO Layer 53: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:27,866 INFO Layer 54: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:08:27,872 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:08:27,874 INFO Layer 54: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:08:27,878 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:08:29,285 INFO     Weight matrix 1/1 (128,512): Alpha: 2.473860645627811, Alpha Weighted: 0.8337626569624386, D: 0.15467484911315998\n",
      "2018-11-26 13:08:29,288 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.7761330008506775\n",
      "2018-11-26 13:08:29,291 INFO Layer 55: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:08:29,294 INFO Layer 55: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:29,298 INFO Layer 56: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:08:29,303 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:08:29,305 INFO Layer 56: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:08:29,308 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:30,483 INFO     Weight matrix 1/9 (128,128): Alpha: 2.1961016784062233, Alpha Weighted: -0.7209741580436906, D: 0.153014580667296\n",
      "2018-11-26 13:08:30,489 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.3529805839061737\n",
      "2018-11-26 13:08:30,492 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:31,542 INFO     Weight matrix 2/9 (128,128): Alpha: 1.8447376449620867, Alpha Weighted: -0.1291505891785297, D: 0.12739360185353932\n",
      "2018-11-26 13:08:31,547 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.45145049691200256\n",
      "2018-11-26 13:08:31,549 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:32,829 INFO     Weight matrix 3/9 (128,128): Alpha: 2.5395494519001067, Alpha Weighted: -0.5604060475332021, D: 0.14483616028270552\n",
      "2018-11-26 13:08:32,833 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.38322097063064575\n",
      "2018-11-26 13:08:32,835 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:34,122 INFO     Weight matrix 4/9 (128,128): Alpha: 1.850981818963215, Alpha Weighted: -0.047382613083403136, D: 0.10879847671047582\n",
      "2018-11-26 13:08:34,129 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.4580128490924835\n",
      "2018-11-26 13:08:34,134 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:35,350 INFO     Weight matrix 5/9 (128,128): Alpha: 1.7026121146910367, Alpha Weighted: 0.016740872593587107, D: 0.1380409724682753\n",
      "2018-11-26 13:08:35,355 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.4879652261734009\n",
      "2018-11-26 13:08:35,358 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:36,594 INFO     Weight matrix 6/9 (128,128): Alpha: 1.7369545509396689, Alpha Weighted: 0.10580970013755757, D: 0.12464231862911657\n",
      "2018-11-26 13:08:36,597 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.49989432096481323\n",
      "2018-11-26 13:08:36,600 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:37,714 INFO     Weight matrix 7/9 (128,128): Alpha: 2.6895333969028234, Alpha Weighted: -0.7869827363256712, D: 0.17055204078818087\n",
      "2018-11-26 13:08:37,719 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.3757755160331726\n",
      "2018-11-26 13:08:37,722 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:38,936 INFO     Weight matrix 8/9 (128,128): Alpha: 1.7167007651301422, Alpha Weighted: 0.012277048427761448, D: 0.1230438584248939\n",
      "2018-11-26 13:08:38,941 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.49046680331230164\n",
      "2018-11-26 13:08:38,946 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:40,098 INFO     Weight matrix 9/9 (128,128): Alpha: 2.6375636039520733, Alpha Weighted: -0.4204367597917147, D: 0.160820126014734\n",
      "2018-11-26 13:08:40,104 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.42086261510849\n",
      "2018-11-26 13:08:40,107 INFO Layer 57: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:08:40,111 INFO Layer 57: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:40,117 INFO Layer 58: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:08:40,122 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:08:40,124 INFO Layer 58: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:08:40,129 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:08:41,298 INFO     Weight matrix 1/1 (128,512): Alpha: 3.506324243452527, Alpha Weighted: 0.7073591011728771, D: 0.1966989127399431\n",
      "2018-11-26 13:08:41,301 INFO     Weight matrix 1/1 (128,512): Alpha 3.506324243452527 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:08:41,304 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.8261816501617432\n",
      "2018-11-26 13:08:41,308 INFO Layer 59: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:08:41,311 INFO Layer 59: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:41,314 INFO Layer 60: ReLU(inplace)\n",
      "2018-11-26 13:08:41,317 INFO Layer 60: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:41,320 INFO Layer 61: Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:08:41,323 INFO Layer 61: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:41,325 INFO Layer 62: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:08:41,328 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:08:41,331 INFO Layer 62: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:08:41,333 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:08:42,331 INFO     Weight matrix 1/1 (128,512): Alpha: 2.9831575911726214, Alpha Weighted: 0.9817868067504645, D: 0.17075922742700433\n",
      "2018-11-26 13:08:42,334 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.7945184111595154\n",
      "2018-11-26 13:08:42,337 INFO Layer 63: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:08:42,345 INFO Layer 63: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:42,347 INFO Layer 64: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:08:42,353 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:08:42,357 INFO Layer 64: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:08:42,360 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:43,375 INFO     Weight matrix 1/9 (128,128): Alpha: 2.2034575630250233, Alpha Weighted: -0.8773306566429371, D: 0.13257410570943728\n",
      "2018-11-26 13:08:43,379 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.3698806166648865\n",
      "2018-11-26 13:08:43,381 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:44,345 INFO     Weight matrix 2/9 (128,128): Alpha: 2.054046326000177, Alpha Weighted: -0.2800692592049806, D: 0.14776676011163487\n",
      "2018-11-26 13:08:44,348 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.45097166299819946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:08:44,351 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:45,417 INFO     Weight matrix 3/9 (128,128): Alpha: 1.9180892455796101, Alpha Weighted: -0.6361601148942772, D: 0.1488474088679207\n",
      "2018-11-26 13:08:45,420 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.4040957987308502\n",
      "2018-11-26 13:08:45,423 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:46,479 INFO     Weight matrix 4/9 (128,128): Alpha: 1.681466570040949, Alpha Weighted: -0.17577332064426188, D: 0.14678506861106183\n",
      "2018-11-26 13:08:46,483 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.46653345227241516\n",
      "2018-11-26 13:08:46,486 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:47,447 INFO     Weight matrix 5/9 (128,128): Alpha: 1.7526381646752394, Alpha Weighted: -0.1513469806900392, D: 0.15428512387005577\n",
      "2018-11-26 13:08:47,450 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.5235927104949951\n",
      "2018-11-26 13:08:47,453 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:48,402 INFO     Weight matrix 6/9 (128,128): Alpha: 1.6322804413295486, Alpha Weighted: -0.03574332676067112, D: 0.15804434578979554\n",
      "2018-11-26 13:08:48,406 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.5114250183105469\n",
      "2018-11-26 13:08:48,409 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:49,380 INFO     Weight matrix 7/9 (128,128): Alpha: 1.9426450273766682, Alpha Weighted: -0.5890677065460209, D: 0.13872888472997646\n",
      "2018-11-26 13:08:49,383 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.4056152105331421\n",
      "2018-11-26 13:08:49,387 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:50,374 INFO     Weight matrix 8/9 (128,128): Alpha: 1.6439005917443257, Alpha Weighted: -0.13455028671618008, D: 0.1508171650184998\n",
      "2018-11-26 13:08:50,377 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.49384811520576477\n",
      "2018-11-26 13:08:50,380 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:08:51,340 INFO     Weight matrix 9/9 (128,128): Alpha: 1.8745739729352815, Alpha Weighted: -0.3514013898048063, D: 0.14707487816537135\n",
      "2018-11-26 13:08:51,345 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.44529879093170166\n",
      "2018-11-26 13:08:51,347 INFO Layer 65: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:08:51,349 INFO Layer 65: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:51,352 INFO Layer 66: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:08:51,356 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:08:51,359 INFO Layer 66: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:08:51,362 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:08:52,397 INFO     Weight matrix 1/1 (128,512): Alpha: 2.894874270304915, Alpha Weighted: 0.5835067915251431, D: 0.15732740773833148\n",
      "2018-11-26 13:08:52,400 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.7946745753288269\n",
      "2018-11-26 13:08:52,402 INFO Layer 67: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:08:52,405 INFO Layer 67: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:52,409 INFO Layer 68: ReLU(inplace)\n",
      "2018-11-26 13:08:52,412 INFO Layer 68: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:52,417 INFO Layer 69: Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:08:52,421 INFO Layer 69: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:52,425 INFO Layer 70: Bottleneck(\n",
      "  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:08:52,428 INFO Layer 70: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:52,431 INFO Layer 71: Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:08:52,435 INFO Pytorch tensor shape detected: 256x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:08:52,437 INFO Layer 71: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:08:52,440 INFO     Weight matrix 1/1 (256,512): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:08:55,053 INFO     Weight matrix 1/1 (256,512): Alpha: 5.3033910840181955, Alpha Weighted: 3.168497505641687, D: 0.10960726889051464\n",
      "2018-11-26 13:08:55,055 INFO     Weight matrix 1/1 (256,512): Alpha 5.3033910840181955 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:08:55,058 INFO     Weight matrix 1/1 (256,512): Lognorm: 1.0471938848495483\n",
      "2018-11-26 13:08:55,061 INFO Layer 72: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:08:55,064 INFO Layer 72: Skipping (Layer not supported)\n",
      "2018-11-26 13:08:55,067 INFO Layer 73: Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:08:55,086 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:08:55,088 INFO Layer 73: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:08:55,092 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:08:57,726 INFO     Weight matrix 1/9 (256,256): Alpha: 3.5171655212541766, Alpha Weighted: -1.4359169047102425, D: 0.10299393901586351\n",
      "2018-11-26 13:08:57,728 INFO     Weight matrix 1/9 (256,256): Alpha 3.5171655212541766 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:08:57,732 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.540160596370697\n",
      "2018-11-26 13:08:57,737 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:00,318 INFO     Weight matrix 2/9 (256,256): Alpha: 4.784834066719885, Alpha Weighted: -1.1030243100403712, D: 0.15570096528769417\n",
      "2018-11-26 13:09:00,322 INFO     Weight matrix 2/9 (256,256): Alpha 4.784834066719885 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:09:00,328 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6468981504440308\n",
      "2018-11-26 13:09:00,331 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:02,958 INFO     Weight matrix 3/9 (256,256): Alpha: 4.478991291726031, Alpha Weighted: -1.1901518701217249, D: 0.12719486220675713\n",
      "2018-11-26 13:09:02,961 INFO     Weight matrix 3/9 (256,256): Alpha 4.478991291726031 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:09:02,965 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.6063258647918701\n",
      "2018-11-26 13:09:02,969 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:05,866 INFO     Weight matrix 4/9 (256,256): Alpha: 4.323668830871739, Alpha Weighted: -1.116072818968536, D: 0.13626901347104603\n",
      "2018-11-26 13:09:05,869 INFO     Weight matrix 4/9 (256,256): Alpha 4.323668830871739 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:09:05,873 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.6331512331962585\n",
      "2018-11-26 13:09:05,877 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:08,225 INFO     Weight matrix 5/9 (256,256): Alpha: 2.4436056082855817, Alpha Weighted: -0.5263481581520248, D: 0.17491174705842133\n",
      "2018-11-26 13:09:08,230 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.6476794481277466\n",
      "2018-11-26 13:09:08,232 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:10,990 INFO     Weight matrix 6/9 (256,256): Alpha: 5.162165663317341, Alpha Weighted: -0.5676098761513155, D: 0.14293159278046874\n",
      "2018-11-26 13:09:10,993 INFO     Weight matrix 6/9 (256,256): Alpha 5.162165663317341 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:09:10,999 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.7162935733795166\n",
      "2018-11-26 13:09:11,002 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:13,797 INFO     Weight matrix 7/9 (256,256): Alpha: 3.43231742984665, Alpha Weighted: -0.905661666992995, D: 0.1143362514118168\n",
      "2018-11-26 13:09:13,801 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.5948140025138855\n",
      "2018-11-26 13:09:13,805 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:16,497 INFO     Weight matrix 8/9 (256,256): Alpha: 4.779841955528527, Alpha Weighted: -0.6156820568165694, D: 0.17897392361252223\n",
      "2018-11-26 13:09:16,500 INFO     Weight matrix 8/9 (256,256): Alpha 4.779841955528527 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:09:16,510 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.7168353199958801\n",
      "2018-11-26 13:09:16,514 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:19,162 INFO     Weight matrix 9/9 (256,256): Alpha: 4.377401410345632, Alpha Weighted: -0.7571282554890385, D: 0.11277846471930836\n",
      "2018-11-26 13:09:19,164 INFO     Weight matrix 9/9 (256,256): Alpha 4.377401410345632 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:09:19,173 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6711245179176331\n",
      "2018-11-26 13:09:19,176 INFO Layer 74: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:09:19,178 INFO Layer 74: Skipping (Layer not supported)\n",
      "2018-11-26 13:09:19,181 INFO Layer 75: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:09:19,191 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:09:19,193 INFO Layer 75: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:09:19,196 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:09:22,102 INFO     Weight matrix 1/1 (256,1024): Alpha: 7.209589014526275, Alpha Weighted: 3.7302548673572087, D: 0.08258803684718496\n",
      "2018-11-26 13:09:22,104 INFO     Weight matrix 1/1 (256,1024): Alpha 7.209589014526275 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:09:22,107 INFO     Weight matrix 1/1 (256,1024): Lognorm: 1.078093409538269\n",
      "2018-11-26 13:09:22,115 INFO Layer 76: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:09:22,118 INFO Layer 76: Skipping (Layer not supported)\n",
      "2018-11-26 13:09:22,123 INFO Layer 77: ReLU(inplace)\n",
      "2018-11-26 13:09:22,126 INFO Layer 77: Skipping (Layer not supported)\n",
      "2018-11-26 13:09:22,129 INFO Layer 78: Sequential(\n",
      "  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:09:22,132 INFO Layer 78: Skipping (Layer not supported)\n",
      "2018-11-26 13:09:22,134 INFO Layer 79: Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 13:09:22,140 INFO Pytorch tensor shape detected: 1024x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:09:22,142 INFO Layer 79: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:09:22,147 INFO     Weight matrix 1/1 (512,1024): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:09:22,151 INFO Layer 80: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:09:22,153 INFO Layer 80: Skipping (Layer not supported)\n",
      "2018-11-26 13:09:22,156 INFO Layer 81: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:09:22,159 INFO Layer 81: Skipping (Layer not supported)\n",
      "2018-11-26 13:09:22,163 INFO Layer 82: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:09:22,167 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:09:22,169 INFO Layer 82: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:09:22,172 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:09:25,082 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.990364884146791, Alpha Weighted: 1.0734212664470093, D: 0.15571090827153533\n",
      "2018-11-26 13:09:25,085 INFO     Weight matrix 1/1 (256,1024): Alpha 4.990364884146791 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:09:25,088 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8917931318283081\n",
      "2018-11-26 13:09:25,093 INFO Layer 83: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:09:25,095 INFO Layer 83: Skipping (Layer not supported)\n",
      "2018-11-26 13:09:25,099 INFO Layer 84: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:09:25,104 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:09:25,107 INFO Layer 84: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:09:25,110 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:27,581 INFO     Weight matrix 1/9 (256,256): Alpha: 1.7085161233789101, Alpha Weighted: -0.30511702002423213, D: 0.14325879174243106\n",
      "2018-11-26 13:09:27,586 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.5395923852920532\n",
      "2018-11-26 13:09:27,589 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:30,542 INFO     Weight matrix 2/9 (256,256): Alpha: 2.0035614710413574, Alpha Weighted: -0.07518379731122153, D: 0.12732733061487078\n",
      "2018-11-26 13:09:30,548 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.600640058517456\n",
      "2018-11-26 13:09:30,553 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:33,445 INFO     Weight matrix 3/9 (256,256): Alpha: 1.692947566412167, Alpha Weighted: -0.2758705135660663, D: 0.14319865235110513\n",
      "2018-11-26 13:09:33,451 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.5560106635093689\n",
      "2018-11-26 13:09:33,455 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:36,180 INFO     Weight matrix 4/9 (256,256): Alpha: 1.84781566736131, Alpha Weighted: 0.07292159975099813, D: 0.10630535524330453\n",
      "2018-11-26 13:09:36,184 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5905593633651733\n",
      "2018-11-26 13:09:36,187 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:38,878 INFO     Weight matrix 5/9 (256,256): Alpha: 2.426648287817175, Alpha Weighted: 0.6601807876275335, D: 0.09086872667210766\n",
      "2018-11-26 13:09:38,882 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.6200026869773865\n",
      "2018-11-26 13:09:38,885 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:41,328 INFO     Weight matrix 6/9 (256,256): Alpha: 1.900440881306759, Alpha Weighted: 0.1196802585420227, D: 0.1180300290703521\n",
      "2018-11-26 13:09:41,333 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.606558620929718\n",
      "2018-11-26 13:09:41,335 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:43,784 INFO     Weight matrix 7/9 (256,256): Alpha: 1.7034530548159124, Alpha Weighted: -0.29760087536097707, D: 0.14630044987574176\n",
      "2018-11-26 13:09:43,789 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.553230345249176\n",
      "2018-11-26 13:09:43,792 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:46,305 INFO     Weight matrix 8/9 (256,256): Alpha: 1.801523578374888, Alpha Weighted: 0.005204837970329996, D: 0.13340319681685164\n",
      "2018-11-26 13:09:46,309 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6257272362709045\n",
      "2018-11-26 13:09:46,312 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:48,784 INFO     Weight matrix 9/9 (256,256): Alpha: 1.7054322461499276, Alpha Weighted: -0.23477719261883748, D: 0.1491708915435745\n",
      "2018-11-26 13:09:48,789 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.5755025744438171\n",
      "2018-11-26 13:09:48,792 INFO Layer 85: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:09:48,794 INFO Layer 85: Skipping (Layer not supported)\n",
      "2018-11-26 13:09:48,797 INFO Layer 86: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:09:48,801 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:09:48,804 INFO Layer 86: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:09:48,807 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:09:51,294 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.812705101358966, Alpha Weighted: 2.0115988553429838, D: 0.09398047424247002\n",
      "2018-11-26 13:09:51,296 INFO     Weight matrix 1/1 (256,1024): Alpha 3.812705101358966 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:09:51,299 INFO     Weight matrix 1/1 (256,1024): Lognorm: 1.0185887813568115\n",
      "2018-11-26 13:09:51,302 INFO Layer 87: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:09:51,305 INFO Layer 87: Skipping (Layer not supported)\n",
      "2018-11-26 13:09:51,308 INFO Layer 88: ReLU(inplace)\n",
      "2018-11-26 13:09:51,311 INFO Layer 88: Skipping (Layer not supported)\n",
      "2018-11-26 13:09:51,317 INFO Layer 89: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:09:51,318 INFO Layer 89: Skipping (Layer not supported)\n",
      "2018-11-26 13:09:51,321 INFO Layer 90: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:09:51,326 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:09:51,332 INFO Layer 90: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:09:51,335 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:09:54,173 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.7291630029001805, Alpha Weighted: 0.4947299744274746, D: 0.14027682921960577\n",
      "2018-11-26 13:09:54,177 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.9067794680595398\n",
      "2018-11-26 13:09:54,182 INFO Layer 91: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:09:54,185 INFO Layer 91: Skipping (Layer not supported)\n",
      "2018-11-26 13:09:54,189 INFO Layer 92: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:09:54,195 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:09:54,198 INFO Layer 92: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:09:54,201 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:56,561 INFO     Weight matrix 1/9 (256,256): Alpha: 1.9328190666823788, Alpha Weighted: -0.26096160331517404, D: 0.12258432211217463\n",
      "2018-11-26 13:09:56,566 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.5513647794723511\n",
      "2018-11-26 13:09:56,569 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:09:59,217 INFO     Weight matrix 2/9 (256,256): Alpha: 1.869548517192003, Alpha Weighted: -0.037254860116220555, D: 0.10430001067508066\n",
      "2018-11-26 13:09:59,222 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.594482958316803\n",
      "2018-11-26 13:09:59,228 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:01,954 INFO     Weight matrix 3/9 (256,256): Alpha: 1.8669819736579982, Alpha Weighted: -0.18231817405434123, D: 0.1224333168918525\n",
      "2018-11-26 13:10:01,959 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.5671756863594055\n",
      "2018-11-26 13:10:01,962 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:04,307 INFO     Weight matrix 4/9 (256,256): Alpha: 1.841677192118944, Alpha Weighted: 0.12638293501016548, D: 0.09686578286743108\n",
      "2018-11-26 13:10:04,312 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.6008004546165466\n",
      "2018-11-26 13:10:04,314 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:06,776 INFO     Weight matrix 5/9 (256,256): Alpha: 2.013556130026074, Alpha Weighted: -0.17285194282268493, D: 0.11648981269746395\n",
      "2018-11-26 13:10:06,781 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.5846433639526367\n",
      "2018-11-26 13:10:06,783 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:09,254 INFO     Weight matrix 6/9 (256,256): Alpha: 1.8393530382246244, Alpha Weighted: 0.17806453003371617, D: 0.10138510170928533\n",
      "2018-11-26 13:10:09,259 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6159815192222595\n",
      "2018-11-26 13:10:09,262 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:11,811 INFO     Weight matrix 7/9 (256,256): Alpha: 1.8820072575215427, Alpha Weighted: -0.26562608184344355, D: 0.12195379283483443\n",
      "2018-11-26 13:10:11,816 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.561366856098175\n",
      "2018-11-26 13:10:11,819 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:14,884 INFO     Weight matrix 8/9 (256,256): Alpha: 1.8559266846882174, Alpha Weighted: -0.034524872209349806, D: 0.1055603394623324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:10:14,890 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6025023460388184\n",
      "2018-11-26 13:10:14,896 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:17,626 INFO     Weight matrix 9/9 (256,256): Alpha: 1.7682445086786507, Alpha Weighted: -0.2070329890070797, D: 0.1277514435210585\n",
      "2018-11-26 13:10:17,631 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.57761549949646\n",
      "2018-11-26 13:10:17,633 INFO Layer 93: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:10:17,637 INFO Layer 93: Skipping (Layer not supported)\n",
      "2018-11-26 13:10:17,640 INFO Layer 94: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:10:17,646 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:10:17,649 INFO Layer 94: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:10:17,653 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:10:20,898 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.963596169117725, Alpha Weighted: 2.011770001550082, D: 0.14427874168915522\n",
      "2018-11-26 13:10:20,901 INFO     Weight matrix 1/1 (256,1024): Alpha 5.963596169117725 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:10:20,904 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.9901520013809204\n",
      "2018-11-26 13:10:20,909 INFO Layer 95: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:10:20,912 INFO Layer 95: Skipping (Layer not supported)\n",
      "2018-11-26 13:10:20,915 INFO Layer 96: ReLU(inplace)\n",
      "2018-11-26 13:10:20,918 INFO Layer 96: Skipping (Layer not supported)\n",
      "2018-11-26 13:10:20,921 INFO Layer 97: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:10:20,924 INFO Layer 97: Skipping (Layer not supported)\n",
      "2018-11-26 13:10:20,928 INFO Layer 98: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:10:20,933 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:10:20,936 INFO Layer 98: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:10:20,939 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:10:24,964 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.212507921142585, Alpha Weighted: 0.926432024288254, D: 0.13686297574898298\n",
      "2018-11-26 13:10:24,967 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.9488285183906555\n",
      "2018-11-26 13:10:24,971 INFO Layer 99: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:10:24,974 INFO Layer 99: Skipping (Layer not supported)\n",
      "2018-11-26 13:10:24,978 INFO Layer 100: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:10:24,984 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:10:24,989 INFO Layer 100: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:10:24,992 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:27,857 INFO     Weight matrix 1/9 (256,256): Alpha: 2.47425499562629, Alpha Weighted: -0.2814035427266031, D: 0.0998938684504651\n",
      "2018-11-26 13:10:27,862 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.5660850405693054\n",
      "2018-11-26 13:10:27,865 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:31,331 INFO     Weight matrix 2/9 (256,256): Alpha: 2.804964759520673, Alpha Weighted: -0.5673001625761052, D: 0.11725230374108286\n",
      "2018-11-26 13:10:31,335 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.5767800211906433\n",
      "2018-11-26 13:10:31,339 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:34,484 INFO     Weight matrix 3/9 (256,256): Alpha: 2.2846985373649202, Alpha Weighted: -0.23666920738532385, D: 0.1012089649438992\n",
      "2018-11-26 13:10:34,489 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.5752161741256714\n",
      "2018-11-26 13:10:34,492 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:37,757 INFO     Weight matrix 4/9 (256,256): Alpha: 2.24113346160577, Alpha Weighted: -0.28085537773820507, D: 0.1095608638970802\n",
      "2018-11-26 13:10:37,770 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5676506757736206\n",
      "2018-11-26 13:10:37,774 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:40,428 INFO     Weight matrix 5/9 (256,256): Alpha: 2.188032997886106, Alpha Weighted: -0.2802121521137574, D: 0.1305471660283194\n",
      "2018-11-26 13:10:40,432 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.6166491508483887\n",
      "2018-11-26 13:10:40,436 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:42,935 INFO     Weight matrix 6/9 (256,256): Alpha: 2.5512656494895762, Alpha Weighted: -0.2455500745932524, D: 0.11588013795886443\n",
      "2018-11-26 13:10:42,939 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.5844677090644836\n",
      "2018-11-26 13:10:42,942 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:45,273 INFO     Weight matrix 7/9 (256,256): Alpha: 2.526966640135508, Alpha Weighted: -0.31801982352574193, D: 0.1053424210624494\n",
      "2018-11-26 13:10:45,277 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.5754414796829224\n",
      "2018-11-26 13:10:45,280 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:47,757 INFO     Weight matrix 8/9 (256,256): Alpha: 2.173814594568606, Alpha Weighted: -0.3591704581671542, D: 0.14310342544835725\n",
      "2018-11-26 13:10:47,762 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.5932742953300476\n",
      "2018-11-26 13:10:47,764 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:50,621 INFO     Weight matrix 9/9 (256,256): Alpha: 2.526608287621535, Alpha Weighted: -0.29613269037284756, D: 0.1063424381939656\n",
      "2018-11-26 13:10:50,627 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.5846142768859863\n",
      "2018-11-26 13:10:50,630 INFO Layer 101: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:10:50,632 INFO Layer 101: Skipping (Layer not supported)\n",
      "2018-11-26 13:10:50,634 INFO Layer 102: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:10:50,640 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:10:50,643 INFO Layer 102: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:10:50,645 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:10:53,245 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.331017634959009, Alpha Weighted: 1.7183579784911742, D: 0.09259414338986238\n",
      "2018-11-26 13:10:53,247 INFO     Weight matrix 1/1 (256,1024): Alpha 4.331017634959009 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:10:53,251 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.9704855680465698\n",
      "2018-11-26 13:10:53,254 INFO Layer 103: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:10:53,257 INFO Layer 103: Skipping (Layer not supported)\n",
      "2018-11-26 13:10:53,260 INFO Layer 104: ReLU(inplace)\n",
      "2018-11-26 13:10:53,263 INFO Layer 104: Skipping (Layer not supported)\n",
      "2018-11-26 13:10:53,267 INFO Layer 105: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:10:53,270 INFO Layer 105: Skipping (Layer not supported)\n",
      "2018-11-26 13:10:53,273 INFO Layer 106: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:10:53,278 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:10:53,281 INFO Layer 106: Analyzing 1 weight matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:10:53,284 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:10:55,961 INFO     Weight matrix 1/1 (256,1024): Alpha: 10.27677547542684, Alpha Weighted: 3.0588651655782164, D: 0.12499999999999956\n",
      "2018-11-26 13:10:55,964 INFO     Weight matrix 1/1 (256,1024): Alpha 10.27677547542684 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:10:55,967 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.9678803086280823\n",
      "2018-11-26 13:10:55,970 INFO Layer 107: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:10:55,973 INFO Layer 107: Skipping (Layer not supported)\n",
      "2018-11-26 13:10:55,976 INFO Layer 108: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:10:55,983 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:10:55,986 INFO Layer 108: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:10:55,989 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:10:58,434 INFO     Weight matrix 1/9 (256,256): Alpha: 2.258917667011099, Alpha Weighted: -0.24022722003452185, D: 0.09650454311996726\n",
      "2018-11-26 13:10:58,438 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.5750290751457214\n",
      "2018-11-26 13:10:58,441 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:00,847 INFO     Weight matrix 2/9 (256,256): Alpha: 2.6081608038809545, Alpha Weighted: -0.5792644814417057, D: 0.11761043744363786\n",
      "2018-11-26 13:11:00,852 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.5733855366706848\n",
      "2018-11-26 13:11:00,854 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:03,163 INFO     Weight matrix 3/9 (256,256): Alpha: 2.3939843370584404, Alpha Weighted: -0.16304948489618792, D: 0.09190950875469175\n",
      "2018-11-26 13:11:03,168 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.5880002379417419\n",
      "2018-11-26 13:11:03,172 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:05,548 INFO     Weight matrix 4/9 (256,256): Alpha: 2.522265103943404, Alpha Weighted: -0.634125920923284, D: 0.1049333268747884\n",
      "2018-11-26 13:11:05,552 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5479896068572998\n",
      "2018-11-26 13:11:05,555 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:08,430 INFO     Weight matrix 5/9 (256,256): Alpha: 2.0177904902234323, Alpha Weighted: -0.24812901936650494, D: 0.136612165106698\n",
      "2018-11-26 13:11:08,434 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.6136241555213928\n",
      "2018-11-26 13:11:08,438 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:11,166 INFO     Weight matrix 6/9 (256,256): Alpha: 2.622496132835143, Alpha Weighted: -0.5849508060295989, D: 0.11347009647842554\n",
      "2018-11-26 13:11:11,171 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.5596779584884644\n",
      "2018-11-26 13:11:11,173 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:13,502 INFO     Weight matrix 7/9 (256,256): Alpha: 2.3871699829570945, Alpha Weighted: -0.13651376101786863, D: 0.09860743145086653\n",
      "2018-11-26 13:11:13,506 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.5868608951568604\n",
      "2018-11-26 13:11:13,509 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:15,840 INFO     Weight matrix 8/9 (256,256): Alpha: 2.712407109387671, Alpha Weighted: -0.653864144283796, D: 0.1293548698075963\n",
      "2018-11-26 13:11:15,845 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.583977997303009\n",
      "2018-11-26 13:11:15,848 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:18,261 INFO     Weight matrix 9/9 (256,256): Alpha: 2.434240498571049, Alpha Weighted: -0.11265411203661846, D: 0.08881188921414229\n",
      "2018-11-26 13:11:18,265 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.597758948802948\n",
      "2018-11-26 13:11:18,268 INFO Layer 109: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:18,270 INFO Layer 109: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:18,273 INFO Layer 110: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:11:18,279 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:11:18,281 INFO Layer 110: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:11:18,284 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:11:20,761 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.657101129212204, Alpha Weighted: 2.3134609129061694, D: 0.06590783077399942\n",
      "2018-11-26 13:11:20,764 INFO     Weight matrix 1/1 (256,1024): Alpha 4.657101129212204 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:11:20,767 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.9698952436447144\n",
      "2018-11-26 13:11:20,771 INFO Layer 111: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:20,773 INFO Layer 111: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:20,775 INFO Layer 112: ReLU(inplace)\n",
      "2018-11-26 13:11:20,781 INFO Layer 112: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:20,783 INFO Layer 113: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:11:20,786 INFO Layer 113: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:20,788 INFO Layer 114: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:11:20,794 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:11:20,796 INFO Layer 114: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:11:20,798 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:11:23,280 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.102814093147542, Alpha Weighted: 1.8843543152667732, D: 0.10160509063089473\n",
      "2018-11-26 13:11:23,283 INFO     Weight matrix 1/1 (256,1024): Alpha 5.102814093147542 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:11:23,286 INFO     Weight matrix 1/1 (256,1024): Lognorm: 1.0043326616287231\n",
      "2018-11-26 13:11:23,289 INFO Layer 115: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:23,291 INFO Layer 115: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:23,294 INFO Layer 116: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:11:23,300 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:11:23,304 INFO Layer 116: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:11:23,307 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:25,856 INFO     Weight matrix 1/9 (256,256): Alpha: 2.341765624246443, Alpha Weighted: -0.32515988786253236, D: 0.09857809360088676\n",
      "2018-11-26 13:11:25,860 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.5731755495071411\n",
      "2018-11-26 13:11:25,864 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:29,138 INFO     Weight matrix 2/9 (256,256): Alpha: 2.955582115219535, Alpha Weighted: -0.5727376056188739, D: 0.1387186177978817\n",
      "2018-11-26 13:11:29,144 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6026630401611328\n",
      "2018-11-26 13:11:29,149 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:32,872 INFO     Weight matrix 3/9 (256,256): Alpha: 2.750961280917238, Alpha Weighted: -0.3466641691139136, D: 0.09220087689192236\n",
      "2018-11-26 13:11:32,878 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.5806841254234314\n",
      "2018-11-26 13:11:32,882 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:36,919 INFO     Weight matrix 4/9 (256,256): Alpha: 2.9205941598274348, Alpha Weighted: -0.8246663288951894, D: 0.08842847859812286\n",
      "2018-11-26 13:11:36,924 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5409337878227234\n",
      "2018-11-26 13:11:36,931 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:40,946 INFO     Weight matrix 5/9 (256,256): Alpha: 2.6927257519343315, Alpha Weighted: -0.17399656349653406, D: 0.14074097422608034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:11:40,952 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.6547537446022034\n",
      "2018-11-26 13:11:40,955 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:44,219 INFO     Weight matrix 6/9 (256,256): Alpha: 3.247070025125432, Alpha Weighted: -0.8750000761701199, D: 0.09692962531129584\n",
      "2018-11-26 13:11:44,225 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.555638313293457\n",
      "2018-11-26 13:11:44,228 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:47,247 INFO     Weight matrix 7/9 (256,256): Alpha: 2.538155482080193, Alpha Weighted: -0.359228302642005, D: 0.10646626222052413\n",
      "2018-11-26 13:11:47,251 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.5808740258216858\n",
      "2018-11-26 13:11:47,257 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:50,630 INFO     Weight matrix 8/9 (256,256): Alpha: 2.770637260101269, Alpha Weighted: -0.5749646483369935, D: 0.1554687313132438\n",
      "2018-11-26 13:11:50,636 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6211288571357727\n",
      "2018-11-26 13:11:50,639 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:11:53,100 INFO     Weight matrix 9/9 (256,256): Alpha: 2.5256459469777655, Alpha Weighted: -0.34823293312479936, D: 0.11005952933254176\n",
      "2018-11-26 13:11:53,104 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.5961933732032776\n",
      "2018-11-26 13:11:53,107 INFO Layer 117: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:53,110 INFO Layer 117: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:53,113 INFO Layer 118: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:11:53,117 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:11:53,119 INFO Layer 118: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:11:53,121 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:11:55,791 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.7967673074038806, Alpha Weighted: 2.636492691177208, D: 0.0483598158710703\n",
      "2018-11-26 13:11:55,794 INFO     Weight matrix 1/1 (256,1024): Alpha 3.7967673074038806 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:11:55,800 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.9964689016342163\n",
      "2018-11-26 13:11:55,803 INFO Layer 119: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:55,805 INFO Layer 119: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:55,808 INFO Layer 120: ReLU(inplace)\n",
      "2018-11-26 13:11:55,816 INFO Layer 120: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:55,820 INFO Layer 121: Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:11:55,827 INFO Layer 121: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:55,833 INFO Layer 122: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:11:55,836 INFO Layer 122: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:55,841 INFO Layer 123: Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:11:55,847 INFO Pytorch tensor shape detected: 512x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:11:55,850 INFO Layer 123: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:11:55,855 INFO     Weight matrix 1/1 (512,1024): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:55,857 INFO Layer 124: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:55,860 INFO Layer 124: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:55,863 INFO Layer 125: Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:11:55,913 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:11:55,916 INFO Layer 125: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:11:55,919 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:55,923 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:55,927 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:55,931 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:55,935 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:55,937 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:55,941 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:55,947 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:55,951 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:55,953 INFO Layer 126: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:55,956 INFO Layer 126: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:55,958 INFO Layer 127: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:11:55,984 INFO Pytorch tensor shape detected: 2048x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:11:55,987 INFO Layer 127: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:11:55,990 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:55,992 INFO Layer 128: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:55,994 INFO Layer 128: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:55,997 INFO Layer 129: ReLU(inplace)\n",
      "2018-11-26 13:11:56,000 INFO Layer 129: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:56,002 INFO Layer 130: Sequential(\n",
      "  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:11:56,004 INFO Layer 130: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:56,008 INFO Layer 131: Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 13:11:56,027 INFO Pytorch tensor shape detected: 2048x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:11:56,029 INFO Layer 131: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:11:56,032 INFO     Weight matrix 1/1 (1024,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,035 INFO Layer 132: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:56,039 INFO Layer 132: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:56,042 INFO Layer 133: Bottleneck(\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:11:56,044 INFO Layer 133: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:56,047 INFO Layer 134: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:11:56,065 INFO Pytorch tensor shape detected: 512x2048 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:11:56,067 INFO Layer 134: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:11:56,070 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,073 INFO Layer 135: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:56,076 INFO Layer 135: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:56,079 INFO Layer 136: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:11:56,104 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:11:56,106 INFO Layer 136: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:11:56,109 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,111 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,118 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,121 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,124 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,126 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,129 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,132 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,135 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,137 INFO Layer 137: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:56,139 INFO Layer 137: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:56,142 INFO Layer 138: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:11:56,156 INFO Pytorch tensor shape detected: 2048x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:11:56,159 INFO Layer 138: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:11:56,163 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,166 INFO Layer 139: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:56,170 INFO Layer 139: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:56,173 INFO Layer 140: ReLU(inplace)\n",
      "2018-11-26 13:11:56,176 INFO Layer 140: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:56,180 INFO Layer 141: Bottleneck(\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:11:56,183 INFO Layer 141: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:56,186 INFO Layer 142: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:11:56,256 INFO Pytorch tensor shape detected: 512x2048 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:11:56,268 INFO Layer 142: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:11:56,276 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,282 INFO Layer 143: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:56,285 INFO Layer 143: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:56,287 INFO Layer 144: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:11:56,312 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:11:56,317 INFO Layer 144: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:11:56,319 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,323 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,327 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,331 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,334 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,336 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,339 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,342 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,344 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,346 INFO Layer 145: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:56,355 INFO Layer 145: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:56,365 INFO Layer 146: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:11:56,380 INFO Pytorch tensor shape detected: 2048x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:11:56,383 INFO Layer 146: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:11:56,386 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,391 INFO Layer 147: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:11:56,394 INFO Layer 147: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:56,402 INFO Layer 148: ReLU(inplace)\n",
      "2018-11-26 13:11:56,406 INFO Layer 148: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:56,409 INFO Layer 149: AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "2018-11-26 13:11:56,413 INFO Layer 149: Skipping (Layer not supported)\n",
      "2018-11-26 13:11:56,416 INFO Layer 150: Linear(in_features=2048, out_features=1000, bias=True)\n",
      "2018-11-26 13:11:56,439 INFO Layer 150: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:11:56,443 INFO     Weight matrix 1/1 (1000,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:11:56,446 INFO ### Printing results ###\n",
      "2018-11-26 13:11:56,448 DEBUG Layer 7: Lognorm: 0.6571754217147827\n",
      "2018-11-26 13:11:56,454 DEBUG Layer 9: Lognorm compound: 0.24690835260682636\n",
      "2018-11-26 13:11:56,461 DEBUG Layer 11: Lognorm: 0.6545941829681396\n",
      "2018-11-26 13:11:56,466 DEBUG Layer 15: Lognorm: 0.8676601648330688\n",
      "2018-11-26 13:11:56,470 DEBUG Layer 18: Lognorm: 0.593684196472168\n",
      "2018-11-26 13:11:56,477 DEBUG Layer 20: Lognorm compound: 0.24544101456801096\n",
      "2018-11-26 13:11:56,483 DEBUG Layer 22: Lognorm: 0.6196277141571045\n",
      "2018-11-26 13:11:56,488 DEBUG Layer 26: Lognorm: 0.5854821801185608\n",
      "2018-11-26 13:11:56,490 DEBUG Layer 28: Lognorm compound: 0.2956855429543389\n",
      "2018-11-26 13:11:56,493 DEBUG Layer 30: Lognorm: 0.6012221574783325\n",
      "2018-11-26 13:11:56,496 DEBUG Layer 35: Lognorm: 0.8073619604110718\n",
      "2018-11-26 13:11:56,503 DEBUG Layer 37: Lognorm compound: 0.45159852504730225\n",
      "2018-11-26 13:11:56,507 DEBUG Layer 39: Lognorm: 0.856681764125824\n",
      "2018-11-26 13:11:56,510 DEBUG Layer 43: Lognorm: 0.9226973056793213\n",
      "2018-11-26 13:11:56,514 DEBUG Layer 46: Lognorm: 0.6298876404762268\n",
      "2018-11-26 13:11:56,518 DEBUG Layer 48: Lognorm compound: 0.38037408888339996\n",
      "2018-11-26 13:11:56,522 DEBUG Layer 50: Lognorm: 0.7524837255477905\n",
      "2018-11-26 13:11:56,527 DEBUG Layer 54: Lognorm: 0.7761330008506775\n",
      "2018-11-26 13:11:56,530 DEBUG Layer 56: Lognorm compound: 0.43562548690372044\n",
      "2018-11-26 13:11:56,533 DEBUG Layer 58: Lognorm: 0.8261816501617432\n",
      "2018-11-26 13:11:56,538 DEBUG Layer 62: Lognorm: 0.7945184111595154\n",
      "2018-11-26 13:11:56,542 DEBUG Layer 64: Lognorm compound: 0.45236237512694466\n",
      "2018-11-26 13:11:56,545 DEBUG Layer 66: Lognorm: 0.7946745753288269\n",
      "2018-11-26 13:11:56,547 DEBUG Layer 71: Lognorm: 1.0471938848495483\n",
      "2018-11-26 13:11:56,550 DEBUG Layer 73: Lognorm compound: 0.6414758563041687\n",
      "2018-11-26 13:11:56,558 DEBUG Layer 75: Lognorm: 1.078093409538269\n",
      "2018-11-26 13:11:56,566 DEBUG Layer 82: Lognorm: 0.8917931318283081\n",
      "2018-11-26 13:11:56,571 DEBUG Layer 84: Lognorm compound: 0.5853137705061171\n",
      "2018-11-26 13:11:56,575 DEBUG Layer 86: Lognorm: 1.0185887813568115\n",
      "2018-11-26 13:11:56,579 DEBUG Layer 90: Lognorm: 0.9067794680595398\n",
      "2018-11-26 13:11:56,581 DEBUG Layer 92: Lognorm compound: 0.5839926070637174\n",
      "2018-11-26 13:11:56,584 DEBUG Layer 94: Lognorm: 0.9901520013809204\n",
      "2018-11-26 13:11:56,587 DEBUG Layer 98: Lognorm: 0.9488285183906555\n",
      "2018-11-26 13:11:56,589 DEBUG Layer 100: Lognorm compound: 0.5822420914967855\n",
      "2018-11-26 13:11:56,598 DEBUG Layer 102: Lognorm: 0.9704855680465698\n",
      "2018-11-26 13:11:56,601 DEBUG Layer 106: Lognorm: 0.9678803086280823\n",
      "2018-11-26 13:11:56,605 DEBUG Layer 108: Lognorm compound: 0.5807004902097914\n",
      "2018-11-26 13:11:56,609 DEBUG Layer 110: Lognorm: 0.9698952436447144\n",
      "2018-11-26 13:11:56,613 DEBUG Layer 114: Lognorm: 1.0043326616287231\n",
      "2018-11-26 13:11:56,616 DEBUG Layer 116: Lognorm compound: 0.5895605352189806\n",
      "2018-11-26 13:11:56,622 DEBUG Layer 118: Lognorm: 0.9964689016342163\n",
      "2018-11-26 13:11:56,627 INFO LogNorm: min: 0.1128871813416481, max: 1.078093409538269, avg: 0.5391178131103516\n",
      "2018-11-26 13:11:56,632 INFO LogNorm compound: min: 0.24544101456801096, max: 1.078093409538269, avg: 0.7219960650575517\n",
      "2018-11-26 13:11:56,636 DEBUG Layer 7: Alpha: 10.446010528952465\n",
      "2018-11-26 13:11:56,639 DEBUG Layer 9: Alpha compound: 1.9590663987336727\n",
      "2018-11-26 13:11:56,642 DEBUG Layer 11: Alpha: 3.7837070383280946\n",
      "2018-11-26 13:11:56,647 DEBUG Layer 15: Alpha: 3.2753482641674876\n",
      "2018-11-26 13:11:56,649 DEBUG Layer 18: Alpha: 5.157142466567017\n",
      "2018-11-26 13:11:56,653 DEBUG Layer 20: Alpha compound: 2.043297251905831\n",
      "2018-11-26 13:11:56,658 DEBUG Layer 22: Alpha: 6.066928198524358\n",
      "2018-11-26 13:11:56,661 DEBUG Layer 26: Alpha: 1.778434394499036\n",
      "2018-11-26 13:11:56,664 DEBUG Layer 28: Alpha compound: 1.7795750120243978\n",
      "2018-11-26 13:11:56,666 DEBUG Layer 30: Alpha: 7.0701668469902685\n",
      "2018-11-26 13:11:56,668 DEBUG Layer 35: Alpha: 5.618319957177584\n",
      "2018-11-26 13:11:56,671 DEBUG Layer 37: Alpha compound: 2.2629000107496635\n",
      "2018-11-26 13:11:56,673 DEBUG Layer 39: Alpha: 4.894880010137086\n",
      "2018-11-26 13:11:56,676 DEBUG Layer 43: Alpha: 1.6427641443311631\n",
      "2018-11-26 13:11:56,678 DEBUG Layer 46: Alpha: 1.6051311913613768\n",
      "2018-11-26 13:11:56,680 DEBUG Layer 48: Alpha compound: 1.5473492839998206\n",
      "2018-11-26 13:11:56,683 DEBUG Layer 50: Alpha: 7.039391081203674\n",
      "2018-11-26 13:11:56,686 DEBUG Layer 54: Alpha: 2.473860645627811\n",
      "2018-11-26 13:11:56,689 DEBUG Layer 56: Alpha compound: 2.1016372250941533\n",
      "2018-11-26 13:11:56,693 DEBUG Layer 58: Alpha: 3.506324243452527\n",
      "2018-11-26 13:11:56,698 DEBUG Layer 62: Alpha: 2.9831575911726214\n",
      "2018-11-26 13:11:56,702 DEBUG Layer 64: Alpha compound: 1.8558997669674246\n",
      "2018-11-26 13:11:56,704 DEBUG Layer 66: Alpha: 2.894874270304915\n",
      "2018-11-26 13:11:56,710 DEBUG Layer 71: Alpha: 5.3033910840181955\n",
      "2018-11-26 13:11:56,714 DEBUG Layer 73: Alpha compound: 4.144443530877285\n",
      "2018-11-26 13:11:56,718 DEBUG Layer 75: Alpha: 7.209589014526275\n",
      "2018-11-26 13:11:56,721 DEBUG Layer 82: Alpha: 4.990364884146791\n",
      "2018-11-26 13:11:56,725 DEBUG Layer 84: Alpha compound: 1.8655932085176008\n",
      "2018-11-26 13:11:56,732 DEBUG Layer 86: Alpha: 3.812705101358966\n",
      "2018-11-26 13:11:56,735 DEBUG Layer 90: Alpha: 1.7291630029001805\n",
      "2018-11-26 13:11:56,737 DEBUG Layer 92: Alpha compound: 1.8744571520878257\n",
      "2018-11-26 13:11:56,740 DEBUG Layer 94: Alpha: 5.963596169117725\n",
      "2018-11-26 13:11:56,742 DEBUG Layer 98: Alpha: 3.212507921142585\n",
      "2018-11-26 13:11:56,745 DEBUG Layer 100: Alpha compound: 2.419082213757665\n",
      "2018-11-26 13:11:56,750 DEBUG Layer 102: Alpha: 4.331017634959009\n",
      "2018-11-26 13:11:56,752 DEBUG Layer 106: Alpha: 10.27677547542684\n",
      "2018-11-26 13:11:56,759 DEBUG Layer 108: Alpha compound: 2.439714680652032\n",
      "2018-11-26 13:11:56,761 DEBUG Layer 110: Alpha: 4.657101129212204\n",
      "2018-11-26 13:11:56,766 DEBUG Layer 114: Alpha: 5.102814093147542\n",
      "2018-11-26 13:11:56,775 DEBUG Layer 116: Alpha compound: 2.74923751626996\n",
      "2018-11-26 13:11:56,781 DEBUG Layer 118: Alpha: 3.7967673074038806\n",
      "2018-11-26 13:11:56,785 INFO Alpha: min: 1.4104423307007656, max: 10.446010528952465, avg: 2.7034656065854734\n",
      "2018-11-26 13:11:56,789 INFO Alpha compound: min: 1.5473492839998206, max: 10.446010528952465, avg: 3.894255779068171\n",
      "2018-11-26 13:11:56,793 DEBUG Layer 7: Alpha Weigthed: 2.956207824751127\n",
      "2018-11-26 13:11:56,795 DEBUG Layer 9: Alpha Weighted compound: -0.07724538357725776\n",
      "2018-11-26 13:11:56,799 DEBUG Layer 11: Alpha Weigthed: 1.995679611445936\n",
      "2018-11-26 13:11:56,806 DEBUG Layer 15: Alpha Weigthed: 2.41984151376588\n",
      "2018-11-26 13:11:56,809 DEBUG Layer 18: Alpha Weigthed: 0.9424509641742017\n",
      "2018-11-26 13:11:56,811 DEBUG Layer 20: Alpha Weighted compound: -0.7101020201433946\n",
      "2018-11-26 13:11:56,815 DEBUG Layer 22: Alpha Weigthed: 0.8830111902366142\n",
      "2018-11-26 13:11:56,827 DEBUG Layer 26: Alpha Weigthed: 0.286697964557169\n",
      "2018-11-26 13:11:56,832 DEBUG Layer 28: Alpha Weighted compound: -0.44801595163073543\n",
      "2018-11-26 13:11:56,836 DEBUG Layer 30: Alpha Weigthed: 0.04334644477657957\n",
      "2018-11-26 13:11:56,839 DEBUG Layer 35: Alpha Weigthed: 2.4762422214765127\n",
      "2018-11-26 13:11:56,843 DEBUG Layer 37: Alpha Weighted compound: -0.4271340771939565\n",
      "2018-11-26 13:11:56,845 DEBUG Layer 39: Alpha Weigthed: 1.2696346229573083\n",
      "2018-11-26 13:11:56,848 DEBUG Layer 43: Alpha Weigthed: 1.2899124078568749\n",
      "2018-11-26 13:11:56,851 DEBUG Layer 46: Alpha Weigthed: 0.6235918972714211\n",
      "2018-11-26 13:11:56,858 DEBUG Layer 48: Alpha Weighted compound: 0.09737359996924357\n",
      "2018-11-26 13:11:56,861 DEBUG Layer 50: Alpha Weigthed: 2.2407076834663644\n",
      "2018-11-26 13:11:56,865 DEBUG Layer 54: Alpha Weigthed: 0.8337626569624386\n",
      "2018-11-26 13:11:56,869 DEBUG Layer 56: Alpha Weighted compound: -0.281167253644145\n",
      "2018-11-26 13:11:56,872 DEBUG Layer 58: Alpha Weigthed: 0.7073591011728771\n",
      "2018-11-26 13:11:56,875 DEBUG Layer 62: Alpha Weigthed: 0.9817868067504645\n",
      "2018-11-26 13:11:56,878 DEBUG Layer 64: Alpha Weighted compound: -0.35904922687824153\n",
      "2018-11-26 13:11:56,881 DEBUG Layer 66: Alpha Weigthed: 0.5835067915251431\n",
      "2018-11-26 13:11:56,885 DEBUG Layer 71: Alpha Weigthed: 3.168497505641687\n",
      "2018-11-26 13:11:56,888 DEBUG Layer 73: Alpha Weighted compound: -0.913066213049202\n",
      "2018-11-26 13:11:56,891 DEBUG Layer 75: Alpha Weigthed: 3.7302548673572087\n",
      "2018-11-26 13:11:56,894 DEBUG Layer 82: Alpha Weigthed: 1.0734212664470093\n",
      "2018-11-26 13:11:56,896 DEBUG Layer 84: Alpha Weighted compound: -0.036729101665605585\n",
      "2018-11-26 13:11:56,899 DEBUG Layer 86: Alpha Weigthed: 2.0115988553429838\n",
      "2018-11-26 13:11:56,905 DEBUG Layer 90: Alpha Weigthed: 0.4947299744274746\n",
      "2018-11-26 13:11:56,907 DEBUG Layer 92: Alpha Weighted compound: -0.09512478425826802\n",
      "2018-11-26 13:11:56,910 DEBUG Layer 94: Alpha Weigthed: 2.011770001550082\n",
      "2018-11-26 13:11:56,912 DEBUG Layer 98: Alpha Weigthed: 0.926432024288254\n",
      "2018-11-26 13:11:56,915 DEBUG Layer 100: Alpha Weighted compound: -0.3183681654665545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:11:56,917 DEBUG Layer 102: Alpha Weigthed: 1.7183579784911742\n",
      "2018-11-26 13:11:56,920 DEBUG Layer 106: Alpha Weigthed: 3.0588651655782164\n",
      "2018-11-26 13:11:56,923 DEBUG Layer 108: Alpha Weighted compound: -0.37253099444778737\n",
      "2018-11-26 13:11:56,927 DEBUG Layer 110: Alpha Weigthed: 2.3134609129061694\n",
      "2018-11-26 13:11:56,933 DEBUG Layer 114: Alpha Weigthed: 1.8843543152667732\n",
      "2018-11-26 13:11:56,935 DEBUG Layer 116: Alpha Weighted compound: -0.48896116836232895\n",
      "2018-11-26 13:11:56,938 DEBUG Layer 118: Alpha Weigthed: 2.636492691177208\n",
      "2018-11-26 13:11:56,942 INFO Alpha Weighted: min: -1.620542512978525, max: 3.7302548673572087, avg: 0.03924750757577274\n",
      "2018-11-26 13:11:56,945 INFO Alpha Weighted compound: min: -0.913066213049202, max: 3.7302548673572087, avg: 1.003215963933486\n",
      "2018-11-26 13:12:02,735 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 13:12:02,738 INFO Analyzing model\n",
      "2018-11-26 13:12:02,752 INFO Layer 0: ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:12:02,755 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:02,762 INFO Layer 1: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "2018-11-26 13:12:02,764 INFO Pytorch tensor shape detected: 64x3 (NxM), 7x7 (i,j)\n",
      "2018-11-26 13:12:02,767 INFO Layer 1: Analyzing 49 weight matrices...\n",
      "2018-11-26 13:12:02,770 INFO     Weight matrix 1/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,773 INFO     Weight matrix 2/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,775 INFO     Weight matrix 3/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,779 INFO     Weight matrix 4/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,782 INFO     Weight matrix 5/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,785 INFO     Weight matrix 6/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,789 INFO     Weight matrix 7/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,793 INFO     Weight matrix 8/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,796 INFO     Weight matrix 9/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,798 INFO     Weight matrix 10/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,802 INFO     Weight matrix 11/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,804 INFO     Weight matrix 12/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,808 INFO     Weight matrix 13/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,812 INFO     Weight matrix 14/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,815 INFO     Weight matrix 15/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,819 INFO     Weight matrix 16/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,822 INFO     Weight matrix 17/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,825 INFO     Weight matrix 18/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,828 INFO     Weight matrix 19/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,831 INFO     Weight matrix 20/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,833 INFO     Weight matrix 21/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,836 INFO     Weight matrix 22/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,839 INFO     Weight matrix 23/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,841 INFO     Weight matrix 24/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,844 INFO     Weight matrix 25/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,847 INFO     Weight matrix 26/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,849 INFO     Weight matrix 27/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,851 INFO     Weight matrix 28/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,859 INFO     Weight matrix 29/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,861 INFO     Weight matrix 30/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,864 INFO     Weight matrix 31/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,867 INFO     Weight matrix 32/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,871 INFO     Weight matrix 33/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,874 INFO     Weight matrix 34/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,877 INFO     Weight matrix 35/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,879 INFO     Weight matrix 36/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,882 INFO     Weight matrix 37/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,885 INFO     Weight matrix 38/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,888 INFO     Weight matrix 39/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,891 INFO     Weight matrix 40/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,894 INFO     Weight matrix 41/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,896 INFO     Weight matrix 42/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,899 INFO     Weight matrix 43/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,901 INFO     Weight matrix 44/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,904 INFO     Weight matrix 45/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,907 INFO     Weight matrix 46/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,909 INFO     Weight matrix 47/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,912 INFO     Weight matrix 48/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,914 INFO     Weight matrix 49/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:12:02,917 INFO Layer 2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:02,919 INFO Layer 2: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:02,921 INFO Layer 3: ReLU(inplace)\n",
      "2018-11-26 13:12:02,923 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:02,927 INFO Layer 4: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "2018-11-26 13:12:02,932 INFO Layer 4: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:02,937 INFO Layer 5: Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:12:02,941 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:02,943 INFO Layer 6: Bottleneck(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:12:02,947 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:02,949 INFO Layer 7: Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:12:02,952 INFO Pytorch tensor shape detected: 64x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:02,954 INFO Layer 7: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:02,957 INFO     Weight matrix 1/1 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:03,543 INFO     Weight matrix 1/1 (64,64): Alpha: 1.2888696680201484, Alpha Weighted: 0.477747766282832, D: 0.27223680898371977\n",
      "2018-11-26 13:12:03,545 INFO     Weight matrix 1/1 (64,64): Alpha 1.2888696680201484 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:03,549 INFO     Weight matrix 1/1 (64,64): Lognorm: 0.6557127833366394\n",
      "2018-11-26 13:12:03,552 INFO Layer 8: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:03,554 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:03,557 INFO Layer 9: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:12:03,561 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:12:03,564 INFO Layer 9: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:12:03,567 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:04,220 INFO     Weight matrix 1/9 (64,64): Alpha: 1.9746386462534764, Alpha Weighted: -0.965547202649823, D: 0.1268848997832206\n",
      "2018-11-26 13:12:04,223 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.04454262554645538\n",
      "2018-11-26 13:12:04,226 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:04,678 INFO     Weight matrix 2/9 (64,64): Alpha: 2.843749524909651, Alpha Weighted: -0.8913681433558807, D: 0.14449139459938026\n",
      "2018-11-26 13:12:04,681 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.1330978274345398\n",
      "2018-11-26 13:12:04,686 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:05,117 INFO     Weight matrix 3/9 (64,64): Alpha: 2.8412591210459293, Alpha Weighted: -1.2137116058827944, D: 0.1111111111111115\n",
      "2018-11-26 13:12:05,120 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.08114084601402283\n",
      "2018-11-26 13:12:05,123 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:05,555 INFO     Weight matrix 4/9 (64,64): Alpha: 2.884026257108001, Alpha Weighted: -1.112096513355153, D: 0.10000000000000031\n",
      "2018-11-26 13:12:05,558 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.12735946476459503\n",
      "2018-11-26 13:12:05,560 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:05,976 INFO     Weight matrix 5/9 (64,64): Alpha: 1.4480630275941382, Alpha Weighted: 0.1741740532005307, D: 0.1772330405615637\n",
      "2018-11-26 13:12:05,978 INFO     Weight matrix 5/9 (64,64): Alpha 1.4480630275941382 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:05,982 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.3987429738044739\n",
      "2018-11-26 13:12:05,984 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:06,397 INFO     Weight matrix 6/9 (64,64): Alpha: 2.344929137404743, Alpha Weighted: -0.24208607726191847, D: 0.19565282659493144\n",
      "2018-11-26 13:12:06,402 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.25322893261909485\n",
      "2018-11-26 13:12:06,405 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:06,818 INFO     Weight matrix 7/9 (64,64): Alpha: 2.6901829346126043, Alpha Weighted: -1.2369816436244798, D: 0.1327246520181251\n",
      "2018-11-26 13:12:06,822 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.07833591103553772\n",
      "2018-11-26 13:12:06,825 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:07,260 INFO     Weight matrix 8/9 (64,64): Alpha: 2.2026598741298615, Alpha Weighted: -0.15087589347816338, D: 0.1754241491699733\n",
      "2018-11-26 13:12:07,264 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.2587515115737915\n",
      "2018-11-26 13:12:07,268 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:07,795 INFO     Weight matrix 9/9 (64,64): Alpha: 3.1471619453373565, Alpha Weighted: -0.8737106523784166, D: 0.14285714285714324\n",
      "2018-11-26 13:12:07,800 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.15796321630477905\n",
      "2018-11-26 13:12:07,808 INFO Layer 10: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:07,810 INFO Layer 10: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:07,815 INFO Layer 11: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:12:07,820 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:07,825 INFO Layer 11: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:07,828 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:12:08,351 INFO     Weight matrix 1/1 (64,256): Alpha: 4.442632730677695, Alpha Weighted: 1.7082882617362385, D: 0.12101124428271237\n",
      "2018-11-26 13:12:08,353 INFO     Weight matrix 1/1 (64,256): Alpha 4.442632730677695 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:08,356 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.5727798342704773\n",
      "2018-11-26 13:12:08,359 INFO Layer 12: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:08,364 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:08,369 INFO Layer 13: ReLU(inplace)\n",
      "2018-11-26 13:12:08,374 INFO Layer 13: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:08,378 INFO Layer 14: Sequential(\n",
      "  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:12:08,382 INFO Layer 14: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:08,384 INFO Layer 15: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:12:08,387 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:08,390 INFO Layer 15: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:08,393 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:12:08,867 INFO     Weight matrix 1/1 (64,256): Alpha: 2.4133015443368366, Alpha Weighted: 1.747382162108019, D: 0.1645866136530476\n",
      "2018-11-26 13:12:08,870 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.8214689493179321\n",
      "2018-11-26 13:12:08,872 INFO Layer 16: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:08,875 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:08,879 INFO Layer 17: Bottleneck(\n",
      "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:12:08,882 INFO Layer 17: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:08,884 INFO Layer 18: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:12:08,888 INFO Pytorch tensor shape detected: 64x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:08,891 INFO Layer 18: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:08,893 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:12:09,377 INFO     Weight matrix 1/1 (64,256): Alpha: 2.4758786406149396, Alpha Weighted: 0.08921024720279805, D: 0.14312904135944704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:12:09,380 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.3141155540943146\n",
      "2018-11-26 13:12:09,383 INFO Layer 19: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:09,385 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:09,388 INFO Layer 20: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:12:09,392 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:12:09,394 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:12:09,397 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:09,855 INFO     Weight matrix 1/9 (64,64): Alpha: 1.9731724470978482, Alpha Weighted: -2.0921180365843397, D: 0.18691520672413664\n",
      "2018-11-26 13:12:09,858 INFO     Weight matrix 1/9 (64,64): Lognorm: -0.23450779914855957\n",
      "2018-11-26 13:12:09,861 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:10,254 INFO     Weight matrix 2/9 (64,64): Alpha: 1.656067520146054, Alpha Weighted: -0.7088583009501107, D: 0.14005544412903392\n",
      "2018-11-26 13:12:10,258 INFO     Weight matrix 2/9 (64,64): Lognorm: -0.06069374829530716\n",
      "2018-11-26 13:12:10,264 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:10,704 INFO     Weight matrix 3/9 (64,64): Alpha: 1.8379840694464105, Alpha Weighted: -1.7777047305809093, D: 0.1838597595584931\n",
      "2018-11-26 13:12:10,707 INFO     Weight matrix 3/9 (64,64): Lognorm: -0.20217445492744446\n",
      "2018-11-26 13:12:10,711 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:11,117 INFO     Weight matrix 4/9 (64,64): Alpha: 1.799005586621547, Alpha Weighted: -0.7717536489227083, D: 0.14857062302277146\n",
      "2018-11-26 13:12:11,120 INFO     Weight matrix 4/9 (64,64): Lognorm: -0.0695783942937851\n",
      "2018-11-26 13:12:11,122 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:11,456 INFO     Weight matrix 5/9 (64,64): Alpha: 1.6456293131701016, Alpha Weighted: 0.26054521998611074, D: 0.12119301375125568\n",
      "2018-11-26 13:12:11,459 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.15562359988689423\n",
      "2018-11-26 13:12:11,462 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:11,843 INFO     Weight matrix 6/9 (64,64): Alpha: 1.6816246509883013, Alpha Weighted: -0.5392677404812497, D: 0.12400724740520164\n",
      "2018-11-26 13:12:11,846 INFO     Weight matrix 6/9 (64,64): Lognorm: -0.031897932291030884\n",
      "2018-11-26 13:12:11,849 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:12,319 INFO     Weight matrix 7/9 (64,64): Alpha: 1.6478664337159044, Alpha Weighted: -1.5279984382089271, D: 0.19454222978078772\n",
      "2018-11-26 13:12:12,321 INFO     Weight matrix 7/9 (64,64): Lognorm: -0.20605871081352234\n",
      "2018-11-26 13:12:12,324 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:12,683 INFO     Weight matrix 8/9 (64,64): Alpha: 1.9316185903056002, Alpha Weighted: -0.6456640135488909, D: 0.14203325733899952\n",
      "2018-11-26 13:12:12,686 INFO     Weight matrix 8/9 (64,64): Lognorm: -0.019575834274291992\n",
      "2018-11-26 13:12:12,688 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:13,105 INFO     Weight matrix 9/9 (64,64): Alpha: 1.917203573631521, Alpha Weighted: -1.3359074376734068, D: 0.17616091523422459\n",
      "2018-11-26 13:12:13,109 INFO     Weight matrix 9/9 (64,64): Lognorm: -0.12676817178726196\n",
      "2018-11-26 13:12:13,112 INFO Layer 21: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:13,115 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:13,119 INFO Layer 22: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:12:13,123 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:13,126 INFO Layer 22: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:13,130 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:12:13,608 INFO     Weight matrix 1/1 (64,256): Alpha: 3.8788626492752525, Alpha Weighted: -0.8022207519727896, D: 0.20917412214890885\n",
      "2018-11-26 13:12:13,610 INFO     Weight matrix 1/1 (64,256): Alpha 3.8788626492752525 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:13,613 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.2727549970149994\n",
      "2018-11-26 13:12:13,616 INFO Layer 23: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:13,619 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:13,622 INFO Layer 24: ReLU(inplace)\n",
      "2018-11-26 13:12:13,625 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:13,628 INFO Layer 25: Bottleneck(\n",
      "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:12:13,631 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:13,633 INFO Layer 26: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:12:13,637 INFO Pytorch tensor shape detected: 64x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:13,641 INFO Layer 26: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:13,644 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:12:14,184 INFO     Weight matrix 1/1 (64,256): Alpha: 1.55704907575113, Alpha Weighted: 0.06343303388614573, D: 0.1787022482790629\n",
      "2018-11-26 13:12:14,188 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.5081485509872437\n",
      "2018-11-26 13:12:14,190 INFO Layer 27: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:14,193 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:14,197 INFO Layer 28: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:12:14,201 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:12:14,204 INFO Layer 28: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:12:14,208 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:14,684 INFO     Weight matrix 1/9 (64,64): Alpha: 1.9531965975809131, Alpha Weighted: -1.3020141021731497, D: 0.19187920385189\n",
      "2018-11-26 13:12:14,687 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.08880262076854706\n",
      "2018-11-26 13:12:14,690 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:15,139 INFO     Weight matrix 2/9 (64,64): Alpha: 1.8163218977246343, Alpha Weighted: -0.41008955555150794, D: 0.14985498257626034\n",
      "2018-11-26 13:12:15,142 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.21688176691532135\n",
      "2018-11-26 13:12:15,145 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:15,576 INFO     Weight matrix 3/9 (64,64): Alpha: 2.3020062477895062, Alpha Weighted: -1.3169626436905344, D: 0.18018934828162636\n",
      "2018-11-26 13:12:15,582 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.09902031719684601\n",
      "2018-11-26 13:12:15,586 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:16,054 INFO     Weight matrix 4/9 (64,64): Alpha: 1.6474426369256736, Alpha Weighted: -0.3829517861981218, D: 0.16152573358462113\n",
      "2018-11-26 13:12:16,057 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.2014198899269104\n",
      "2018-11-26 13:12:16,062 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:16,487 INFO     Weight matrix 5/9 (64,64): Alpha: 1.4181833401215165, Alpha Weighted: 0.009495672563287766, D: 0.178549646336488\n",
      "2018-11-26 13:12:16,490 INFO     Weight matrix 5/9 (64,64): Alpha 1.4181833401215165 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:16,493 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.36791419982910156\n",
      "2018-11-26 13:12:16,496 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:16,985 INFO     Weight matrix 6/9 (64,64): Alpha: 1.808853583711949, Alpha Weighted: -0.2677147812525893, D: 0.13460279551928162\n",
      "2018-11-26 13:12:16,988 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.23650464415550232\n",
      "2018-11-26 13:12:16,991 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:12:17,492 INFO     Weight matrix 7/9 (64,64): Alpha: 1.9699906937610976, Alpha Weighted: -1.141823820714726, D: 0.17475060004518017\n",
      "2018-11-26 13:12:17,496 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.10143450647592545\n",
      "2018-11-26 13:12:17,499 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:17,999 INFO     Weight matrix 8/9 (64,64): Alpha: 1.9946590917329172, Alpha Weighted: -0.3372561946092345, D: 0.1492458160992769\n",
      "2018-11-26 13:12:18,002 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.23234663903713226\n",
      "2018-11-26 13:12:18,005 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:12:18,569 INFO     Weight matrix 9/9 (64,64): Alpha: 2.049920983052137, Alpha Weighted: -0.9242219242724863, D: 0.1562221286672691\n",
      "2018-11-26 13:12:18,572 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.1494244486093521\n",
      "2018-11-26 13:12:18,578 INFO Layer 29: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:18,582 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:18,585 INFO Layer 30: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:12:18,588 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:18,591 INFO Layer 30: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:18,594 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:12:19,119 INFO     Weight matrix 1/1 (64,256): Alpha: 3.6547114006665007, Alpha Weighted: -0.5057894692948892, D: 0.2000365415288039\n",
      "2018-11-26 13:12:19,124 INFO     Weight matrix 1/1 (64,256): Alpha 3.6547114006665007 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:19,128 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.44833919405937195\n",
      "2018-11-26 13:12:19,131 INFO Layer 31: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:19,135 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:19,138 INFO Layer 32: ReLU(inplace)\n",
      "2018-11-26 13:12:19,141 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:19,146 INFO Layer 33: Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:12:19,149 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:19,159 INFO Layer 34: Bottleneck(\n",
      "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:12:19,162 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:19,165 INFO Layer 35: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:12:19,173 INFO Pytorch tensor shape detected: 128x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:19,176 INFO Layer 35: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:19,179 INFO     Weight matrix 1/1 (128,256): Analyzing ...\n",
      "2018-11-26 13:12:20,708 INFO     Weight matrix 1/1 (128,256): Alpha: 1.5633365534806956, Alpha Weighted: 0.5707473800763022, D: 0.14702345712099696\n",
      "2018-11-26 13:12:20,711 INFO     Weight matrix 1/1 (128,256): Lognorm: 0.6902310252189636\n",
      "2018-11-26 13:12:20,715 INFO Layer 36: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:20,720 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:20,724 INFO Layer 37: Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:12:20,735 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:12:20,741 INFO Layer 37: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:12:20,744 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:22,054 INFO     Weight matrix 1/9 (128,128): Alpha: 2.001082054477253, Alpha Weighted: -0.7911708068529555, D: 0.1292512259945489\n",
      "2018-11-26 13:12:22,057 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.28914767503738403\n",
      "2018-11-26 13:12:22,060 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:23,340 INFO     Weight matrix 2/9 (128,128): Alpha: 1.8740737393053268, Alpha Weighted: -0.32185322003557926, D: 0.11963662378256557\n",
      "2018-11-26 13:12:23,344 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.37479811906814575\n",
      "2018-11-26 13:12:23,347 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:24,305 INFO     Weight matrix 3/9 (128,128): Alpha: 1.9506955555190797, Alpha Weighted: -0.48654626835135134, D: 0.13752691232968095\n",
      "2018-11-26 13:12:24,309 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.3552376627922058\n",
      "2018-11-26 13:12:24,313 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:25,269 INFO     Weight matrix 4/9 (128,128): Alpha: 1.773825429527078, Alpha Weighted: -0.27343658066850596, D: 0.11551169185048993\n",
      "2018-11-26 13:12:25,272 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.37735673785209656\n",
      "2018-11-26 13:12:25,275 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:26,190 INFO     Weight matrix 5/9 (128,128): Alpha: 1.736234441943504, Alpha Weighted: 0.011636651998879751, D: 0.1094184822817762\n",
      "2018-11-26 13:12:26,194 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.4496895968914032\n",
      "2018-11-26 13:12:26,196 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:12:27,229 INFO     Weight matrix 6/9 (128,128): Alpha: 1.5612205551614058, Alpha Weighted: 0.009403741022064354, D: 0.1352423193873789\n",
      "2018-11-26 13:12:27,233 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.4554271101951599\n",
      "2018-11-26 13:12:27,236 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:28,331 INFO     Weight matrix 7/9 (128,128): Alpha: 1.9428930028233289, Alpha Weighted: -0.5017141300866459, D: 0.13589061001563318\n",
      "2018-11-26 13:12:28,335 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.3502623438835144\n",
      "2018-11-26 13:12:28,338 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:29,377 INFO     Weight matrix 8/9 (128,128): Alpha: 1.8187918348802095, Alpha Weighted: 0.05306689072335674, D: 0.13397077301439853\n",
      "2018-11-26 13:12:29,381 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.456059992313385\n",
      "2018-11-26 13:12:29,385 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:30,340 INFO     Weight matrix 9/9 (128,128): Alpha: 1.7757894277999653, Alpha Weighted: -0.1160013263854499, D: 0.12406204762787493\n",
      "2018-11-26 13:12:30,343 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.43336018919944763\n",
      "2018-11-26 13:12:30,345 INFO Layer 38: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:30,349 INFO Layer 38: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:30,354 INFO Layer 39: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:12:30,365 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:30,369 INFO Layer 39: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:30,376 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:12:31,372 INFO     Weight matrix 1/1 (128,512): Alpha: 5.849537280894447, Alpha Weighted: 1.3683022774863902, D: 0.1496123347012147\n",
      "2018-11-26 13:12:31,375 INFO     Weight matrix 1/1 (128,512): Alpha 5.849537280894447 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:31,377 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.8216822147369385\n",
      "2018-11-26 13:12:31,381 INFO Layer 40: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:31,383 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:31,386 INFO Layer 41: ReLU(inplace)\n",
      "2018-11-26 13:12:31,388 INFO Layer 41: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:31,390 INFO Layer 42: Sequential(\n",
      "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:12:31,393 INFO Layer 42: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:31,396 INFO Layer 43: Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 13:12:31,403 INFO Pytorch tensor shape detected: 512x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:31,407 INFO Layer 43: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:31,409 INFO     Weight matrix 1/1 (256,512): Analyzing ...\n",
      "2018-11-26 13:12:33,931 INFO     Weight matrix 1/1 (256,512): Alpha: 1.5517755878834776, Alpha Weighted: 1.093793654236257, D: 0.12339331183443236\n",
      "2018-11-26 13:12:33,934 INFO     Weight matrix 1/1 (256,512): Lognorm: 0.8642119765281677\n",
      "2018-11-26 13:12:33,940 INFO Layer 44: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:33,943 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:33,945 INFO Layer 45: Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:12:33,948 INFO Layer 45: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:33,951 INFO Layer 46: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:12:33,956 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:33,958 INFO Layer 46: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:33,962 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:12:35,061 INFO     Weight matrix 1/1 (128,512): Alpha: 1.6350174113743532, Alpha Weighted: 0.6277738928151021, D: 0.07885330270406393\n",
      "2018-11-26 13:12:35,065 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.5191983580589294\n",
      "2018-11-26 13:12:35,067 INFO Layer 47: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:35,069 INFO Layer 47: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:35,073 INFO Layer 48: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:12:35,076 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:12:35,079 INFO Layer 48: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:12:35,082 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:36,086 INFO     Weight matrix 1/9 (128,128): Alpha: 1.6058006847748376, Alpha Weighted: -1.0672542096622781, D: 0.13807380734326724\n",
      "2018-11-26 13:12:36,089 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.03150093927979469\n",
      "2018-11-26 13:12:36,092 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:37,324 INFO     Weight matrix 2/9 (128,128): Alpha: 1.4708037650873695, Alpha Weighted: 0.16942884327973956, D: 0.10117466100433031\n",
      "2018-11-26 13:12:37,327 INFO     Weight matrix 2/9 (128,128): Alpha 1.4708037650873695 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:37,337 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.3053216338157654\n",
      "2018-11-26 13:12:37,340 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:38,450 INFO     Weight matrix 3/9 (128,128): Alpha: 1.5399001587889178, Alpha Weighted: -0.5550568280042081, D: 0.10675396829301265\n",
      "2018-11-26 13:12:38,453 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.12966452538967133\n",
      "2018-11-26 13:12:38,458 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:39,528 INFO     Weight matrix 4/9 (128,128): Alpha: 1.4640729468257578, Alpha Weighted: 0.10144971189624388, D: 0.09663884761284686\n",
      "2018-11-26 13:12:39,531 INFO     Weight matrix 4/9 (128,128): Alpha 1.4640729468257578 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:39,536 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.2949518859386444\n",
      "2018-11-26 13:12:39,539 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:40,477 INFO     Weight matrix 5/9 (128,128): Alpha: 1.4512160627393016, Alpha Weighted: 0.12513190948702255, D: 0.09195164520193677\n",
      "2018-11-26 13:12:40,479 INFO     Weight matrix 5/9 (128,128): Alpha 1.4512160627393016 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:40,485 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.3284396529197693\n",
      "2018-11-26 13:12:40,488 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:41,471 INFO     Weight matrix 6/9 (128,128): Alpha: 1.4604460144052511, Alpha Weighted: 0.2670936564472703, D: 0.09593178547645681\n",
      "2018-11-26 13:12:41,473 INFO     Weight matrix 6/9 (128,128): Alpha 1.4604460144052511 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:41,478 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.34851330518722534\n",
      "2018-11-26 13:12:41,481 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:42,693 INFO     Weight matrix 7/9 (128,128): Alpha: 1.4209202481665442, Alpha Weighted: -0.5673898984271996, D: 0.11138546673926464\n",
      "2018-11-26 13:12:42,695 INFO     Weight matrix 7/9 (128,128): Alpha 1.4209202481665442 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:42,699 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.11836008727550507\n",
      "2018-11-26 13:12:42,702 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:43,803 INFO     Weight matrix 8/9 (128,128): Alpha: 1.4303768447968195, Alpha Weighted: 0.32420659155076453, D: 0.08639441954205324\n",
      "2018-11-26 13:12:43,806 INFO     Weight matrix 8/9 (128,128): Alpha 1.4303768447968195 is in the danger zone (1.5,3.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:12:43,811 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.3631327152252197\n",
      "2018-11-26 13:12:43,815 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:44,816 INFO     Weight matrix 9/9 (128,128): Alpha: 1.479083865270331, Alpha Weighted: -0.163397861364964, D: 0.08624768207544142\n",
      "2018-11-26 13:12:44,818 INFO     Weight matrix 9/9 (128,128): Alpha 1.479083865270331 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:44,823 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.2359333485364914\n",
      "2018-11-26 13:12:44,827 INFO Layer 49: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:44,830 INFO Layer 49: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:44,833 INFO Layer 50: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:12:44,837 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:44,840 INFO Layer 50: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:44,843 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:12:45,869 INFO     Weight matrix 1/1 (128,512): Alpha: 5.698359139587815, Alpha Weighted: 1.562950936120003, D: 0.09999999999999987\n",
      "2018-11-26 13:12:45,872 INFO     Weight matrix 1/1 (128,512): Alpha 5.698359139587815 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:45,875 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.6135491728782654\n",
      "2018-11-26 13:12:45,878 INFO Layer 51: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:45,881 INFO Layer 51: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:45,884 INFO Layer 52: ReLU(inplace)\n",
      "2018-11-26 13:12:45,888 INFO Layer 52: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:45,891 INFO Layer 53: Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:12:45,894 INFO Layer 53: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:45,897 INFO Layer 54: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:12:45,901 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:45,903 INFO Layer 54: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:45,907 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:12:47,064 INFO     Weight matrix 1/1 (128,512): Alpha: 1.5943905143925607, Alpha Weighted: 0.4002938265308685, D: 0.12339992051398113\n",
      "2018-11-26 13:12:47,068 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.6973446011543274\n",
      "2018-11-26 13:12:47,070 INFO Layer 55: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:47,074 INFO Layer 55: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:47,077 INFO Layer 56: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:12:47,082 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:12:47,085 INFO Layer 56: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:12:47,088 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:48,128 INFO     Weight matrix 1/9 (128,128): Alpha: 1.7361932665842306, Alpha Weighted: -1.2071573493319738, D: 0.17932494221986567\n",
      "2018-11-26 13:12:48,132 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.21877996623516083\n",
      "2018-11-26 13:12:48,135 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:49,177 INFO     Weight matrix 2/9 (128,128): Alpha: 1.8535319523469345, Alpha Weighted: -0.3449736284735312, D: 0.11612018228710125\n",
      "2018-11-26 13:12:49,181 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.3596239984035492\n",
      "2018-11-26 13:12:49,184 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:50,433 INFO     Weight matrix 3/9 (128,128): Alpha: 1.7830164916287872, Alpha Weighted: -1.0915120412618318, D: 0.17872144662144196\n",
      "2018-11-26 13:12:50,437 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.2555132806301117\n",
      "2018-11-26 13:12:50,442 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:51,480 INFO     Weight matrix 4/9 (128,128): Alpha: 1.802680545912237, Alpha Weighted: -0.28103037848903917, D: 0.11007924273374359\n",
      "2018-11-26 13:12:51,484 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.3615185618400574\n",
      "2018-11-26 13:12:51,488 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:52,489 INFO     Weight matrix 5/9 (128,128): Alpha: 1.908984648306044, Alpha Weighted: 0.2813003770069837, D: 0.113488875832079\n",
      "2018-11-26 13:12:52,493 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.47151249647140503\n",
      "2018-11-26 13:12:52,496 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:53,450 INFO     Weight matrix 6/9 (128,128): Alpha: 1.6032207209943574, Alpha Weighted: -0.15880316974536834, D: 0.12130858155301072\n",
      "2018-11-26 13:12:53,453 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.40716055035591125\n",
      "2018-11-26 13:12:53,456 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:54,500 INFO     Weight matrix 7/9 (128,128): Alpha: 1.7168856054952648, Alpha Weighted: -1.091834825573502, D: 0.16460644742462777\n",
      "2018-11-26 13:12:54,504 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.24795664846897125\n",
      "2018-11-26 13:12:54,507 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:55,626 INFO     Weight matrix 8/9 (128,128): Alpha: 1.7116562232646868, Alpha Weighted: -0.16499037173635794, D: 0.13498320202760472\n",
      "2018-11-26 13:12:55,631 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.4046876132488251\n",
      "2018-11-26 13:12:55,636 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:12:56,696 INFO     Weight matrix 9/9 (128,128): Alpha: 1.6595746861978526, Alpha Weighted: -0.6737679152098385, D: 0.15453672662815943\n",
      "2018-11-26 13:12:56,700 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.3161705732345581\n",
      "2018-11-26 13:12:56,704 INFO Layer 57: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:56,708 INFO Layer 57: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:56,711 INFO Layer 58: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:12:56,715 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:56,717 INFO Layer 58: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:56,719 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:12:57,771 INFO     Weight matrix 1/1 (128,512): Alpha: 10.837149709317695, Alpha Weighted: 0.27303834081524825, D: 0.20892193029855766\n",
      "2018-11-26 13:12:57,774 INFO     Weight matrix 1/1 (128,512): Alpha 10.837149709317695 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:57,779 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.7107180953025818\n",
      "2018-11-26 13:12:57,783 INFO Layer 59: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:57,786 INFO Layer 59: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:57,789 INFO Layer 60: ReLU(inplace)\n",
      "2018-11-26 13:12:57,791 INFO Layer 60: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:57,794 INFO Layer 61: Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:12:57,797 INFO Layer 61: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:57,800 INFO Layer 62: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:12:57,803 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:12:57,806 INFO Layer 62: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:12:57,809 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:12:59,037 INFO     Weight matrix 1/1 (128,512): Alpha: 4.389838392695652, Alpha Weighted: 1.2666029149827924, D: 0.11727046616760373\n",
      "2018-11-26 13:12:59,042 INFO     Weight matrix 1/1 (128,512): Alpha 4.389838392695652 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:12:59,047 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.7432159781455994\n",
      "2018-11-26 13:12:59,055 INFO Layer 63: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:12:59,060 INFO Layer 63: Skipping (Layer not supported)\n",
      "2018-11-26 13:12:59,065 INFO Layer 64: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:12:59,072 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:12:59,076 INFO Layer 64: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:12:59,081 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:13:00,411 INFO     Weight matrix 1/9 (128,128): Alpha: 2.0337711399619898, Alpha Weighted: -1.230817792417547, D: 0.1676383413461613\n",
      "2018-11-26 13:13:00,422 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.28001317381858826\n",
      "2018-11-26 13:13:00,425 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:13:01,613 INFO     Weight matrix 2/9 (128,128): Alpha: 1.8467443552888199, Alpha Weighted: -0.3690314491030519, D: 0.12691962908972215\n",
      "2018-11-26 13:13:01,617 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.4003533124923706\n",
      "2018-11-26 13:13:01,620 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:13:02,693 INFO     Weight matrix 3/9 (128,128): Alpha: 1.8136811896640874, Alpha Weighted: -0.7968074428564107, D: 0.1557454139908208\n",
      "2018-11-26 13:13:02,697 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.324584424495697\n",
      "2018-11-26 13:13:02,701 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:13:03,802 INFO     Weight matrix 4/9 (128,128): Alpha: 1.8565713749580808, Alpha Weighted: -0.34441315442286813, D: 0.12351776933886216\n",
      "2018-11-26 13:13:03,805 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.4048703908920288\n",
      "2018-11-26 13:13:03,809 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:13:04,852 INFO     Weight matrix 5/9 (128,128): Alpha: 1.7671506585685002, Alpha Weighted: 0.009803635669746244, D: 0.14081044976935958\n",
      "2018-11-26 13:13:04,856 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.5237230062484741\n",
      "2018-11-26 13:13:04,859 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:13:05,890 INFO     Weight matrix 6/9 (128,128): Alpha: 1.6964550932082196, Alpha Weighted: -0.027817901158234, D: 0.13943486934790517\n",
      "2018-11-26 13:13:05,894 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.491221159696579\n",
      "2018-11-26 13:13:05,896 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:13:06,865 INFO     Weight matrix 7/9 (128,128): Alpha: 1.890222298364589, Alpha Weighted: -0.7476695672911736, D: 0.14617673922662267\n",
      "2018-11-26 13:13:06,869 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.3238542973995209\n",
      "2018-11-26 13:13:06,877 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:13:08,044 INFO     Weight matrix 8/9 (128,128): Alpha: 1.6512774835724564, Alpha Weighted: -0.05778355337188232, D: 0.13738887332144434\n",
      "2018-11-26 13:13:08,047 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.4790005385875702\n",
      "2018-11-26 13:13:08,050 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:13:09,102 INFO     Weight matrix 9/9 (128,128): Alpha: 2.318740872028035, Alpha Weighted: -0.5627793725468196, D: 0.13627946856317352\n",
      "2018-11-26 13:13:09,107 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.3847738206386566\n",
      "2018-11-26 13:13:09,110 INFO Layer 65: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:13:09,112 INFO Layer 65: Skipping (Layer not supported)\n",
      "2018-11-26 13:13:09,115 INFO Layer 66: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:13:09,118 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:13:09,121 INFO Layer 66: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:13:09,123 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:13:10,141 INFO     Weight matrix 1/1 (128,512): Alpha: 2.95654776164967, Alpha Weighted: 0.18164674337930403, D: 0.20235142975775883\n",
      "2018-11-26 13:13:10,144 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.741195023059845\n",
      "2018-11-26 13:13:10,147 INFO Layer 67: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:13:10,150 INFO Layer 67: Skipping (Layer not supported)\n",
      "2018-11-26 13:13:10,153 INFO Layer 68: ReLU(inplace)\n",
      "2018-11-26 13:13:10,155 INFO Layer 68: Skipping (Layer not supported)\n",
      "2018-11-26 13:13:10,163 INFO Layer 69: Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (6): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (7): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (8): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (9): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (10): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (11): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (12): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (13): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (14): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (15): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (16): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (17): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (18): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (19): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (20): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (21): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (22): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:13:10,167 INFO Layer 69: Skipping (Layer not supported)\n",
      "2018-11-26 13:13:10,170 INFO Layer 70: Bottleneck(\n",
      "  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:13:10,173 INFO Layer 70: Skipping (Layer not supported)\n",
      "2018-11-26 13:13:10,176 INFO Layer 71: Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:13:10,181 INFO Pytorch tensor shape detected: 256x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:13:10,184 INFO Layer 71: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:13:10,187 INFO     Weight matrix 1/1 (256,512): Analyzing ...\n",
      "2018-11-26 13:13:12,777 INFO     Weight matrix 1/1 (256,512): Alpha: 1.6266720658986935, Alpha Weighted: 0.8132178421095596, D: 0.14921015666530574\n",
      "2018-11-26 13:13:12,780 INFO     Weight matrix 1/1 (256,512): Lognorm: 1.0100165605545044\n",
      "2018-11-26 13:13:12,783 INFO Layer 72: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:13:12,786 INFO Layer 72: Skipping (Layer not supported)\n",
      "2018-11-26 13:13:12,790 INFO Layer 73: Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:13:12,805 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:13:12,808 INFO Layer 73: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:13:12,812 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:15,276 INFO     Weight matrix 1/9 (256,256): Alpha: 3.7256510646908785, Alpha Weighted: -1.7072029360679055, D: 0.11405343751936747\n",
      "2018-11-26 13:13:15,278 INFO     Weight matrix 1/9 (256,256): Alpha 3.7256510646908785 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:13:15,283 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.48084211349487305\n",
      "2018-11-26 13:13:15,286 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:17,752 INFO     Weight matrix 2/9 (256,256): Alpha: 3.7624887832494727, Alpha Weighted: -0.934497157328742, D: 0.15575025617138827\n",
      "2018-11-26 13:13:17,754 INFO     Weight matrix 2/9 (256,256): Alpha 3.7624887832494727 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:13:17,758 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.6036051511764526\n",
      "2018-11-26 13:13:17,761 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:20,180 INFO     Weight matrix 3/9 (256,256): Alpha: 3.8162662163713956, Alpha Weighted: -1.2890251876973415, D: 0.1245041618017183\n",
      "2018-11-26 13:13:20,182 INFO     Weight matrix 3/9 (256,256): Alpha 3.8162662163713956 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:13:20,186 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.5580068826675415\n",
      "2018-11-26 13:13:20,189 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:22,784 INFO     Weight matrix 4/9 (256,256): Alpha: 3.9283364086739314, Alpha Weighted: -1.0525030218349671, D: 0.1321006564511798\n",
      "2018-11-26 13:13:22,786 INFO     Weight matrix 4/9 (256,256): Alpha 3.9283364086739314 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:13:22,791 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5922664403915405\n",
      "2018-11-26 13:13:22,796 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:25,280 INFO     Weight matrix 5/9 (256,256): Alpha: 2.8887962658865476, Alpha Weighted: -0.2730801961798882, D: 0.1648809084488312\n",
      "2018-11-26 13:13:25,286 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.6485157012939453\n",
      "2018-11-26 13:13:25,290 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:27,822 INFO     Weight matrix 6/9 (256,256): Alpha: 3.414063172169263, Alpha Weighted: -0.2494313228922174, D: 0.14952210036286595\n",
      "2018-11-26 13:13:27,826 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6937280297279358\n",
      "2018-11-26 13:13:27,829 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:30,633 INFO     Weight matrix 7/9 (256,256): Alpha: 3.4418416415071826, Alpha Weighted: -1.2799427176708478, D: 0.13198587337601542\n",
      "2018-11-26 13:13:30,638 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.5420007109642029\n",
      "2018-11-26 13:13:30,642 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:33,392 INFO     Weight matrix 8/9 (256,256): Alpha: 3.15929895015633, Alpha Weighted: -0.28283006906151326, D: 0.17417856316240438\n",
      "2018-11-26 13:13:33,397 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6901731491088867\n",
      "2018-11-26 13:13:33,400 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:35,837 INFO     Weight matrix 9/9 (256,256): Alpha: 3.711847962788746, Alpha Weighted: -0.7787177337130489, D: 0.1546044408650442\n",
      "2018-11-26 13:13:35,841 INFO     Weight matrix 9/9 (256,256): Alpha 3.711847962788746 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:13:35,846 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6361157298088074\n",
      "2018-11-26 13:13:35,849 INFO Layer 74: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:13:35,852 INFO Layer 74: Skipping (Layer not supported)\n",
      "2018-11-26 13:13:35,855 INFO Layer 75: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:13:35,864 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:13:35,868 INFO Layer 75: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:13:35,872 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:13:38,578 INFO     Weight matrix 1/1 (256,1024): Alpha: 6.831729496105003, Alpha Weighted: 2.7628511116699657, D: 0.11030592015799878\n",
      "2018-11-26 13:13:38,580 INFO     Weight matrix 1/1 (256,1024): Alpha 6.831729496105003 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:13:38,584 INFO     Weight matrix 1/1 (256,1024): Lognorm: 1.01131010055542\n",
      "2018-11-26 13:13:38,587 INFO Layer 76: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:13:38,590 INFO Layer 76: Skipping (Layer not supported)\n",
      "2018-11-26 13:13:38,593 INFO Layer 77: ReLU(inplace)\n",
      "2018-11-26 13:13:38,596 INFO Layer 77: Skipping (Layer not supported)\n",
      "2018-11-26 13:13:38,598 INFO Layer 78: Sequential(\n",
      "  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:13:38,601 INFO Layer 78: Skipping (Layer not supported)\n",
      "2018-11-26 13:13:38,604 INFO Layer 79: Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 13:13:38,609 INFO Pytorch tensor shape detected: 1024x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:13:38,613 INFO Layer 79: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:13:38,616 INFO     Weight matrix 1/1 (512,1024): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:13:38,620 INFO Layer 80: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:13:38,623 INFO Layer 80: Skipping (Layer not supported)\n",
      "2018-11-26 13:13:38,626 INFO Layer 81: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:13:38,630 INFO Layer 81: Skipping (Layer not supported)\n",
      "2018-11-26 13:13:38,634 INFO Layer 82: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:13:38,640 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:13:38,643 INFO Layer 82: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:13:38,646 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:13:41,427 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.104895906747542, Alpha Weighted: 0.2581951806703783, D: 0.09455282708261104\n",
      "2018-11-26 13:13:41,431 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.467148095369339\n",
      "2018-11-26 13:13:41,434 INFO Layer 83: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:13:41,437 INFO Layer 83: Skipping (Layer not supported)\n",
      "2018-11-26 13:13:41,441 INFO Layer 84: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:13:41,448 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:13:41,452 INFO Layer 84: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:13:41,457 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:44,017 INFO     Weight matrix 1/9 (256,256): Alpha: 1.9513553906376429, Alpha Weighted: -1.6636859023429071, D: 0.10930598617539589\n",
      "2018-11-26 13:13:44,021 INFO     Weight matrix 1/9 (256,256): Lognorm: -0.00046842615120112896\n",
      "2018-11-26 13:13:44,024 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:46,474 INFO     Weight matrix 2/9 (256,256): Alpha: 1.8782996196699635, Alpha Weighted: -0.9166811484330886, D: 0.10391599849092026\n",
      "2018-11-26 13:13:46,479 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.11339300870895386\n",
      "2018-11-26 13:13:46,481 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:49,071 INFO     Weight matrix 3/9 (256,256): Alpha: 1.9933175794136697, Alpha Weighted: -1.5806216781406366, D: 0.10624846760688228\n",
      "2018-11-26 13:13:49,075 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.020974496379494667\n",
      "2018-11-26 13:13:49,078 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:51,651 INFO     Weight matrix 4/9 (256,256): Alpha: 1.787757846095397, Alpha Weighted: -0.9094268987859723, D: 0.0766783257905907\n",
      "2018-11-26 13:13:51,656 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.10425108671188354\n",
      "2018-11-26 13:13:51,659 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:54,118 INFO     Weight matrix 5/9 (256,256): Alpha: 1.6466086347315085, Alpha Weighted: -0.6567017036121646, D: 0.10164986968240952\n",
      "2018-11-26 13:13:54,122 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.17877252399921417\n",
      "2018-11-26 13:13:54,126 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:56,990 INFO     Weight matrix 6/9 (256,256): Alpha: 1.7997335828433212, Alpha Weighted: -0.9250596262875389, D: 0.08944085983379213\n",
      "2018-11-26 13:13:56,995 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.1184643805027008\n",
      "2018-11-26 13:13:57,002 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:13:59,687 INFO     Weight matrix 7/9 (256,256): Alpha: 1.7909667378901224, Alpha Weighted: -1.4070237257976268, D: 0.09421228768544354\n",
      "2018-11-26 13:13:59,691 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.01835959404706955\n",
      "2018-11-26 13:13:59,696 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:02,312 INFO     Weight matrix 8/9 (256,256): Alpha: 1.7953045939721783, Alpha Weighted: -0.813940248790216, D: 0.10100207120029786\n",
      "2018-11-26 13:14:02,317 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.13504032790660858\n",
      "2018-11-26 13:14:02,320 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:05,059 INFO     Weight matrix 9/9 (256,256): Alpha: 1.7625742501435473, Alpha Weighted: -1.323281203210821, D: 0.10837091222076511\n",
      "2018-11-26 13:14:05,064 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.0372484065592289\n",
      "2018-11-26 13:14:05,067 INFO Layer 85: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:14:05,069 INFO Layer 85: Skipping (Layer not supported)\n",
      "2018-11-26 13:14:05,072 INFO Layer 86: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:14:05,077 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:14:05,080 INFO Layer 86: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:14:05,083 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:14:07,817 INFO     Weight matrix 1/1 (256,1024): Alpha: 6.186232461059174, Alpha Weighted: -1.0751255757119202, D: 0.12245816736424764\n",
      "2018-11-26 13:14:07,820 INFO     Weight matrix 1/1 (256,1024): Alpha 6.186232461059174 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:14:07,824 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.5173341035842896\n",
      "2018-11-26 13:14:07,827 INFO Layer 87: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:14:07,830 INFO Layer 87: Skipping (Layer not supported)\n",
      "2018-11-26 13:14:07,833 INFO Layer 88: ReLU(inplace)\n",
      "2018-11-26 13:14:07,836 INFO Layer 88: Skipping (Layer not supported)\n",
      "2018-11-26 13:14:07,839 INFO Layer 89: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:14:07,842 INFO Layer 89: Skipping (Layer not supported)\n",
      "2018-11-26 13:14:07,844 INFO Layer 90: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:14:07,849 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:14:07,854 INFO Layer 90: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:14:07,857 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:14:10,928 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.7191218882947021, Alpha Weighted: 0.45704695989813865, D: 0.11487123227301044\n",
      "2018-11-26 13:14:10,931 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6699070334434509\n",
      "2018-11-26 13:14:10,935 INFO Layer 91: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:14:10,937 INFO Layer 91: Skipping (Layer not supported)\n",
      "2018-11-26 13:14:10,941 INFO Layer 92: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:14:10,946 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:14:10,949 INFO Layer 92: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:14:10,954 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:13,486 INFO     Weight matrix 1/9 (256,256): Alpha: 2.01479015462177, Alpha Weighted: -0.8697979219302285, D: 0.10004371229903053\n",
      "2018-11-26 13:14:13,491 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.24772872030735016\n",
      "2018-11-26 13:14:13,494 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:16,255 INFO     Weight matrix 2/9 (256,256): Alpha: 1.9071912275307947, Alpha Weighted: -0.28827963313529176, D: 0.09372007066451515\n",
      "2018-11-26 13:14:16,260 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3195585310459137\n",
      "2018-11-26 13:14:16,262 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:19,175 INFO     Weight matrix 3/9 (256,256): Alpha: 2.0265577110705335, Alpha Weighted: -0.7487165839397699, D: 0.09924992558706647\n",
      "2018-11-26 13:14:19,181 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.2684386074542999\n",
      "2018-11-26 13:14:19,186 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:23,510 INFO     Weight matrix 4/9 (256,256): Alpha: 2.0903356244374174, Alpha Weighted: -0.4898120530968004, D: 0.09715336655364559\n",
      "2018-11-26 13:14:23,515 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3025202751159668\n",
      "2018-11-26 13:14:23,518 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:26,334 INFO     Weight matrix 5/9 (256,256): Alpha: 1.539526437974391, Alpha Weighted: -0.07168104587640023, D: 0.10638885378808921\n",
      "2018-11-26 13:14:26,341 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.40436193346977234\n",
      "2018-11-26 13:14:26,345 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:14:29,155 INFO     Weight matrix 6/9 (256,256): Alpha: 1.9875115077056913, Alpha Weighted: -0.3790864325780646, D: 0.10284546936773942\n",
      "2018-11-26 13:14:29,160 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.3248765468597412\n",
      "2018-11-26 13:14:29,165 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:31,731 INFO     Weight matrix 7/9 (256,256): Alpha: 1.785277745905367, Alpha Weighted: -0.7433830833339847, D: 0.1046384792377748\n",
      "2018-11-26 13:14:31,736 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.2597777843475342\n",
      "2018-11-26 13:14:31,741 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:34,075 INFO     Weight matrix 8/9 (256,256): Alpha: 2.083049241210965, Alpha Weighted: -0.255349129460414, D: 0.08642593469529569\n",
      "2018-11-26 13:14:34,083 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.3364141285419464\n",
      "2018-11-26 13:14:34,085 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:36,463 INFO     Weight matrix 9/9 (256,256): Alpha: 1.951658372256504, Alpha Weighted: -0.6271499624131773, D: 0.10347782836587971\n",
      "2018-11-26 13:14:36,467 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.29207950830459595\n",
      "2018-11-26 13:14:36,469 INFO Layer 93: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:14:36,471 INFO Layer 93: Skipping (Layer not supported)\n",
      "2018-11-26 13:14:36,474 INFO Layer 94: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:14:36,478 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:14:36,480 INFO Layer 94: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:14:36,482 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:14:39,053 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.6497989572077392, Alpha Weighted: 0.2313592484069329, D: 0.14286522261671897\n",
      "2018-11-26 13:14:39,056 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7336246371269226\n",
      "2018-11-26 13:14:39,060 INFO Layer 95: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:14:39,062 INFO Layer 95: Skipping (Layer not supported)\n",
      "2018-11-26 13:14:39,064 INFO Layer 96: ReLU(inplace)\n",
      "2018-11-26 13:14:39,068 INFO Layer 96: Skipping (Layer not supported)\n",
      "2018-11-26 13:14:39,072 INFO Layer 97: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:14:39,076 INFO Layer 97: Skipping (Layer not supported)\n",
      "2018-11-26 13:14:39,079 INFO Layer 98: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:14:39,084 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:14:39,087 INFO Layer 98: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:14:39,090 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:14:41,545 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.7730349038925275, Alpha Weighted: 0.23637095390591742, D: 0.09792194484411093\n",
      "2018-11-26 13:14:41,548 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.5936395525932312\n",
      "2018-11-26 13:14:41,551 INFO Layer 99: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:14:41,554 INFO Layer 99: Skipping (Layer not supported)\n",
      "2018-11-26 13:14:41,556 INFO Layer 100: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:14:41,562 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:14:41,564 INFO Layer 100: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:14:41,567 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:43,907 INFO     Weight matrix 1/9 (256,256): Alpha: 1.7470881632586577, Alpha Weighted: -1.1083461879546457, D: 0.11477435306079853\n",
      "2018-11-26 13:14:43,910 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.1457539200782776\n",
      "2018-11-26 13:14:43,913 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:46,363 INFO     Weight matrix 2/9 (256,256): Alpha: 1.8228178718823274, Alpha Weighted: -0.6992356456062059, D: 0.08698500572143364\n",
      "2018-11-26 13:14:46,368 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.21949386596679688\n",
      "2018-11-26 13:14:46,372 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:48,747 INFO     Weight matrix 3/9 (256,256): Alpha: 1.6824247594142343, Alpha Weighted: -1.0383372353280627, D: 0.11280470786317953\n",
      "2018-11-26 13:14:48,751 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.15854553878307343\n",
      "2018-11-26 13:14:48,754 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:52,188 INFO     Weight matrix 4/9 (256,256): Alpha: 2.00850166286883, Alpha Weighted: -0.8588291382927549, D: 0.08751369019845545\n",
      "2018-11-26 13:14:52,192 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.2077532410621643\n",
      "2018-11-26 13:14:52,195 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:54,658 INFO     Weight matrix 5/9 (256,256): Alpha: 1.6917062037896846, Alpha Weighted: -0.5166330319122322, D: 0.09362082954407241\n",
      "2018-11-26 13:14:54,661 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.28156620264053345\n",
      "2018-11-26 13:14:54,664 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:14:57,598 INFO     Weight matrix 6/9 (256,256): Alpha: 1.860286350528296, Alpha Weighted: -0.7374037686221562, D: 0.08296293625427509\n",
      "2018-11-26 13:14:57,603 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.23063071072101593\n",
      "2018-11-26 13:14:57,607 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:00,390 INFO     Weight matrix 7/9 (256,256): Alpha: 2.171283903544512, Alpha Weighted: -1.3615621604522357, D: 0.10370355320268831\n",
      "2018-11-26 13:15:00,395 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.15360309183597565\n",
      "2018-11-26 13:15:00,399 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:02,924 INFO     Weight matrix 8/9 (256,256): Alpha: 1.9222215927161872, Alpha Weighted: -0.6328090390107988, D: 0.09566034455623956\n",
      "2018-11-26 13:15:02,928 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.24739432334899902\n",
      "2018-11-26 13:15:02,933 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:05,244 INFO     Weight matrix 9/9 (256,256): Alpha: 1.9203539204178228, Alpha Weighted: -1.1542436409229802, D: 0.11234083600529837\n",
      "2018-11-26 13:15:05,249 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.17969286441802979\n",
      "2018-11-26 13:15:05,252 INFO Layer 101: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:15:05,254 INFO Layer 101: Skipping (Layer not supported)\n",
      "2018-11-26 13:15:05,258 INFO Layer 102: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:15:05,262 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:15:05,265 INFO Layer 102: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:15:05,267 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:15:07,704 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.02291577897414, Alpha Weighted: -0.4701875445415229, D: 0.14089339542405488\n",
      "2018-11-26 13:15:07,707 INFO     Weight matrix 1/1 (256,1024): Alpha 4.02291577897414 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:15:07,710 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.607159435749054\n",
      "2018-11-26 13:15:07,713 INFO Layer 103: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:15:07,716 INFO Layer 103: Skipping (Layer not supported)\n",
      "2018-11-26 13:15:07,721 INFO Layer 104: ReLU(inplace)\n",
      "2018-11-26 13:15:07,730 INFO Layer 104: Skipping (Layer not supported)\n",
      "2018-11-26 13:15:07,734 INFO Layer 105: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:15:07,736 INFO Layer 105: Skipping (Layer not supported)\n",
      "2018-11-26 13:15:07,740 INFO Layer 106: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:15:07,744 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:15:07,746 INFO Layer 106: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:15:07,749 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:15:10,147 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.7903894893482208, Alpha Weighted: 0.5710258877265435, D: 0.08371206170647677\n",
      "2018-11-26 13:15:10,151 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.61812424659729\n",
      "2018-11-26 13:15:10,154 INFO Layer 107: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:15:10,157 INFO Layer 107: Skipping (Layer not supported)\n",
      "2018-11-26 13:15:10,160 INFO Layer 108: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:15:10,164 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:15:10,166 INFO Layer 108: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:15:10,169 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:12,695 INFO     Weight matrix 1/9 (256,256): Alpha: 1.9695949287198058, Alpha Weighted: -0.7987176920673759, D: 0.1057385818198483\n",
      "2018-11-26 13:15:12,701 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.1890479177236557\n",
      "2018-11-26 13:15:12,704 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:15,341 INFO     Weight matrix 2/9 (256,256): Alpha: 1.7578184396196708, Alpha Weighted: -0.10182522956079292, D: 0.08525452728928362\n",
      "2018-11-26 13:15:15,345 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.2904123067855835\n",
      "2018-11-26 13:15:15,348 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:17,913 INFO     Weight matrix 3/9 (256,256): Alpha: 1.6500596236219987, Alpha Weighted: -0.6191236694079604, D: 0.10073044816339599\n",
      "2018-11-26 13:15:17,917 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.20010755956172943\n",
      "2018-11-26 13:15:17,919 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:20,308 INFO     Weight matrix 4/9 (256,256): Alpha: 1.8835046518155378, Alpha Weighted: -0.19785758426853728, D: 0.07566609882713438\n",
      "2018-11-26 13:15:20,313 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.27731654047966003\n",
      "2018-11-26 13:15:20,316 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:22,775 INFO     Weight matrix 5/9 (256,256): Alpha: 1.589689281572002, Alpha Weighted: -0.5862068388242658, D: 0.09911511177171128\n",
      "2018-11-26 13:15:22,780 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.3082844316959381\n",
      "2018-11-26 13:15:22,783 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:25,328 INFO     Weight matrix 6/9 (256,256): Alpha: 2.016093088788918, Alpha Weighted: -0.1918450344298068, D: 0.08286315041488934\n",
      "2018-11-26 13:15:25,331 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.2893942892551422\n",
      "2018-11-26 13:15:25,335 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:27,747 INFO     Weight matrix 7/9 (256,256): Alpha: 2.0643426176944946, Alpha Weighted: -0.7547491718755232, D: 0.09762456167232914\n",
      "2018-11-26 13:15:27,752 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.20009472966194153\n",
      "2018-11-26 13:15:27,756 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:30,122 INFO     Weight matrix 8/9 (256,256): Alpha: 1.8802747505471356, Alpha Weighted: -0.03455279780673035, D: 0.08273140171729643\n",
      "2018-11-26 13:15:30,127 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.3088359534740448\n",
      "2018-11-26 13:15:30,133 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:32,571 INFO     Weight matrix 9/9 (256,256): Alpha: 2.35995881644528, Alpha Weighted: -0.6617666523992207, D: 0.0982565937912494\n",
      "2018-11-26 13:15:32,576 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.22279943525791168\n",
      "2018-11-26 13:15:32,580 INFO Layer 109: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:15:32,583 INFO Layer 109: Skipping (Layer not supported)\n",
      "2018-11-26 13:15:32,586 INFO Layer 110: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:15:32,591 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:15:32,593 INFO Layer 110: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:15:32,597 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:15:35,225 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.9726215025263505, Alpha Weighted: 0.10529318132047523, D: 0.10974162393595571\n",
      "2018-11-26 13:15:35,228 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6445986032485962\n",
      "2018-11-26 13:15:35,234 INFO Layer 111: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:15:35,236 INFO Layer 111: Skipping (Layer not supported)\n",
      "2018-11-26 13:15:35,238 INFO Layer 112: ReLU(inplace)\n",
      "2018-11-26 13:15:35,240 INFO Layer 112: Skipping (Layer not supported)\n",
      "2018-11-26 13:15:35,243 INFO Layer 113: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:15:35,245 INFO Layer 113: Skipping (Layer not supported)\n",
      "2018-11-26 13:15:35,247 INFO Layer 114: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:15:35,252 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:15:35,253 INFO Layer 114: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:15:35,256 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:15:37,687 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.655421475356104, Alpha Weighted: 0.08444636349858915, D: 0.13200279216467387\n",
      "2018-11-26 13:15:37,690 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7247174978256226\n",
      "2018-11-26 13:15:37,693 INFO Layer 115: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:15:37,695 INFO Layer 115: Skipping (Layer not supported)\n",
      "2018-11-26 13:15:37,697 INFO Layer 116: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:15:37,703 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:15:37,705 INFO Layer 116: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:15:37,707 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:40,699 INFO     Weight matrix 1/9 (256,256): Alpha: 1.8469045322968531, Alpha Weighted: -1.2196829342330293, D: 0.13442439719344645\n",
      "2018-11-26 13:15:40,703 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3066217601299286\n",
      "2018-11-26 13:15:40,707 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:43,209 INFO     Weight matrix 2/9 (256,256): Alpha: 2.089137350532563, Alpha Weighted: -1.1340982091791372, D: 0.10827425499308196\n",
      "2018-11-26 13:15:43,213 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.35055115818977356\n",
      "2018-11-26 13:15:43,220 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:45,616 INFO     Weight matrix 3/9 (256,256): Alpha: 1.9592387573270749, Alpha Weighted: -1.2736107144267719, D: 0.12075097132541435\n",
      "2018-11-26 13:15:45,621 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.3193068504333496\n",
      "2018-11-26 13:15:45,624 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:47,925 INFO     Weight matrix 4/9 (256,256): Alpha: 1.8978683937701626, Alpha Weighted: -1.0470855462154478, D: 0.11282678673158042\n",
      "2018-11-26 13:15:47,929 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3285196125507355\n",
      "2018-11-26 13:15:47,932 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:50,270 INFO     Weight matrix 5/9 (256,256): Alpha: 1.7829214250593188, Alpha Weighted: -0.6907995119922017, D: 0.1267408081815441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:15:50,275 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.38785314559936523\n",
      "2018-11-26 13:15:50,277 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:52,580 INFO     Weight matrix 6/9 (256,256): Alpha: 2.028831656345499, Alpha Weighted: -0.9735050497945547, D: 0.105820552803918\n",
      "2018-11-26 13:15:52,584 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.3506081998348236\n",
      "2018-11-26 13:15:52,588 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:54,907 INFO     Weight matrix 7/9 (256,256): Alpha: 1.9914978080939807, Alpha Weighted: -1.257469679185415, D: 0.1289707022300438\n",
      "2018-11-26 13:15:54,912 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.320029079914093\n",
      "2018-11-26 13:15:54,915 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:15:57,504 INFO     Weight matrix 8/9 (256,256): Alpha: 1.8815268716216527, Alpha Weighted: -0.9110951995682923, D: 0.1092774944413567\n",
      "2018-11-26 13:15:57,508 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.3701152503490448\n",
      "2018-11-26 13:15:57,511 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:00,570 INFO     Weight matrix 9/9 (256,256): Alpha: 2.0151889184039184, Alpha Weighted: -1.158961221263541, D: 0.12004981730006559\n",
      "2018-11-26 13:16:00,575 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.33966338634490967\n",
      "2018-11-26 13:16:00,577 INFO Layer 117: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:16:00,582 INFO Layer 117: Skipping (Layer not supported)\n",
      "2018-11-26 13:16:00,586 INFO Layer 118: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:16:00,592 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:16:00,596 INFO Layer 118: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:16:00,599 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:16:03,713 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.274965171355338, Alpha Weighted: 0.2531121955258964, D: 0.10840573171387252\n",
      "2018-11-26 13:16:03,716 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7434602975845337\n",
      "2018-11-26 13:16:03,718 INFO Layer 119: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:16:03,723 INFO Layer 119: Skipping (Layer not supported)\n",
      "2018-11-26 13:16:03,727 INFO Layer 120: ReLU(inplace)\n",
      "2018-11-26 13:16:03,730 INFO Layer 120: Skipping (Layer not supported)\n",
      "2018-11-26 13:16:03,734 INFO Layer 121: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:16:03,738 INFO Layer 121: Skipping (Layer not supported)\n",
      "2018-11-26 13:16:03,743 INFO Layer 122: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:16:03,747 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:16:03,749 INFO Layer 122: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:16:03,753 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:16:06,845 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.9072956688493412, Alpha Weighted: 0.19519743785660673, D: 0.1266773321045782\n",
      "2018-11-26 13:16:06,849 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7412078380584717\n",
      "2018-11-26 13:16:06,851 INFO Layer 123: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:16:06,854 INFO Layer 123: Skipping (Layer not supported)\n",
      "2018-11-26 13:16:06,857 INFO Layer 124: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:16:06,865 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:16:06,868 INFO Layer 124: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:16:06,872 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:09,665 INFO     Weight matrix 1/9 (256,256): Alpha: 2.4202198054635877, Alpha Weighted: -1.479589548819328, D: 0.09993879637271899\n",
      "2018-11-26 13:16:09,668 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3103805482387543\n",
      "2018-11-26 13:16:09,671 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:12,140 INFO     Weight matrix 2/9 (256,256): Alpha: 2.3856033676296473, Alpha Weighted: -0.9494200218197179, D: 0.09068680502487758\n",
      "2018-11-26 13:16:12,145 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.36242568492889404\n",
      "2018-11-26 13:16:12,147 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:14,603 INFO     Weight matrix 3/9 (256,256): Alpha: 2.4108906279000784, Alpha Weighted: -1.4503817218023636, D: 0.11599242737485371\n",
      "2018-11-26 13:16:14,607 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.3212072551250458\n",
      "2018-11-26 13:16:14,610 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:16,906 INFO     Weight matrix 4/9 (256,256): Alpha: 2.3306294987929568, Alpha Weighted: -0.9136245903833522, D: 0.07269552024454373\n",
      "2018-11-26 13:16:16,909 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3419557809829712\n",
      "2018-11-26 13:16:16,912 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:19,449 INFO     Weight matrix 5/9 (256,256): Alpha: 2.2641445259211803, Alpha Weighted: -0.39483057429242296, D: 0.09174922566659505\n",
      "2018-11-26 13:16:19,454 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.42858120799064636\n",
      "2018-11-26 13:16:19,458 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:22,044 INFO     Weight matrix 6/9 (256,256): Alpha: 2.404906480456133, Alpha Weighted: -0.8845370679828669, D: 0.08563367103995245\n",
      "2018-11-26 13:16:22,048 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.35577142238616943\n",
      "2018-11-26 13:16:22,051 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:24,359 INFO     Weight matrix 7/9 (256,256): Alpha: 2.22860348345898, Alpha Weighted: -1.4081735396173947, D: 0.10989289925423762\n",
      "2018-11-26 13:16:24,364 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3196132481098175\n",
      "2018-11-26 13:16:24,367 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:26,801 INFO     Weight matrix 8/9 (256,256): Alpha: 2.2635404337949963, Alpha Weighted: -0.8869449661623953, D: 0.09452624867893417\n",
      "2018-11-26 13:16:26,805 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.37830421328544617\n",
      "2018-11-26 13:16:26,808 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:29,122 INFO     Weight matrix 9/9 (256,256): Alpha: 2.2508073009419105, Alpha Weighted: -1.3933619155581902, D: 0.11382837311732336\n",
      "2018-11-26 13:16:29,127 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.3314208686351776\n",
      "2018-11-26 13:16:29,129 INFO Layer 125: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:16:29,131 INFO Layer 125: Skipping (Layer not supported)\n",
      "2018-11-26 13:16:29,134 INFO Layer 126: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:16:29,138 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:16:29,141 INFO Layer 126: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:16:29,144 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:16:31,580 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.089153069991752, Alpha Weighted: 0.6011573548941376, D: 0.1013230064860654\n",
      "2018-11-26 13:16:31,582 INFO     Weight matrix 1/1 (256,1024): Alpha 4.089153069991752 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:16:31,586 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7663451433181763\n",
      "2018-11-26 13:16:31,589 INFO Layer 127: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:16:31,592 INFO Layer 127: Skipping (Layer not supported)\n",
      "2018-11-26 13:16:31,595 INFO Layer 128: ReLU(inplace)\n",
      "2018-11-26 13:16:31,598 INFO Layer 128: Skipping (Layer not supported)\n",
      "2018-11-26 13:16:31,600 INFO Layer 129: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:16:31,603 INFO Layer 129: Skipping (Layer not supported)\n",
      "2018-11-26 13:16:31,608 INFO Layer 130: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:16:31,612 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:16:31,614 INFO Layer 130: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:16:31,617 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:16:34,030 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.8270009335803472, Alpha Weighted: 0.2312817879932395, D: 0.1257641294511157\n",
      "2018-11-26 13:16:34,033 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.782488226890564\n",
      "2018-11-26 13:16:34,036 INFO Layer 131: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:16:34,042 INFO Layer 131: Skipping (Layer not supported)\n",
      "2018-11-26 13:16:34,045 INFO Layer 132: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:16:34,052 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:16:34,054 INFO Layer 132: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:16:34,057 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:36,412 INFO     Weight matrix 1/9 (256,256): Alpha: 2.7640043160079806, Alpha Weighted: -1.4678505951364034, D: 0.12081002679975517\n",
      "2018-11-26 13:16:36,416 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.35207197070121765\n",
      "2018-11-26 13:16:36,419 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:39,163 INFO     Weight matrix 2/9 (256,256): Alpha: 2.0074593351015486, Alpha Weighted: -0.5507603831850687, D: 0.10368821191479072\n",
      "2018-11-26 13:16:39,167 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.41036736965179443\n",
      "2018-11-26 13:16:39,170 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:43,394 INFO     Weight matrix 3/9 (256,256): Alpha: 1.921726888004513, Alpha Weighted: -0.9470240844089225, D: 0.12012562358908502\n",
      "2018-11-26 13:16:43,399 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.3680925667285919\n",
      "2018-11-26 13:16:43,402 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:46,413 INFO     Weight matrix 4/9 (256,256): Alpha: 2.262208895109652, Alpha Weighted: -0.5539806153493539, D: 0.09136381364506585\n",
      "2018-11-26 13:16:46,418 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.41143205761909485\n",
      "2018-11-26 13:16:46,421 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:49,047 INFO     Weight matrix 5/9 (256,256): Alpha: 1.893202205377243, Alpha Weighted: -0.21812418436966913, D: 0.11448157487498922\n",
      "2018-11-26 13:16:49,052 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.486750990152359\n",
      "2018-11-26 13:16:49,055 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:51,445 INFO     Weight matrix 6/9 (256,256): Alpha: 1.984563386592014, Alpha Weighted: -0.3940836492563923, D: 0.09365954048534053\n",
      "2018-11-26 13:16:51,450 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.4340836703777313\n",
      "2018-11-26 13:16:51,452 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:53,801 INFO     Weight matrix 7/9 (256,256): Alpha: 2.187415565354169, Alpha Weighted: -1.101322242897887, D: 0.10945915053969801\n",
      "2018-11-26 13:16:53,805 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3630320131778717\n",
      "2018-11-26 13:16:53,808 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:56,350 INFO     Weight matrix 8/9 (256,256): Alpha: 1.99199865847615, Alpha Weighted: -0.4675085383505734, D: 0.10324999281023506\n",
      "2018-11-26 13:16:56,355 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.4320828914642334\n",
      "2018-11-26 13:16:56,358 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:16:58,667 INFO     Weight matrix 9/9 (256,256): Alpha: 2.0085092354400516, Alpha Weighted: -0.9375293209858059, D: 0.1300088719477453\n",
      "2018-11-26 13:16:58,672 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.383739173412323\n",
      "2018-11-26 13:16:58,674 INFO Layer 133: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:16:58,677 INFO Layer 133: Skipping (Layer not supported)\n",
      "2018-11-26 13:16:58,680 INFO Layer 134: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:16:58,685 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:16:58,688 INFO Layer 134: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:16:58,691 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:17:01,249 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.249523341568153, Alpha Weighted: 0.8985207854839886, D: 0.10526007932412107\n",
      "2018-11-26 13:17:01,252 INFO     Weight matrix 1/1 (256,1024): Alpha 4.249523341568153 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:17:01,257 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8183230757713318\n",
      "2018-11-26 13:17:01,260 INFO Layer 135: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:17:01,264 INFO Layer 135: Skipping (Layer not supported)\n",
      "2018-11-26 13:17:01,271 INFO Layer 136: ReLU(inplace)\n",
      "2018-11-26 13:17:01,274 INFO Layer 136: Skipping (Layer not supported)\n",
      "2018-11-26 13:17:01,277 INFO Layer 137: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:17:01,281 INFO Layer 137: Skipping (Layer not supported)\n",
      "2018-11-26 13:17:01,284 INFO Layer 138: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:17:01,289 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:17:01,300 INFO Layer 138: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:17:01,302 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:17:03,754 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.3184996840229797, Alpha Weighted: 0.2574393208619271, D: 0.12290893739732867\n",
      "2018-11-26 13:17:03,757 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7919532656669617\n",
      "2018-11-26 13:17:03,760 INFO Layer 139: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:17:03,765 INFO Layer 139: Skipping (Layer not supported)\n",
      "2018-11-26 13:17:03,767 INFO Layer 140: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:17:03,772 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:17:03,777 INFO Layer 140: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:17:03,779 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:06,102 INFO     Weight matrix 1/9 (256,256): Alpha: 2.249038679037474, Alpha Weighted: -1.1137748453688414, D: 0.09160297880197277\n",
      "2018-11-26 13:17:06,107 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3554999828338623\n",
      "2018-11-26 13:17:06,110 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:08,423 INFO     Weight matrix 2/9 (256,256): Alpha: 2.1609653075234334, Alpha Weighted: -0.8805230978925508, D: 0.09973426555671683\n",
      "2018-11-26 13:17:08,428 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.41089025139808655\n",
      "2018-11-26 13:17:08,432 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:10,781 INFO     Weight matrix 3/9 (256,256): Alpha: 2.4226401973654115, Alpha Weighted: -1.2016858344920305, D: 0.10304636029706427\n",
      "2018-11-26 13:17:10,787 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.37045904994010925\n",
      "2018-11-26 13:17:10,790 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:13,080 INFO     Weight matrix 4/9 (256,256): Alpha: 2.168271675801014, Alpha Weighted: -0.761338855048955, D: 0.0816701973661938\n",
      "2018-11-26 13:17:13,085 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.4122123122215271\n",
      "2018-11-26 13:17:13,088 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:17:15,382 INFO     Weight matrix 5/9 (256,256): Alpha: 2.1821258665639656, Alpha Weighted: -0.4643507506724045, D: 0.09218661968152853\n",
      "2018-11-26 13:17:15,386 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.47894367575645447\n",
      "2018-11-26 13:17:15,389 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:17,688 INFO     Weight matrix 6/9 (256,256): Alpha: 2.1354834237947014, Alpha Weighted: -0.6456862916473431, D: 0.09113217266695345\n",
      "2018-11-26 13:17:17,693 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.43246158957481384\n",
      "2018-11-26 13:17:17,695 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:20,224 INFO     Weight matrix 7/9 (256,256): Alpha: 2.577274720148223, Alpha Weighted: -1.2373673510854812, D: 0.09595717562866879\n",
      "2018-11-26 13:17:20,229 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.371564656496048\n",
      "2018-11-26 13:17:20,233 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:23,017 INFO     Weight matrix 8/9 (256,256): Alpha: 1.971897605292098, Alpha Weighted: -0.669877561160583, D: 0.10255033924223828\n",
      "2018-11-26 13:17:23,021 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.4380660653114319\n",
      "2018-11-26 13:17:23,025 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:25,910 INFO     Weight matrix 9/9 (256,256): Alpha: 2.470387502332155, Alpha Weighted: -1.0341293703234338, D: 0.10716383948912256\n",
      "2018-11-26 13:17:25,916 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.3886481523513794\n",
      "2018-11-26 13:17:25,920 INFO Layer 141: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:17:25,924 INFO Layer 141: Skipping (Layer not supported)\n",
      "2018-11-26 13:17:25,930 INFO Layer 142: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:17:25,938 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:17:25,942 INFO Layer 142: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:17:25,946 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:17:28,838 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.210641704525478, Alpha Weighted: 0.3220417725458169, D: 0.1339190527734777\n",
      "2018-11-26 13:17:28,841 INFO     Weight matrix 1/1 (256,1024): Alpha 4.210641704525478 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:17:28,845 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8139934539794922\n",
      "2018-11-26 13:17:28,848 INFO Layer 143: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:17:28,851 INFO Layer 143: Skipping (Layer not supported)\n",
      "2018-11-26 13:17:28,854 INFO Layer 144: ReLU(inplace)\n",
      "2018-11-26 13:17:28,857 INFO Layer 144: Skipping (Layer not supported)\n",
      "2018-11-26 13:17:28,861 INFO Layer 145: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:17:28,865 INFO Layer 145: Skipping (Layer not supported)\n",
      "2018-11-26 13:17:28,867 INFO Layer 146: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:17:28,872 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:17:28,876 INFO Layer 146: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:17:28,879 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:17:31,652 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.7991433691813936, Alpha Weighted: 0.13238290706685177, D: 0.11603506241878031\n",
      "2018-11-26 13:17:31,655 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7483446002006531\n",
      "2018-11-26 13:17:31,658 INFO Layer 147: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:17:31,661 INFO Layer 147: Skipping (Layer not supported)\n",
      "2018-11-26 13:17:31,663 INFO Layer 148: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:17:31,670 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:17:31,673 INFO Layer 148: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:17:31,676 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:34,155 INFO     Weight matrix 1/9 (256,256): Alpha: 2.466990237324141, Alpha Weighted: -1.1443155329004744, D: 0.10104422136473384\n",
      "2018-11-26 13:17:34,160 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.34120869636535645\n",
      "2018-11-26 13:17:34,163 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:36,589 INFO     Weight matrix 2/9 (256,256): Alpha: 2.0429710352206376, Alpha Weighted: -0.22578646009440462, D: 0.0831069500228423\n",
      "2018-11-26 13:17:36,593 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.4264954626560211\n",
      "2018-11-26 13:17:36,596 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:39,007 INFO     Weight matrix 3/9 (256,256): Alpha: 2.532955654213329, Alpha Weighted: -1.0133854148859764, D: 0.10071363061475935\n",
      "2018-11-26 13:17:39,011 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.35696443915367126\n",
      "2018-11-26 13:17:39,014 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:41,327 INFO     Weight matrix 4/9 (256,256): Alpha: 1.9275883488319185, Alpha Weighted: -0.23123949214884723, D: 0.09177436301519643\n",
      "2018-11-26 13:17:41,332 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.4279768764972687\n",
      "2018-11-26 13:17:41,335 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:44,012 INFO     Weight matrix 5/9 (256,256): Alpha: 2.1478880723375364, Alpha Weighted: -0.041643481021812014, D: 0.10056650961108027\n",
      "2018-11-26 13:17:44,017 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.4986380338668823\n",
      "2018-11-26 13:17:44,019 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:46,279 INFO     Weight matrix 6/9 (256,256): Alpha: 1.9601400500945008, Alpha Weighted: -0.10636100465702986, D: 0.08975214499627038\n",
      "2018-11-26 13:17:46,283 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.4506444036960602\n",
      "2018-11-26 13:17:46,287 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:48,689 INFO     Weight matrix 7/9 (256,256): Alpha: 2.306604842829321, Alpha Weighted: -0.9822517332618019, D: 0.10217429663673339\n",
      "2018-11-26 13:17:48,695 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3564259707927704\n",
      "2018-11-26 13:17:48,697 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:51,008 INFO     Weight matrix 8/9 (256,256): Alpha: 1.8880384303786264, Alpha Weighted: -0.1052369388244814, D: 0.09193632627955706\n",
      "2018-11-26 13:17:51,014 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.44307905435562134\n",
      "2018-11-26 13:17:51,017 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:17:53,353 INFO     Weight matrix 9/9 (256,256): Alpha: 2.539307428599993, Alpha Weighted: -0.8981626032223917, D: 0.10274350452786973\n",
      "2018-11-26 13:17:53,358 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.37037575244903564\n",
      "2018-11-26 13:17:53,360 INFO Layer 149: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:17:53,363 INFO Layer 149: Skipping (Layer not supported)\n",
      "2018-11-26 13:17:53,366 INFO Layer 150: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:17:53,375 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:17:53,378 INFO Layer 150: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:17:53,380 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:17:55,882 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.3166446671267917, Alpha Weighted: 0.41845676536695553, D: 0.12497496546014741\n",
      "2018-11-26 13:17:55,885 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8049644827842712\n",
      "2018-11-26 13:17:55,888 INFO Layer 151: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:17:55,891 INFO Layer 151: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:17:55,894 INFO Layer 152: ReLU(inplace)\n",
      "2018-11-26 13:17:55,896 INFO Layer 152: Skipping (Layer not supported)\n",
      "2018-11-26 13:17:55,899 INFO Layer 153: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:17:55,902 INFO Layer 153: Skipping (Layer not supported)\n",
      "2018-11-26 13:17:55,906 INFO Layer 154: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:17:55,910 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:17:55,913 INFO Layer 154: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:17:55,916 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:17:58,810 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.856459113424708, Alpha Weighted: 0.5738779902721788, D: 0.0995205681372755\n",
      "2018-11-26 13:17:58,817 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8029250502586365\n",
      "2018-11-26 13:17:58,822 INFO Layer 155: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:17:58,828 INFO Layer 155: Skipping (Layer not supported)\n",
      "2018-11-26 13:17:58,834 INFO Layer 156: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:17:58,846 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:17:58,853 INFO Layer 156: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:17:58,857 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:01,596 INFO     Weight matrix 1/9 (256,256): Alpha: 2.3198398886484553, Alpha Weighted: -0.8366459762292102, D: 0.09775630744245101\n",
      "2018-11-26 13:18:01,600 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3883029520511627\n",
      "2018-11-26 13:18:01,604 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:04,138 INFO     Weight matrix 2/9 (256,256): Alpha: 2.1673945741370133, Alpha Weighted: -0.23102010682661506, D: 0.08878793138332397\n",
      "2018-11-26 13:18:04,142 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.46704062819480896\n",
      "2018-11-26 13:18:04,144 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:06,503 INFO     Weight matrix 3/9 (256,256): Alpha: 2.2343239767006406, Alpha Weighted: -0.7439824831430394, D: 0.10676421876185077\n",
      "2018-11-26 13:18:06,508 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.4049958884716034\n",
      "2018-11-26 13:18:06,510 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:08,903 INFO     Weight matrix 4/9 (256,256): Alpha: 1.961738404035739, Alpha Weighted: -0.11516281201824186, D: 0.0774084570126396\n",
      "2018-11-26 13:18:08,908 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.4678923785686493\n",
      "2018-11-26 13:18:08,911 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:11,252 INFO     Weight matrix 5/9 (256,256): Alpha: 1.8531926706548159, Alpha Weighted: -0.09594857600280396, D: 0.09694310305487502\n",
      "2018-11-26 13:18:11,256 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.5209764838218689\n",
      "2018-11-26 13:18:11,259 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:13,639 INFO     Weight matrix 6/9 (256,256): Alpha: 1.876015544967083, Alpha Weighted: -0.044970501057283396, D: 0.08686227325140733\n",
      "2018-11-26 13:18:13,644 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.49219444394111633\n",
      "2018-11-26 13:18:13,646 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:16,139 INFO     Weight matrix 7/9 (256,256): Alpha: 2.2412016252591203, Alpha Weighted: -0.7488203469060142, D: 0.09567990770795431\n",
      "2018-11-26 13:18:16,147 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.40029433369636536\n",
      "2018-11-26 13:18:16,149 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:19,036 INFO     Weight matrix 8/9 (256,256): Alpha: 1.9038375403432135, Alpha Weighted: -0.12538891682036768, D: 0.08571734254408858\n",
      "2018-11-26 13:18:19,041 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.48373958468437195\n",
      "2018-11-26 13:18:19,044 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:22,317 INFO     Weight matrix 9/9 (256,256): Alpha: 2.320193397294606, Alpha Weighted: -0.6364238146044853, D: 0.09927067252746036\n",
      "2018-11-26 13:18:22,322 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4183237850666046\n",
      "2018-11-26 13:18:22,327 INFO Layer 157: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:18:22,331 INFO Layer 157: Skipping (Layer not supported)\n",
      "2018-11-26 13:18:22,338 INFO Layer 158: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:18:22,349 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:18:22,351 INFO Layer 158: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:18:22,355 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:18:25,905 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.772550852653292, Alpha Weighted: 0.22051975601401463, D: 0.1433800263375647\n",
      "2018-11-26 13:18:25,908 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8348313570022583\n",
      "2018-11-26 13:18:25,911 INFO Layer 159: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:18:25,916 INFO Layer 159: Skipping (Layer not supported)\n",
      "2018-11-26 13:18:25,923 INFO Layer 160: ReLU(inplace)\n",
      "2018-11-26 13:18:25,927 INFO Layer 160: Skipping (Layer not supported)\n",
      "2018-11-26 13:18:25,933 INFO Layer 161: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:18:25,940 INFO Layer 161: Skipping (Layer not supported)\n",
      "2018-11-26 13:18:25,944 INFO Layer 162: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:18:25,951 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:18:25,954 INFO Layer 162: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:18:25,958 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:18:28,622 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.7757295542334144, Alpha Weighted: 0.3518315617671231, D: 0.1061841519123169\n",
      "2018-11-26 13:18:28,630 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.793337345123291\n",
      "2018-11-26 13:18:28,635 INFO Layer 163: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:18:28,640 INFO Layer 163: Skipping (Layer not supported)\n",
      "2018-11-26 13:18:28,644 INFO Layer 164: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:18:28,650 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:18:28,653 INFO Layer 164: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:18:28,657 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:31,737 INFO     Weight matrix 1/9 (256,256): Alpha: 1.9569962074873557, Alpha Weighted: -0.7131970131892305, D: 0.100654685832403\n",
      "2018-11-26 13:18:31,741 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4052611291408539\n",
      "2018-11-26 13:18:31,746 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:34,401 INFO     Weight matrix 2/9 (256,256): Alpha: 1.91647329985409, Alpha Weighted: -0.5088374432749151, D: 0.10359190459015577\n",
      "2018-11-26 13:18:34,406 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.44359397888183594\n",
      "2018-11-26 13:18:34,409 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:37,004 INFO     Weight matrix 3/9 (256,256): Alpha: 2.255382210677719, Alpha Weighted: -0.8639635322204663, D: 0.0946505191890431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:18:37,008 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.41677990555763245\n",
      "2018-11-26 13:18:37,011 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:39,845 INFO     Weight matrix 4/9 (256,256): Alpha: 2.0300340332051707, Alpha Weighted: -0.30330102122995967, D: 0.09277140677464091\n",
      "2018-11-26 13:18:39,849 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.4613741934299469\n",
      "2018-11-26 13:18:39,853 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:42,358 INFO     Weight matrix 5/9 (256,256): Alpha: 2.2651120916388257, Alpha Weighted: -0.3708839052161798, D: 0.12507718131555112\n",
      "2018-11-26 13:18:42,363 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.5053096413612366\n",
      "2018-11-26 13:18:42,367 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:44,954 INFO     Weight matrix 6/9 (256,256): Alpha: 2.143000702202573, Alpha Weighted: -0.2675974286108683, D: 0.10006410004711086\n",
      "2018-11-26 13:18:44,959 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.48256269097328186\n",
      "2018-11-26 13:18:44,962 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:47,875 INFO     Weight matrix 7/9 (256,256): Alpha: 2.300092487443994, Alpha Weighted: -0.8111288190726915, D: 0.10871080794294102\n",
      "2018-11-26 13:18:47,880 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.4149152636528015\n",
      "2018-11-26 13:18:47,885 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:50,448 INFO     Weight matrix 8/9 (256,256): Alpha: 1.8794524980641896, Alpha Weighted: -0.38877047594130354, D: 0.10662445692653322\n",
      "2018-11-26 13:18:50,452 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.4581092596054077\n",
      "2018-11-26 13:18:50,455 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:18:52,917 INFO     Weight matrix 9/9 (256,256): Alpha: 2.2522155706864737, Alpha Weighted: -0.7109367830643943, D: 0.10616769914264201\n",
      "2018-11-26 13:18:52,923 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4261789917945862\n",
      "2018-11-26 13:18:52,927 INFO Layer 165: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:18:52,930 INFO Layer 165: Skipping (Layer not supported)\n",
      "2018-11-26 13:18:52,933 INFO Layer 166: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:18:52,938 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:18:52,943 INFO Layer 166: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:18:52,946 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:18:56,324 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.813714816723249, Alpha Weighted: 0.20658733076884922, D: 0.153717305407567\n",
      "2018-11-26 13:18:56,328 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.832996666431427\n",
      "2018-11-26 13:18:56,331 INFO Layer 167: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:18:56,335 INFO Layer 167: Skipping (Layer not supported)\n",
      "2018-11-26 13:18:56,338 INFO Layer 168: ReLU(inplace)\n",
      "2018-11-26 13:18:56,342 INFO Layer 168: Skipping (Layer not supported)\n",
      "2018-11-26 13:18:56,347 INFO Layer 169: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:18:56,351 INFO Layer 169: Skipping (Layer not supported)\n",
      "2018-11-26 13:18:56,357 INFO Layer 170: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:18:56,363 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:18:56,366 INFO Layer 170: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:18:56,369 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:18:59,354 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.9101292047337914, Alpha Weighted: 0.1588442916123133, D: 0.14111690574554397\n",
      "2018-11-26 13:18:59,358 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8159905672073364\n",
      "2018-11-26 13:18:59,360 INFO Layer 171: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:18:59,363 INFO Layer 171: Skipping (Layer not supported)\n",
      "2018-11-26 13:18:59,366 INFO Layer 172: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:18:59,373 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:18:59,376 INFO Layer 172: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:18:59,379 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:02,059 INFO     Weight matrix 1/9 (256,256): Alpha: 2.18174890989626, Alpha Weighted: -0.8184347170709108, D: 0.11266655961432603\n",
      "2018-11-26 13:19:02,064 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4133481979370117\n",
      "2018-11-26 13:19:02,067 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:04,760 INFO     Weight matrix 2/9 (256,256): Alpha: 2.532040620938086, Alpha Weighted: -0.8792303907555745, D: 0.11855799930722383\n",
      "2018-11-26 13:19:04,764 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.43941110372543335\n",
      "2018-11-26 13:19:04,767 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:07,378 INFO     Weight matrix 3/9 (256,256): Alpha: 2.2763242669764256, Alpha Weighted: -0.8510721823238103, D: 0.09967873240082792\n",
      "2018-11-26 13:19:07,382 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.4207548499107361\n",
      "2018-11-26 13:19:07,385 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:10,022 INFO     Weight matrix 4/9 (256,256): Alpha: 2.0620386719368025, Alpha Weighted: -0.6858546441095736, D: 0.10035744848513761\n",
      "2018-11-26 13:19:10,026 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.42667320370674133\n",
      "2018-11-26 13:19:10,029 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:12,617 INFO     Weight matrix 5/9 (256,256): Alpha: 2.646017694129487, Alpha Weighted: -0.3627610118010372, D: 0.1069937772556161\n",
      "2018-11-26 13:19:12,624 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.46430638432502747\n",
      "2018-11-26 13:19:12,629 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:15,383 INFO     Weight matrix 6/9 (256,256): Alpha: 2.051847050248978, Alpha Weighted: -0.6235214702249715, D: 0.10316545306995317\n",
      "2018-11-26 13:19:15,386 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.44027790427207947\n",
      "2018-11-26 13:19:15,389 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:18,064 INFO     Weight matrix 7/9 (256,256): Alpha: 2.374806550044329, Alpha Weighted: -0.8728788686925328, D: 0.11741056986317389\n",
      "2018-11-26 13:19:18,068 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.42020416259765625\n",
      "2018-11-26 13:19:18,071 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:21,425 INFO     Weight matrix 8/9 (256,256): Alpha: 1.9911384445226423, Alpha Weighted: -0.6786025060469185, D: 0.12374373238399894\n",
      "2018-11-26 13:19:21,434 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.44917595386505127\n",
      "2018-11-26 13:19:21,437 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:24,145 INFO     Weight matrix 9/9 (256,256): Alpha: 2.2625046502936232, Alpha Weighted: -0.8067611192114307, D: 0.11491762870456823\n",
      "2018-11-26 13:19:24,149 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4256148040294647\n",
      "2018-11-26 13:19:24,151 INFO Layer 173: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:19:24,154 INFO Layer 173: Skipping (Layer not supported)\n",
      "2018-11-26 13:19:24,157 INFO Layer 174: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:19:24,162 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:19:24,164 INFO Layer 174: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:19:24,168 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:19:26,924 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.380235953445571, Alpha Weighted: 1.4233157688287477, D: 0.09258546862224992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:19:26,928 INFO     Weight matrix 1/1 (256,1024): Alpha 5.380235953445571 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:19:26,933 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8275728821754456\n",
      "2018-11-26 13:19:26,938 INFO Layer 175: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:19:26,941 INFO Layer 175: Skipping (Layer not supported)\n",
      "2018-11-26 13:19:26,945 INFO Layer 176: ReLU(inplace)\n",
      "2018-11-26 13:19:26,949 INFO Layer 176: Skipping (Layer not supported)\n",
      "2018-11-26 13:19:26,953 INFO Layer 177: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:19:26,958 INFO Layer 177: Skipping (Layer not supported)\n",
      "2018-11-26 13:19:26,961 INFO Layer 178: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:19:26,973 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:19:26,979 INFO Layer 178: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:19:26,986 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:19:30,827 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.15852376508517, Alpha Weighted: 0.5314344105906085, D: 0.13584698317589466\n",
      "2018-11-26 13:19:30,830 INFO     Weight matrix 1/1 (256,1024): Alpha 5.15852376508517 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:19:30,836 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8391174077987671\n",
      "2018-11-26 13:19:30,842 INFO Layer 179: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:19:30,846 INFO Layer 179: Skipping (Layer not supported)\n",
      "2018-11-26 13:19:30,850 INFO Layer 180: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:19:30,856 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:19:30,861 INFO Layer 180: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:19:30,865 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:33,716 INFO     Weight matrix 1/9 (256,256): Alpha: 2.600439494178544, Alpha Weighted: -1.0282625684623308, D: 0.10112492505306103\n",
      "2018-11-26 13:19:33,720 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.40747806429862976\n",
      "2018-11-26 13:19:33,727 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:36,679 INFO     Weight matrix 2/9 (256,256): Alpha: 2.3821543927233084, Alpha Weighted: -0.9947535403871562, D: 0.11282984628408987\n",
      "2018-11-26 13:19:36,685 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.42941102385520935\n",
      "2018-11-26 13:19:36,689 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:39,597 INFO     Weight matrix 3/9 (256,256): Alpha: 2.225182065866132, Alpha Weighted: -0.8317193617050734, D: 0.10844101749900859\n",
      "2018-11-26 13:19:39,601 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.416846364736557\n",
      "2018-11-26 13:19:39,605 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:42,384 INFO     Weight matrix 4/9 (256,256): Alpha: 2.1329948654822988, Alpha Weighted: -0.7923113192496346, D: 0.10763234368877789\n",
      "2018-11-26 13:19:42,389 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.4315152168273926\n",
      "2018-11-26 13:19:42,392 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:45,369 INFO     Weight matrix 5/9 (256,256): Alpha: 2.695011302871266, Alpha Weighted: -0.8811571136946499, D: 0.11797455749252705\n",
      "2018-11-26 13:19:45,374 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.472497820854187\n",
      "2018-11-26 13:19:45,377 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:48,142 INFO     Weight matrix 6/9 (256,256): Alpha: 2.397752368598961, Alpha Weighted: -0.8477554744583163, D: 0.12129320555423173\n",
      "2018-11-26 13:19:48,147 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.4442279636859894\n",
      "2018-11-26 13:19:48,151 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:51,012 INFO     Weight matrix 7/9 (256,256): Alpha: 2.1664262090399564, Alpha Weighted: -0.8876741886891145, D: 0.11381362807578466\n",
      "2018-11-26 13:19:51,017 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.4194834232330322\n",
      "2018-11-26 13:19:51,019 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:53,572 INFO     Weight matrix 8/9 (256,256): Alpha: 1.8874423293074964, Alpha Weighted: -0.8110985198825349, D: 0.14042744160630655\n",
      "2018-11-26 13:19:53,579 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.4479857087135315\n",
      "2018-11-26 13:19:53,582 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:19:56,331 INFO     Weight matrix 9/9 (256,256): Alpha: 2.4230601179529168, Alpha Weighted: -0.9752837281005137, D: 0.11886352629463809\n",
      "2018-11-26 13:19:56,336 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4275527894496918\n",
      "2018-11-26 13:19:56,339 INFO Layer 181: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:19:56,344 INFO Layer 181: Skipping (Layer not supported)\n",
      "2018-11-26 13:19:56,347 INFO Layer 182: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:19:56,353 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:19:56,356 INFO Layer 182: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:19:56,359 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:19:58,832 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.3669216668304593, Alpha Weighted: 0.29191254802744543, D: 0.13766709424737955\n",
      "2018-11-26 13:19:58,837 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8274749517440796\n",
      "2018-11-26 13:19:58,841 INFO Layer 183: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:19:58,844 INFO Layer 183: Skipping (Layer not supported)\n",
      "2018-11-26 13:19:58,847 INFO Layer 184: ReLU(inplace)\n",
      "2018-11-26 13:19:58,849 INFO Layer 184: Skipping (Layer not supported)\n",
      "2018-11-26 13:19:58,852 INFO Layer 185: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:19:58,855 INFO Layer 185: Skipping (Layer not supported)\n",
      "2018-11-26 13:19:58,858 INFO Layer 186: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:19:58,862 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:19:58,864 INFO Layer 186: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:19:58,867 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:20:01,402 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.6239368760213138, Alpha Weighted: 0.5213158971521292, D: 0.1256597110928565\n",
      "2018-11-26 13:20:01,404 INFO     Weight matrix 1/1 (256,1024): Alpha 3.6239368760213138 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:20:01,408 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8566838502883911\n",
      "2018-11-26 13:20:01,410 INFO Layer 187: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:20:01,413 INFO Layer 187: Skipping (Layer not supported)\n",
      "2018-11-26 13:20:01,416 INFO Layer 188: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:20:01,422 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:20:01,424 INFO Layer 188: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:20:01,427 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:04,129 INFO     Weight matrix 1/9 (256,256): Alpha: 2.3848312554926454, Alpha Weighted: -1.0103655229470059, D: 0.11038771145945814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:20:04,133 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.42139095067977905\n",
      "2018-11-26 13:20:04,140 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:06,790 INFO     Weight matrix 2/9 (256,256): Alpha: 2.901304508269047, Alpha Weighted: -1.319885466578479, D: 0.11939343451709494\n",
      "2018-11-26 13:20:06,794 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.4417199194431305\n",
      "2018-11-26 13:20:06,797 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:09,403 INFO     Weight matrix 3/9 (256,256): Alpha: 2.428302448854614, Alpha Weighted: -1.038979834304428, D: 0.11130643556253872\n",
      "2018-11-26 13:20:09,407 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.42854219675064087\n",
      "2018-11-26 13:20:09,411 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:11,903 INFO     Weight matrix 4/9 (256,256): Alpha: 2.61441586739039, Alpha Weighted: -1.3619642577668032, D: 0.09596206954774966\n",
      "2018-11-26 13:20:11,908 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.40897417068481445\n",
      "2018-11-26 13:20:11,911 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:14,379 INFO     Weight matrix 5/9 (256,256): Alpha: 2.7884564162905168, Alpha Weighted: -0.4332553044348155, D: 0.09020576504808236\n",
      "2018-11-26 13:20:14,385 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.4634205102920532\n",
      "2018-11-26 13:20:14,389 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:16,863 INFO     Weight matrix 6/9 (256,256): Alpha: 2.687268812892736, Alpha Weighted: -1.3805624536749677, D: 0.10978009974732028\n",
      "2018-11-26 13:20:16,867 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.4183676540851593\n",
      "2018-11-26 13:20:16,870 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:19,558 INFO     Weight matrix 7/9 (256,256): Alpha: 2.43664969885819, Alpha Weighted: -1.1071598205603246, D: 0.10580309482987371\n",
      "2018-11-26 13:20:19,562 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.42958584427833557\n",
      "2018-11-26 13:20:19,564 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:22,282 INFO     Weight matrix 8/9 (256,256): Alpha: 2.7048256532774966, Alpha Weighted: -1.2513004518232116, D: 0.11146628449421986\n",
      "2018-11-26 13:20:22,286 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.447494775056839\n",
      "2018-11-26 13:20:22,289 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:24,759 INFO     Weight matrix 9/9 (256,256): Alpha: 2.326288008945199, Alpha Weighted: -1.056059178811158, D: 0.11243480682096035\n",
      "2018-11-26 13:20:24,764 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4377341568470001\n",
      "2018-11-26 13:20:24,766 INFO Layer 189: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:20:24,769 INFO Layer 189: Skipping (Layer not supported)\n",
      "2018-11-26 13:20:24,772 INFO Layer 190: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:20:24,776 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:20:24,779 INFO Layer 190: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:20:24,781 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:20:27,212 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.2516799203426205, Alpha Weighted: 0.4077199828307935, D: 0.10030665280587825\n",
      "2018-11-26 13:20:27,216 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8170077800750732\n",
      "2018-11-26 13:20:27,219 INFO Layer 191: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:20:27,225 INFO Layer 191: Skipping (Layer not supported)\n",
      "2018-11-26 13:20:27,227 INFO Layer 192: ReLU(inplace)\n",
      "2018-11-26 13:20:27,230 INFO Layer 192: Skipping (Layer not supported)\n",
      "2018-11-26 13:20:27,233 INFO Layer 193: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:20:27,236 INFO Layer 193: Skipping (Layer not supported)\n",
      "2018-11-26 13:20:27,238 INFO Layer 194: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:20:27,243 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:20:27,245 INFO Layer 194: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:20:27,248 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:20:29,680 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.5245349721035355, Alpha Weighted: 0.25539656571064184, D: 0.1285448105213957\n",
      "2018-11-26 13:20:29,684 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.797701358795166\n",
      "2018-11-26 13:20:29,689 INFO Layer 195: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:20:29,691 INFO Layer 195: Skipping (Layer not supported)\n",
      "2018-11-26 13:20:29,693 INFO Layer 196: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:20:29,699 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:20:29,702 INFO Layer 196: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:20:29,705 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:32,077 INFO     Weight matrix 1/9 (256,256): Alpha: 1.921598252710798, Alpha Weighted: -0.6281062242759183, D: 0.1015435360764157\n",
      "2018-11-26 13:20:32,081 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4038289785385132\n",
      "2018-11-26 13:20:32,084 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:34,413 INFO     Weight matrix 2/9 (256,256): Alpha: 2.148757454930734, Alpha Weighted: -0.9357797644835778, D: 0.10201750248599173\n",
      "2018-11-26 13:20:34,418 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.39292120933532715\n",
      "2018-11-26 13:20:34,421 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:36,745 INFO     Weight matrix 3/9 (256,256): Alpha: 2.047065094773802, Alpha Weighted: -0.6472341289437503, D: 0.0889299939774405\n",
      "2018-11-26 13:20:36,749 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.41369184851646423\n",
      "2018-11-26 13:20:36,755 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:39,062 INFO     Weight matrix 4/9 (256,256): Alpha: 2.140676531084959, Alpha Weighted: -0.9595932067004407, D: 0.10563109233336687\n",
      "2018-11-26 13:20:39,066 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3834032416343689\n",
      "2018-11-26 13:20:39,069 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:41,380 INFO     Weight matrix 5/9 (256,256): Alpha: 2.9167648871247707, Alpha Weighted: -1.0726732872708793, D: 0.12289719322582521\n",
      "2018-11-26 13:20:41,384 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.3899041712284088\n",
      "2018-11-26 13:20:41,386 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:43,880 INFO     Weight matrix 6/9 (256,256): Alpha: 2.1694647984299866, Alpha Weighted: -0.9602518264147489, D: 0.10604679547174328\n",
      "2018-11-26 13:20:43,884 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.3922339379787445\n",
      "2018-11-26 13:20:43,887 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:46,507 INFO     Weight matrix 7/9 (256,256): Alpha: 2.096212946836597, Alpha Weighted: -0.679164188220183, D: 0.08823064348446241\n",
      "2018-11-26 13:20:46,512 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.4044070839881897\n",
      "2018-11-26 13:20:46,515 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:49,318 INFO     Weight matrix 8/9 (256,256): Alpha: 2.028399133599641, Alpha Weighted: -0.9496995535804597, D: 0.11562200001058393\n",
      "2018-11-26 13:20:49,323 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.3912183344364166\n",
      "2018-11-26 13:20:49,326 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:51,840 INFO     Weight matrix 9/9 (256,256): Alpha: 2.1221829735211366, Alpha Weighted: -0.6617000096572794, D: 0.08915691899949502\n",
      "2018-11-26 13:20:51,847 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4133688807487488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:20:51,850 INFO Layer 197: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:20:51,854 INFO Layer 197: Skipping (Layer not supported)\n",
      "2018-11-26 13:20:51,857 INFO Layer 198: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:20:51,862 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:20:51,864 INFO Layer 198: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:20:51,866 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:20:54,615 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.8658369049998793, Alpha Weighted: 0.15121597673419704, D: 0.13204331938848457\n",
      "2018-11-26 13:20:54,618 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7707751989364624\n",
      "2018-11-26 13:20:54,621 INFO Layer 199: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:20:54,628 INFO Layer 199: Skipping (Layer not supported)\n",
      "2018-11-26 13:20:54,632 INFO Layer 200: ReLU(inplace)\n",
      "2018-11-26 13:20:54,634 INFO Layer 200: Skipping (Layer not supported)\n",
      "2018-11-26 13:20:54,637 INFO Layer 201: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:20:54,640 INFO Layer 201: Skipping (Layer not supported)\n",
      "2018-11-26 13:20:54,642 INFO Layer 202: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:20:54,647 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:20:54,650 INFO Layer 202: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:20:54,652 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:20:57,474 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.0859903539065314, Alpha Weighted: 0.06757901768282952, D: 0.14384790671510095\n",
      "2018-11-26 13:20:57,477 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8159993290901184\n",
      "2018-11-26 13:20:57,480 INFO Layer 203: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:20:57,482 INFO Layer 203: Skipping (Layer not supported)\n",
      "2018-11-26 13:20:57,485 INFO Layer 204: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:20:57,490 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:20:57,493 INFO Layer 204: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:20:57,496 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:20:59,851 INFO     Weight matrix 1/9 (256,256): Alpha: 2.186774059978983, Alpha Weighted: -0.7309588239350215, D: 0.09807398871331285\n",
      "2018-11-26 13:20:59,858 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.39736196398735046\n",
      "2018-11-26 13:20:59,860 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:02,358 INFO     Weight matrix 2/9 (256,256): Alpha: 2.3378269430865473, Alpha Weighted: -1.1370957039460141, D: 0.11799870984506788\n",
      "2018-11-26 13:21:02,363 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.38682469725608826\n",
      "2018-11-26 13:21:02,367 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:04,833 INFO     Weight matrix 3/9 (256,256): Alpha: 1.897091351849901, Alpha Weighted: -0.6490620511672037, D: 0.11318214089697198\n",
      "2018-11-26 13:21:04,838 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.39993682503700256\n",
      "2018-11-26 13:21:04,840 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:07,312 INFO     Weight matrix 4/9 (256,256): Alpha: 2.3723575330874, Alpha Weighted: -1.080346639315756, D: 0.0932238107238757\n",
      "2018-11-26 13:21:07,316 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3689732849597931\n",
      "2018-11-26 13:21:07,318 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:09,894 INFO     Weight matrix 5/9 (256,256): Alpha: 1.886734992203153, Alpha Weighted: -0.6696305366406613, D: 0.11660118319855728\n",
      "2018-11-26 13:21:09,900 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.40878063440322876\n",
      "2018-11-26 13:21:09,902 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:12,552 INFO     Weight matrix 6/9 (256,256): Alpha: 2.3889701182670127, Alpha Weighted: -1.1566597350006864, D: 0.10782686317445817\n",
      "2018-11-26 13:21:12,556 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.3763441741466522\n",
      "2018-11-26 13:21:12,559 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:15,219 INFO     Weight matrix 7/9 (256,256): Alpha: 2.4179726745228978, Alpha Weighted: -0.803371274681872, D: 0.10628530220352939\n",
      "2018-11-26 13:21:15,224 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3987762928009033\n",
      "2018-11-26 13:21:15,228 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:17,963 INFO     Weight matrix 8/9 (256,256): Alpha: 2.269161651483396, Alpha Weighted: -1.161919969569908, D: 0.12340494288012915\n",
      "2018-11-26 13:21:17,967 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.38784849643707275\n",
      "2018-11-26 13:21:17,970 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:20,440 INFO     Weight matrix 9/9 (256,256): Alpha: 2.2765618335043087, Alpha Weighted: -0.7503359333421696, D: 0.09852371353487466\n",
      "2018-11-26 13:21:20,446 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4035017788410187\n",
      "2018-11-26 13:21:20,450 INFO Layer 205: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:21:20,453 INFO Layer 205: Skipping (Layer not supported)\n",
      "2018-11-26 13:21:20,456 INFO Layer 206: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:21:20,462 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:21:20,464 INFO Layer 206: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:21:20,467 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:21:23,014 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.5587651671648395, Alpha Weighted: 0.28704317767778625, D: 0.12388113539348816\n",
      "2018-11-26 13:21:23,017 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7660306692123413\n",
      "2018-11-26 13:21:23,020 INFO Layer 207: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:21:23,022 INFO Layer 207: Skipping (Layer not supported)\n",
      "2018-11-26 13:21:23,024 INFO Layer 208: ReLU(inplace)\n",
      "2018-11-26 13:21:23,026 INFO Layer 208: Skipping (Layer not supported)\n",
      "2018-11-26 13:21:23,030 INFO Layer 209: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:21:23,033 INFO Layer 209: Skipping (Layer not supported)\n",
      "2018-11-26 13:21:23,035 INFO Layer 210: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:21:23,041 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:21:23,043 INFO Layer 210: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:21:23,046 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:21:25,912 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.96708675266429, Alpha Weighted: 0.33116376656625396, D: 0.11996044278337903\n",
      "2018-11-26 13:21:25,916 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8350929617881775\n",
      "2018-11-26 13:21:25,918 INFO Layer 211: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:21:25,922 INFO Layer 211: Skipping (Layer not supported)\n",
      "2018-11-26 13:21:25,925 INFO Layer 212: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:21:25,930 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:21:25,934 INFO Layer 212: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:21:25,938 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:28,551 INFO     Weight matrix 1/9 (256,256): Alpha: 1.8538893270605814, Alpha Weighted: -0.48115737065058445, D: 0.10219944645795209\n",
      "2018-11-26 13:21:28,555 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4359111189842224\n",
      "2018-11-26 13:21:28,560 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:31,301 INFO     Weight matrix 2/9 (256,256): Alpha: 2.2351216082768968, Alpha Weighted: -1.0956812876316735, D: 0.11553502400950966\n",
      "2018-11-26 13:21:31,307 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.40365567803382874\n",
      "2018-11-26 13:21:31,310 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:33,868 INFO     Weight matrix 3/9 (256,256): Alpha: 1.857838173782411, Alpha Weighted: -0.4699962219297414, D: 0.1012339207319577\n",
      "2018-11-26 13:21:33,873 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.44157952070236206\n",
      "2018-11-26 13:21:33,876 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:36,791 INFO     Weight matrix 4/9 (256,256): Alpha: 1.9174700377993878, Alpha Weighted: -0.6568255509241318, D: 0.10784267913381651\n",
      "2018-11-26 13:21:36,796 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.42816486954689026\n",
      "2018-11-26 13:21:36,801 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:39,384 INFO     Weight matrix 5/9 (256,256): Alpha: 2.352476667100358, Alpha Weighted: -0.7106990523317358, D: 0.11437602627739318\n",
      "2018-11-26 13:21:39,389 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.43192002177238464\n",
      "2018-11-26 13:21:39,392 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:41,826 INFO     Weight matrix 6/9 (256,256): Alpha: 2.007440103712434, Alpha Weighted: -0.6928575895806586, D: 0.10647837880795402\n",
      "2018-11-26 13:21:41,831 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.43634629249572754\n",
      "2018-11-26 13:21:41,834 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:44,284 INFO     Weight matrix 7/9 (256,256): Alpha: 2.001338211194001, Alpha Weighted: -0.5558908049456359, D: 0.09513675480558165\n",
      "2018-11-26 13:21:44,288 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.4425865411758423\n",
      "2018-11-26 13:21:44,291 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:46,823 INFO     Weight matrix 8/9 (256,256): Alpha: 2.1862542526584967, Alpha Weighted: -1.0333914984050563, D: 0.11692689666020872\n",
      "2018-11-26 13:21:46,828 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.41171950101852417\n",
      "2018-11-26 13:21:46,831 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:49,669 INFO     Weight matrix 9/9 (256,256): Alpha: 2.061757164953373, Alpha Weighted: -0.553861251831542, D: 0.10423186299298093\n",
      "2018-11-26 13:21:49,674 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.44745126366615295\n",
      "2018-11-26 13:21:49,678 INFO Layer 213: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:21:49,681 INFO Layer 213: Skipping (Layer not supported)\n",
      "2018-11-26 13:21:49,685 INFO Layer 214: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:21:49,689 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:21:49,693 INFO Layer 214: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:21:49,696 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:21:52,858 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.8147961969848039, Alpha Weighted: 0.10558067257281918, D: 0.15228781127487978\n",
      "2018-11-26 13:21:52,861 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8145038485527039\n",
      "2018-11-26 13:21:52,864 INFO Layer 215: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:21:52,866 INFO Layer 215: Skipping (Layer not supported)\n",
      "2018-11-26 13:21:52,869 INFO Layer 216: ReLU(inplace)\n",
      "2018-11-26 13:21:52,871 INFO Layer 216: Skipping (Layer not supported)\n",
      "2018-11-26 13:21:52,874 INFO Layer 217: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:21:52,877 INFO Layer 217: Skipping (Layer not supported)\n",
      "2018-11-26 13:21:52,880 INFO Layer 218: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:21:52,885 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:21:52,889 INFO Layer 218: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:21:52,892 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:21:55,396 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.2401544510123763, Alpha Weighted: 0.07977849616570674, D: 0.15583215915726384\n",
      "2018-11-26 13:21:55,400 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8540765047073364\n",
      "2018-11-26 13:21:55,403 INFO Layer 219: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:21:55,406 INFO Layer 219: Skipping (Layer not supported)\n",
      "2018-11-26 13:21:55,410 INFO Layer 220: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:21:55,416 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:21:55,419 INFO Layer 220: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:21:55,423 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:21:58,047 INFO     Weight matrix 1/9 (256,256): Alpha: 2.30470682682168, Alpha Weighted: -0.8201682078185276, D: 0.10117791895135891\n",
      "2018-11-26 13:21:58,053 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4273497760295868\n",
      "2018-11-26 13:21:58,056 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:00,895 INFO     Weight matrix 2/9 (256,256): Alpha: 2.340145700630384, Alpha Weighted: -1.0468685620850047, D: 0.1175237430612111\n",
      "2018-11-26 13:22:00,900 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.4420238137245178\n",
      "2018-11-26 13:22:00,903 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:03,257 INFO     Weight matrix 3/9 (256,256): Alpha: 2.377531676512669, Alpha Weighted: -0.8234185923155324, D: 0.10430987198295594\n",
      "2018-11-26 13:22:03,261 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.43437254428863525\n",
      "2018-11-26 13:22:03,263 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:05,613 INFO     Weight matrix 4/9 (256,256): Alpha: 2.6115396792975876, Alpha Weighted: -1.2911241114573138, D: 0.09117462734573689\n",
      "2018-11-26 13:22:05,618 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3977513611316681\n",
      "2018-11-26 13:22:05,620 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:07,940 INFO     Weight matrix 5/9 (256,256): Alpha: 2.3948764989032427, Alpha Weighted: -0.6960384039548269, D: 0.1012924522090714\n",
      "2018-11-26 13:22:07,945 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.4452415704727173\n",
      "2018-11-26 13:22:07,949 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:10,611 INFO     Weight matrix 6/9 (256,256): Alpha: 2.7579284912539945, Alpha Weighted: -1.2571194420743348, D: 0.09217511297235159\n",
      "2018-11-26 13:22:10,616 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.408196359872818\n",
      "2018-11-26 13:22:10,618 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:13,272 INFO     Weight matrix 7/9 (256,256): Alpha: 2.480676145537875, Alpha Weighted: -0.8835799018613358, D: 0.09747875819226437\n",
      "2018-11-26 13:22:13,276 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.4310586750507355\n",
      "2018-11-26 13:22:13,281 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:16,162 INFO     Weight matrix 8/9 (256,256): Alpha: 2.2483664886764347, Alpha Weighted: -0.9801128783995459, D: 0.12685204331948408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:22:16,166 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.4440824091434479\n",
      "2018-11-26 13:22:16,169 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:19,311 INFO     Weight matrix 9/9 (256,256): Alpha: 2.3866295072483297, Alpha Weighted: -0.8481473037581715, D: 0.10489736908554809\n",
      "2018-11-26 13:22:19,316 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.44159260392189026\n",
      "2018-11-26 13:22:19,319 INFO Layer 221: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:22:19,324 INFO Layer 221: Skipping (Layer not supported)\n",
      "2018-11-26 13:22:19,326 INFO Layer 222: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:22:19,332 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:22:19,336 INFO Layer 222: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:22:19,340 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:22:22,588 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.8854406657958, Alpha Weighted: 0.5396622550079743, D: 0.10073147840492236\n",
      "2018-11-26 13:22:22,592 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.821229100227356\n",
      "2018-11-26 13:22:22,594 INFO Layer 223: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:22:22,598 INFO Layer 223: Skipping (Layer not supported)\n",
      "2018-11-26 13:22:22,601 INFO Layer 224: ReLU(inplace)\n",
      "2018-11-26 13:22:22,604 INFO Layer 224: Skipping (Layer not supported)\n",
      "2018-11-26 13:22:22,608 INFO Layer 225: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:22:22,611 INFO Layer 225: Skipping (Layer not supported)\n",
      "2018-11-26 13:22:22,615 INFO Layer 226: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:22:22,619 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:22:22,623 INFO Layer 226: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:22:22,627 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:22:25,442 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.450351314045683, Alpha Weighted: 0.7534039139809693, D: 0.1090516222242287\n",
      "2018-11-26 13:22:25,445 INFO     Weight matrix 1/1 (256,1024): Alpha 4.450351314045683 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:22:25,448 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.9085201025009155\n",
      "2018-11-26 13:22:25,451 INFO Layer 227: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:22:25,455 INFO Layer 227: Skipping (Layer not supported)\n",
      "2018-11-26 13:22:25,458 INFO Layer 228: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:22:25,464 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:22:25,467 INFO Layer 228: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:22:25,470 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:28,307 INFO     Weight matrix 1/9 (256,256): Alpha: 2.8910169370666923, Alpha Weighted: -1.1370769300346548, D: 0.0791646134220283\n",
      "2018-11-26 13:22:28,311 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.43076080083847046\n",
      "2018-11-26 13:22:28,314 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:31,171 INFO     Weight matrix 2/9 (256,256): Alpha: 2.6980512690793743, Alpha Weighted: -1.2356215364580256, D: 0.12743739834064904\n",
      "2018-11-26 13:22:31,175 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.4945143759250641\n",
      "2018-11-26 13:22:31,179 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:33,574 INFO     Weight matrix 3/9 (256,256): Alpha: 4.009033304716028, Alpha Weighted: -1.4438689145584929, D: 0.09236928557316615\n",
      "2018-11-26 13:22:33,576 INFO     Weight matrix 3/9 (256,256): Alpha 4.009033304716028 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:22:33,580 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.44122347235679626\n",
      "2018-11-26 13:22:33,584 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:35,978 INFO     Weight matrix 4/9 (256,256): Alpha: 4.189977649653575, Alpha Weighted: -2.5925066141485544, D: 0.08784335034054824\n",
      "2018-11-26 13:22:35,980 INFO     Weight matrix 4/9 (256,256): Alpha 4.189977649653575 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:22:35,985 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.40601274371147156\n",
      "2018-11-26 13:22:35,988 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:38,329 INFO     Weight matrix 5/9 (256,256): Alpha: 2.8053884601949743, Alpha Weighted: -0.552495474279924, D: 0.0975086398758061\n",
      "2018-11-26 13:22:38,333 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.543887197971344\n",
      "2018-11-26 13:22:38,336 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:41,015 INFO     Weight matrix 6/9 (256,256): Alpha: 5.08027448902185, Alpha Weighted: -3.1723663427316815, D: 0.11235909473756545\n",
      "2018-11-26 13:22:41,018 INFO     Weight matrix 6/9 (256,256): Alpha 5.08027448902185 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:22:41,022 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.4226885735988617\n",
      "2018-11-26 13:22:41,026 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:43,485 INFO     Weight matrix 7/9 (256,256): Alpha: 3.2526894171385603, Alpha Weighted: -1.3070330925126765, D: 0.0842514774047633\n",
      "2018-11-26 13:22:43,490 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.43984371423721313\n",
      "2018-11-26 13:22:43,495 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:46,012 INFO     Weight matrix 8/9 (256,256): Alpha: 2.897491748861537, Alpha Weighted: -1.2949663768817912, D: 0.14270598685930475\n",
      "2018-11-26 13:22:46,016 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.5107027888298035\n",
      "2018-11-26 13:22:46,018 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:48,639 INFO     Weight matrix 9/9 (256,256): Alpha: 3.869525786843133, Alpha Weighted: -1.4762793485117982, D: 0.07777967567468502\n",
      "2018-11-26 13:22:48,642 INFO     Weight matrix 9/9 (256,256): Alpha 3.869525786843133 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:22:48,649 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.45527634024620056\n",
      "2018-11-26 13:22:48,652 INFO Layer 229: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:22:48,655 INFO Layer 229: Skipping (Layer not supported)\n",
      "2018-11-26 13:22:48,659 INFO Layer 230: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:22:48,665 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:22:48,669 INFO Layer 230: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:22:48,673 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:22:51,564 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.75248791736929, Alpha Weighted: 1.0553166933109364, D: 0.07053829966439595\n",
      "2018-11-26 13:22:51,567 INFO     Weight matrix 1/1 (256,1024): Alpha 4.75248791736929 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:22:51,570 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8632466793060303\n",
      "2018-11-26 13:22:51,572 INFO Layer 231: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:22:51,574 INFO Layer 231: Skipping (Layer not supported)\n",
      "2018-11-26 13:22:51,577 INFO Layer 232: ReLU(inplace)\n",
      "2018-11-26 13:22:51,580 INFO Layer 232: Skipping (Layer not supported)\n",
      "2018-11-26 13:22:51,583 INFO Layer 233: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:22:51,586 INFO Layer 233: Skipping (Layer not supported)\n",
      "2018-11-26 13:22:51,589 INFO Layer 234: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:22:51,600 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:22:51,603 INFO Layer 234: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:22:51,606 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:22:54,485 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.595537003902988, Alpha Weighted: 0.9147996552667834, D: 0.12426756499602704\n",
      "2018-11-26 13:22:54,488 INFO     Weight matrix 1/1 (256,1024): Alpha 5.595537003902988 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:22:54,491 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.9294024109840393\n",
      "2018-11-26 13:22:54,495 INFO Layer 235: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:22:54,499 INFO Layer 235: Skipping (Layer not supported)\n",
      "2018-11-26 13:22:54,503 INFO Layer 236: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:22:54,509 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:22:54,513 INFO Layer 236: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:22:54,517 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:57,143 INFO     Weight matrix 1/9 (256,256): Alpha: 3.330717487282381, Alpha Weighted: -1.0318846634761136, D: 0.06273382964366747\n",
      "2018-11-26 13:22:57,148 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4399292469024658\n",
      "2018-11-26 13:22:57,153 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:22:59,738 INFO     Weight matrix 2/9 (256,256): Alpha: 3.1472816273165676, Alpha Weighted: -1.5637468045695333, D: 0.1442026165872064\n",
      "2018-11-26 13:22:59,743 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.5032614469528198\n",
      "2018-11-26 13:22:59,746 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:02,444 INFO     Weight matrix 3/9 (256,256): Alpha: 3.5110074218964433, Alpha Weighted: -1.0123798974339515, D: 0.08321483362061691\n",
      "2018-11-26 13:23:02,446 INFO     Weight matrix 3/9 (256,256): Alpha 3.5110074218964433 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:02,451 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.45613840222358704\n",
      "2018-11-26 13:23:02,455 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:05,139 INFO     Weight matrix 4/9 (256,256): Alpha: 5.052656043871251, Alpha Weighted: -2.9416008882361013, D: 0.08863463674898098\n",
      "2018-11-26 13:23:05,142 INFO     Weight matrix 4/9 (256,256): Alpha 5.052656043871251 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:05,149 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.41761088371276855\n",
      "2018-11-26 13:23:05,153 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:07,591 INFO     Weight matrix 5/9 (256,256): Alpha: 3.4902733387177722, Alpha Weighted: -1.0454999256209425, D: 0.11392309754226726\n",
      "2018-11-26 13:23:07,596 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.5355498790740967\n",
      "2018-11-26 13:23:07,598 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:10,077 INFO     Weight matrix 6/9 (256,256): Alpha: 4.450803396181939, Alpha Weighted: -2.6024528731219903, D: 0.09793284750480441\n",
      "2018-11-26 13:23:10,080 INFO     Weight matrix 6/9 (256,256): Alpha 4.450803396181939 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:10,084 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.440120130777359\n",
      "2018-11-26 13:23:10,087 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:12,447 INFO     Weight matrix 7/9 (256,256): Alpha: 3.9091050631414954, Alpha Weighted: -1.1342451893157983, D: 0.07142857142857117\n",
      "2018-11-26 13:23:12,450 INFO     Weight matrix 7/9 (256,256): Alpha 3.9091050631414954 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:12,456 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.4533270299434662\n",
      "2018-11-26 13:23:12,459 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:15,136 INFO     Weight matrix 8/9 (256,256): Alpha: 2.8270334550575225, Alpha Weighted: -1.310199227516571, D: 0.1545308590105332\n",
      "2018-11-26 13:23:15,141 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.5229128003120422\n",
      "2018-11-26 13:23:15,145 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:18,306 INFO     Weight matrix 9/9 (256,256): Alpha: 3.67934089905982, Alpha Weighted: -1.0913506781053572, D: 0.0901493934040587\n",
      "2018-11-26 13:23:18,310 INFO     Weight matrix 9/9 (256,256): Alpha 3.67934089905982 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:18,315 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4735083281993866\n",
      "2018-11-26 13:23:18,318 INFO Layer 237: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:23:18,323 INFO Layer 237: Skipping (Layer not supported)\n",
      "2018-11-26 13:23:18,325 INFO Layer 238: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:23:18,334 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:23:18,338 INFO Layer 238: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:23:18,342 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:23:21,285 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.2855660264332744, Alpha Weighted: 1.318664955839957, D: 0.0642345042560796\n",
      "2018-11-26 13:23:21,288 INFO     Weight matrix 1/1 (256,1024): Alpha 5.2855660264332744 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:21,291 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8782376050949097\n",
      "2018-11-26 13:23:21,294 INFO Layer 239: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:23:21,297 INFO Layer 239: Skipping (Layer not supported)\n",
      "2018-11-26 13:23:21,299 INFO Layer 240: ReLU(inplace)\n",
      "2018-11-26 13:23:21,302 INFO Layer 240: Skipping (Layer not supported)\n",
      "2018-11-26 13:23:21,306 INFO Layer 241: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:23:21,309 INFO Layer 241: Skipping (Layer not supported)\n",
      "2018-11-26 13:23:21,312 INFO Layer 242: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:23:21,317 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:23:21,319 INFO Layer 242: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:23:21,321 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:23:24,172 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.541024447613924, Alpha Weighted: 1.496380179164089, D: 0.0842113748823553\n",
      "2018-11-26 13:23:24,175 INFO     Weight matrix 1/1 (256,1024): Alpha 5.541024447613924 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:24,178 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.943623960018158\n",
      "2018-11-26 13:23:24,181 INFO Layer 243: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:23:24,185 INFO Layer 243: Skipping (Layer not supported)\n",
      "2018-11-26 13:23:24,189 INFO Layer 244: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:23:24,197 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:23:24,200 INFO Layer 244: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:23:24,203 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:26,548 INFO     Weight matrix 1/9 (256,256): Alpha: 3.838353286369386, Alpha Weighted: -1.9713816481539441, D: 0.06812328383900844\n",
      "2018-11-26 13:23:26,550 INFO     Weight matrix 1/9 (256,256): Alpha 3.838353286369386 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:26,555 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4230709373950958\n",
      "2018-11-26 13:23:26,557 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:23:28,957 INFO     Weight matrix 2/9 (256,256): Alpha: 6.6879061418211325, Alpha Weighted: -3.474125386907782, D: 0.09999999999999976\n",
      "2018-11-26 13:23:28,960 INFO     Weight matrix 2/9 (256,256): Alpha 6.6879061418211325 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:28,965 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.48528099060058594\n",
      "2018-11-26 13:23:28,968 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:31,720 INFO     Weight matrix 3/9 (256,256): Alpha: 4.648259607498568, Alpha Weighted: -2.1939400369951825, D: 0.074309934582804\n",
      "2018-11-26 13:23:31,722 INFO     Weight matrix 3/9 (256,256): Alpha 4.648259607498568 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:31,726 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.4418952167034149\n",
      "2018-11-26 13:23:31,729 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:34,160 INFO     Weight matrix 4/9 (256,256): Alpha: 5.1618390462824895, Alpha Weighted: -3.3059945833612754, D: 0.06357014434261721\n",
      "2018-11-26 13:23:34,163 INFO     Weight matrix 4/9 (256,256): Alpha 5.1618390462824895 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:34,167 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.41656970977783203\n",
      "2018-11-26 13:23:34,171 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:36,505 INFO     Weight matrix 5/9 (256,256): Alpha: 3.1568243424582167, Alpha Weighted: -0.26363970231381273, D: 0.05956643091120617\n",
      "2018-11-26 13:23:36,510 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.5438411235809326\n",
      "2018-11-26 13:23:36,513 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:38,837 INFO     Weight matrix 6/9 (256,256): Alpha: 7.417458075349427, Alpha Weighted: -4.994623033251945, D: 0.1129101183656746\n",
      "2018-11-26 13:23:38,840 INFO     Weight matrix 6/9 (256,256): Alpha 7.417458075349427 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:38,845 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.44638141989707947\n",
      "2018-11-26 13:23:38,849 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:41,492 INFO     Weight matrix 7/9 (256,256): Alpha: 4.496672410926589, Alpha Weighted: -2.3137950876907265, D: 0.08939230360242034\n",
      "2018-11-26 13:23:41,497 INFO     Weight matrix 7/9 (256,256): Alpha 4.496672410926589 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:41,505 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.4376269280910492\n",
      "2018-11-26 13:23:41,509 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:44,158 INFO     Weight matrix 8/9 (256,256): Alpha: 5.014501635559345, Alpha Weighted: -2.641088794466759, D: 0.14393108230677498\n",
      "2018-11-26 13:23:44,161 INFO     Weight matrix 8/9 (256,256): Alpha 5.014501635559345 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:44,165 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.5128156542778015\n",
      "2018-11-26 13:23:44,168 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:46,836 INFO     Weight matrix 9/9 (256,256): Alpha: 4.670860825017066, Alpha Weighted: -2.183801026781247, D: 0.08047296703926055\n",
      "2018-11-26 13:23:46,839 INFO     Weight matrix 9/9 (256,256): Alpha 4.670860825017066 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:46,843 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4669923484325409\n",
      "2018-11-26 13:23:46,846 INFO Layer 245: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:23:46,848 INFO Layer 245: Skipping (Layer not supported)\n",
      "2018-11-26 13:23:46,852 INFO Layer 246: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:23:46,860 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:23:46,862 INFO Layer 246: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:23:46,865 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:23:49,679 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.599844711520445, Alpha Weighted: 1.584436753170869, D: 0.07824483843136154\n",
      "2018-11-26 13:23:49,681 INFO     Weight matrix 1/1 (256,1024): Alpha 5.599844711520445 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:49,685 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8704231381416321\n",
      "2018-11-26 13:23:49,688 INFO Layer 247: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:23:49,691 INFO Layer 247: Skipping (Layer not supported)\n",
      "2018-11-26 13:23:49,693 INFO Layer 248: ReLU(inplace)\n",
      "2018-11-26 13:23:49,696 INFO Layer 248: Skipping (Layer not supported)\n",
      "2018-11-26 13:23:49,699 INFO Layer 249: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:23:49,702 INFO Layer 249: Skipping (Layer not supported)\n",
      "2018-11-26 13:23:49,705 INFO Layer 250: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:23:49,710 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:23:49,714 INFO Layer 250: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:23:49,716 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:23:52,541 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.4951047786772484, Alpha Weighted: 1.6121549897345888, D: 0.05591272082476184\n",
      "2018-11-26 13:23:52,544 INFO     Weight matrix 1/1 (256,1024): Alpha 4.4951047786772484 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:52,547 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.9518858194351196\n",
      "2018-11-26 13:23:52,551 INFO Layer 251: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:23:52,554 INFO Layer 251: Skipping (Layer not supported)\n",
      "2018-11-26 13:23:52,557 INFO Layer 252: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:23:52,569 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:23:52,572 INFO Layer 252: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:23:52,575 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:55,213 INFO     Weight matrix 1/9 (256,256): Alpha: 2.8316886264381766, Alpha Weighted: -1.0138649831058497, D: 0.08738437594176629\n",
      "2018-11-26 13:23:55,218 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4349372982978821\n",
      "2018-11-26 13:23:55,221 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:23:57,946 INFO     Weight matrix 2/9 (256,256): Alpha: 4.114389231019218, Alpha Weighted: -1.3207452237038075, D: 0.0848465632448136\n",
      "2018-11-26 13:23:57,949 INFO     Weight matrix 2/9 (256,256): Alpha 4.114389231019218 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:23:57,954 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.47181662917137146\n",
      "2018-11-26 13:23:57,958 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:24:00,579 INFO     Weight matrix 3/9 (256,256): Alpha: 3.0332319189829597, Alpha Weighted: -1.5305599323761039, D: 0.10318375107013167\n",
      "2018-11-26 13:24:00,584 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.44628679752349854\n",
      "2018-11-26 13:24:00,587 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:24:03,276 INFO     Weight matrix 4/9 (256,256): Alpha: 4.393365019643651, Alpha Weighted: -2.394311996163604, D: 0.0769830790854093\n",
      "2018-11-26 13:24:03,279 INFO     Weight matrix 4/9 (256,256): Alpha 4.393365019643651 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:24:03,283 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.4117964804172516\n",
      "2018-11-26 13:24:03,286 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:24:05,915 INFO     Weight matrix 5/9 (256,256): Alpha: 2.5782895556532113, Alpha Weighted: -0.4006218045283304, D: 0.075864071468494\n",
      "2018-11-26 13:24:05,920 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.5363126993179321\n",
      "2018-11-26 13:24:05,923 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:24:08,480 INFO     Weight matrix 6/9 (256,256): Alpha: 5.001351911123761, Alpha Weighted: -2.950414433009129, D: 0.11014150818632884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:24:08,484 INFO     Weight matrix 6/9 (256,256): Alpha 5.001351911123761 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:24:08,490 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.4428028464317322\n",
      "2018-11-26 13:24:08,495 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:24:10,942 INFO     Weight matrix 7/9 (256,256): Alpha: 3.8842610141635516, Alpha Weighted: -2.1184943383309114, D: 0.11207630156288118\n",
      "2018-11-26 13:24:10,945 INFO     Weight matrix 7/9 (256,256): Alpha 3.8842610141635516 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:24:10,953 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.4407276511192322\n",
      "2018-11-26 13:24:10,956 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:24:13,463 INFO     Weight matrix 8/9 (256,256): Alpha: 4.063784048403019, Alpha Weighted: -1.5656148386074045, D: 0.08777173264960736\n",
      "2018-11-26 13:24:13,466 INFO     Weight matrix 8/9 (256,256): Alpha 4.063784048403019 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:24:13,472 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.4978967308998108\n",
      "2018-11-26 13:24:13,474 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:24:17,026 INFO     Weight matrix 9/9 (256,256): Alpha: 4.457526332204305, Alpha Weighted: -2.424219871435331, D: 0.12055832702144675\n",
      "2018-11-26 13:24:17,028 INFO     Weight matrix 9/9 (256,256): Alpha 4.457526332204305 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:24:17,034 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.472356915473938\n",
      "2018-11-26 13:24:17,037 INFO Layer 253: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:17,042 INFO Layer 253: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:17,046 INFO Layer 254: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:17,055 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:17,058 INFO Layer 254: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:17,062 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:24:20,287 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.787351454560779, Alpha Weighted: 1.893498631317859, D: 0.042267399083558144\n",
      "2018-11-26 13:24:20,290 INFO     Weight matrix 1/1 (256,1024): Alpha 3.787351454560779 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:24:20,297 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.890950620174408\n",
      "2018-11-26 13:24:20,300 INFO Layer 255: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:20,303 INFO Layer 255: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,306 INFO Layer 256: ReLU(inplace)\n",
      "2018-11-26 13:24:20,314 INFO Layer 256: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,320 INFO Layer 257: Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:24:20,324 INFO Layer 257: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,328 INFO Layer 258: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:24:20,332 INFO Layer 258: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,345 INFO Layer 259: Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:20,353 INFO Pytorch tensor shape detected: 512x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:20,358 INFO Layer 259: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:20,362 INFO     Weight matrix 1/1 (512,1024): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,366 INFO Layer 260: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:20,368 INFO Layer 260: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,370 INFO Layer 261: Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:24:20,418 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:24:20,422 INFO Layer 261: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:24:20,428 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,431 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,437 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,445 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,451 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,458 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,462 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,466 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,470 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,476 INFO Layer 262: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:20,478 INFO Layer 262: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,480 INFO Layer 263: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:20,512 INFO Pytorch tensor shape detected: 2048x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:20,515 INFO Layer 263: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:20,519 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,521 INFO Layer 264: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:20,526 INFO Layer 264: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,531 INFO Layer 265: ReLU(inplace)\n",
      "2018-11-26 13:24:20,540 INFO Layer 265: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,553 INFO Layer 266: Sequential(\n",
      "  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:24:20,557 INFO Layer 266: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,563 INFO Layer 267: Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 13:24:20,592 INFO Pytorch tensor shape detected: 2048x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:20,597 INFO Layer 267: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:20,601 INFO     Weight matrix 1/1 (1024,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,607 INFO Layer 268: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:20,612 INFO Layer 268: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,617 INFO Layer 269: Bottleneck(\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:24:20,622 INFO Layer 269: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,626 INFO Layer 270: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:20,646 INFO Pytorch tensor shape detected: 512x2048 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:20,650 INFO Layer 270: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:20,653 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,658 INFO Layer 271: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:20,662 INFO Layer 271: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,665 INFO Layer 272: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:24:20,689 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:24:20,693 INFO Layer 272: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:24:20,702 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,705 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,712 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,715 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,721 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,725 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,734 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,737 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,741 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,746 INFO Layer 273: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:20,750 INFO Layer 273: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,753 INFO Layer 274: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:20,766 INFO Pytorch tensor shape detected: 2048x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:20,769 INFO Layer 274: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:20,772 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,776 INFO Layer 275: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:20,779 INFO Layer 275: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,783 INFO Layer 276: ReLU(inplace)\n",
      "2018-11-26 13:24:20,792 INFO Layer 276: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,795 INFO Layer 277: Bottleneck(\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:24:20,799 INFO Layer 277: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,804 INFO Layer 278: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:20,820 INFO Pytorch tensor shape detected: 512x2048 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:20,825 INFO Layer 278: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:20,829 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,833 INFO Layer 279: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:20,844 INFO Layer 279: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,849 INFO Layer 280: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:24:20,871 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:24:20,874 INFO Layer 280: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:24:20,879 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,884 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,891 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,894 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,899 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,902 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,907 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,913 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,917 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,923 INFO Layer 281: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:20,926 INFO Layer 281: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,929 INFO Layer 282: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:20,948 INFO Pytorch tensor shape detected: 2048x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:20,956 INFO Layer 282: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:20,961 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:20,964 INFO Layer 283: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:20,967 INFO Layer 283: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,970 INFO Layer 284: ReLU(inplace)\n",
      "2018-11-26 13:24:20,973 INFO Layer 284: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,979 INFO Layer 285: AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "2018-11-26 13:24:20,982 INFO Layer 285: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:20,988 INFO Layer 286: Linear(in_features=2048, out_features=1000, bias=True)\n",
      "2018-11-26 13:24:21,007 INFO Layer 286: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:21,010 INFO     Weight matrix 1/1 (1000,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:24:21,015 INFO ### Printing results ###\n",
      "2018-11-26 13:24:21,019 DEBUG Layer 7: Lognorm: 0.6557127833366394\n",
      "2018-11-26 13:24:21,027 DEBUG Layer 9: Lognorm compound: 0.17035147878858778\n",
      "2018-11-26 13:24:21,032 DEBUG Layer 11: Lognorm: 0.5727798342704773\n",
      "2018-11-26 13:24:21,038 DEBUG Layer 15: Lognorm: 0.8214689493179321\n",
      "2018-11-26 13:24:21,047 DEBUG Layer 18: Lognorm: 0.3141155540943146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:24:21,051 DEBUG Layer 20: Lognorm compound: -0.08840349399381214\n",
      "2018-11-26 13:24:21,055 DEBUG Layer 22: Lognorm: 0.2727549970149994\n",
      "2018-11-26 13:24:21,057 DEBUG Layer 26: Lognorm: 0.5081485509872437\n",
      "2018-11-26 13:24:21,060 DEBUG Layer 28: Lognorm compound: 0.18819433699051538\n",
      "2018-11-26 13:24:21,064 DEBUG Layer 30: Lognorm: 0.44833919405937195\n",
      "2018-11-26 13:24:21,068 DEBUG Layer 35: Lognorm: 0.6902310252189636\n",
      "2018-11-26 13:24:21,070 DEBUG Layer 37: Lognorm compound: 0.39348215858141583\n",
      "2018-11-26 13:24:21,072 DEBUG Layer 39: Lognorm: 0.8216822147369385\n",
      "2018-11-26 13:24:21,075 DEBUG Layer 43: Lognorm: 0.8642119765281677\n",
      "2018-11-26 13:24:21,077 DEBUG Layer 46: Lognorm: 0.5191983580589294\n",
      "2018-11-26 13:24:21,080 DEBUG Layer 48: Lognorm compound: 0.2395353437297874\n",
      "2018-11-26 13:24:21,083 DEBUG Layer 50: Lognorm: 0.6135491728782654\n",
      "2018-11-26 13:24:21,086 DEBUG Layer 54: Lognorm: 0.6973446011543274\n",
      "2018-11-26 13:24:21,100 DEBUG Layer 56: Lognorm compound: 0.33810263209872776\n",
      "2018-11-26 13:24:21,103 DEBUG Layer 58: Lognorm: 0.7107180953025818\n",
      "2018-11-26 13:24:21,105 DEBUG Layer 62: Lognorm: 0.7432159781455994\n",
      "2018-11-26 13:24:21,108 DEBUG Layer 64: Lognorm compound: 0.4013771249188317\n",
      "2018-11-26 13:24:21,110 DEBUG Layer 66: Lognorm: 0.741195023059845\n",
      "2018-11-26 13:24:21,114 DEBUG Layer 71: Lognorm: 1.0100165605545044\n",
      "2018-11-26 13:24:21,117 DEBUG Layer 73: Lognorm compound: 0.6050282120704651\n",
      "2018-11-26 13:24:21,120 DEBUG Layer 75: Lognorm: 1.01131010055542\n",
      "2018-11-26 13:24:21,124 DEBUG Layer 82: Lognorm: 0.467148095369339\n",
      "2018-11-26 13:24:21,128 DEBUG Layer 84: Lognorm compound: 0.08067059985155033\n",
      "2018-11-26 13:24:21,131 DEBUG Layer 86: Lognorm: 0.5173341035842896\n",
      "2018-11-26 13:24:21,135 DEBUG Layer 90: Lognorm: 0.6699070334434509\n",
      "2018-11-26 13:24:21,139 DEBUG Layer 92: Lognorm compound: 0.30619511504968006\n",
      "2018-11-26 13:24:21,142 DEBUG Layer 94: Lognorm: 0.7336246371269226\n",
      "2018-11-26 13:24:21,148 DEBUG Layer 98: Lognorm: 0.5936395525932312\n",
      "2018-11-26 13:24:21,151 DEBUG Layer 100: Lognorm compound: 0.20271486209498513\n",
      "2018-11-26 13:24:21,155 DEBUG Layer 102: Lognorm: 0.607159435749054\n",
      "2018-11-26 13:24:21,159 DEBUG Layer 106: Lognorm: 0.61812424659729\n",
      "2018-11-26 13:24:21,163 DEBUG Layer 108: Lognorm compound: 0.25403257376617855\n",
      "2018-11-26 13:24:21,166 DEBUG Layer 110: Lognorm: 0.6445986032485962\n",
      "2018-11-26 13:24:21,170 DEBUG Layer 114: Lognorm: 0.7247174978256226\n",
      "2018-11-26 13:24:21,174 DEBUG Layer 116: Lognorm compound: 0.3414742714828915\n",
      "2018-11-26 13:24:21,177 DEBUG Layer 118: Lognorm: 0.7434602975845337\n",
      "2018-11-26 13:24:21,180 DEBUG Layer 122: Lognorm: 0.7412078380584717\n",
      "2018-11-26 13:24:21,185 DEBUG Layer 124: Lognorm compound: 0.3499622477425469\n",
      "2018-11-26 13:24:21,188 DEBUG Layer 126: Lognorm: 0.7663451433181763\n",
      "2018-11-26 13:24:21,191 DEBUG Layer 130: Lognorm: 0.782488226890564\n",
      "2018-11-26 13:24:21,195 DEBUG Layer 132: Lognorm compound: 0.40462807814280194\n",
      "2018-11-26 13:24:21,199 DEBUG Layer 134: Lognorm: 0.8183230757713318\n",
      "2018-11-26 13:24:21,202 DEBUG Layer 138: Lognorm: 0.7919532656669617\n",
      "2018-11-26 13:24:21,206 DEBUG Layer 140: Lognorm compound: 0.4065273039870792\n",
      "2018-11-26 13:24:21,210 DEBUG Layer 142: Lognorm: 0.8139934539794922\n",
      "2018-11-26 13:24:21,213 DEBUG Layer 146: Lognorm: 0.7483446002006531\n",
      "2018-11-26 13:24:21,216 DEBUG Layer 148: Lognorm compound: 0.40797874331474304\n",
      "2018-11-26 13:24:21,218 DEBUG Layer 150: Lognorm: 0.8049644827842712\n",
      "2018-11-26 13:24:21,222 DEBUG Layer 154: Lognorm: 0.8029250502586365\n",
      "2018-11-26 13:24:21,224 DEBUG Layer 156: Lognorm compound: 0.4493067198329502\n",
      "2018-11-26 13:24:21,228 DEBUG Layer 158: Lognorm: 0.8348313570022583\n",
      "2018-11-26 13:24:21,231 DEBUG Layer 162: Lognorm: 0.793337345123291\n",
      "2018-11-26 13:24:21,233 DEBUG Layer 164: Lognorm compound: 0.44600945048862034\n",
      "2018-11-26 13:24:21,236 DEBUG Layer 166: Lognorm: 0.832996666431427\n",
      "2018-11-26 13:24:21,240 DEBUG Layer 170: Lognorm: 0.8159905672073364\n",
      "2018-11-26 13:24:21,242 DEBUG Layer 172: Lognorm compound: 0.4333073960410224\n",
      "2018-11-26 13:24:21,244 DEBUG Layer 174: Lognorm: 0.8275728821754456\n",
      "2018-11-26 13:24:21,248 DEBUG Layer 178: Lognorm: 0.8391174077987671\n",
      "2018-11-26 13:24:21,251 DEBUG Layer 180: Lognorm compound: 0.4329998195171356\n",
      "2018-11-26 13:24:21,254 DEBUG Layer 182: Lognorm: 0.8274749517440796\n",
      "2018-11-26 13:24:21,257 DEBUG Layer 186: Lognorm: 0.8566838502883911\n",
      "2018-11-26 13:24:21,260 DEBUG Layer 188: Lognorm compound: 0.4330255753464169\n",
      "2018-11-26 13:24:21,263 DEBUG Layer 190: Lognorm: 0.8170077800750732\n",
      "2018-11-26 13:24:21,265 DEBUG Layer 194: Lognorm: 0.797701358795166\n",
      "2018-11-26 13:24:21,267 DEBUG Layer 196: Lognorm compound: 0.3983308540450202\n",
      "2018-11-26 13:24:21,271 DEBUG Layer 198: Lognorm: 0.7707751989364624\n",
      "2018-11-26 13:24:21,273 DEBUG Layer 202: Lognorm: 0.8159993290901184\n",
      "2018-11-26 13:24:21,276 DEBUG Layer 204: Lognorm compound: 0.3920386830965678\n",
      "2018-11-26 13:24:21,279 DEBUG Layer 206: Lognorm: 0.7660306692123413\n",
      "2018-11-26 13:24:21,283 DEBUG Layer 210: Lognorm: 0.8350929617881775\n",
      "2018-11-26 13:24:21,286 DEBUG Layer 212: Lognorm compound: 0.43103720082177055\n",
      "2018-11-26 13:24:21,289 DEBUG Layer 214: Lognorm: 0.8145038485527039\n",
      "2018-11-26 13:24:21,293 DEBUG Layer 218: Lognorm: 0.8540765047073364\n",
      "2018-11-26 13:24:21,296 DEBUG Layer 220: Lognorm compound: 0.4301854570706685\n",
      "2018-11-26 13:24:21,298 DEBUG Layer 222: Lognorm: 0.821229100227356\n",
      "2018-11-26 13:24:21,302 DEBUG Layer 226: Lognorm: 0.9085201025009155\n",
      "2018-11-26 13:24:21,305 DEBUG Layer 228: Lognorm compound: 0.4605455564128028\n",
      "2018-11-26 13:24:21,309 DEBUG Layer 230: Lognorm: 0.8632466793060303\n",
      "2018-11-26 13:24:21,312 DEBUG Layer 234: Lognorm: 0.9294024109840393\n",
      "2018-11-26 13:24:21,315 DEBUG Layer 236: Lognorm compound: 0.47137312756644356\n",
      "2018-11-26 13:24:21,320 DEBUG Layer 238: Lognorm: 0.8782376050949097\n",
      "2018-11-26 13:24:21,323 DEBUG Layer 242: Lognorm: 0.943623960018158\n",
      "2018-11-26 13:24:21,327 DEBUG Layer 244: Lognorm compound: 0.46383048097292584\n",
      "2018-11-26 13:24:21,331 DEBUG Layer 246: Lognorm: 0.8704231381416321\n",
      "2018-11-26 13:24:21,334 DEBUG Layer 250: Lognorm: 0.9518858194351196\n",
      "2018-11-26 13:24:21,337 DEBUG Layer 252: Lognorm compound: 0.4616593387391832\n",
      "2018-11-26 13:24:21,341 DEBUG Layer 254: Lognorm: 0.890950620174408\n",
      "2018-11-26 13:24:21,345 INFO LogNorm: min: -0.23450779914855957, max: 1.01131010055542, avg: 0.43045926094055176\n",
      "2018-11-26 13:24:21,349 INFO LogNorm compound: min: -0.08840349399381214, max: 1.01131010055542, avg: 0.6224833149207049\n",
      "2018-11-26 13:24:21,353 DEBUG Layer 7: Alpha: 1.2888696680201484\n",
      "2018-11-26 13:24:21,356 DEBUG Layer 9: Alpha compound: 2.4862967187106397\n",
      "2018-11-26 13:24:21,359 DEBUG Layer 11: Alpha: 4.442632730677695\n",
      "2018-11-26 13:24:21,362 DEBUG Layer 15: Alpha: 2.4133015443368366\n",
      "2018-11-26 13:24:21,365 DEBUG Layer 18: Alpha: 2.4758786406149396\n",
      "2018-11-26 13:24:21,368 DEBUG Layer 20: Alpha compound: 1.787796909458143\n",
      "2018-11-26 13:24:21,371 DEBUG Layer 22: Alpha: 3.8788626492752525\n",
      "2018-11-26 13:24:21,375 DEBUG Layer 26: Alpha: 1.55704907575113\n",
      "2018-11-26 13:24:21,377 DEBUG Layer 28: Alpha compound: 1.884508341377816\n",
      "2018-11-26 13:24:21,381 DEBUG Layer 30: Alpha: 3.6547114006665007\n",
      "2018-11-26 13:24:21,390 DEBUG Layer 35: Alpha: 1.5633365534806956\n",
      "2018-11-26 13:24:21,395 DEBUG Layer 37: Alpha compound: 1.826067337937461\n",
      "2018-11-26 13:24:21,398 DEBUG Layer 39: Alpha: 5.849537280894447\n",
      "2018-11-26 13:24:21,401 DEBUG Layer 43: Alpha: 1.5517755878834776\n",
      "2018-11-26 13:24:21,405 DEBUG Layer 46: Alpha: 1.6350174113743532\n",
      "2018-11-26 13:24:21,408 DEBUG Layer 48: Alpha compound: 1.480291176761681\n",
      "2018-11-26 13:24:21,412 DEBUG Layer 50: Alpha: 5.698359139587815\n",
      "2018-11-26 13:24:21,416 DEBUG Layer 54: Alpha: 1.5943905143925607\n",
      "2018-11-26 13:24:21,419 DEBUG Layer 56: Alpha compound: 1.752860460081155\n",
      "2018-11-26 13:24:21,422 DEBUG Layer 58: Alpha: 10.837149709317695\n",
      "2018-11-26 13:24:21,424 DEBUG Layer 62: Alpha: 4.389838392695652\n",
      "2018-11-26 13:24:21,428 DEBUG Layer 64: Alpha compound: 1.8749571628460866\n",
      "2018-11-26 13:24:21,432 DEBUG Layer 66: Alpha: 2.95654776164967\n",
      "2018-11-26 13:24:21,436 DEBUG Layer 71: Alpha: 1.6266720658986935\n",
      "2018-11-26 13:24:21,440 DEBUG Layer 73: Alpha compound: 3.5387322739437495\n",
      "2018-11-26 13:24:21,448 DEBUG Layer 75: Alpha: 6.831729496105003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:24:21,452 DEBUG Layer 82: Alpha: 2.104895906747542\n",
      "2018-11-26 13:24:21,455 DEBUG Layer 84: Alpha compound: 1.822879803933039\n",
      "2018-11-26 13:24:21,459 DEBUG Layer 86: Alpha: 6.186232461059174\n",
      "2018-11-26 13:24:21,465 DEBUG Layer 90: Alpha: 1.7191218882947021\n",
      "2018-11-26 13:24:21,469 DEBUG Layer 92: Alpha compound: 1.9317664469681592\n",
      "2018-11-26 13:24:21,473 DEBUG Layer 94: Alpha: 1.6497989572077392\n",
      "2018-11-26 13:24:21,478 DEBUG Layer 98: Alpha: 1.7730349038925275\n",
      "2018-11-26 13:24:21,481 DEBUG Layer 100: Alpha compound: 1.8696316031578393\n",
      "2018-11-26 13:24:21,486 DEBUG Layer 102: Alpha: 4.02291577897414\n",
      "2018-11-26 13:24:21,490 DEBUG Layer 106: Alpha: 1.7903894893482208\n",
      "2018-11-26 13:24:21,494 DEBUG Layer 108: Alpha compound: 1.9079262443138718\n",
      "2018-11-26 13:24:21,506 DEBUG Layer 110: Alpha: 1.9726215025263505\n",
      "2018-11-26 13:24:21,510 DEBUG Layer 114: Alpha: 1.655421475356104\n",
      "2018-11-26 13:24:21,513 DEBUG Layer 116: Alpha compound: 1.9436795237167803\n",
      "2018-11-26 13:24:21,520 DEBUG Layer 118: Alpha: 3.274965171355338\n",
      "2018-11-26 13:24:21,523 DEBUG Layer 122: Alpha: 1.9072956688493412\n",
      "2018-11-26 13:24:21,526 DEBUG Layer 124: Alpha compound: 2.3288161693732743\n",
      "2018-11-26 13:24:21,529 DEBUG Layer 126: Alpha: 4.089153069991752\n",
      "2018-11-26 13:24:21,532 DEBUG Layer 130: Alpha: 1.8270009335803472\n",
      "2018-11-26 13:24:21,535 DEBUG Layer 132: Alpha compound: 2.113454276162591\n",
      "2018-11-26 13:24:21,538 DEBUG Layer 134: Alpha: 4.249523341568153\n",
      "2018-11-26 13:24:21,542 DEBUG Layer 138: Alpha: 2.3184996840229797\n",
      "2018-11-26 13:24:21,545 DEBUG Layer 140: Alpha compound: 2.2597872197620528\n",
      "2018-11-26 13:24:21,548 DEBUG Layer 142: Alpha: 4.210641704525478\n",
      "2018-11-26 13:24:21,551 DEBUG Layer 146: Alpha: 1.7991433691813936\n",
      "2018-11-26 13:24:21,556 DEBUG Layer 148: Alpha compound: 2.201387122203334\n",
      "2018-11-26 13:24:21,561 DEBUG Layer 150: Alpha: 2.3166446671267917\n",
      "2018-11-26 13:24:21,568 DEBUG Layer 154: Alpha: 1.856459113424708\n",
      "2018-11-26 13:24:21,577 DEBUG Layer 156: Alpha compound: 2.097526402448965\n",
      "2018-11-26 13:24:21,585 DEBUG Layer 158: Alpha: 1.772550852653292\n",
      "2018-11-26 13:24:21,589 DEBUG Layer 162: Alpha: 1.7757295542334144\n",
      "2018-11-26 13:24:21,593 DEBUG Layer 164: Alpha compound: 2.110973233473377\n",
      "2018-11-26 13:24:21,596 DEBUG Layer 166: Alpha: 1.813714816723249\n",
      "2018-11-26 13:24:21,599 DEBUG Layer 170: Alpha: 1.9101292047337914\n",
      "2018-11-26 13:24:21,601 DEBUG Layer 172: Alpha compound: 2.264274095442959\n",
      "2018-11-26 13:24:21,609 DEBUG Layer 174: Alpha: 5.380235953445571\n",
      "2018-11-26 13:24:21,613 DEBUG Layer 178: Alpha: 5.15852376508517\n",
      "2018-11-26 13:24:21,615 DEBUG Layer 180: Alpha compound: 2.3233847940023207\n",
      "2018-11-26 13:24:21,617 DEBUG Layer 182: Alpha: 2.3669216668304593\n",
      "2018-11-26 13:24:21,620 DEBUG Layer 186: Alpha: 3.6239368760213138\n",
      "2018-11-26 13:24:21,623 DEBUG Layer 188: Alpha compound: 2.5858158522523147\n",
      "2018-11-26 13:24:21,625 DEBUG Layer 190: Alpha: 3.2516799203426205\n",
      "2018-11-26 13:24:21,627 DEBUG Layer 194: Alpha: 2.5245349721035355\n",
      "2018-11-26 13:24:21,630 DEBUG Layer 196: Alpha compound: 2.1767913414458255\n",
      "2018-11-26 13:24:21,632 DEBUG Layer 198: Alpha: 1.8658369049998793\n",
      "2018-11-26 13:24:21,643 DEBUG Layer 202: Alpha: 2.0859903539065314\n",
      "2018-11-26 13:24:21,646 DEBUG Layer 204: Alpha compound: 2.2259390175537335\n",
      "2018-11-26 13:24:21,649 DEBUG Layer 206: Alpha: 2.5587651671648395\n",
      "2018-11-26 13:24:21,652 DEBUG Layer 210: Alpha: 1.96708675266429\n",
      "2018-11-26 13:24:21,657 DEBUG Layer 212: Alpha compound: 2.0526206162819935\n",
      "2018-11-26 13:24:21,660 DEBUG Layer 214: Alpha: 1.8147961969848039\n",
      "2018-11-26 13:24:21,662 DEBUG Layer 218: Alpha: 2.2401544510123763\n",
      "2018-11-26 13:24:21,666 DEBUG Layer 220: Alpha compound: 2.4336001127646885\n",
      "2018-11-26 13:24:21,668 DEBUG Layer 222: Alpha: 2.8854406657958\n",
      "2018-11-26 13:24:21,675 DEBUG Layer 226: Alpha: 4.450351314045683\n",
      "2018-11-26 13:24:21,681 DEBUG Layer 228: Alpha compound: 3.521494340286191\n",
      "2018-11-26 13:24:21,683 DEBUG Layer 230: Alpha: 4.75248791736929\n",
      "2018-11-26 13:24:21,686 DEBUG Layer 234: Alpha: 5.595537003902988\n",
      "2018-11-26 13:24:21,688 DEBUG Layer 236: Alpha compound: 3.710913192502799\n",
      "2018-11-26 13:24:21,692 DEBUG Layer 238: Alpha: 5.2855660264332744\n",
      "2018-11-26 13:24:21,694 DEBUG Layer 242: Alpha: 5.541024447613924\n",
      "2018-11-26 13:24:21,705 DEBUG Layer 244: Alpha compound: 5.0102972634758025\n",
      "2018-11-26 13:24:21,708 DEBUG Layer 246: Alpha: 5.599844711520445\n",
      "2018-11-26 13:24:21,712 DEBUG Layer 250: Alpha: 4.4951047786772484\n",
      "2018-11-26 13:24:21,715 DEBUG Layer 252: Alpha compound: 3.8175430730702056\n",
      "2018-11-26 13:24:21,717 DEBUG Layer 254: Alpha: 3.787351454560779\n",
      "2018-11-26 13:24:21,721 INFO Alpha: min: 1.2888696680201484, max: 10.837149709317695, avg: 2.5347916372586132\n",
      "2018-11-26 13:24:21,725 INFO Alpha compound: min: 1.2888696680201484, max: 10.837149709317695, avg: 2.943638332219444\n",
      "2018-11-26 13:24:21,732 DEBUG Layer 7: Alpha Weigthed: 0.477747766282832\n",
      "2018-11-26 13:24:21,735 DEBUG Layer 9: Alpha Weighted compound: -0.7235781865317887\n",
      "2018-11-26 13:24:21,739 DEBUG Layer 11: Alpha Weigthed: 1.7082882617362385\n",
      "2018-11-26 13:24:21,742 DEBUG Layer 15: Alpha Weigthed: 1.747382162108019\n",
      "2018-11-26 13:24:21,750 DEBUG Layer 18: Alpha Weigthed: 0.08921024720279805\n",
      "2018-11-26 13:24:21,754 DEBUG Layer 20: Alpha Weighted compound: -1.0154141252182702\n",
      "2018-11-26 13:24:21,757 DEBUG Layer 22: Alpha Weigthed: -0.8022207519727896\n",
      "2018-11-26 13:24:21,761 DEBUG Layer 26: Alpha Weigthed: 0.06343303388614573\n",
      "2018-11-26 13:24:21,764 DEBUG Layer 28: Alpha Weighted compound: -0.6748376817665624\n",
      "2018-11-26 13:24:21,772 DEBUG Layer 30: Alpha Weigthed: -0.5057894692948892\n",
      "2018-11-26 13:24:21,775 DEBUG Layer 35: Alpha Weigthed: 0.5707473800763022\n",
      "2018-11-26 13:24:21,781 DEBUG Layer 37: Alpha Weighted compound: -0.26851278318179855\n",
      "2018-11-26 13:24:21,786 DEBUG Layer 39: Alpha Weigthed: 1.3683022774863902\n",
      "2018-11-26 13:24:21,790 DEBUG Layer 43: Alpha Weigthed: 1.093793654236257\n",
      "2018-11-26 13:24:21,793 DEBUG Layer 46: Alpha Weigthed: 0.6277738928151021\n",
      "2018-11-26 13:24:21,796 DEBUG Layer 48: Alpha Weighted compound: -0.15175423164417878\n",
      "2018-11-26 13:24:21,799 DEBUG Layer 50: Alpha Weigthed: 1.562950936120003\n",
      "2018-11-26 13:24:21,801 DEBUG Layer 54: Alpha Weigthed: 0.4002938265308685\n",
      "2018-11-26 13:24:21,808 DEBUG Layer 56: Alpha Weighted compound: -0.5258632558682732\n",
      "2018-11-26 13:24:21,814 DEBUG Layer 58: Alpha Weigthed: 0.27303834081524825\n",
      "2018-11-26 13:24:21,819 DEBUG Layer 62: Alpha Weigthed: 1.2666029149827924\n",
      "2018-11-26 13:24:21,822 DEBUG Layer 64: Alpha Weighted compound: -0.4585907330553601\n",
      "2018-11-26 13:24:21,825 DEBUG Layer 66: Alpha Weigthed: 0.18164674337930403\n",
      "2018-11-26 13:24:21,828 DEBUG Layer 71: Alpha Weigthed: 0.8132178421095596\n",
      "2018-11-26 13:24:21,832 DEBUG Layer 73: Alpha Weighted compound: -0.8719144824940526\n",
      "2018-11-26 13:24:21,837 DEBUG Layer 75: Alpha Weigthed: 2.7628511116699657\n",
      "2018-11-26 13:24:21,842 DEBUG Layer 82: Alpha Weigthed: 0.2581951806703783\n",
      "2018-11-26 13:24:21,848 DEBUG Layer 84: Alpha Weighted compound: -1.1329357928223303\n",
      "2018-11-26 13:24:21,851 DEBUG Layer 86: Alpha Weigthed: -1.0751255757119202\n",
      "2018-11-26 13:24:21,853 DEBUG Layer 90: Alpha Weigthed: 0.45704695989813865\n",
      "2018-11-26 13:24:21,855 DEBUG Layer 92: Alpha Weighted compound: -0.49702842730712565\n",
      "2018-11-26 13:24:21,858 DEBUG Layer 94: Alpha Weigthed: 0.2313592484069329\n",
      "2018-11-26 13:24:21,860 DEBUG Layer 98: Alpha Weigthed: 0.23637095390591742\n",
      "2018-11-26 13:24:21,863 DEBUG Layer 100: Alpha Weighted compound: -0.9008222053446748\n",
      "2018-11-26 13:24:21,865 DEBUG Layer 102: Alpha Weigthed: -0.4701875445415229\n",
      "2018-11-26 13:24:21,868 DEBUG Layer 106: Alpha Weigthed: 0.5710258877265435\n",
      "2018-11-26 13:24:21,870 DEBUG Layer 108: Alpha Weighted compound: -0.43851607451557917\n",
      "2018-11-26 13:24:21,872 DEBUG Layer 110: Alpha Weigthed: 0.10529318132047523\n",
      "2018-11-26 13:24:21,874 DEBUG Layer 114: Alpha Weigthed: 0.08444636349858915\n",
      "2018-11-26 13:24:21,877 DEBUG Layer 116: Alpha Weighted compound: -1.074034229539821\n",
      "2018-11-26 13:24:21,879 DEBUG Layer 118: Alpha Weigthed: 0.2531121955258964\n",
      "2018-11-26 13:24:21,882 DEBUG Layer 122: Alpha Weigthed: 0.19519743785660673\n",
      "2018-11-26 13:24:21,884 DEBUG Layer 124: Alpha Weighted compound: -1.0845404384931148\n",
      "2018-11-26 13:24:21,886 DEBUG Layer 126: Alpha Weigthed: 0.6011573548941376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:24:21,888 DEBUG Layer 130: Alpha Weigthed: 0.2312817879932395\n",
      "2018-11-26 13:24:21,890 DEBUG Layer 132: Alpha Weighted compound: -0.7375759571044529\n",
      "2018-11-26 13:24:21,893 DEBUG Layer 134: Alpha Weigthed: 0.8985207854839886\n",
      "2018-11-26 13:24:21,895 DEBUG Layer 138: Alpha Weigthed: 0.2574393208619271\n",
      "2018-11-26 13:24:21,898 DEBUG Layer 140: Alpha Weighted compound: -0.8898593286324026\n",
      "2018-11-26 13:24:21,902 DEBUG Layer 142: Alpha Weigthed: 0.3220417725458169\n",
      "2018-11-26 13:24:21,904 DEBUG Layer 146: Alpha Weigthed: 0.13238290706685177\n",
      "2018-11-26 13:24:21,906 DEBUG Layer 148: Alpha Weighted compound: -0.5275980734463578\n",
      "2018-11-26 13:24:21,909 DEBUG Layer 150: Alpha Weigthed: 0.41845676536695553\n",
      "2018-11-26 13:24:21,911 DEBUG Layer 154: Alpha Weigthed: 0.5738779902721788\n",
      "2018-11-26 13:24:21,914 DEBUG Layer 156: Alpha Weighted compound: -0.3975959481786735\n",
      "2018-11-26 13:24:21,916 DEBUG Layer 158: Alpha Weigthed: 0.22051975601401463\n",
      "2018-11-26 13:24:21,919 DEBUG Layer 162: Alpha Weigthed: 0.3518315617671231\n",
      "2018-11-26 13:24:21,921 DEBUG Layer 164: Alpha Weighted compound: -0.5487351579800009\n",
      "2018-11-26 13:24:21,924 DEBUG Layer 166: Alpha Weigthed: 0.20658733076884922\n",
      "2018-11-26 13:24:21,926 DEBUG Layer 170: Alpha Weigthed: 0.1588442916123133\n",
      "2018-11-26 13:24:21,929 DEBUG Layer 172: Alpha Weighted compound: -0.7310129900263067\n",
      "2018-11-26 13:24:21,931 DEBUG Layer 174: Alpha Weigthed: 1.4233157688287477\n",
      "2018-11-26 13:24:21,933 DEBUG Layer 178: Alpha Weigthed: 0.5314344105906085\n",
      "2018-11-26 13:24:21,935 DEBUG Layer 180: Alpha Weighted compound: -0.8944462016254805\n",
      "2018-11-26 13:24:21,938 DEBUG Layer 182: Alpha Weigthed: 0.29191254802744543\n",
      "2018-11-26 13:24:21,941 DEBUG Layer 186: Alpha Weigthed: 0.5213158971521292\n",
      "2018-11-26 13:24:21,944 DEBUG Layer 188: Alpha Weighted compound: -1.1066146989890215\n",
      "2018-11-26 13:24:21,946 DEBUG Layer 190: Alpha Weigthed: 0.4077199828307935\n",
      "2018-11-26 13:24:21,948 DEBUG Layer 194: Alpha Weigthed: 0.25539656571064184\n",
      "2018-11-26 13:24:21,951 DEBUG Layer 196: Alpha Weighted compound: -0.8326891321719151\n",
      "2018-11-26 13:24:21,953 DEBUG Layer 198: Alpha Weigthed: 0.15121597673419704\n",
      "2018-11-26 13:24:21,956 DEBUG Layer 202: Alpha Weigthed: 0.06757901768282952\n",
      "2018-11-26 13:24:21,959 DEBUG Layer 204: Alpha Weighted compound: -0.9043756297332547\n",
      "2018-11-26 13:24:21,961 DEBUG Layer 206: Alpha Weigthed: 0.28704317767778625\n",
      "2018-11-26 13:24:21,963 DEBUG Layer 210: Alpha Weigthed: 0.33116376656625396\n",
      "2018-11-26 13:24:21,966 DEBUG Layer 212: Alpha Weighted compound: -0.6944845142478623\n",
      "2018-11-26 13:24:21,969 DEBUG Layer 214: Alpha Weigthed: 0.10558067257281918\n",
      "2018-11-26 13:24:21,971 DEBUG Layer 218: Alpha Weigthed: 0.07977849616570674\n",
      "2018-11-26 13:24:21,974 DEBUG Layer 220: Alpha Weighted compound: -0.9607308226360658\n",
      "2018-11-26 13:24:21,976 DEBUG Layer 222: Alpha Weigthed: 0.5396622550079743\n",
      "2018-11-26 13:24:21,978 DEBUG Layer 226: Alpha Weigthed: 0.7534039139809693\n",
      "2018-11-26 13:24:21,981 DEBUG Layer 228: Alpha Weighted compound: -1.5791349589019557\n",
      "2018-11-26 13:24:21,983 DEBUG Layer 230: Alpha Weigthed: 1.0553166933109364\n",
      "2018-11-26 13:24:21,985 DEBUG Layer 234: Alpha Weigthed: 0.9147996552667834\n",
      "2018-11-26 13:24:21,988 DEBUG Layer 236: Alpha Weighted compound: -1.5259289052662621\n",
      "2018-11-26 13:24:21,990 DEBUG Layer 238: Alpha Weigthed: 1.318664955839957\n",
      "2018-11-26 13:24:21,993 DEBUG Layer 242: Alpha Weigthed: 1.496380179164089\n",
      "2018-11-26 13:24:21,997 DEBUG Layer 244: Alpha Weighted compound: -2.593598811102519\n",
      "2018-11-26 13:24:21,999 DEBUG Layer 246: Alpha Weigthed: 1.584436753170869\n",
      "2018-11-26 13:24:22,002 DEBUG Layer 250: Alpha Weigthed: 1.6121549897345888\n",
      "2018-11-26 13:24:22,004 DEBUG Layer 252: Alpha Weighted compound: -1.7465386023622744\n",
      "2018-11-26 13:24:22,006 DEBUG Layer 254: Alpha Weigthed: 1.893498631317859\n",
      "2018-11-26 13:24:22,009 INFO Alpha Weighted: min: -4.994623033251945, max: 2.7628511116699657, avg: -0.6140440994909098\n",
      "2018-11-26 13:24:22,014 INFO Alpha Weighted compound: min: -2.593598811102519, max: 2.7628511116699657, avg: 0.08751584794043292\n",
      "2018-11-26 13:24:30,864 INFO \n",
      "WeightWatcher v0.2.dev0 by Calculation Consulting\n",
      "Analyze weight matrices of Deep Neural Networks\n",
      "https://calculationconsulting.com/\n",
      "python      version 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "numpy       version 1.15.4\n",
      "tensforflow version 1.12.0\n",
      "keras       version 2.2.4\n",
      "2018-11-26 13:24:30,867 INFO Analyzing model\n",
      "2018-11-26 13:24:30,881 INFO Layer 0: ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (23): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (24): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (25): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (26): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (27): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (28): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (29): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (30): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (31): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (32): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (33): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (34): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (35): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:24:30,884 INFO Layer 0: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:30,886 INFO Layer 1: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "2018-11-26 13:24:30,889 INFO Pytorch tensor shape detected: 64x3 (NxM), 7x7 (i,j)\n",
      "2018-11-26 13:24:30,892 INFO Layer 1: Analyzing 49 weight matrices...\n",
      "2018-11-26 13:24:30,895 INFO     Weight matrix 1/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,897 INFO     Weight matrix 2/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,900 INFO     Weight matrix 3/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,902 INFO     Weight matrix 4/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,905 INFO     Weight matrix 5/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,908 INFO     Weight matrix 6/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,911 INFO     Weight matrix 7/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,913 INFO     Weight matrix 8/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,916 INFO     Weight matrix 9/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,919 INFO     Weight matrix 10/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,921 INFO     Weight matrix 11/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,924 INFO     Weight matrix 12/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,926 INFO     Weight matrix 13/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,929 INFO     Weight matrix 14/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,931 INFO     Weight matrix 15/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,934 INFO     Weight matrix 16/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,937 INFO     Weight matrix 17/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,939 INFO     Weight matrix 18/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,942 INFO     Weight matrix 19/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,946 INFO     Weight matrix 20/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,948 INFO     Weight matrix 21/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,952 INFO     Weight matrix 22/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,955 INFO     Weight matrix 23/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,958 INFO     Weight matrix 24/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,962 INFO     Weight matrix 25/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,965 INFO     Weight matrix 26/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,967 INFO     Weight matrix 27/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,970 INFO     Weight matrix 28/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,974 INFO     Weight matrix 29/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,978 INFO     Weight matrix 30/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,981 INFO     Weight matrix 31/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,986 INFO     Weight matrix 32/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,989 INFO     Weight matrix 33/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:30,996 INFO     Weight matrix 34/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,000 INFO     Weight matrix 35/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,003 INFO     Weight matrix 36/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,006 INFO     Weight matrix 37/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,009 INFO     Weight matrix 38/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,013 INFO     Weight matrix 39/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,018 INFO     Weight matrix 40/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,022 INFO     Weight matrix 41/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,024 INFO     Weight matrix 42/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,027 INFO     Weight matrix 43/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,029 INFO     Weight matrix 44/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,032 INFO     Weight matrix 45/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,035 INFO     Weight matrix 46/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,039 INFO     Weight matrix 47/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,042 INFO     Weight matrix 48/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,046 INFO     Weight matrix 49/49 (3,64): Skipping: too small (<50)\n",
      "2018-11-26 13:24:31,050 INFO Layer 2: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:31,054 INFO Layer 2: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:31,056 INFO Layer 3: ReLU(inplace)\n",
      "2018-11-26 13:24:31,059 INFO Layer 3: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:31,062 INFO Layer 4: MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "2018-11-26 13:24:31,064 INFO Layer 4: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:24:31,068 INFO Layer 5: Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:24:31,071 INFO Layer 5: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:31,074 INFO Layer 6: Bottleneck(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:24:31,077 INFO Layer 6: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:31,079 INFO Layer 7: Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:31,082 INFO Pytorch tensor shape detected: 64x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:31,085 INFO Layer 7: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:31,088 INFO     Weight matrix 1/1 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:31,747 INFO     Weight matrix 1/1 (64,64): Alpha: 1.3111378014317996, Alpha Weighted: 0.3823579733303639, D: 0.30522964570195926\n",
      "2018-11-26 13:24:31,749 INFO     Weight matrix 1/1 (64,64): Alpha 1.3111378014317996 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:24:31,755 INFO     Weight matrix 1/1 (64,64): Lognorm: 0.5928643345832825\n",
      "2018-11-26 13:24:31,763 INFO Layer 8: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:31,765 INFO Layer 8: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:31,767 INFO Layer 9: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:24:31,772 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:24:31,774 INFO Layer 9: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:24:31,778 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:32,530 INFO     Weight matrix 1/9 (64,64): Alpha: 1.9978324444883895, Alpha Weighted: -0.8817340871347754, D: 0.12302297004177865\n",
      "2018-11-26 13:24:32,533 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.0071212854236364365\n",
      "2018-11-26 13:24:32,535 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:33,008 INFO     Weight matrix 2/9 (64,64): Alpha: 1.8675179105616109, Alpha Weighted: -0.20320774083205365, D: 0.1604787973953889\n",
      "2018-11-26 13:24:33,012 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.16726990044116974\n",
      "2018-11-26 13:24:33,015 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:33,486 INFO     Weight matrix 3/9 (64,64): Alpha: 2.39071542056229, Alpha Weighted: -0.5189457525852342, D: 0.14708516399344795\n",
      "2018-11-26 13:24:33,489 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.08370821177959442\n",
      "2018-11-26 13:24:33,492 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:34,060 INFO     Weight matrix 4/9 (64,64): Alpha: 1.7428111225482983, Alpha Weighted: -0.1474809084237571, D: 0.1396567512802076\n",
      "2018-11-26 13:24:34,065 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.17275509238243103\n",
      "2018-11-26 13:24:34,070 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:34,543 INFO     Weight matrix 5/9 (64,64): Alpha: 1.533536636639343, Alpha Weighted: 0.3449805845434201, D: 0.18931348067298237\n",
      "2018-11-26 13:24:34,547 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.36473777890205383\n",
      "2018-11-26 13:24:34,551 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:34,988 INFO     Weight matrix 6/9 (64,64): Alpha: 2.521992161607593, Alpha Weighted: 0.227471571997078, D: 0.1666666666666673\n",
      "2018-11-26 13:24:34,992 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.2728247046470642\n",
      "2018-11-26 13:24:34,995 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:35,486 INFO     Weight matrix 7/9 (64,64): Alpha: 2.108741780884537, Alpha Weighted: -0.4407228348861336, D: 0.12248156678685418\n",
      "2018-11-26 13:24:35,491 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.0784839391708374\n",
      "2018-11-26 13:24:35,495 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:35,973 INFO     Weight matrix 8/9 (64,64): Alpha: 2.6749210322448764, Alpha Weighted: 0.20211851740851658, D: 0.1666666666666673\n",
      "2018-11-26 13:24:35,976 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.2643391489982605\n",
      "2018-11-26 13:24:35,979 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:36,452 INFO     Weight matrix 9/9 (64,64): Alpha: 2.2388036210874134, Alpha Weighted: 0.014576442716453027, D: 0.1111111111111115\n",
      "2018-11-26 13:24:36,456 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.1910843700170517\n",
      "2018-11-26 13:24:36,460 INFO Layer 10: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:36,465 INFO Layer 10: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:36,468 INFO Layer 11: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:36,473 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:36,477 INFO Layer 11: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:36,480 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:24:37,025 INFO     Weight matrix 1/1 (64,256): Alpha: 3.5175179565482733, Alpha Weighted: 1.7675651347431802, D: 0.11465731958136449\n",
      "2018-11-26 13:24:37,029 INFO     Weight matrix 1/1 (64,256): Alpha 3.5175179565482733 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:24:37,032 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.6120220422744751\n",
      "2018-11-26 13:24:37,035 INFO Layer 12: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:37,040 INFO Layer 12: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:37,043 INFO Layer 13: ReLU(inplace)\n",
      "2018-11-26 13:24:37,047 INFO Layer 13: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:37,051 INFO Layer 14: Sequential(\n",
      "  (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:24:37,054 INFO Layer 14: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:24:37,057 INFO Layer 15: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:37,061 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:37,064 INFO Layer 15: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:37,067 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:24:37,607 INFO     Weight matrix 1/1 (64,256): Alpha: 2.8531390582331717, Alpha Weighted: 2.0171496361487833, D: 0.17279381129119897\n",
      "2018-11-26 13:24:37,611 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.8432208895683289\n",
      "2018-11-26 13:24:37,613 INFO Layer 16: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:37,616 INFO Layer 16: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:37,620 INFO Layer 17: Bottleneck(\n",
      "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:24:37,623 INFO Layer 17: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:37,627 INFO Layer 18: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:37,631 INFO Pytorch tensor shape detected: 64x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:37,635 INFO Layer 18: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:37,638 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:24:38,193 INFO     Weight matrix 1/1 (64,256): Alpha: 1.5846334995950602, Alpha Weighted: 0.2646658066960755, D: 0.20015148094612822\n",
      "2018-11-26 13:24:38,197 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.5337738990783691\n",
      "2018-11-26 13:24:38,203 INFO Layer 19: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:38,206 INFO Layer 19: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:38,209 INFO Layer 20: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:24:38,213 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:24:38,216 INFO Layer 20: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:24:38,220 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:38,783 INFO     Weight matrix 1/9 (64,64): Alpha: 2.108575955457992, Alpha Weighted: -1.8052968336296615, D: 0.22314117353451773\n",
      "2018-11-26 13:24:38,787 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.027689345180988312\n",
      "2018-11-26 13:24:38,790 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:39,315 INFO     Weight matrix 2/9 (64,64): Alpha: 2.3436731357923852, Alpha Weighted: -1.1723968797469588, D: 0.16731466362299127\n",
      "2018-11-26 13:24:39,318 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.12736648321151733\n",
      "2018-11-26 13:24:39,321 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:39,828 INFO     Weight matrix 3/9 (64,64): Alpha: 1.7732815891432885, Alpha Weighted: -1.4183177176199004, D: 0.19158115293849443\n",
      "2018-11-26 13:24:39,831 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.04750386252999306\n",
      "2018-11-26 13:24:39,833 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:40,361 INFO     Weight matrix 4/9 (64,64): Alpha: 1.5636791303487017, Alpha Weighted: -0.6587184983998722, D: 0.1800829455721924\n",
      "2018-11-26 13:24:40,365 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.13411906361579895\n",
      "2018-11-26 13:24:40,367 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:40,838 INFO     Weight matrix 5/9 (64,64): Alpha: 1.4279424535728074, Alpha Weighted: 0.12081564735858864, D: 0.15422955336918087\n",
      "2018-11-26 13:24:40,840 INFO     Weight matrix 5/9 (64,64): Alpha 1.4279424535728074 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:24:40,844 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.375908225774765\n",
      "2018-11-26 13:24:40,847 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:41,378 INFO     Weight matrix 6/9 (64,64): Alpha: 1.5242314623702558, Alpha Weighted: -0.44534904280818177, D: 0.16595088694182253\n",
      "2018-11-26 13:24:41,381 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.19032444059848785\n",
      "2018-11-26 13:24:41,384 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:41,898 INFO     Weight matrix 7/9 (64,64): Alpha: 1.9574327493910495, Alpha Weighted: -1.4687636273696145, D: 0.18169947375355666\n",
      "2018-11-26 13:24:41,905 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.04926489293575287\n",
      "2018-11-26 13:24:41,908 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:42,419 INFO     Weight matrix 8/9 (64,64): Alpha: 2.542314909482204, Alpha Weighted: -0.8570960306314414, D: 0.14222626085827283\n",
      "2018-11-26 13:24:42,423 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.17002511024475098\n",
      "2018-11-26 13:24:42,426 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:42,974 INFO     Weight matrix 9/9 (64,64): Alpha: 2.332966975415467, Alpha Weighted: -1.4230389699861956, D: 0.20483150194543076\n",
      "2018-11-26 13:24:42,977 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.10489676147699356\n",
      "2018-11-26 13:24:42,980 INFO Layer 21: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:42,982 INFO Layer 21: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:42,986 INFO Layer 22: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:42,990 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:42,993 INFO Layer 22: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:42,996 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:24:43,565 INFO     Weight matrix 1/1 (64,256): Alpha: 4.054514446416214, Alpha Weighted: 0.553318941848482, D: 0.14156607362567886\n",
      "2018-11-26 13:24:43,570 INFO     Weight matrix 1/1 (64,256): Alpha 4.054514446416214 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:24:43,574 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.5406745672225952\n",
      "2018-11-26 13:24:43,577 INFO Layer 23: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:43,580 INFO Layer 23: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:43,583 INFO Layer 24: ReLU(inplace)\n",
      "2018-11-26 13:24:43,590 INFO Layer 24: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:43,593 INFO Layer 25: Bottleneck(\n",
      "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:24:43,596 INFO Layer 25: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:43,601 INFO Layer 26: Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:43,607 INFO Pytorch tensor shape detected: 64x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:43,610 INFO Layer 26: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:43,614 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:24:44,271 INFO     Weight matrix 1/1 (64,256): Alpha: 1.865161718770696, Alpha Weighted: 0.24284691589151589, D: 0.1881796876593887\n",
      "2018-11-26 13:24:44,276 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.5374316573143005\n",
      "2018-11-26 13:24:44,280 INFO Layer 27: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:44,282 INFO Layer 27: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:44,289 INFO Layer 28: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:24:44,295 INFO Pytorch tensor shape detected: 64x64 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:24:44,301 INFO Layer 28: Analyzing 9 weight matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:24:44,304 INFO     Weight matrix 1/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:44,813 INFO     Weight matrix 1/9 (64,64): Alpha: 1.6232098790346197, Alpha Weighted: -1.1211486358543286, D: 0.21758747701648185\n",
      "2018-11-26 13:24:44,816 INFO     Weight matrix 1/9 (64,64): Lognorm: 0.1108664870262146\n",
      "2018-11-26 13:24:44,822 INFO     Weight matrix 2/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:45,242 INFO     Weight matrix 2/9 (64,64): Alpha: 1.7684157227872153, Alpha Weighted: -0.44939927630155424, D: 0.16151880044406774\n",
      "2018-11-26 13:24:45,245 INFO     Weight matrix 2/9 (64,64): Lognorm: 0.2392445206642151\n",
      "2018-11-26 13:24:45,248 INFO     Weight matrix 3/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:45,695 INFO     Weight matrix 3/9 (64,64): Alpha: 2.077211198180585, Alpha Weighted: -1.4030713030225397, D: 0.1902572794948938\n",
      "2018-11-26 13:24:45,698 INFO     Weight matrix 3/9 (64,64): Lognorm: 0.13737550377845764\n",
      "2018-11-26 13:24:45,702 INFO     Weight matrix 4/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:46,137 INFO     Weight matrix 4/9 (64,64): Alpha: 1.7978725328584169, Alpha Weighted: -0.4089361776555748, D: 0.1333485990540263\n",
      "2018-11-26 13:24:46,140 INFO     Weight matrix 4/9 (64,64): Lognorm: 0.23054595291614532\n",
      "2018-11-26 13:24:46,143 INFO     Weight matrix 5/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:46,540 INFO     Weight matrix 5/9 (64,64): Alpha: 1.540448981980199, Alpha Weighted: 0.0759804029979797, D: 0.15652922728715524\n",
      "2018-11-26 13:24:46,543 INFO     Weight matrix 5/9 (64,64): Lognorm: 0.3831087350845337\n",
      "2018-11-26 13:24:46,548 INFO     Weight matrix 6/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:46,936 INFO     Weight matrix 6/9 (64,64): Alpha: 1.701169283002876, Alpha Weighted: -0.24599238047671743, D: 0.15245310805321466\n",
      "2018-11-26 13:24:46,941 INFO     Weight matrix 6/9 (64,64): Lognorm: 0.2761145830154419\n",
      "2018-11-26 13:24:46,944 INFO     Weight matrix 7/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:47,374 INFO     Weight matrix 7/9 (64,64): Alpha: 2.136615683626734, Alpha Weighted: -1.4198678445557265, D: 0.19155473562763692\n",
      "2018-11-26 13:24:47,377 INFO     Weight matrix 7/9 (64,64): Lognorm: 0.1296645998954773\n",
      "2018-11-26 13:24:47,382 INFO     Weight matrix 8/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:47,787 INFO     Weight matrix 8/9 (64,64): Alpha: 1.6959441951861676, Alpha Weighted: -0.17945406198638245, D: 0.15309975209819315\n",
      "2018-11-26 13:24:47,790 INFO     Weight matrix 8/9 (64,64): Lognorm: 0.2874045968055725\n",
      "2018-11-26 13:24:47,795 INFO     Weight matrix 9/9 (64,64): Analyzing ...\n",
      "2018-11-26 13:24:48,223 INFO     Weight matrix 9/9 (64,64): Alpha: 1.9356701905344624, Alpha Weighted: -1.0699457193266275, D: 0.2006522482414685\n",
      "2018-11-26 13:24:48,226 INFO     Weight matrix 9/9 (64,64): Lognorm: 0.17457324266433716\n",
      "2018-11-26 13:24:48,229 INFO Layer 29: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:48,231 INFO Layer 29: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:48,234 INFO Layer 30: Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:48,239 INFO Pytorch tensor shape detected: 256x64 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:48,247 INFO Layer 30: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:48,250 INFO     Weight matrix 1/1 (64,256): Analyzing ...\n",
      "2018-11-26 13:24:48,695 INFO     Weight matrix 1/1 (64,256): Alpha: 9.386195486708251, Alpha Weighted: -1.0441823418441443, D: 0.1666666666666673\n",
      "2018-11-26 13:24:48,698 INFO     Weight matrix 1/1 (64,256): Alpha 9.386195486708251 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:24:48,705 INFO     Weight matrix 1/1 (64,256): Lognorm: 0.5174378752708435\n",
      "2018-11-26 13:24:48,709 INFO Layer 31: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:48,713 INFO Layer 31: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:48,716 INFO Layer 32: ReLU(inplace)\n",
      "2018-11-26 13:24:48,720 INFO Layer 32: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:48,725 INFO Layer 33: Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (6): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (7): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:24:48,729 INFO Layer 33: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:48,733 INFO Layer 34: Bottleneck(\n",
      "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:24:48,736 INFO Layer 34: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:48,739 INFO Layer 35: Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:48,745 INFO Pytorch tensor shape detected: 128x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:48,748 INFO Layer 35: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:48,755 INFO     Weight matrix 1/1 (128,256): Analyzing ...\n",
      "2018-11-26 13:24:49,751 INFO     Weight matrix 1/1 (128,256): Alpha: 1.6002481924227092, Alpha Weighted: 0.594926550864705, D: 0.13679708575976834\n",
      "2018-11-26 13:24:49,754 INFO     Weight matrix 1/1 (128,256): Lognorm: 0.726112425327301\n",
      "2018-11-26 13:24:49,757 INFO Layer 36: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:49,759 INFO Layer 36: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:49,762 INFO Layer 37: Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:24:49,768 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:24:49,770 INFO Layer 37: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:24:49,772 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:24:50,834 INFO     Weight matrix 1/9 (128,128): Alpha: 2.034532178329457, Alpha Weighted: -0.8342952181906073, D: 0.1364012033143357\n",
      "2018-11-26 13:24:50,837 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.30428585410118103\n",
      "2018-11-26 13:24:50,840 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:24:51,778 INFO     Weight matrix 2/9 (128,128): Alpha: 1.622310494319953, Alpha Weighted: -0.2984447924568397, D: 0.15363311028239557\n",
      "2018-11-26 13:24:51,781 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.4025734066963196\n",
      "2018-11-26 13:24:51,786 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:24:52,712 INFO     Weight matrix 3/9 (128,128): Alpha: 1.8265045093505026, Alpha Weighted: -0.48406215374142136, D: 0.1556870730597668\n",
      "2018-11-26 13:24:52,715 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.3659771978855133\n",
      "2018-11-26 13:24:52,718 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:24:53,716 INFO     Weight matrix 4/9 (128,128): Alpha: 1.9608920580464644, Alpha Weighted: -0.3700700152326043, D: 0.15200847189272476\n",
      "2018-11-26 13:24:53,720 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.3968113362789154\n",
      "2018-11-26 13:24:53,722 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:24:54,650 INFO     Weight matrix 5/9 (128,128): Alpha: 1.640652208580849, Alpha Weighted: 0.13053379257403072, D: 0.1228825827062211\n",
      "2018-11-26 13:24:54,653 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.48376333713531494\n",
      "2018-11-26 13:24:54,659 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:24:55,653 INFO     Weight matrix 6/9 (128,128): Alpha: 2.1212566256943406, Alpha Weighted: -0.08437870147626099, D: 0.17205429880382783\n",
      "2018-11-26 13:24:55,656 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.47628867626190186\n",
      "2018-11-26 13:24:55,659 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:24:56,584 INFO     Weight matrix 7/9 (128,128): Alpha: 2.2305080837508973, Alpha Weighted: -0.6482347112285477, D: 0.1484711293302523\n",
      "2018-11-26 13:24:56,588 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.3584505617618561\n",
      "2018-11-26 13:24:56,591 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:24:57,495 INFO     Weight matrix 8/9 (128,128): Alpha: 2.200609412577255, Alpha Weighted: -0.026105261227218308, D: 0.15907583233009726\n",
      "2018-11-26 13:24:57,498 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.47330784797668457\n",
      "2018-11-26 13:24:57,503 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:24:58,421 INFO     Weight matrix 9/9 (128,128): Alpha: 2.1032450799941174, Alpha Weighted: -0.26911311801557614, D: 0.1384954270701491\n",
      "2018-11-26 13:24:58,426 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.43212050199508667\n",
      "2018-11-26 13:24:58,428 INFO Layer 38: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:58,431 INFO Layer 38: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:58,434 INFO Layer 39: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:24:58,445 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:58,447 INFO Layer 39: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:58,449 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:24:59,459 INFO     Weight matrix 1/1 (128,512): Alpha: 2.6384253732388663, Alpha Weighted: 0.8260565706914399, D: 0.16748458265548205\n",
      "2018-11-26 13:24:59,462 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.822799026966095\n",
      "2018-11-26 13:24:59,465 INFO Layer 40: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:24:59,467 INFO Layer 40: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:59,470 INFO Layer 41: ReLU(inplace)\n",
      "2018-11-26 13:24:59,475 INFO Layer 41: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:59,478 INFO Layer 42: Sequential(\n",
      "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:24:59,481 INFO Layer 42: Skipping (Layer not supported)\n",
      "2018-11-26 13:24:59,484 INFO Layer 43: Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 13:24:59,495 INFO Pytorch tensor shape detected: 512x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:24:59,498 INFO Layer 43: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:24:59,502 INFO     Weight matrix 1/1 (256,512): Analyzing ...\n",
      "2018-11-26 13:25:02,102 INFO     Weight matrix 1/1 (256,512): Alpha: 1.5379124675860336, Alpha Weighted: 1.214849132326766, D: 0.10976409785319885\n",
      "2018-11-26 13:25:02,105 INFO     Weight matrix 1/1 (256,512): Lognorm: 0.8873290419578552\n",
      "2018-11-26 13:25:02,111 INFO Layer 44: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:25:02,115 INFO Layer 44: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:02,118 INFO Layer 45: Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:25:02,121 INFO Layer 45: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:02,124 INFO Layer 46: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:25:02,129 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:25:02,132 INFO Layer 46: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:25:02,136 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:25:03,221 INFO     Weight matrix 1/1 (128,512): Alpha: 1.622841610957761, Alpha Weighted: 0.5646565366299456, D: 0.06505153623455379\n",
      "2018-11-26 13:25:03,224 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.5109164714813232\n",
      "2018-11-26 13:25:03,226 INFO Layer 47: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:25:03,229 INFO Layer 47: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:03,231 INFO Layer 48: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:25:03,236 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:25:03,239 INFO Layer 48: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:25:03,242 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:04,343 INFO     Weight matrix 1/9 (128,128): Alpha: 1.3882083346014968, Alpha Weighted: -0.9153488115089543, D: 0.12746227596610132\n",
      "2018-11-26 13:25:04,345 INFO     Weight matrix 1/9 (128,128): Alpha 1.3882083346014968 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:25:04,350 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.03822610154747963\n",
      "2018-11-26 13:25:04,354 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:05,446 INFO     Weight matrix 2/9 (128,128): Alpha: 1.5358373003282586, Alpha Weighted: 0.11972347349920104, D: 0.09327217511669889\n",
      "2018-11-26 13:25:05,451 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.21976955235004425\n",
      "2018-11-26 13:25:05,458 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:06,471 INFO     Weight matrix 3/9 (128,128): Alpha: 1.4748016595837483, Alpha Weighted: -0.6912833023149816, D: 0.11698117618231718\n",
      "2018-11-26 13:25:06,474 INFO     Weight matrix 3/9 (128,128): Alpha 1.4748016595837483 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:25:06,480 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.0675375908613205\n",
      "2018-11-26 13:25:06,483 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:07,408 INFO     Weight matrix 4/9 (128,128): Alpha: 1.5524211747307102, Alpha Weighted: 0.07915373451924784, D: 0.09970140985230774\n",
      "2018-11-26 13:25:07,412 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.22316093742847443\n",
      "2018-11-26 13:25:07,416 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:08,372 INFO     Weight matrix 5/9 (128,128): Alpha: 1.4458929441632662, Alpha Weighted: 0.3539618555586392, D: 0.08180969159410945\n",
      "2018-11-26 13:25:08,374 INFO     Weight matrix 5/9 (128,128): Alpha 1.4458929441632662 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:25:08,381 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.38057348132133484\n",
      "2018-11-26 13:25:08,383 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:09,370 INFO     Weight matrix 6/9 (128,128): Alpha: 1.5020183125160047, Alpha Weighted: 0.2089286213922821, D: 0.08356473923107044\n",
      "2018-11-26 13:25:09,374 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.2555308938026428\n",
      "2018-11-26 13:25:09,377 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:10,346 INFO     Weight matrix 7/9 (128,128): Alpha: 1.393419570928756, Alpha Weighted: -0.6864909946674933, D: 0.11792092093771933\n",
      "2018-11-26 13:25:10,349 INFO     Weight matrix 7/9 (128,128): Alpha 1.393419570928756 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:25:10,354 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.08384289592504501\n",
      "2018-11-26 13:25:10,357 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:11,382 INFO     Weight matrix 8/9 (128,128): Alpha: 1.4933757517620199, Alpha Weighted: 0.21075678241820567, D: 0.07935697898973282\n",
      "2018-11-26 13:25:11,385 INFO     Weight matrix 8/9 (128,128): Alpha 1.4933757517620199 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:25:11,393 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.2756684124469757\n",
      "2018-11-26 13:25:11,397 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:12,568 INFO     Weight matrix 9/9 (128,128): Alpha: 1.4722881443888332, Alpha Weighted: -0.40920013960368384, D: 0.1091866546720075\n",
      "2018-11-26 13:25:12,571 INFO     Weight matrix 9/9 (128,128): Alpha 1.4722881443888332 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:25:12,576 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.16791389882564545\n",
      "2018-11-26 13:25:12,579 INFO Layer 49: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:25:12,582 INFO Layer 49: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:12,588 INFO Layer 50: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:25:12,592 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:25:12,596 INFO Layer 50: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:25:12,600 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:25:13,750 INFO     Weight matrix 1/1 (128,512): Alpha: 4.124810720239806, Alpha Weighted: 1.1189768927096695, D: 0.11315647130758966\n",
      "2018-11-26 13:25:13,754 INFO     Weight matrix 1/1 (128,512): Alpha 4.124810720239806 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:25:13,759 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.5689065456390381\n",
      "2018-11-26 13:25:13,763 INFO Layer 51: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:25:13,766 INFO Layer 51: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:13,772 INFO Layer 52: ReLU(inplace)\n",
      "2018-11-26 13:25:13,775 INFO Layer 52: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:13,778 INFO Layer 53: Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:25:13,781 INFO Layer 53: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:13,784 INFO Layer 54: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:25:13,788 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:25:13,792 INFO Layer 54: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:25:13,798 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:25:15,368 INFO     Weight matrix 1/1 (128,512): Alpha: 1.6168132855905422, Alpha Weighted: 0.10231469331911724, D: 0.1476827433241622\n",
      "2018-11-26 13:25:15,374 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.5885189175605774\n",
      "2018-11-26 13:25:15,377 INFO Layer 55: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:25:15,381 INFO Layer 55: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:15,384 INFO Layer 56: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:25:15,391 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:25:15,397 INFO Layer 56: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:25:15,408 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:16,538 INFO     Weight matrix 1/9 (128,128): Alpha: 1.8429958208484258, Alpha Weighted: -1.1489558410272636, D: 0.1439085436973031\n",
      "2018-11-26 13:25:16,543 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.17475999891757965\n",
      "2018-11-26 13:25:16,548 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:17,784 INFO     Weight matrix 2/9 (128,128): Alpha: 1.9035964270020673, Alpha Weighted: -0.6493797272080986, D: 0.12210358739162586\n",
      "2018-11-26 13:25:17,790 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.26798099279403687\n",
      "2018-11-26 13:25:17,794 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:19,102 INFO     Weight matrix 3/9 (128,128): Alpha: 1.861861192926662, Alpha Weighted: -0.8837977160919598, D: 0.1291534686566505\n",
      "2018-11-26 13:25:19,107 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.20599541068077087\n",
      "2018-11-26 13:25:19,111 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:20,228 INFO     Weight matrix 4/9 (128,128): Alpha: 1.7528738402716408, Alpha Weighted: -0.5237003370049496, D: 0.1181391009049722\n",
      "2018-11-26 13:25:20,233 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.27179908752441406\n",
      "2018-11-26 13:25:20,240 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:21,308 INFO     Weight matrix 5/9 (128,128): Alpha: 1.7056449405644023, Alpha Weighted: -0.127839362739396, D: 0.12667664090417974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:25:21,312 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.36193689703941345\n",
      "2018-11-26 13:25:21,316 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:22,374 INFO     Weight matrix 6/9 (128,128): Alpha: 1.942097364235813, Alpha Weighted: -0.43105663143615885, D: 0.11651256151057587\n",
      "2018-11-26 13:25:22,378 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.31305912137031555\n",
      "2018-11-26 13:25:22,383 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:23,438 INFO     Weight matrix 7/9 (128,128): Alpha: 2.3031795750183517, Alpha Weighted: -1.1773272167646622, D: 0.12958035732536077\n",
      "2018-11-26 13:25:23,443 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.19802089035511017\n",
      "2018-11-26 13:25:23,445 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:24,520 INFO     Weight matrix 8/9 (128,128): Alpha: 1.868803991036553, Alpha Weighted: -0.5657302670171248, D: 0.13077611311569604\n",
      "2018-11-26 13:25:24,524 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.29548102617263794\n",
      "2018-11-26 13:25:24,527 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:25,554 INFO     Weight matrix 9/9 (128,128): Alpha: 1.9998800147773976, Alpha Weighted: -0.8539967771166161, D: 0.11828019991568428\n",
      "2018-11-26 13:25:25,558 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.23987306654453278\n",
      "2018-11-26 13:25:25,565 INFO Layer 57: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:25:25,568 INFO Layer 57: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:25,571 INFO Layer 58: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:25:25,574 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:25:25,578 INFO Layer 58: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:25:25,581 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:25:26,829 INFO     Weight matrix 1/1 (128,512): Alpha: 6.164983783519854, Alpha Weighted: -0.49399208733265787, D: 0.21210379624969533\n",
      "2018-11-26 13:25:26,832 INFO     Weight matrix 1/1 (128,512): Alpha 6.164983783519854 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:25:26,835 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.6500002145767212\n",
      "2018-11-26 13:25:26,838 INFO Layer 59: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:25:26,842 INFO Layer 59: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:26,846 INFO Layer 60: ReLU(inplace)\n",
      "2018-11-26 13:25:26,849 INFO Layer 60: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:26,853 INFO Layer 61: Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:25:26,855 INFO Layer 61: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:26,859 INFO Layer 62: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:25:26,864 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:25:26,867 INFO Layer 62: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:25:26,870 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:25:28,198 INFO     Weight matrix 1/1 (128,512): Alpha: 1.6813964994651238, Alpha Weighted: 0.5574673636920158, D: 0.0749103393666436\n",
      "2018-11-26 13:25:28,202 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.6058210730552673\n",
      "2018-11-26 13:25:28,205 INFO Layer 63: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:25:28,212 INFO Layer 63: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:28,217 INFO Layer 64: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:25:28,221 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:25:28,227 INFO Layer 64: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:25:28,232 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:29,436 INFO     Weight matrix 1/9 (128,128): Alpha: 1.8179934591350988, Alpha Weighted: -1.0131170985905604, D: 0.12438378074764134\n",
      "2018-11-26 13:25:29,440 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.11582526564598083\n",
      "2018-11-26 13:25:29,443 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:30,530 INFO     Weight matrix 2/9 (128,128): Alpha: 1.9051846496356073, Alpha Weighted: -0.3284048006329747, D: 0.07110786082134524\n",
      "2018-11-26 13:25:30,535 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.2407405823469162\n",
      "2018-11-26 13:25:30,539 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:31,591 INFO     Weight matrix 3/9 (128,128): Alpha: 2.0311569927278033, Alpha Weighted: -0.9702888912081624, D: 0.11762504780136868\n",
      "2018-11-26 13:25:31,594 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.151533305644989\n",
      "2018-11-26 13:25:31,597 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:32,462 INFO     Weight matrix 4/9 (128,128): Alpha: 1.8758705855575526, Alpha Weighted: -0.2969051653785586, D: 0.09710900025083907\n",
      "2018-11-26 13:25:32,466 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.228804349899292\n",
      "2018-11-26 13:25:32,468 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:33,322 INFO     Weight matrix 5/9 (128,128): Alpha: 1.7177154126532006, Alpha Weighted: -0.11943164398066237, D: 0.10719750090240138\n",
      "2018-11-26 13:25:33,325 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.33591631054878235\n",
      "2018-11-26 13:25:33,328 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:34,290 INFO     Weight matrix 6/9 (128,128): Alpha: 1.6945846078507363, Alpha Weighted: -0.20502073509876537, D: 0.10363481329880392\n",
      "2018-11-26 13:25:34,294 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.2857878506183624\n",
      "2018-11-26 13:25:34,298 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:35,229 INFO     Weight matrix 7/9 (128,128): Alpha: 1.8337320470979106, Alpha Weighted: -0.9120998790043673, D: 0.10843156145276778\n",
      "2018-11-26 13:25:35,233 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.14627055823802948\n",
      "2018-11-26 13:25:35,236 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:36,236 INFO     Weight matrix 8/9 (128,128): Alpha: 1.8934039148306698, Alpha Weighted: -0.235713056219178, D: 0.08513543052145511\n",
      "2018-11-26 13:25:36,240 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.2701539397239685\n",
      "2018-11-26 13:25:36,242 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:37,198 INFO     Weight matrix 9/9 (128,128): Alpha: 1.9956470893213512, Alpha Weighted: -0.6568220210982415, D: 0.10005596329207889\n",
      "2018-11-26 13:25:37,201 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.21299748122692108\n",
      "2018-11-26 13:25:37,203 INFO Layer 65: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:25:37,206 INFO Layer 65: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:37,209 INFO Layer 66: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:25:37,212 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:25:37,215 INFO Layer 66: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:25:37,218 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:25:38,437 INFO     Weight matrix 1/1 (128,512): Alpha: 1.4774061775884624, Alpha Weighted: -0.11019318466202829, D: 0.17009326599356472\n",
      "2018-11-26 13:25:38,440 INFO     Weight matrix 1/1 (128,512): Alpha 1.4774061775884624 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:25:38,445 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.5825130939483643\n",
      "2018-11-26 13:25:38,448 INFO Layer 67: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:25:38,454 INFO Layer 67: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:38,457 INFO Layer 68: ReLU(inplace)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:25:38,460 INFO Layer 68: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:38,464 INFO Layer 69: Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:25:38,467 INFO Layer 69: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:38,474 INFO Layer 70: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:25:38,478 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:25:38,481 INFO Layer 70: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:25:38,485 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:25:39,822 INFO     Weight matrix 1/1 (128,512): Alpha: 3.742374458849538, Alpha Weighted: 0.5632357748968362, D: 0.15410978612586687\n",
      "2018-11-26 13:25:39,826 INFO     Weight matrix 1/1 (128,512): Alpha 3.742374458849538 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:25:39,829 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.624896228313446\n",
      "2018-11-26 13:25:39,832 INFO Layer 71: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:25:39,835 INFO Layer 71: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:39,837 INFO Layer 72: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:25:39,845 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:25:39,849 INFO Layer 72: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:25:39,855 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:40,950 INFO     Weight matrix 1/9 (128,128): Alpha: 1.8700494202880371, Alpha Weighted: -1.2240682978859436, D: 0.15319509642051887\n",
      "2018-11-26 13:25:40,955 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.2040281742811203\n",
      "2018-11-26 13:25:40,958 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:42,053 INFO     Weight matrix 2/9 (128,128): Alpha: 2.032616643943949, Alpha Weighted: -0.3547536419323456, D: 0.11957976865915976\n",
      "2018-11-26 13:25:42,057 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.29492515325546265\n",
      "2018-11-26 13:25:42,060 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:43,054 INFO     Weight matrix 3/9 (128,128): Alpha: 1.955342592779435, Alpha Weighted: -1.0528073722081508, D: 0.1367676459644982\n",
      "2018-11-26 13:25:43,058 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.21791835129261017\n",
      "2018-11-26 13:25:43,060 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:44,162 INFO     Weight matrix 4/9 (128,128): Alpha: 1.8390300471492051, Alpha Weighted: -0.35137320447016623, D: 0.11299945626355667\n",
      "2018-11-26 13:25:44,166 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.3000335395336151\n",
      "2018-11-26 13:25:44,170 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:45,302 INFO     Weight matrix 5/9 (128,128): Alpha: 1.8819854187687945, Alpha Weighted: -0.14081495280411888, D: 0.12629970665251097\n",
      "2018-11-26 13:25:45,305 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.38767534494400024\n",
      "2018-11-26 13:25:45,309 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:46,419 INFO     Weight matrix 6/9 (128,128): Alpha: 1.82123440893863, Alpha Weighted: -0.23220141232586428, D: 0.10879283737505219\n",
      "2018-11-26 13:25:46,423 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.3247565031051636\n",
      "2018-11-26 13:25:46,428 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:47,539 INFO     Weight matrix 7/9 (128,128): Alpha: 1.9282293597996052, Alpha Weighted: -1.1233876844837891, D: 0.14403942593563085\n",
      "2018-11-26 13:25:47,544 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.21347860991954803\n",
      "2018-11-26 13:25:47,550 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:48,627 INFO     Weight matrix 8/9 (128,128): Alpha: 1.8213553257330863, Alpha Weighted: -0.17257810250764624, D: 0.10730600104832688\n",
      "2018-11-26 13:25:48,630 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.3164508640766144\n",
      "2018-11-26 13:25:48,633 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:49,889 INFO     Weight matrix 9/9 (128,128): Alpha: 1.9109695080591291, Alpha Weighted: -0.7910210468341603, D: 0.1259783990629263\n",
      "2018-11-26 13:25:49,893 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.2453783005475998\n",
      "2018-11-26 13:25:49,896 INFO Layer 73: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:25:49,900 INFO Layer 73: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:49,904 INFO Layer 74: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:25:49,910 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:25:49,913 INFO Layer 74: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:25:49,916 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:25:51,224 INFO     Weight matrix 1/1 (128,512): Alpha: 1.6178181284725142, Alpha Weighted: 0.014351366709810057, D: 0.1818144189827483\n",
      "2018-11-26 13:25:51,228 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.6439647674560547\n",
      "2018-11-26 13:25:51,231 INFO Layer 75: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:25:51,233 INFO Layer 75: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:51,237 INFO Layer 76: ReLU(inplace)\n",
      "2018-11-26 13:25:51,240 INFO Layer 76: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:51,243 INFO Layer 77: Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:25:51,246 INFO Layer 77: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:51,250 INFO Layer 78: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:25:51,258 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:25:51,262 INFO Layer 78: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:25:51,266 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:25:52,525 INFO     Weight matrix 1/1 (128,512): Alpha: 1.6000308270072654, Alpha Weighted: 0.249994135361749, D: 0.14566379639297178\n",
      "2018-11-26 13:25:52,528 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.6281276941299438\n",
      "2018-11-26 13:25:52,532 INFO Layer 79: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:25:52,537 INFO Layer 79: Skipping (Layer not supported)\n",
      "2018-11-26 13:25:52,541 INFO Layer 80: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:25:52,552 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:25:52,556 INFO Layer 80: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:25:52,560 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:53,582 INFO     Weight matrix 1/9 (128,128): Alpha: 1.93239613278881, Alpha Weighted: -1.0720397655606486, D: 0.1203200391561513\n",
      "2018-11-26 13:25:53,586 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.15643581748008728\n",
      "2018-11-26 13:25:53,588 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:54,593 INFO     Weight matrix 2/9 (128,128): Alpha: 1.9179050439334846, Alpha Weighted: -0.5119070381476912, D: 0.10421731010673574\n",
      "2018-11-26 13:25:54,598 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.25651857256889343\n",
      "2018-11-26 13:25:54,601 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:55,621 INFO     Weight matrix 3/9 (128,128): Alpha: 2.1213387431186064, Alpha Weighted: -0.8001141772323478, D: 0.09083376452590886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:25:55,625 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.196871817111969\n",
      "2018-11-26 13:25:55,628 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:56,708 INFO     Weight matrix 4/9 (128,128): Alpha: 1.8139078634626449, Alpha Weighted: -0.42714747590347274, D: 0.09397574787531976\n",
      "2018-11-26 13:25:56,714 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.2766146659851074\n",
      "2018-11-26 13:25:56,720 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:57,714 INFO     Weight matrix 5/9 (128,128): Alpha: 1.8182105175301864, Alpha Weighted: -0.169836592858256, D: 0.10838392619399273\n",
      "2018-11-26 13:25:57,718 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.36132165789604187\n",
      "2018-11-26 13:25:57,721 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:58,575 INFO     Weight matrix 6/9 (128,128): Alpha: 1.7714456230998712, Alpha Weighted: -0.13965764921105975, D: 0.09831136010108443\n",
      "2018-11-26 13:25:58,578 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.3291946351528168\n",
      "2018-11-26 13:25:58,581 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:25:59,401 INFO     Weight matrix 7/9 (128,128): Alpha: 2.1762612360290126, Alpha Weighted: -0.7922237368959052, D: 0.09020517234136777\n",
      "2018-11-26 13:25:59,404 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.2035689502954483\n",
      "2018-11-26 13:25:59,409 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:00,207 INFO     Weight matrix 8/9 (128,128): Alpha: 1.756929271206883, Alpha Weighted: -0.17892775282089107, D: 0.08869908224146938\n",
      "2018-11-26 13:26:00,210 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.3208874464035034\n",
      "2018-11-26 13:26:00,217 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:01,048 INFO     Weight matrix 9/9 (128,128): Alpha: 1.8844646022478588, Alpha Weighted: -0.4557170257265704, D: 0.0983163751065731\n",
      "2018-11-26 13:26:01,051 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.25257375836372375\n",
      "2018-11-26 13:26:01,053 INFO Layer 81: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:26:01,058 INFO Layer 81: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:01,062 INFO Layer 82: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:26:01,069 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:26:01,072 INFO Layer 82: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:26:01,076 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:26:02,082 INFO     Weight matrix 1/1 (128,512): Alpha: 1.6280600816900483, Alpha Weighted: -0.04124898077877864, D: 0.17662519710028046\n",
      "2018-11-26 13:26:02,086 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.6274072527885437\n",
      "2018-11-26 13:26:02,089 INFO Layer 83: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:26:02,093 INFO Layer 83: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:02,095 INFO Layer 84: ReLU(inplace)\n",
      "2018-11-26 13:26:02,098 INFO Layer 84: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:02,101 INFO Layer 85: Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:26:02,104 INFO Layer 85: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:02,107 INFO Layer 86: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:26:02,110 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:26:02,113 INFO Layer 86: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:26:02,116 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:26:03,336 INFO     Weight matrix 1/1 (128,512): Alpha: 1.6867438565277113, Alpha Weighted: 0.27349419835701394, D: 0.12708540689135273\n",
      "2018-11-26 13:26:03,340 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.6829442977905273\n",
      "2018-11-26 13:26:03,343 INFO Layer 87: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:26:03,347 INFO Layer 87: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:03,350 INFO Layer 88: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:26:03,360 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:26:03,362 INFO Layer 88: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:26:03,366 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:04,525 INFO     Weight matrix 1/9 (128,128): Alpha: 2.5719442037052387, Alpha Weighted: -1.529229483649045, D: 0.12250431853871435\n",
      "2018-11-26 13:26:04,532 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.2200363427400589\n",
      "2018-11-26 13:26:04,535 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:05,664 INFO     Weight matrix 2/9 (128,128): Alpha: 1.9713671865172044, Alpha Weighted: -0.4526213476739011, D: 0.11120797876570976\n",
      "2018-11-26 13:26:05,669 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.3335237503051758\n",
      "2018-11-26 13:26:05,672 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:06,681 INFO     Weight matrix 3/9 (128,128): Alpha: 2.2694896243432137, Alpha Weighted: -1.0184291158671028, D: 0.11476691278801765\n",
      "2018-11-26 13:26:06,685 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.26383447647094727\n",
      "2018-11-26 13:26:06,688 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:07,647 INFO     Weight matrix 4/9 (128,128): Alpha: 1.955045458176686, Alpha Weighted: -0.47261750222472526, D: 0.10393797900336166\n",
      "2018-11-26 13:26:07,651 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.33432599902153015\n",
      "2018-11-26 13:26:07,655 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:08,549 INFO     Weight matrix 5/9 (128,128): Alpha: 1.7670146515818548, Alpha Weighted: -0.07173684188785483, D: 0.113392630493654\n",
      "2018-11-26 13:26:08,553 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.460150808095932\n",
      "2018-11-26 13:26:08,557 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:09,514 INFO     Weight matrix 6/9 (128,128): Alpha: 1.8030434998360971, Alpha Weighted: -0.14811927988522736, D: 0.11222013960009747\n",
      "2018-11-26 13:26:09,517 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.4186878502368927\n",
      "2018-11-26 13:26:09,520 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:10,518 INFO     Weight matrix 7/9 (128,128): Alpha: 2.3433972281367583, Alpha Weighted: -1.1214910983790027, D: 0.11375554242294461\n",
      "2018-11-26 13:26:10,522 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.2582261264324188\n",
      "2018-11-26 13:26:10,525 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:11,494 INFO     Weight matrix 8/9 (128,128): Alpha: 1.7935277476229041, Alpha Weighted: -0.22433921561162976, D: 0.09963239822752645\n",
      "2018-11-26 13:26:11,498 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.3988456428050995\n",
      "2018-11-26 13:26:11,502 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:12,514 INFO     Weight matrix 9/9 (128,128): Alpha: 1.987900497617791, Alpha Weighted: -0.6138363265154089, D: 0.10155983295006882\n",
      "2018-11-26 13:26:12,516 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.3200015425682068\n",
      "2018-11-26 13:26:12,519 INFO Layer 89: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:26:12,522 INFO Layer 89: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:12,526 INFO Layer 90: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:26:12,530 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:26:12,533 INFO Layer 90: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:26:12,535 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:26:13,622 INFO     Weight matrix 1/1 (128,512): Alpha: 1.5923654268655434, Alpha Weighted: -0.00943170599899397, D: 0.1873487099367468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:26:13,625 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.6469484567642212\n",
      "2018-11-26 13:26:13,627 INFO Layer 91: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:26:13,631 INFO Layer 91: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:13,634 INFO Layer 92: ReLU(inplace)\n",
      "2018-11-26 13:26:13,637 INFO Layer 92: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:13,641 INFO Layer 93: Bottleneck(\n",
      "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:26:13,644 INFO Layer 93: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:13,648 INFO Layer 94: Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:26:13,652 INFO Pytorch tensor shape detected: 128x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:26:13,655 INFO Layer 94: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:26:13,660 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:26:15,017 INFO     Weight matrix 1/1 (128,512): Alpha: 2.5603311475795683, Alpha Weighted: 0.3832165642014882, D: 0.15505847837616016\n",
      "2018-11-26 13:26:15,020 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.7136598229408264\n",
      "2018-11-26 13:26:15,024 INFO Layer 95: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:26:15,028 INFO Layer 95: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:15,032 INFO Layer 96: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:26:15,036 INFO Pytorch tensor shape detected: 128x128 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:26:15,043 INFO Layer 96: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:26:15,049 INFO     Weight matrix 1/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:16,222 INFO     Weight matrix 1/9 (128,128): Alpha: 2.1581071134448426, Alpha Weighted: -1.4123420697169773, D: 0.1560953027993104\n",
      "2018-11-26 13:26:16,226 INFO     Weight matrix 1/9 (128,128): Lognorm: 0.22443769872188568\n",
      "2018-11-26 13:26:16,229 INFO     Weight matrix 2/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:17,236 INFO     Weight matrix 2/9 (128,128): Alpha: 1.718128741474548, Alpha Weighted: -0.9251819308165653, D: 0.16583088053557082\n",
      "2018-11-26 13:26:17,241 INFO     Weight matrix 2/9 (128,128): Lognorm: 0.28978633880615234\n",
      "2018-11-26 13:26:17,246 INFO     Weight matrix 3/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:18,445 INFO     Weight matrix 3/9 (128,128): Alpha: 2.225133274069711, Alpha Weighted: -1.4466669521354425, D: 0.16891346446403405\n",
      "2018-11-26 13:26:18,449 INFO     Weight matrix 3/9 (128,128): Lognorm: 0.2420671135187149\n",
      "2018-11-26 13:26:18,453 INFO     Weight matrix 4/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:19,486 INFO     Weight matrix 4/9 (128,128): Alpha: 1.8531467129242496, Alpha Weighted: -0.9811753667654594, D: 0.15276017469067393\n",
      "2018-11-26 13:26:19,490 INFO     Weight matrix 4/9 (128,128): Lognorm: 0.2995791733264923\n",
      "2018-11-26 13:26:19,492 INFO     Weight matrix 5/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:20,513 INFO     Weight matrix 5/9 (128,128): Alpha: 1.8912394638049985, Alpha Weighted: -0.46960279257594995, D: 0.13479211074726344\n",
      "2018-11-26 13:26:20,516 INFO     Weight matrix 5/9 (128,128): Lognorm: 0.38214701414108276\n",
      "2018-11-26 13:26:20,520 INFO     Weight matrix 6/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:21,624 INFO     Weight matrix 6/9 (128,128): Alpha: 1.7845542845899538, Alpha Weighted: -0.8145500978695502, D: 0.16273034610996473\n",
      "2018-11-26 13:26:21,628 INFO     Weight matrix 6/9 (128,128): Lognorm: 0.3396771252155304\n",
      "2018-11-26 13:26:21,630 INFO     Weight matrix 7/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:22,688 INFO     Weight matrix 7/9 (128,128): Alpha: 2.223513865456856, Alpha Weighted: -1.3956363716612175, D: 0.15433308387834083\n",
      "2018-11-26 13:26:22,692 INFO     Weight matrix 7/9 (128,128): Lognorm: 0.2527408003807068\n",
      "2018-11-26 13:26:22,695 INFO     Weight matrix 8/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:23,667 INFO     Weight matrix 8/9 (128,128): Alpha: 1.8323634875355272, Alpha Weighted: -0.8073090044199118, D: 0.1610067870762265\n",
      "2018-11-26 13:26:23,672 INFO     Weight matrix 8/9 (128,128): Lognorm: 0.3348912000656128\n",
      "2018-11-26 13:26:23,675 INFO     Weight matrix 9/9 (128,128): Analyzing ...\n",
      "2018-11-26 13:26:24,692 INFO     Weight matrix 9/9 (128,128): Alpha: 2.50349861497755, Alpha Weighted: -1.3849455970106364, D: 0.16027386437784596\n",
      "2018-11-26 13:26:24,698 INFO     Weight matrix 9/9 (128,128): Lognorm: 0.28262317180633545\n",
      "2018-11-26 13:26:24,701 INFO Layer 97: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:26:24,708 INFO Layer 97: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:24,711 INFO Layer 98: Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:26:24,715 INFO Pytorch tensor shape detected: 512x128 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:26:24,717 INFO Layer 98: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:26:24,721 INFO     Weight matrix 1/1 (128,512): Analyzing ...\n",
      "2018-11-26 13:26:25,798 INFO     Weight matrix 1/1 (128,512): Alpha: 3.50776265645448, Alpha Weighted: 0.12432218376795329, D: 0.13394395519313507\n",
      "2018-11-26 13:26:25,802 INFO     Weight matrix 1/1 (128,512): Alpha 3.50776265645448 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:26:25,810 INFO     Weight matrix 1/1 (128,512): Lognorm: 0.5965591073036194\n",
      "2018-11-26 13:26:25,814 INFO Layer 99: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:26:25,817 INFO Layer 99: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:25,821 INFO Layer 100: ReLU(inplace)\n",
      "2018-11-26 13:26:25,825 INFO Layer 100: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:25,838 INFO Layer 101: Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (6): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (7): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (8): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (9): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (10): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (11): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (12): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (13): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (14): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (15): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (16): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (17): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (18): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (19): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (20): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (21): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (22): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (23): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (24): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (25): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (26): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (27): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (28): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (29): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (30): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (31): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (32): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (33): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (34): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (35): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:26:25,842 INFO Layer 101: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:25,847 INFO Layer 102: Bottleneck(\n",
      "  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:26:25,855 INFO Layer 102: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:25,858 INFO Layer 103: Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:26:25,868 INFO Pytorch tensor shape detected: 256x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:26:25,870 INFO Layer 103: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:26:25,874 INFO     Weight matrix 1/1 (256,512): Analyzing ...\n",
      "2018-11-26 13:26:28,728 INFO     Weight matrix 1/1 (256,512): Alpha: 4.587098140023352, Alpha Weighted: 2.324607893323734, D: 0.12508976230942714\n",
      "2018-11-26 13:26:28,731 INFO     Weight matrix 1/1 (256,512): Alpha 4.587098140023352 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:26:28,736 INFO     Weight matrix 1/1 (256,512): Lognorm: 0.9734541773796082\n",
      "2018-11-26 13:26:28,740 INFO Layer 104: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:26:28,743 INFO Layer 104: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:28,750 INFO Layer 105: Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:26:28,772 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:26:28,775 INFO Layer 105: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:26:28,780 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:26:31,648 INFO     Weight matrix 1/9 (256,256): Alpha: 2.886299800779608, Alpha Weighted: -1.6338846024182776, D: 0.15233629113510977\n",
      "2018-11-26 13:26:31,653 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.4512857496738434\n",
      "2018-11-26 13:26:31,657 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:26:34,186 INFO     Weight matrix 2/9 (256,256): Alpha: 4.024859800370987, Alpha Weighted: -1.6108477686643747, D: 0.2013118496601211\n",
      "2018-11-26 13:26:34,189 INFO     Weight matrix 2/9 (256,256): Alpha 4.024859800370987 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:26:34,193 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.5622708797454834\n",
      "2018-11-26 13:26:34,196 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:26:36,731 INFO     Weight matrix 3/9 (256,256): Alpha: 4.0941056792045085, Alpha Weighted: -1.7650265933563838, D: 0.14795393060565842\n",
      "2018-11-26 13:26:36,733 INFO     Weight matrix 3/9 (256,256): Alpha 4.0941056792045085 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:26:36,737 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.5272653698921204\n",
      "2018-11-26 13:26:36,740 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:26:39,116 INFO     Weight matrix 4/9 (256,256): Alpha: 4.352634870855862, Alpha Weighted: -1.9845875961310155, D: 0.18747856673584917\n",
      "2018-11-26 13:26:39,119 INFO     Weight matrix 4/9 (256,256): Alpha 4.352634870855862 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:26:39,125 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.5451438426971436\n",
      "2018-11-26 13:26:39,127 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:26:42,590 INFO     Weight matrix 5/9 (256,256): Alpha: 3.0659470570883043, Alpha Weighted: -1.0451125603754623, D: 0.16460137312921963\n",
      "2018-11-26 13:26:42,595 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.5521740317344666\n",
      "2018-11-26 13:26:42,598 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:26:45,146 INFO     Weight matrix 6/9 (256,256): Alpha: 3.8350615373423698, Alpha Weighted: -0.8942744556018069, D: 0.2014804680967246\n",
      "2018-11-26 13:26:45,148 INFO     Weight matrix 6/9 (256,256): Alpha 3.8350615373423698 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:26:45,152 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.6499215364456177\n",
      "2018-11-26 13:26:45,155 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:26:48,108 INFO     Weight matrix 7/9 (256,256): Alpha: 5.135191364416106, Alpha Weighted: -2.5293647558268995, D: 0.15905392481346475\n",
      "2018-11-26 13:26:48,111 INFO     Weight matrix 7/9 (256,256): Alpha 5.135191364416106 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:26:48,115 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.5102505087852478\n",
      "2018-11-26 13:26:48,118 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:26:50,663 INFO     Weight matrix 8/9 (256,256): Alpha: 1.4023510300725253, Alpha Weighted: -0.3290778236276829, D: 0.21012081548821948\n",
      "2018-11-26 13:26:50,666 INFO     Weight matrix 8/9 (256,256): Alpha 1.4023510300725253 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:26:50,672 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.6496988534927368\n",
      "2018-11-26 13:26:50,675 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:26:53,318 INFO     Weight matrix 9/9 (256,256): Alpha: 4.118022989066844, Alpha Weighted: -1.1941086921565032, D: 0.15575096369363395\n",
      "2018-11-26 13:26:53,326 INFO     Weight matrix 9/9 (256,256): Alpha 4.118022989066844 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:26:53,343 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.6076442003250122\n",
      "2018-11-26 13:26:53,347 INFO Layer 106: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:26:53,355 INFO Layer 106: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:53,361 INFO Layer 107: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:26:53,369 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:26:53,372 INFO Layer 107: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:26:53,381 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:26:56,332 INFO     Weight matrix 1/1 (256,1024): Alpha: 6.868421632536605, Alpha Weighted: 2.2366769861147766, D: 0.0957780359443604\n",
      "2018-11-26 13:26:56,335 INFO     Weight matrix 1/1 (256,1024): Alpha 6.868421632536605 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:26:56,338 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.9785140752792358\n",
      "2018-11-26 13:26:56,342 INFO Layer 108: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:26:56,346 INFO Layer 108: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:56,349 INFO Layer 109: ReLU(inplace)\n",
      "2018-11-26 13:26:56,353 INFO Layer 109: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:56,356 INFO Layer 110: Sequential(\n",
      "  (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:26:56,358 INFO Layer 110: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:56,361 INFO Layer 111: Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 13:26:56,369 INFO Pytorch tensor shape detected: 1024x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:26:56,372 INFO Layer 111: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:26:56,375 INFO     Weight matrix 1/1 (512,1024): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:26:56,378 INFO Layer 112: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:26:56,380 INFO Layer 112: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:56,383 INFO Layer 113: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:26:56,386 INFO Layer 113: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:56,389 INFO Layer 114: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:26:56,395 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:26:56,399 INFO Layer 114: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:26:56,402 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:26:58,860 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.6361684688078217, Alpha Weighted: 0.4079548793566238, D: 0.0824604681298805\n",
      "2018-11-26 13:26:58,863 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.4623584449291229\n",
      "2018-11-26 13:26:58,869 INFO Layer 115: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:26:58,871 INFO Layer 115: Skipping (Layer not supported)\n",
      "2018-11-26 13:26:58,874 INFO Layer 116: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:26:58,884 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:26:58,886 INFO Layer 116: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:26:58,889 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:01,663 INFO     Weight matrix 1/9 (256,256): Alpha: 1.3677229382983476, Alpha Weighted: -0.8609818772706833, D: 0.1038576154046682\n",
      "2018-11-26 13:27:01,666 INFO     Weight matrix 1/9 (256,256): Alpha 1.3677229382983476 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:27:01,670 INFO     Weight matrix 1/9 (256,256): Lognorm: -0.02132391557097435\n",
      "2018-11-26 13:27:01,674 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:04,343 INFO     Weight matrix 2/9 (256,256): Alpha: 1.5091098610914178, Alpha Weighted: -0.3212656719010164, D: 0.0785158159937045\n",
      "2018-11-26 13:27:04,348 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.153903529047966\n",
      "2018-11-26 13:27:04,351 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:07,088 INFO     Weight matrix 3/9 (256,256): Alpha: 1.5395982024186305, Alpha Weighted: -0.9515990171914035, D: 0.09722053091124716\n",
      "2018-11-26 13:27:07,093 INFO     Weight matrix 3/9 (256,256): Lognorm: -0.00965286698192358\n",
      "2018-11-26 13:27:07,095 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:09,664 INFO     Weight matrix 4/9 (256,256): Alpha: 1.3893955094817076, Alpha Weighted: -0.3498730196614511, D: 0.08821570429456105\n",
      "2018-11-26 13:27:09,667 INFO     Weight matrix 4/9 (256,256): Alpha 1.3893955094817076 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:27:09,674 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.133581280708313\n",
      "2018-11-26 13:27:09,677 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:12,191 INFO     Weight matrix 5/9 (256,256): Alpha: 1.4325688813241795, Alpha Weighted: -0.4020309308905596, D: 0.08743500007918609\n",
      "2018-11-26 13:27:12,193 INFO     Weight matrix 5/9 (256,256): Alpha 1.4325688813241795 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:27:12,197 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.11103715002536774\n",
      "2018-11-26 13:27:12,201 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:14,924 INFO     Weight matrix 6/9 (256,256): Alpha: 1.473502220873631, Alpha Weighted: -0.36193891366615494, D: 0.07358219494327878\n",
      "2018-11-26 13:27:14,926 INFO     Weight matrix 6/9 (256,256): Alpha 1.473502220873631 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:27:14,933 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.15247099101543427\n",
      "2018-11-26 13:27:14,936 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:17,612 INFO     Weight matrix 7/9 (256,256): Alpha: 1.5453356577470676, Alpha Weighted: -0.8736661927301632, D: 0.09835948566611702\n",
      "2018-11-26 13:27:17,618 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.0066995336674153805\n",
      "2018-11-26 13:27:17,622 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:20,010 INFO     Weight matrix 8/9 (256,256): Alpha: 1.453857051061838, Alpha Weighted: -0.2462135920294942, D: 0.08093254752986356\n",
      "2018-11-26 13:27:20,012 INFO     Weight matrix 8/9 (256,256): Alpha 1.453857051061838 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:27:20,017 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.18283416330814362\n",
      "2018-11-26 13:27:20,020 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:23,055 INFO     Weight matrix 9/9 (256,256): Alpha: 1.5008719380853925, Alpha Weighted: -0.8452492041660731, D: 0.10165262430570032\n",
      "2018-11-26 13:27:23,060 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.02279989793896675\n",
      "2018-11-26 13:27:23,064 INFO Layer 117: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:27:23,067 INFO Layer 117: Skipping (Layer not supported)\n",
      "2018-11-26 13:27:23,071 INFO Layer 118: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:27:23,075 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:27:23,078 INFO Layer 118: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:27:23,082 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:27:25,563 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.4465828550231477, Alpha Weighted: -0.20929974598324294, D: 0.11277899566245225\n",
      "2018-11-26 13:27:25,565 INFO     Weight matrix 1/1 (256,1024): Alpha 1.4465828550231477 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:27:25,568 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.49823620915412903\n",
      "2018-11-26 13:27:25,571 INFO Layer 119: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:27:25,575 INFO Layer 119: Skipping (Layer not supported)\n",
      "2018-11-26 13:27:25,578 INFO Layer 120: ReLU(inplace)\n",
      "2018-11-26 13:27:25,580 INFO Layer 120: Skipping (Layer not supported)\n",
      "2018-11-26 13:27:25,583 INFO Layer 121: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:27:25,586 INFO Layer 121: Skipping (Layer not supported)\n",
      "2018-11-26 13:27:25,589 INFO Layer 122: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:27:25,593 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:27:25,598 INFO Layer 122: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:27:25,600 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:27:28,039 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.767897509169574, Alpha Weighted: 0.42756348995963284, D: 0.09159067495145845\n",
      "2018-11-26 13:27:28,043 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.5266568660736084\n",
      "2018-11-26 13:27:28,048 INFO Layer 123: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:27:28,050 INFO Layer 123: Skipping (Layer not supported)\n",
      "2018-11-26 13:27:28,052 INFO Layer 124: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:27:28,060 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:27:28,062 INFO Layer 124: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:27:28,065 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:30,366 INFO     Weight matrix 1/9 (256,256): Alpha: 2.2525997953214594, Alpha Weighted: -1.182359197495779, D: 0.08936783354567424\n",
      "2018-11-26 13:27:30,370 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.08170976489782333\n",
      "2018-11-26 13:27:30,374 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:32,805 INFO     Weight matrix 2/9 (256,256): Alpha: 1.7079384100524502, Alpha Weighted: -0.1747877282739218, D: 0.07282669082063731\n",
      "2018-11-26 13:27:32,812 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.20598362386226654\n",
      "2018-11-26 13:27:32,815 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:35,561 INFO     Weight matrix 3/9 (256,256): Alpha: 1.6706459169437515, Alpha Weighted: -0.7808573366029492, D: 0.09864478627511031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:27:35,566 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.10109289735555649\n",
      "2018-11-26 13:27:35,570 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:38,504 INFO     Weight matrix 4/9 (256,256): Alpha: 1.812056078703703, Alpha Weighted: -0.3328307342714532, D: 0.08124443876164522\n",
      "2018-11-26 13:27:38,509 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.18548625707626343\n",
      "2018-11-26 13:27:38,512 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:41,254 INFO     Weight matrix 5/9 (256,256): Alpha: 1.7686780704731597, Alpha Weighted: -0.7735746910151163, D: 0.10742203914747517\n",
      "2018-11-26 13:27:41,259 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.17622922360897064\n",
      "2018-11-26 13:27:41,261 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:44,095 INFO     Weight matrix 6/9 (256,256): Alpha: 1.7769642399424102, Alpha Weighted: -0.2506851774887773, D: 0.08122994740094491\n",
      "2018-11-26 13:27:44,100 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.20692577958106995\n",
      "2018-11-26 13:27:44,103 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:46,893 INFO     Weight matrix 7/9 (256,256): Alpha: 1.595194760715696, Alpha Weighted: -0.6701142264395332, D: 0.09849652758450755\n",
      "2018-11-26 13:27:46,897 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.10380828380584717\n",
      "2018-11-26 13:27:46,901 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:49,426 INFO     Weight matrix 8/9 (256,256): Alpha: 1.5297585492656314, Alpha Weighted: -0.07663485492754649, D: 0.08822067167772518\n",
      "2018-11-26 13:27:49,431 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.22718314826488495\n",
      "2018-11-26 13:27:49,434 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:27:52,130 INFO     Weight matrix 9/9 (256,256): Alpha: 1.58308337094827, Alpha Weighted: -0.5131111288693269, D: 0.09555677489423442\n",
      "2018-11-26 13:27:52,134 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.13816618919372559\n",
      "2018-11-26 13:27:52,137 INFO Layer 125: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:27:52,139 INFO Layer 125: Skipping (Layer not supported)\n",
      "2018-11-26 13:27:52,142 INFO Layer 126: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:27:52,147 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:27:52,149 INFO Layer 126: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:27:52,153 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:27:54,933 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.6670557855921913, Alpha Weighted: -0.07372281555236648, D: 0.11603610879579307\n",
      "2018-11-26 13:27:54,936 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.5557334423065186\n",
      "2018-11-26 13:27:54,939 INFO Layer 127: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:27:54,942 INFO Layer 127: Skipping (Layer not supported)\n",
      "2018-11-26 13:27:54,944 INFO Layer 128: ReLU(inplace)\n",
      "2018-11-26 13:27:54,948 INFO Layer 128: Skipping (Layer not supported)\n",
      "2018-11-26 13:27:54,951 INFO Layer 129: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:27:54,957 INFO Layer 129: Skipping (Layer not supported)\n",
      "2018-11-26 13:27:54,962 INFO Layer 130: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:27:54,968 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:27:54,972 INFO Layer 130: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:27:54,974 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:27:57,590 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.077725520625744, Alpha Weighted: 0.5918827809248614, D: 0.0936183101139344\n",
      "2018-11-26 13:27:57,593 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6023969650268555\n",
      "2018-11-26 13:27:57,596 INFO Layer 131: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:27:57,599 INFO Layer 131: Skipping (Layer not supported)\n",
      "2018-11-26 13:27:57,603 INFO Layer 132: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:27:57,608 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:27:57,610 INFO Layer 132: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:27:57,615 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:00,146 INFO     Weight matrix 1/9 (256,256): Alpha: 1.6540515657786834, Alpha Weighted: -0.8294893287199299, D: 0.1102880003475859\n",
      "2018-11-26 13:28:00,150 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.17428769171237946\n",
      "2018-11-26 13:28:00,153 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:02,577 INFO     Weight matrix 2/9 (256,256): Alpha: 1.8974318784556854, Alpha Weighted: -0.3080959595282335, D: 0.08719736174562964\n",
      "2018-11-26 13:28:02,581 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.24933463335037231\n",
      "2018-11-26 13:28:02,583 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:04,910 INFO     Weight matrix 3/9 (256,256): Alpha: 2.0078989369217055, Alpha Weighted: -0.8830008761703239, D: 0.10207165646447036\n",
      "2018-11-26 13:28:04,915 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.18904335796833038\n",
      "2018-11-26 13:28:04,917 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:07,565 INFO     Weight matrix 4/9 (256,256): Alpha: 1.913281467428323, Alpha Weighted: -0.5981184469148871, D: 0.09907977478081581\n",
      "2018-11-26 13:28:07,571 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.22084510326385498\n",
      "2018-11-26 13:28:07,575 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:10,027 INFO     Weight matrix 5/9 (256,256): Alpha: 1.51550372691485, Alpha Weighted: -0.2601775975159279, D: 0.10734144385816313\n",
      "2018-11-26 13:28:10,031 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.3069385290145874\n",
      "2018-11-26 13:28:10,034 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:12,294 INFO     Weight matrix 6/9 (256,256): Alpha: 1.9875017002244073, Alpha Weighted: -0.5594620275207633, D: 0.10115559138773489\n",
      "2018-11-26 13:28:12,297 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.23748813569545746\n",
      "2018-11-26 13:28:12,301 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:14,564 INFO     Weight matrix 7/9 (256,256): Alpha: 1.9573744486313704, Alpha Weighted: -0.8817485606989761, D: 0.10794856812947717\n",
      "2018-11-26 13:28:14,568 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.1839456707239151\n",
      "2018-11-26 13:28:14,570 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:16,837 INFO     Weight matrix 8/9 (256,256): Alpha: 1.9821138024267766, Alpha Weighted: -0.34603383970407686, D: 0.08916100230448698\n",
      "2018-11-26 13:28:16,842 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.25490137934684753\n",
      "2018-11-26 13:28:16,845 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:19,575 INFO     Weight matrix 9/9 (256,256): Alpha: 1.901913690915476, Alpha Weighted: -0.7128220542888561, D: 0.09692234340725547\n",
      "2018-11-26 13:28:19,581 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.21154429018497467\n",
      "2018-11-26 13:28:19,585 INFO Layer 133: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:28:19,588 INFO Layer 133: Skipping (Layer not supported)\n",
      "2018-11-26 13:28:19,592 INFO Layer 134: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:28:19,599 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:28:19,605 INFO Layer 134: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:28:19,611 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:28:22,311 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.5691945863074666, Alpha Weighted: -0.013237431743550679, D: 0.13168486968393273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:28:22,316 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6498120427131653\n",
      "2018-11-26 13:28:22,319 INFO Layer 135: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:28:22,322 INFO Layer 135: Skipping (Layer not supported)\n",
      "2018-11-26 13:28:22,325 INFO Layer 136: ReLU(inplace)\n",
      "2018-11-26 13:28:22,328 INFO Layer 136: Skipping (Layer not supported)\n",
      "2018-11-26 13:28:22,331 INFO Layer 137: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:28:22,333 INFO Layer 137: Skipping (Layer not supported)\n",
      "2018-11-26 13:28:22,336 INFO Layer 138: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:28:22,341 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:28:22,343 INFO Layer 138: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:28:22,346 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:28:24,830 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.7230241771370847, Alpha Weighted: 0.15936021255529134, D: 0.10109642675861119\n",
      "2018-11-26 13:28:24,833 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6821037530899048\n",
      "2018-11-26 13:28:24,836 INFO Layer 139: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:28:24,840 INFO Layer 139: Skipping (Layer not supported)\n",
      "2018-11-26 13:28:24,843 INFO Layer 140: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:28:24,849 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:28:24,853 INFO Layer 140: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:28:24,857 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:27,434 INFO     Weight matrix 1/9 (256,256): Alpha: 2.04893586443169, Alpha Weighted: -1.3312048379978934, D: 0.11162495657767235\n",
      "2018-11-26 13:28:27,439 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.2576601505279541\n",
      "2018-11-26 13:28:27,442 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:29,896 INFO     Weight matrix 2/9 (256,256): Alpha: 1.795905197791075, Alpha Weighted: -0.6620582376610052, D: 0.10270966134224502\n",
      "2018-11-26 13:28:29,900 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.323661744594574\n",
      "2018-11-26 13:28:29,903 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:32,389 INFO     Weight matrix 3/9 (256,256): Alpha: 2.0773166285363467, Alpha Weighted: -1.3410527593671717, D: 0.122292053532645\n",
      "2018-11-26 13:28:32,394 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.26431146264076233\n",
      "2018-11-26 13:28:32,397 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:34,852 INFO     Weight matrix 4/9 (256,256): Alpha: 2.0329858544777255, Alpha Weighted: -0.6927673940752738, D: 0.07871470973478212\n",
      "2018-11-26 13:28:34,856 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3117464780807495\n",
      "2018-11-26 13:28:34,858 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:37,174 INFO     Weight matrix 5/9 (256,256): Alpha: 1.7480266124342125, Alpha Weighted: -0.7204461911335863, D: 0.10917279486212939\n",
      "2018-11-26 13:28:37,177 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.3652607798576355\n",
      "2018-11-26 13:28:37,180 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:39,549 INFO     Weight matrix 6/9 (256,256): Alpha: 2.0018491704886836, Alpha Weighted: -0.6788520576407667, D: 0.0779272558339299\n",
      "2018-11-26 13:28:39,554 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.3209536671638489\n",
      "2018-11-26 13:28:39,557 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:42,084 INFO     Weight matrix 7/9 (256,256): Alpha: 1.783567445012449, Alpha Weighted: -1.1146001688877172, D: 0.1092509498408954\n",
      "2018-11-26 13:28:42,088 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.26351824402809143\n",
      "2018-11-26 13:28:42,091 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:44,609 INFO     Weight matrix 8/9 (256,256): Alpha: 1.9053259832263323, Alpha Weighted: -0.6142879495674406, D: 0.10352793485300438\n",
      "2018-11-26 13:28:44,612 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.3373388350009918\n",
      "2018-11-26 13:28:44,615 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:47,195 INFO     Weight matrix 9/9 (256,256): Alpha: 1.8927941796360357, Alpha Weighted: -1.1192327978748753, D: 0.11816006837002979\n",
      "2018-11-26 13:28:47,200 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.27773618698120117\n",
      "2018-11-26 13:28:47,202 INFO Layer 141: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:28:47,205 INFO Layer 141: Skipping (Layer not supported)\n",
      "2018-11-26 13:28:47,207 INFO Layer 142: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:28:47,215 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:28:47,217 INFO Layer 142: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:28:47,221 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:28:50,067 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.796159506306808, Alpha Weighted: -0.001586218938883909, D: 0.1395579993779792\n",
      "2018-11-26 13:28:50,070 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.718032717704773\n",
      "2018-11-26 13:28:50,073 INFO Layer 143: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:28:50,076 INFO Layer 143: Skipping (Layer not supported)\n",
      "2018-11-26 13:28:50,079 INFO Layer 144: ReLU(inplace)\n",
      "2018-11-26 13:28:50,082 INFO Layer 144: Skipping (Layer not supported)\n",
      "2018-11-26 13:28:50,092 INFO Layer 145: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:28:50,097 INFO Layer 145: Skipping (Layer not supported)\n",
      "2018-11-26 13:28:50,103 INFO Layer 146: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:28:50,110 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:28:50,113 INFO Layer 146: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:28:50,118 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:28:52,939 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.9788403505293908, Alpha Weighted: 0.3011154525729266, D: 0.11589450707949889\n",
      "2018-11-26 13:28:52,943 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7076888680458069\n",
      "2018-11-26 13:28:52,947 INFO Layer 147: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:28:52,956 INFO Layer 147: Skipping (Layer not supported)\n",
      "2018-11-26 13:28:52,960 INFO Layer 148: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:28:52,968 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:28:52,971 INFO Layer 148: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:28:52,974 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:55,658 INFO     Weight matrix 1/9 (256,256): Alpha: 2.50473551315046, Alpha Weighted: -1.6326104364452958, D: 0.11611942388665575\n",
      "2018-11-26 13:28:55,663 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.2679469883441925\n",
      "2018-11-26 13:28:55,667 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:28:58,205 INFO     Weight matrix 2/9 (256,256): Alpha: 2.2646671210636855, Alpha Weighted: -1.1270101022425205, D: 0.09683991803115827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:28:58,210 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3188198208808899\n",
      "2018-11-26 13:28:58,213 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:00,799 INFO     Weight matrix 3/9 (256,256): Alpha: 2.316609440634007, Alpha Weighted: -1.4111938295431183, D: 0.1173565497854745\n",
      "2018-11-26 13:29:00,804 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.281680703163147\n",
      "2018-11-26 13:29:00,810 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:03,436 INFO     Weight matrix 4/9 (256,256): Alpha: 2.253221900153619, Alpha Weighted: -1.2101700651791292, D: 0.09196686782729391\n",
      "2018-11-26 13:29:03,440 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.29800093173980713\n",
      "2018-11-26 13:29:03,442 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:05,888 INFO     Weight matrix 5/9 (256,256): Alpha: 1.8263878942648073, Alpha Weighted: -0.6052447672085266, D: 0.10617932176039435\n",
      "2018-11-26 13:29:05,892 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.3872050642967224\n",
      "2018-11-26 13:29:05,894 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:08,180 INFO     Weight matrix 6/9 (256,256): Alpha: 2.056058441941834, Alpha Weighted: -0.9316531359384399, D: 0.09232595704632718\n",
      "2018-11-26 13:29:08,185 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.32449716329574585\n",
      "2018-11-26 13:29:08,188 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:10,799 INFO     Weight matrix 7/9 (256,256): Alpha: 2.20397501777945, Alpha Weighted: -1.349149017750984, D: 0.10062083297904567\n",
      "2018-11-26 13:29:10,805 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.2769376039505005\n",
      "2018-11-26 13:29:10,808 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:13,202 INFO     Weight matrix 8/9 (256,256): Alpha: 2.2987364445563574, Alpha Weighted: -1.0596719329170503, D: 0.10798328551842973\n",
      "2018-11-26 13:29:13,207 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.33959782123565674\n",
      "2018-11-26 13:29:13,209 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:15,517 INFO     Weight matrix 9/9 (256,256): Alpha: 2.178029242115467, Alpha Weighted: -1.253114555249753, D: 0.09974550787960668\n",
      "2018-11-26 13:29:15,521 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.30162450671195984\n",
      "2018-11-26 13:29:15,524 INFO Layer 149: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:29:15,526 INFO Layer 149: Skipping (Layer not supported)\n",
      "2018-11-26 13:29:15,529 INFO Layer 150: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:29:15,535 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:29:15,537 INFO Layer 150: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:29:15,539 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:29:17,926 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.6832288608324273, Alpha Weighted: 0.2814701329356637, D: 0.11912985659891373\n",
      "2018-11-26 13:29:17,929 INFO     Weight matrix 1/1 (256,1024): Alpha 3.6832288608324273 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:29:17,932 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7038215398788452\n",
      "2018-11-26 13:29:17,936 INFO Layer 151: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:29:17,938 INFO Layer 151: Skipping (Layer not supported)\n",
      "2018-11-26 13:29:17,941 INFO Layer 152: ReLU(inplace)\n",
      "2018-11-26 13:29:17,943 INFO Layer 152: Skipping (Layer not supported)\n",
      "2018-11-26 13:29:17,953 INFO Layer 153: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:29:17,956 INFO Layer 153: Skipping (Layer not supported)\n",
      "2018-11-26 13:29:17,960 INFO Layer 154: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:29:17,964 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:29:17,966 INFO Layer 154: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:29:17,969 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:29:20,462 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.7938326555859698, Alpha Weighted: -0.10441704828777558, D: 0.13757425224342862\n",
      "2018-11-26 13:29:20,467 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6695762872695923\n",
      "2018-11-26 13:29:20,471 INFO Layer 155: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:29:20,474 INFO Layer 155: Skipping (Layer not supported)\n",
      "2018-11-26 13:29:20,477 INFO Layer 156: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:29:20,483 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:29:20,485 INFO Layer 156: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:29:20,487 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:22,771 INFO     Weight matrix 1/9 (256,256): Alpha: 2.025999954226883, Alpha Weighted: -1.3680926842350418, D: 0.12160346576046588\n",
      "2018-11-26 13:29:22,778 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.2468249499797821\n",
      "2018-11-26 13:29:22,781 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:25,049 INFO     Weight matrix 2/9 (256,256): Alpha: 2.2531501676489802, Alpha Weighted: -0.9292401064247898, D: 0.08724199952130562\n",
      "2018-11-26 13:29:25,054 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.2878439128398895\n",
      "2018-11-26 13:29:25,056 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:27,341 INFO     Weight matrix 3/9 (256,256): Alpha: 2.0768780697255305, Alpha Weighted: -1.4358097577564095, D: 0.12837870938668905\n",
      "2018-11-26 13:29:27,346 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.2520925998687744\n",
      "2018-11-26 13:29:27,349 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:29,624 INFO     Weight matrix 4/9 (256,256): Alpha: 2.219804466483863, Alpha Weighted: -0.8261396033019156, D: 0.08056394522866667\n",
      "2018-11-26 13:29:29,628 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.2806047201156616\n",
      "2018-11-26 13:29:29,630 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:31,944 INFO     Weight matrix 5/9 (256,256): Alpha: 1.828559295332147, Alpha Weighted: -0.735628205963993, D: 0.12004663841091162\n",
      "2018-11-26 13:29:31,948 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.31911271810531616\n",
      "2018-11-26 13:29:31,952 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:34,251 INFO     Weight matrix 6/9 (256,256): Alpha: 2.298353150313165, Alpha Weighted: -0.8206409007866061, D: 0.08590557346186822\n",
      "2018-11-26 13:29:34,255 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.2901179790496826\n",
      "2018-11-26 13:29:34,259 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:36,580 INFO     Weight matrix 7/9 (256,256): Alpha: 1.7709243017960414, Alpha Weighted: -1.180684847336522, D: 0.12260402519010355\n",
      "2018-11-26 13:29:36,583 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.24826233088970184\n",
      "2018-11-26 13:29:36,586 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:38,881 INFO     Weight matrix 8/9 (256,256): Alpha: 2.1809058902251417, Alpha Weighted: -0.8096632694274243, D: 0.08284598502908991\n",
      "2018-11-26 13:29:38,886 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.3041604161262512\n",
      "2018-11-26 13:29:38,890 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:41,187 INFO     Weight matrix 9/9 (256,256): Alpha: 1.737861421812803, Alpha Weighted: -1.1071874395529062, D: 0.12766520491337485\n",
      "2018-11-26 13:29:41,192 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.2638464868068695\n",
      "2018-11-26 13:29:41,195 INFO Layer 157: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:29:41,199 INFO Layer 157: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:29:41,201 INFO Layer 158: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:29:41,206 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:29:41,210 INFO Layer 158: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:29:41,213 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:29:43,624 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.879154728869225, Alpha Weighted: 0.09730791077837161, D: 0.14027697333863182\n",
      "2018-11-26 13:29:43,628 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7139934301376343\n",
      "2018-11-26 13:29:43,630 INFO Layer 159: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:29:43,633 INFO Layer 159: Skipping (Layer not supported)\n",
      "2018-11-26 13:29:43,635 INFO Layer 160: ReLU(inplace)\n",
      "2018-11-26 13:29:43,638 INFO Layer 160: Skipping (Layer not supported)\n",
      "2018-11-26 13:29:43,643 INFO Layer 161: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:29:43,646 INFO Layer 161: Skipping (Layer not supported)\n",
      "2018-11-26 13:29:43,649 INFO Layer 162: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:29:43,654 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:29:43,657 INFO Layer 162: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:29:43,659 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:29:46,070 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.8730054360230746, Alpha Weighted: 0.018352645051409423, D: 0.1024246620844852\n",
      "2018-11-26 13:29:46,074 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.5743681788444519\n",
      "2018-11-26 13:29:46,078 INFO Layer 163: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:29:46,080 INFO Layer 163: Skipping (Layer not supported)\n",
      "2018-11-26 13:29:46,083 INFO Layer 164: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:29:46,091 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:29:46,097 INFO Layer 164: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:29:46,100 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:48,408 INFO     Weight matrix 1/9 (256,256): Alpha: 2.415154131779085, Alpha Weighted: -1.5685890874947055, D: 0.08856100818106166\n",
      "2018-11-26 13:29:48,413 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.1653161346912384\n",
      "2018-11-26 13:29:48,416 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:50,718 INFO     Weight matrix 2/9 (256,256): Alpha: 1.9216070128722644, Alpha Weighted: -0.7837959651940644, D: 0.10029445400289139\n",
      "2018-11-26 13:29:50,722 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.22450906038284302\n",
      "2018-11-26 13:29:50,724 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:53,001 INFO     Weight matrix 3/9 (256,256): Alpha: 2.2143844771350985, Alpha Weighted: -1.396153483514192, D: 0.0864834971297912\n",
      "2018-11-26 13:29:53,004 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.17544642090797424\n",
      "2018-11-26 13:29:53,007 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:55,299 INFO     Weight matrix 4/9 (256,256): Alpha: 2.0220243201295336, Alpha Weighted: -0.7335043748478621, D: 0.07501079601622573\n",
      "2018-11-26 13:29:55,302 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.22858819365501404\n",
      "2018-11-26 13:29:55,306 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:57,610 INFO     Weight matrix 5/9 (256,256): Alpha: 1.907066955111331, Alpha Weighted: -0.3044146415275738, D: 0.08205590814881908\n",
      "2018-11-26 13:29:57,613 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.2974189221858978\n",
      "2018-11-26 13:29:57,616 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:29:59,913 INFO     Weight matrix 6/9 (256,256): Alpha: 1.9287852850198508, Alpha Weighted: -0.618826299574232, D: 0.08345286058691814\n",
      "2018-11-26 13:29:59,918 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.24390026926994324\n",
      "2018-11-26 13:29:59,920 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:02,263 INFO     Weight matrix 7/9 (256,256): Alpha: 2.0738231281608828, Alpha Weighted: -1.2941069442419952, D: 0.09651477480145859\n",
      "2018-11-26 13:30:02,268 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.17020970582962036\n",
      "2018-11-26 13:30:02,271 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:04,628 INFO     Weight matrix 8/9 (256,256): Alpha: 1.828649658389565, Alpha Weighted: -0.6700136987416745, D: 0.0921782555751317\n",
      "2018-11-26 13:30:04,632 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.23703256249427795\n",
      "2018-11-26 13:30:04,636 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:06,940 INFO     Weight matrix 9/9 (256,256): Alpha: 2.0474750802928834, Alpha Weighted: -1.192600253969134, D: 0.09897014081872035\n",
      "2018-11-26 13:30:06,944 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.18408353626728058\n",
      "2018-11-26 13:30:06,947 INFO Layer 165: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:30:06,949 INFO Layer 165: Skipping (Layer not supported)\n",
      "2018-11-26 13:30:06,951 INFO Layer 166: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:30:06,957 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:30:06,961 INFO Layer 166: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:30:06,964 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:30:09,366 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.837285486289572, Alpha Weighted: -0.02650448187341823, D: 0.12372729965985285\n",
      "2018-11-26 13:30:09,369 INFO     Weight matrix 1/1 (256,1024): Alpha 3.837285486289572 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:30:09,371 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.664386510848999\n",
      "2018-11-26 13:30:09,374 INFO Layer 167: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:30:09,378 INFO Layer 167: Skipping (Layer not supported)\n",
      "2018-11-26 13:30:09,380 INFO Layer 168: ReLU(inplace)\n",
      "2018-11-26 13:30:09,383 INFO Layer 168: Skipping (Layer not supported)\n",
      "2018-11-26 13:30:09,386 INFO Layer 169: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:30:09,388 INFO Layer 169: Skipping (Layer not supported)\n",
      "2018-11-26 13:30:09,391 INFO Layer 170: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:30:09,397 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:30:09,401 INFO Layer 170: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:30:09,403 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:30:11,810 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.0737106863986097, Alpha Weighted: -0.030464862793237176, D: 0.11322566050564598\n",
      "2018-11-26 13:30:11,815 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6670804619789124\n",
      "2018-11-26 13:30:11,819 INFO Layer 171: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:30:11,821 INFO Layer 171: Skipping (Layer not supported)\n",
      "2018-11-26 13:30:11,824 INFO Layer 172: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:30:11,829 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:30:11,831 INFO Layer 172: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:30:11,834 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:14,171 INFO     Weight matrix 1/9 (256,256): Alpha: 2.518033577174143, Alpha Weighted: -1.9348787971021757, D: 0.11254010654701063\n",
      "2018-11-26 13:30:14,176 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.22585782408714294\n",
      "2018-11-26 13:30:14,179 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:16,474 INFO     Weight matrix 2/9 (256,256): Alpha: 2.1751608235817974, Alpha Weighted: -1.2044357501776402, D: 0.09509108398594251\n",
      "2018-11-26 13:30:16,479 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.27864354848861694\n",
      "2018-11-26 13:30:16,485 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:18,868 INFO     Weight matrix 3/9 (256,256): Alpha: 2.562096930660241, Alpha Weighted: -1.9107462712625076, D: 0.11388313130277739\n",
      "2018-11-26 13:30:18,872 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.23736996948719025\n",
      "2018-11-26 13:30:18,874 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:21,455 INFO     Weight matrix 4/9 (256,256): Alpha: 2.587594718131834, Alpha Weighted: -1.4925569931587543, D: 0.08280046865211549\n",
      "2018-11-26 13:30:21,459 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.2568832337856293\n",
      "2018-11-26 13:30:21,463 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:23,883 INFO     Weight matrix 5/9 (256,256): Alpha: 2.2626144983826233, Alpha Weighted: -0.8003718058595242, D: 0.0882900422346089\n",
      "2018-11-26 13:30:23,887 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.35332417488098145\n",
      "2018-11-26 13:30:23,889 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:26,168 INFO     Weight matrix 6/9 (256,256): Alpha: 2.397388230943581, Alpha Weighted: -1.3186425767951278, D: 0.07695655970710236\n",
      "2018-11-26 13:30:26,175 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.27700385451316833\n",
      "2018-11-26 13:30:26,179 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:28,495 INFO     Weight matrix 7/9 (256,256): Alpha: 2.135620028952949, Alpha Weighted: -1.655030750604817, D: 0.12786977436599622\n",
      "2018-11-26 13:30:28,499 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.23869651556015015\n",
      "2018-11-26 13:30:28,502 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:30,837 INFO     Weight matrix 8/9 (256,256): Alpha: 2.535003198891982, Alpha Weighted: -1.4289396516712087, D: 0.11159790488529009\n",
      "2018-11-26 13:30:30,841 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.29860591888427734\n",
      "2018-11-26 13:30:30,844 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:33,174 INFO     Weight matrix 9/9 (256,256): Alpha: 2.532542929904764, Alpha Weighted: -1.7264281531405312, D: 0.11877593953673071\n",
      "2018-11-26 13:30:33,179 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.2619491517543793\n",
      "2018-11-26 13:30:33,182 INFO Layer 173: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:30:33,184 INFO Layer 173: Skipping (Layer not supported)\n",
      "2018-11-26 13:30:33,187 INFO Layer 174: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:30:33,191 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:30:33,194 INFO Layer 174: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:30:33,197 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:30:35,655 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.947768431497339, Alpha Weighted: -0.12483188901654398, D: 0.13500856049914745\n",
      "2018-11-26 13:30:35,657 INFO     Weight matrix 1/1 (256,1024): Alpha 5.947768431497339 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:30:35,660 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7012448310852051\n",
      "2018-11-26 13:30:35,663 INFO Layer 175: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:30:35,666 INFO Layer 175: Skipping (Layer not supported)\n",
      "2018-11-26 13:30:35,669 INFO Layer 176: ReLU(inplace)\n",
      "2018-11-26 13:30:35,671 INFO Layer 176: Skipping (Layer not supported)\n",
      "2018-11-26 13:30:35,673 INFO Layer 177: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:30:35,676 INFO Layer 177: Skipping (Layer not supported)\n",
      "2018-11-26 13:30:35,679 INFO Layer 178: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:30:35,683 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:30:35,686 INFO Layer 178: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:30:35,688 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:30:38,124 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.9926658517242501, Alpha Weighted: 0.2179593929694965, D: 0.10890977911463529\n",
      "2018-11-26 13:30:38,128 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7270463109016418\n",
      "2018-11-26 13:30:38,133 INFO Layer 179: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:30:38,135 INFO Layer 179: Skipping (Layer not supported)\n",
      "2018-11-26 13:30:38,138 INFO Layer 180: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:30:38,144 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:30:38,149 INFO Layer 180: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:30:38,152 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:40,509 INFO     Weight matrix 1/9 (256,256): Alpha: 2.2510270672079864, Alpha Weighted: -1.380980684341646, D: 0.10229648977452366\n",
      "2018-11-26 13:30:40,514 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.2953700125217438\n",
      "2018-11-26 13:30:40,517 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:42,811 INFO     Weight matrix 2/9 (256,256): Alpha: 2.1960210265645608, Alpha Weighted: -0.8195748104989262, D: 0.10202054457681081\n",
      "2018-11-26 13:30:42,816 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3486669361591339\n",
      "2018-11-26 13:30:42,819 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:45,128 INFO     Weight matrix 3/9 (256,256): Alpha: 2.1677962667597535, Alpha Weighted: -1.2113386728534785, D: 0.0965334454364205\n",
      "2018-11-26 13:30:45,133 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.30847880244255066\n",
      "2018-11-26 13:30:45,136 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:47,444 INFO     Weight matrix 4/9 (256,256): Alpha: 2.1202040243236278, Alpha Weighted: -0.7280666283402096, D: 0.07065114758156221\n",
      "2018-11-26 13:30:47,448 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.33761826157569885\n",
      "2018-11-26 13:30:47,451 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:49,740 INFO     Weight matrix 5/9 (256,256): Alpha: 1.9356982459232377, Alpha Weighted: -0.5454705391724113, D: 0.0905477541369436\n",
      "2018-11-26 13:30:49,745 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.3990285098552704\n",
      "2018-11-26 13:30:49,748 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:52,058 INFO     Weight matrix 6/9 (256,256): Alpha: 2.047538269645286, Alpha Weighted: -0.6659734157791246, D: 0.07688708290720564\n",
      "2018-11-26 13:30:52,063 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.35002437233924866\n",
      "2018-11-26 13:30:52,065 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:54,377 INFO     Weight matrix 7/9 (256,256): Alpha: 2.2964163334690273, Alpha Weighted: -1.2334230459281859, D: 0.09866398447756436\n",
      "2018-11-26 13:30:54,382 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3100251257419586\n",
      "2018-11-26 13:30:54,386 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:56,702 INFO     Weight matrix 8/9 (256,256): Alpha: 2.0057068803805462, Alpha Weighted: -0.5149376605240878, D: 0.09742026609987686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:30:56,707 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.37572312355041504\n",
      "2018-11-26 13:30:56,709 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:30:59,029 INFO     Weight matrix 9/9 (256,256): Alpha: 2.1089549654215327, Alpha Weighted: -1.095301709346466, D: 0.10329656991463254\n",
      "2018-11-26 13:30:59,033 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.3243056833744049\n",
      "2018-11-26 13:30:59,037 INFO Layer 181: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:30:59,040 INFO Layer 181: Skipping (Layer not supported)\n",
      "2018-11-26 13:30:59,042 INFO Layer 182: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:30:59,046 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:30:59,050 INFO Layer 182: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:30:59,053 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:31:01,490 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.99265189779358, Alpha Weighted: 0.036854017515743784, D: 0.14290729446228678\n",
      "2018-11-26 13:31:01,492 INFO     Weight matrix 1/1 (256,1024): Alpha 3.99265189779358 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:31:01,496 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7489341497421265\n",
      "2018-11-26 13:31:01,499 INFO Layer 183: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:31:01,501 INFO Layer 183: Skipping (Layer not supported)\n",
      "2018-11-26 13:31:01,504 INFO Layer 184: ReLU(inplace)\n",
      "2018-11-26 13:31:01,506 INFO Layer 184: Skipping (Layer not supported)\n",
      "2018-11-26 13:31:01,509 INFO Layer 185: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:31:01,511 INFO Layer 185: Skipping (Layer not supported)\n",
      "2018-11-26 13:31:01,514 INFO Layer 186: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:31:01,519 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:31:01,521 INFO Layer 186: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:31:01,525 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:31:03,922 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.8894786863989337, Alpha Weighted: 0.1253190430587101, D: 0.10635787179171496\n",
      "2018-11-26 13:31:03,926 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6206818222999573\n",
      "2018-11-26 13:31:03,931 INFO Layer 187: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:31:03,933 INFO Layer 187: Skipping (Layer not supported)\n",
      "2018-11-26 13:31:03,936 INFO Layer 188: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:31:03,941 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:31:03,943 INFO Layer 188: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:31:03,945 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:06,274 INFO     Weight matrix 1/9 (256,256): Alpha: 2.1273949778154932, Alpha Weighted: -1.3993666000751575, D: 0.1063340871824815\n",
      "2018-11-26 13:31:06,279 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.18687725067138672\n",
      "2018-11-26 13:31:06,282 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:08,572 INFO     Weight matrix 2/9 (256,256): Alpha: 2.13093830682587, Alpha Weighted: -0.8742663579702072, D: 0.08197666165791895\n",
      "2018-11-26 13:31:08,576 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.25384607911109924\n",
      "2018-11-26 13:31:08,580 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:10,886 INFO     Weight matrix 3/9 (256,256): Alpha: 2.171284318202283, Alpha Weighted: -1.352932139100166, D: 0.10370291637167317\n",
      "2018-11-26 13:31:10,890 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.19922460615634918\n",
      "2018-11-26 13:31:10,893 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:13,179 INFO     Weight matrix 4/9 (256,256): Alpha: 1.9122077091473755, Alpha Weighted: -0.36817223596917936, D: 0.08845792209761638\n",
      "2018-11-26 13:31:13,183 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.2729012370109558\n",
      "2018-11-26 13:31:13,185 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:15,493 INFO     Weight matrix 5/9 (256,256): Alpha: 1.671363645674939, Alpha Weighted: -0.434276190760442, D: 0.09861270857363935\n",
      "2018-11-26 13:31:15,498 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.3092041015625\n",
      "2018-11-26 13:31:15,501 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:17,766 INFO     Weight matrix 6/9 (256,256): Alpha: 1.964305283584609, Alpha Weighted: -0.368553375715164, D: 0.0866620222714698\n",
      "2018-11-26 13:31:17,770 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.28142791986465454\n",
      "2018-11-26 13:31:17,772 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:20,065 INFO     Weight matrix 7/9 (256,256): Alpha: 1.8316744341137217, Alpha Weighted: -1.0750793721772767, D: 0.10849012660517066\n",
      "2018-11-26 13:31:20,069 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.20594096183776855\n",
      "2018-11-26 13:31:20,072 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:22,361 INFO     Weight matrix 8/9 (256,256): Alpha: 2.010477131735045, Alpha Weighted: -0.7551643507067478, D: 0.09271422752546776\n",
      "2018-11-26 13:31:22,366 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.26339074969291687\n",
      "2018-11-26 13:31:22,369 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:24,684 INFO     Weight matrix 9/9 (256,256): Alpha: 2.3130442500201114, Alpha Weighted: -1.2510474450478402, D: 0.10852672259968787\n",
      "2018-11-26 13:31:24,689 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.2172303944826126\n",
      "2018-11-26 13:31:24,691 INFO Layer 189: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:31:24,694 INFO Layer 189: Skipping (Layer not supported)\n",
      "2018-11-26 13:31:24,697 INFO Layer 190: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:31:24,703 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:31:24,706 INFO Layer 190: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:31:24,710 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:31:27,200 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.9687286833878763, Alpha Weighted: -0.08844496843813021, D: 0.11876322147078122\n",
      "2018-11-26 13:31:27,203 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6538853645324707\n",
      "2018-11-26 13:31:27,207 INFO Layer 191: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:31:27,210 INFO Layer 191: Skipping (Layer not supported)\n",
      "2018-11-26 13:31:27,213 INFO Layer 192: ReLU(inplace)\n",
      "2018-11-26 13:31:27,216 INFO Layer 192: Skipping (Layer not supported)\n",
      "2018-11-26 13:31:27,219 INFO Layer 193: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:31:27,222 INFO Layer 193: Skipping (Layer not supported)\n",
      "2018-11-26 13:31:27,224 INFO Layer 194: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:31:27,228 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:31:27,230 INFO Layer 194: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:31:27,234 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:31:29,621 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.7882470175214755, Alpha Weighted: 0.2936078975757856, D: 0.0764995292892483\n",
      "2018-11-26 13:31:29,624 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6611976027488708\n",
      "2018-11-26 13:31:29,628 INFO Layer 195: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:31:29,633 INFO Layer 195: Skipping (Layer not supported)\n",
      "2018-11-26 13:31:29,637 INFO Layer 196: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:31:29,643 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:31:29,645 INFO Layer 196: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:31:29,649 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:32,004 INFO     Weight matrix 1/9 (256,256): Alpha: 2.1361026031325854, Alpha Weighted: -1.0549501597763118, D: 0.1002765871681266\n",
      "2018-11-26 13:31:32,009 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.2599606215953827\n",
      "2018-11-26 13:31:32,012 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:34,296 INFO     Weight matrix 2/9 (256,256): Alpha: 1.8101169209600623, Alpha Weighted: -0.20498108565787504, D: 0.07672863781721495\n",
      "2018-11-26 13:31:34,300 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3519873023033142\n",
      "2018-11-26 13:31:34,304 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:36,603 INFO     Weight matrix 3/9 (256,256): Alpha: 2.151366679033911, Alpha Weighted: -0.9315860723960329, D: 0.09355112224136519\n",
      "2018-11-26 13:31:36,607 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.27161794900894165\n",
      "2018-11-26 13:31:36,613 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:38,898 INFO     Weight matrix 4/9 (256,256): Alpha: 1.862856118786432, Alpha Weighted: -0.5124370618946112, D: 0.08638250424999333\n",
      "2018-11-26 13:31:38,903 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3419828414916992\n",
      "2018-11-26 13:31:38,905 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:41,228 INFO     Weight matrix 5/9 (256,256): Alpha: 1.7022710175767564, Alpha Weighted: -0.16612001106920368, D: 0.08871429485085758\n",
      "2018-11-26 13:31:41,232 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.4061434268951416\n",
      "2018-11-26 13:31:41,235 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:43,536 INFO     Weight matrix 6/9 (256,256): Alpha: 1.775684084333732, Alpha Weighted: -0.37638405815852227, D: 0.08736170787822001\n",
      "2018-11-26 13:31:43,540 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.35868149995803833\n",
      "2018-11-26 13:31:43,542 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:45,834 INFO     Weight matrix 7/9 (256,256): Alpha: 1.9969945077906823, Alpha Weighted: -0.9067948802875541, D: 0.10426224049235072\n",
      "2018-11-26 13:31:45,838 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.2740139961242676\n",
      "2018-11-26 13:31:45,842 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:48,125 INFO     Weight matrix 8/9 (256,256): Alpha: 1.7134414969427993, Alpha Weighted: -0.14167191642144902, D: 0.08764169200647165\n",
      "2018-11-26 13:31:48,129 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.367561936378479\n",
      "2018-11-26 13:31:48,133 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:50,447 INFO     Weight matrix 9/9 (256,256): Alpha: 2.1621710923992454, Alpha Weighted: -0.9099460501535496, D: 0.1056258182391148\n",
      "2018-11-26 13:31:50,451 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.2813253104686737\n",
      "2018-11-26 13:31:50,454 INFO Layer 197: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:31:50,457 INFO Layer 197: Skipping (Layer not supported)\n",
      "2018-11-26 13:31:50,459 INFO Layer 198: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:31:50,463 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:31:50,466 INFO Layer 198: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:31:50,468 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:31:52,864 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.688899193280236, Alpha Weighted: 0.10430507555160122, D: 0.11401929617226492\n",
      "2018-11-26 13:31:52,867 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6972013711929321\n",
      "2018-11-26 13:31:52,870 INFO Layer 199: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:31:52,873 INFO Layer 199: Skipping (Layer not supported)\n",
      "2018-11-26 13:31:52,875 INFO Layer 200: ReLU(inplace)\n",
      "2018-11-26 13:31:52,879 INFO Layer 200: Skipping (Layer not supported)\n",
      "2018-11-26 13:31:52,882 INFO Layer 201: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:31:52,885 INFO Layer 201: Skipping (Layer not supported)\n",
      "2018-11-26 13:31:52,888 INFO Layer 202: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:31:52,892 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:31:52,894 INFO Layer 202: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:31:52,898 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:31:55,333 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.9354722979919479, Alpha Weighted: 0.07651470995834105, D: 0.12888397193161738\n",
      "2018-11-26 13:31:55,336 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.726108968257904\n",
      "2018-11-26 13:31:55,338 INFO Layer 203: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:31:55,341 INFO Layer 203: Skipping (Layer not supported)\n",
      "2018-11-26 13:31:55,345 INFO Layer 204: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:31:55,350 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:31:55,352 INFO Layer 204: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:31:55,355 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:57,677 INFO     Weight matrix 1/9 (256,256): Alpha: 2.1491633391748843, Alpha Weighted: -1.391680187788564, D: 0.11231837008934686\n",
      "2018-11-26 13:31:57,682 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.2961215376853943\n",
      "2018-11-26 13:31:57,684 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:31:59,984 INFO     Weight matrix 2/9 (256,256): Alpha: 2.144209715447892, Alpha Weighted: -1.0131072594710926, D: 0.09854753482404277\n",
      "2018-11-26 13:31:59,990 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.35269469022750854\n",
      "2018-11-26 13:31:59,994 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:02,346 INFO     Weight matrix 3/9 (256,256): Alpha: 2.5598074071275763, Alpha Weighted: -1.5942184342937464, D: 0.10192523747425775\n",
      "2018-11-26 13:32:02,351 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.30622902512550354\n",
      "2018-11-26 13:32:02,354 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:04,681 INFO     Weight matrix 4/9 (256,256): Alpha: 2.3078100429848236, Alpha Weighted: -1.101995920567322, D: 0.08981465835515812\n",
      "2018-11-26 13:32:04,685 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3477453291416168\n",
      "2018-11-26 13:32:04,689 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:06,993 INFO     Weight matrix 5/9 (256,256): Alpha: 2.2861070307154225, Alpha Weighted: -0.77558912700565, D: 0.11200497438516444\n",
      "2018-11-26 13:32:06,999 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.39830267429351807\n",
      "2018-11-26 13:32:07,002 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:09,300 INFO     Weight matrix 6/9 (256,256): Alpha: 1.976694001446202, Alpha Weighted: -0.8212765640829736, D: 0.11023860483618408\n",
      "2018-11-26 13:32:09,304 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.3704589903354645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:32:09,307 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:11,613 INFO     Weight matrix 7/9 (256,256): Alpha: 2.3401215798392565, Alpha Weighted: -1.346669836473963, D: 0.09904284888141168\n",
      "2018-11-26 13:32:11,618 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3075404465198517\n",
      "2018-11-26 13:32:11,620 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:13,923 INFO     Weight matrix 8/9 (256,256): Alpha: 1.975766014295616, Alpha Weighted: -0.8299451176392464, D: 0.106929751826356\n",
      "2018-11-26 13:32:13,928 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.36877426505088806\n",
      "2018-11-26 13:32:13,931 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:16,242 INFO     Weight matrix 9/9 (256,256): Alpha: 2.2120236320336573, Alpha Weighted: -1.2161611847204565, D: 0.10511336564385121\n",
      "2018-11-26 13:32:16,246 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.32365718483924866\n",
      "2018-11-26 13:32:16,248 INFO Layer 205: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:32:16,251 INFO Layer 205: Skipping (Layer not supported)\n",
      "2018-11-26 13:32:16,253 INFO Layer 206: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:32:16,258 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:32:16,260 INFO Layer 206: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:32:16,263 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:32:18,748 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.899464426852899, Alpha Weighted: -0.11752537872393803, D: 0.14432358022926955\n",
      "2018-11-26 13:32:18,751 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7455472350120544\n",
      "2018-11-26 13:32:18,756 INFO Layer 207: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:32:18,758 INFO Layer 207: Skipping (Layer not supported)\n",
      "2018-11-26 13:32:18,761 INFO Layer 208: ReLU(inplace)\n",
      "2018-11-26 13:32:18,763 INFO Layer 208: Skipping (Layer not supported)\n",
      "2018-11-26 13:32:18,766 INFO Layer 209: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:32:18,769 INFO Layer 209: Skipping (Layer not supported)\n",
      "2018-11-26 13:32:18,776 INFO Layer 210: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:32:18,780 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:32:18,785 INFO Layer 210: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:32:18,787 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:32:21,540 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.8103305454503325, Alpha Weighted: 0.2922004698373378, D: 0.08978952911702975\n",
      "2018-11-26 13:32:21,543 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7007266879081726\n",
      "2018-11-26 13:32:21,546 INFO Layer 211: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:32:21,553 INFO Layer 211: Skipping (Layer not supported)\n",
      "2018-11-26 13:32:21,556 INFO Layer 212: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:32:21,562 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:32:21,565 INFO Layer 212: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:32:21,568 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:23,960 INFO     Weight matrix 1/9 (256,256): Alpha: 2.215746678797748, Alpha Weighted: -1.2283066082381324, D: 0.09958045283239692\n",
      "2018-11-26 13:32:23,964 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.29702645540237427\n",
      "2018-11-26 13:32:23,969 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:26,274 INFO     Weight matrix 2/9 (256,256): Alpha: 1.9554530194557311, Alpha Weighted: -0.8104166207785835, D: 0.1127574281156114\n",
      "2018-11-26 13:32:26,278 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3493449091911316\n",
      "2018-11-26 13:32:26,281 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:28,597 INFO     Weight matrix 3/9 (256,256): Alpha: 2.3050319935274475, Alpha Weighted: -1.298697960489367, D: 0.1161210583984097\n",
      "2018-11-26 13:32:28,602 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.30979153513908386\n",
      "2018-11-26 13:32:28,607 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:30,961 INFO     Weight matrix 4/9 (256,256): Alpha: 2.107180375574238, Alpha Weighted: -0.42252510797944975, D: 0.0974197890144608\n",
      "2018-11-26 13:32:30,966 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.37996163964271545\n",
      "2018-11-26 13:32:30,969 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:33,254 INFO     Weight matrix 5/9 (256,256): Alpha: 2.2485565861892507, Alpha Weighted: -0.4188697927268521, D: 0.1023409145130012\n",
      "2018-11-26 13:32:33,259 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.418012410402298\n",
      "2018-11-26 13:32:33,264 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:35,562 INFO     Weight matrix 6/9 (256,256): Alpha: 2.0429676578460736, Alpha Weighted: -0.3450765036245548, D: 0.0796798357685008\n",
      "2018-11-26 13:32:35,567 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.3981456458568573\n",
      "2018-11-26 13:32:35,569 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:37,906 INFO     Weight matrix 7/9 (256,256): Alpha: 2.408338937853131, Alpha Weighted: -1.381815087292461, D: 0.11485322469149256\n",
      "2018-11-26 13:32:37,910 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.30219030380249023\n",
      "2018-11-26 13:32:37,913 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:40,211 INFO     Weight matrix 8/9 (256,256): Alpha: 1.8066240779987144, Alpha Weighted: -0.5442077260816557, D: 0.1012669272377808\n",
      "2018-11-26 13:32:40,215 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.362571120262146\n",
      "2018-11-26 13:32:40,219 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:42,536 INFO     Weight matrix 9/9 (256,256): Alpha: 2.0580762981709944, Alpha Weighted: -1.114314179239299, D: 0.11188179498821199\n",
      "2018-11-26 13:32:42,539 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.31540611386299133\n",
      "2018-11-26 13:32:42,543 INFO Layer 213: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:32:42,546 INFO Layer 213: Skipping (Layer not supported)\n",
      "2018-11-26 13:32:42,548 INFO Layer 214: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:32:42,554 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:32:42,561 INFO Layer 214: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:32:42,564 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:32:45,016 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.666518239626001, Alpha Weighted: -0.0019963829491094266, D: 0.13669805629664228\n",
      "2018-11-26 13:32:45,018 INFO     Weight matrix 1/1 (256,1024): Alpha 3.666518239626001 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:32:45,022 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7326050400733948\n",
      "2018-11-26 13:32:45,024 INFO Layer 215: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:32:45,026 INFO Layer 215: Skipping (Layer not supported)\n",
      "2018-11-26 13:32:45,028 INFO Layer 216: ReLU(inplace)\n",
      "2018-11-26 13:32:45,031 INFO Layer 216: Skipping (Layer not supported)\n",
      "2018-11-26 13:32:45,034 INFO Layer 217: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:32:45,036 INFO Layer 217: Skipping (Layer not supported)\n",
      "2018-11-26 13:32:45,039 INFO Layer 218: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:32:45,046 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:32:45,051 INFO Layer 218: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:32:45,054 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:32:47,501 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.0618652260958665, Alpha Weighted: 0.12251477361360692, D: 0.1427935084031891\n",
      "2018-11-26 13:32:47,504 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7854442596435547\n",
      "2018-11-26 13:32:47,506 INFO Layer 219: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:32:47,509 INFO Layer 219: Skipping (Layer not supported)\n",
      "2018-11-26 13:32:47,511 INFO Layer 220: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:32:47,517 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:32:47,520 INFO Layer 220: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:32:47,523 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:49,862 INFO     Weight matrix 1/9 (256,256): Alpha: 3.9571783417299358, Alpha Weighted: -2.404265881833999, D: 0.10623906673305394\n",
      "2018-11-26 13:32:49,865 INFO     Weight matrix 1/9 (256,256): Alpha 3.9571783417299358 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:32:49,869 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3083251714706421\n",
      "2018-11-26 13:32:49,872 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:52,191 INFO     Weight matrix 2/9 (256,256): Alpha: 2.813707417977777, Alpha Weighted: -1.4718287678073503, D: 0.1288641738062894\n",
      "2018-11-26 13:32:52,195 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3672068417072296\n",
      "2018-11-26 13:32:52,198 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:54,511 INFO     Weight matrix 3/9 (256,256): Alpha: 4.189709203438193, Alpha Weighted: -2.4717610036427526, D: 0.12285809250890106\n",
      "2018-11-26 13:32:54,514 INFO     Weight matrix 3/9 (256,256): Alpha 4.189709203438193 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:32:54,518 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.3249027132987976\n",
      "2018-11-26 13:32:54,521 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:56,858 INFO     Weight matrix 4/9 (256,256): Alpha: 3.546598993541046, Alpha Weighted: -2.1801652869043906, D: 0.10512275281576955\n",
      "2018-11-26 13:32:56,861 INFO     Weight matrix 4/9 (256,256): Alpha 3.546598993541046 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:32:56,867 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.31449607014656067\n",
      "2018-11-26 13:32:56,869 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:32:59,188 INFO     Weight matrix 5/9 (256,256): Alpha: 2.361815009805327, Alpha Weighted: -0.8039900088052354, D: 0.12424827880472727\n",
      "2018-11-26 13:32:59,193 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.418446809053421\n",
      "2018-11-26 13:32:59,197 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:01,542 INFO     Weight matrix 6/9 (256,256): Alpha: 2.7025335500594396, Alpha Weighted: -1.5561355751951313, D: 0.12033511599868679\n",
      "2018-11-26 13:33:01,546 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.33697378635406494\n",
      "2018-11-26 13:33:01,549 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:03,884 INFO     Weight matrix 7/9 (256,256): Alpha: 3.241113870287248, Alpha Weighted: -2.024835914161135, D: 0.1326169527838577\n",
      "2018-11-26 13:33:03,888 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3158385157585144\n",
      "2018-11-26 13:33:03,891 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:06,211 INFO     Weight matrix 8/9 (256,256): Alpha: 3.238817252128412, Alpha Weighted: -1.586142982238458, D: 0.12458339626334802\n",
      "2018-11-26 13:33:06,216 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.3839681148529053\n",
      "2018-11-26 13:33:06,218 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:08,541 INFO     Weight matrix 9/9 (256,256): Alpha: 3.6892838002800024, Alpha Weighted: -2.1419571392807013, D: 0.12651032248852756\n",
      "2018-11-26 13:33:08,546 INFO     Weight matrix 9/9 (256,256): Alpha 3.6892838002800024 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:33:08,550 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.33860287070274353\n",
      "2018-11-26 13:33:08,554 INFO Layer 221: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:33:08,558 INFO Layer 221: Skipping (Layer not supported)\n",
      "2018-11-26 13:33:08,560 INFO Layer 222: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:33:08,564 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:33:08,567 INFO Layer 222: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:33:08,569 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:33:11,036 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.019555906853422, Alpha Weighted: 0.6146982955126611, D: 0.08149095113770533\n",
      "2018-11-26 13:33:11,039 INFO     Weight matrix 1/1 (256,1024): Alpha 5.019555906853422 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:33:11,042 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.758399248123169\n",
      "2018-11-26 13:33:11,045 INFO Layer 223: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:33:11,048 INFO Layer 223: Skipping (Layer not supported)\n",
      "2018-11-26 13:33:11,055 INFO Layer 224: ReLU(inplace)\n",
      "2018-11-26 13:33:11,058 INFO Layer 224: Skipping (Layer not supported)\n",
      "2018-11-26 13:33:11,063 INFO Layer 225: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:33:11,067 INFO Layer 225: Skipping (Layer not supported)\n",
      "2018-11-26 13:33:11,069 INFO Layer 226: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:33:11,075 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:33:11,078 INFO Layer 226: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:33:11,081 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:33:13,548 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.305183108263292, Alpha Weighted: 0.29280085797490846, D: 0.12338800487629364\n",
      "2018-11-26 13:33:13,552 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8030890822410583\n",
      "2018-11-26 13:33:13,554 INFO Layer 227: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:33:13,557 INFO Layer 227: Skipping (Layer not supported)\n",
      "2018-11-26 13:33:13,560 INFO Layer 228: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:33:13,566 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:33:13,571 INFO Layer 228: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:33:13,574 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:15,921 INFO     Weight matrix 1/9 (256,256): Alpha: 2.827230556272143, Alpha Weighted: -1.8944649389103265, D: 0.12028221270400441\n",
      "2018-11-26 13:33:15,926 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3385255038738251\n",
      "2018-11-26 13:33:15,928 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:18,260 INFO     Weight matrix 2/9 (256,256): Alpha: 3.0227760801905905, Alpha Weighted: -1.6132788038337762, D: 0.11642684251527402\n",
      "2018-11-26 13:33:18,264 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.38421690464019775\n",
      "2018-11-26 13:33:18,266 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:20,616 INFO     Weight matrix 3/9 (256,256): Alpha: 2.4624872051698548, Alpha Weighted: -1.5197234129384136, D: 0.11761584564120903\n",
      "2018-11-26 13:33:20,621 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.351701021194458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:33:20,624 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:22,966 INFO     Weight matrix 4/9 (256,256): Alpha: 2.6058443377416545, Alpha Weighted: -1.3544116667221422, D: 0.1085253984358589\n",
      "2018-11-26 13:33:22,971 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.37198278307914734\n",
      "2018-11-26 13:33:22,973 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:25,298 INFO     Weight matrix 5/9 (256,256): Alpha: 2.3926476500888345, Alpha Weighted: -0.889993925708956, D: 0.11799161412162895\n",
      "2018-11-26 13:33:25,302 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.44251328706741333\n",
      "2018-11-26 13:33:25,305 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:27,612 INFO     Weight matrix 6/9 (256,256): Alpha: 2.497957613371348, Alpha Weighted: -1.0672039212981668, D: 0.1107960255933581\n",
      "2018-11-26 13:33:27,617 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.3939136862754822\n",
      "2018-11-26 13:33:27,622 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:29,952 INFO     Weight matrix 7/9 (256,256): Alpha: 2.418724589667601, Alpha Weighted: -1.3999702455487353, D: 0.119931302047741\n",
      "2018-11-26 13:33:29,956 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.35579079389572144\n",
      "2018-11-26 13:33:29,959 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:32,363 INFO     Weight matrix 8/9 (256,256): Alpha: 2.3643501697342897, Alpha Weighted: -1.1866704913794264, D: 0.1270665494613591\n",
      "2018-11-26 13:33:32,367 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.40888842940330505\n",
      "2018-11-26 13:33:32,370 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:34,700 INFO     Weight matrix 9/9 (256,256): Alpha: 2.872661389673781, Alpha Weighted: -1.4845439379699792, D: 0.11623826302036233\n",
      "2018-11-26 13:33:34,705 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.3733235001564026\n",
      "2018-11-26 13:33:34,709 INFO Layer 229: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:33:34,711 INFO Layer 229: Skipping (Layer not supported)\n",
      "2018-11-26 13:33:34,715 INFO Layer 230: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:33:34,723 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:33:34,725 INFO Layer 230: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:33:34,729 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:33:37,190 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.076908498536858, Alpha Weighted: -0.039446479366277855, D: 0.14337746633466897\n",
      "2018-11-26 13:33:37,193 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7744672298431396\n",
      "2018-11-26 13:33:37,197 INFO Layer 231: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:33:37,199 INFO Layer 231: Skipping (Layer not supported)\n",
      "2018-11-26 13:33:37,201 INFO Layer 232: ReLU(inplace)\n",
      "2018-11-26 13:33:37,204 INFO Layer 232: Skipping (Layer not supported)\n",
      "2018-11-26 13:33:37,207 INFO Layer 233: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:33:37,209 INFO Layer 233: Skipping (Layer not supported)\n",
      "2018-11-26 13:33:37,213 INFO Layer 234: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:33:37,225 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:33:37,227 INFO Layer 234: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:33:37,230 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:33:39,657 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.516305723832419, Alpha Weighted: 0.08678285793668145, D: 0.1376436262968151\n",
      "2018-11-26 13:33:39,661 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7655656933784485\n",
      "2018-11-26 13:33:39,664 INFO Layer 235: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:33:39,667 INFO Layer 235: Skipping (Layer not supported)\n",
      "2018-11-26 13:33:39,670 INFO Layer 236: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:33:39,675 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:33:39,677 INFO Layer 236: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:33:39,680 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:42,004 INFO     Weight matrix 1/9 (256,256): Alpha: 2.9140681125609915, Alpha Weighted: -1.6877406219334175, D: 0.10099846787855071\n",
      "2018-11-26 13:33:42,008 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3128463923931122\n",
      "2018-11-26 13:33:42,010 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:44,327 INFO     Weight matrix 2/9 (256,256): Alpha: 2.5016746646236605, Alpha Weighted: -1.3437608913128887, D: 0.11588271364006619\n",
      "2018-11-26 13:33:44,331 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.36639267206192017\n",
      "2018-11-26 13:33:44,337 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:46,648 INFO     Weight matrix 3/9 (256,256): Alpha: 2.8956079246845565, Alpha Weighted: -1.6420619408716024, D: 0.11527192408503617\n",
      "2018-11-26 13:33:46,653 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.32497960329055786\n",
      "2018-11-26 13:33:46,656 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:48,972 INFO     Weight matrix 4/9 (256,256): Alpha: 2.551677268478807, Alpha Weighted: -1.2742365750832525, D: 0.10602184784678381\n",
      "2018-11-26 13:33:48,977 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3428036570549011\n",
      "2018-11-26 13:33:48,980 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:51,317 INFO     Weight matrix 5/9 (256,256): Alpha: 2.8985884323328444, Alpha Weighted: -0.6492277652349625, D: 0.08746667946377007\n",
      "2018-11-26 13:33:51,322 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.4210379421710968\n",
      "2018-11-26 13:33:51,325 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:53,681 INFO     Weight matrix 6/9 (256,256): Alpha: 2.6465920136127083, Alpha Weighted: -1.2193314906866686, D: 0.1073390044988789\n",
      "2018-11-26 13:33:53,685 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.3593023717403412\n",
      "2018-11-26 13:33:53,688 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:56,043 INFO     Weight matrix 7/9 (256,256): Alpha: 2.442089979862594, Alpha Weighted: -1.3335114144364648, D: 0.10602847433603935\n",
      "2018-11-26 13:33:56,047 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3273857831954956\n",
      "2018-11-26 13:33:56,051 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:33:58,364 INFO     Weight matrix 8/9 (256,256): Alpha: 3.104467980638734, Alpha Weighted: -1.5205678808909195, D: 0.13505530255338927\n",
      "2018-11-26 13:33:58,369 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.38709619641304016\n",
      "2018-11-26 13:33:58,372 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:00,711 INFO     Weight matrix 9/9 (256,256): Alpha: 2.659279264420268, Alpha Weighted: -1.5028091548274807, D: 0.11155920364180966\n",
      "2018-11-26 13:34:00,715 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.3396860957145691\n",
      "2018-11-26 13:34:00,718 INFO Layer 237: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:34:00,721 INFO Layer 237: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:00,728 INFO Layer 238: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:34:00,733 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:34:00,735 INFO Layer 238: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:34:00,738 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:34:03,171 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.7691523748677165, Alpha Weighted: 0.4435144453590484, D: 0.11931580145982212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:34:03,174 INFO     Weight matrix 1/1 (256,1024): Alpha 4.7691523748677165 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:34:03,179 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7425299286842346\n",
      "2018-11-26 13:34:03,182 INFO Layer 239: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:34:03,185 INFO Layer 239: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:03,188 INFO Layer 240: ReLU(inplace)\n",
      "2018-11-26 13:34:03,190 INFO Layer 240: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:03,193 INFO Layer 241: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:34:03,195 INFO Layer 241: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:03,197 INFO Layer 242: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:34:03,201 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:34:03,204 INFO Layer 242: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:34:03,209 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:34:05,657 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.904988048103038, Alpha Weighted: -0.057254851305566616, D: 0.11818798996641133\n",
      "2018-11-26 13:34:05,660 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.716942548751831\n",
      "2018-11-26 13:34:05,662 INFO Layer 243: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:34:05,664 INFO Layer 243: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:05,667 INFO Layer 244: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:34:05,674 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:34:05,681 INFO Layer 244: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:34:05,684 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:07,997 INFO     Weight matrix 1/9 (256,256): Alpha: 1.866222924375104, Alpha Weighted: -1.0705659042706641, D: 0.11786520580807097\n",
      "2018-11-26 13:34:08,001 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.29372262954711914\n",
      "2018-11-26 13:34:08,006 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:10,328 INFO     Weight matrix 2/9 (256,256): Alpha: 2.1401805297987164, Alpha Weighted: -0.9996718077292126, D: 0.10054810514479073\n",
      "2018-11-26 13:34:10,335 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.32012248039245605\n",
      "2018-11-26 13:34:10,339 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:12,631 INFO     Weight matrix 3/9 (256,256): Alpha: 2.2303918052323013, Alpha Weighted: -1.2425939445173884, D: 0.11298512958859735\n",
      "2018-11-26 13:34:12,635 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.30270737409591675\n",
      "2018-11-26 13:34:12,638 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:14,972 INFO     Weight matrix 4/9 (256,256): Alpha: 1.8366573487026283, Alpha Weighted: -0.8652973951347133, D: 0.10132703462560472\n",
      "2018-11-26 13:34:14,976 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3439377546310425\n",
      "2018-11-26 13:34:14,978 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:17,281 INFO     Weight matrix 5/9 (256,256): Alpha: 2.949238839683723, Alpha Weighted: -0.794551752819206, D: 0.109794605264532\n",
      "2018-11-26 13:34:17,285 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.3600243330001831\n",
      "2018-11-26 13:34:17,287 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:20,436 INFO     Weight matrix 6/9 (256,256): Alpha: 1.9259005327265952, Alpha Weighted: -0.8515120043024293, D: 0.10504141569089703\n",
      "2018-11-26 13:34:20,443 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.3561294674873352\n",
      "2018-11-26 13:34:20,449 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:22,989 INFO     Weight matrix 7/9 (256,256): Alpha: 1.93008310361816, Alpha Weighted: -1.0610379349732988, D: 0.12285288944057476\n",
      "2018-11-26 13:34:22,994 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.2998296618461609\n",
      "2018-11-26 13:34:22,997 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:25,315 INFO     Weight matrix 8/9 (256,256): Alpha: 1.9974166430966007, Alpha Weighted: -0.8766781770500919, D: 0.10728123263624295\n",
      "2018-11-26 13:34:25,320 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.3307614028453827\n",
      "2018-11-26 13:34:25,325 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:27,689 INFO     Weight matrix 9/9 (256,256): Alpha: 1.9339197337091178, Alpha Weighted: -1.001493554993428, D: 0.11108088074253464\n",
      "2018-11-26 13:34:27,694 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.311816930770874\n",
      "2018-11-26 13:34:27,696 INFO Layer 245: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:34:27,700 INFO Layer 245: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:27,707 INFO Layer 246: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:34:27,712 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:34:27,714 INFO Layer 246: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:34:27,717 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:34:30,259 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.9620703781779296, Alpha Weighted: 0.07557437707384575, D: 0.12363217054401932\n",
      "2018-11-26 13:34:30,262 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7167928218841553\n",
      "2018-11-26 13:34:30,265 INFO Layer 247: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:34:30,267 INFO Layer 247: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:30,271 INFO Layer 248: ReLU(inplace)\n",
      "2018-11-26 13:34:30,275 INFO Layer 248: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:30,277 INFO Layer 249: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:34:30,280 INFO Layer 249: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:30,283 INFO Layer 250: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:34:30,287 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:34:30,290 INFO Layer 250: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:34:30,293 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:34:32,737 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.8516724217220992, Alpha Weighted: 0.10291285154390853, D: 0.11172344515438581\n",
      "2018-11-26 13:34:32,740 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6992054581642151\n",
      "2018-11-26 13:34:32,743 INFO Layer 251: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:34:32,745 INFO Layer 251: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:32,747 INFO Layer 252: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:34:32,753 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:34:32,755 INFO Layer 252: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:34:32,758 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:35,076 INFO     Weight matrix 1/9 (256,256): Alpha: 2.689860778622113, Alpha Weighted: -1.3158257713616637, D: 0.10367700965484994\n",
      "2018-11-26 13:34:35,082 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.2824193835258484\n",
      "2018-11-26 13:34:35,085 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:34:37,400 INFO     Weight matrix 2/9 (256,256): Alpha: 2.149206496264183, Alpha Weighted: -0.7554368697790022, D: 0.09208179782663023\n",
      "2018-11-26 13:34:37,404 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.31444501876831055\n",
      "2018-11-26 13:34:37,407 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:39,747 INFO     Weight matrix 3/9 (256,256): Alpha: 2.0763418387918353, Alpha Weighted: -1.0112177454084075, D: 0.11083021056979703\n",
      "2018-11-26 13:34:39,752 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.28769126534461975\n",
      "2018-11-26 13:34:39,756 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:42,070 INFO     Weight matrix 4/9 (256,256): Alpha: 2.0716585700391383, Alpha Weighted: -0.6920206896442811, D: 0.09426398477501152\n",
      "2018-11-26 13:34:42,075 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3155592679977417\n",
      "2018-11-26 13:34:42,080 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:44,408 INFO     Weight matrix 5/9 (256,256): Alpha: 1.814995590928417, Alpha Weighted: -0.8389647710119642, D: 0.11480909933240635\n",
      "2018-11-26 13:34:44,412 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.30683186650276184\n",
      "2018-11-26 13:34:44,415 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:46,716 INFO     Weight matrix 6/9 (256,256): Alpha: 2.092862123850393, Alpha Weighted: -0.689591000299539, D: 0.09814329372825503\n",
      "2018-11-26 13:34:46,721 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.32163602113723755\n",
      "2018-11-26 13:34:46,724 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:49,037 INFO     Weight matrix 7/9 (256,256): Alpha: 2.6562532125122336, Alpha Weighted: -1.3338396066085167, D: 0.11018303684522357\n",
      "2018-11-26 13:34:49,043 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.2798294126987457\n",
      "2018-11-26 13:34:49,045 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:51,386 INFO     Weight matrix 8/9 (256,256): Alpha: 2.0730670484307394, Alpha Weighted: -0.6756781397723379, D: 0.09870546474867198\n",
      "2018-11-26 13:34:51,390 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.3211495280265808\n",
      "2018-11-26 13:34:51,393 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:34:53,727 INFO     Weight matrix 9/9 (256,256): Alpha: 1.8679065934915207, Alpha Weighted: -0.885827292398594, D: 0.11219024830688568\n",
      "2018-11-26 13:34:53,732 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.29280444979667664\n",
      "2018-11-26 13:34:53,736 INFO Layer 253: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:34:53,742 INFO Layer 253: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:53,744 INFO Layer 254: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:34:53,748 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:34:53,751 INFO Layer 254: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:34:53,755 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:34:56,200 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.8506632151430722, Alpha Weighted: -0.17918036553114275, D: 0.13083387699890914\n",
      "2018-11-26 13:34:56,203 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6795777678489685\n",
      "2018-11-26 13:34:56,206 INFO Layer 255: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:34:56,209 INFO Layer 255: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:56,212 INFO Layer 256: ReLU(inplace)\n",
      "2018-11-26 13:34:56,217 INFO Layer 256: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:56,222 INFO Layer 257: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:34:56,227 INFO Layer 257: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:56,230 INFO Layer 258: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:34:56,236 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:34:56,238 INFO Layer 258: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:34:56,344 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:34:58,751 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.9540719209873008, Alpha Weighted: 0.2661217591131321, D: 0.10806294298377994\n",
      "2018-11-26 13:34:58,755 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7454421520233154\n",
      "2018-11-26 13:34:58,760 INFO Layer 259: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:34:58,762 INFO Layer 259: Skipping (Layer not supported)\n",
      "2018-11-26 13:34:58,765 INFO Layer 260: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:34:58,771 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:34:58,775 INFO Layer 260: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:34:58,783 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:01,140 INFO     Weight matrix 1/9 (256,256): Alpha: 2.169564914759763, Alpha Weighted: -0.9917475078897554, D: 0.10748066513102561\n",
      "2018-11-26 13:35:01,143 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.32946014404296875\n",
      "2018-11-26 13:35:01,146 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:03,506 INFO     Weight matrix 2/9 (256,256): Alpha: 2.2087636005384583, Alpha Weighted: -1.0123243990973951, D: 0.08906171110220662\n",
      "2018-11-26 13:35:03,511 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.34642350673675537\n",
      "2018-11-26 13:35:03,514 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:05,843 INFO     Weight matrix 3/9 (256,256): Alpha: 2.151918659821474, Alpha Weighted: -0.9840245122048096, D: 0.102338201684947\n",
      "2018-11-26 13:35:05,847 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.3363776206970215\n",
      "2018-11-26 13:35:05,850 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:08,191 INFO     Weight matrix 4/9 (256,256): Alpha: 1.9381302784962344, Alpha Weighted: -0.6337171787222056, D: 0.09529566247843435\n",
      "2018-11-26 13:35:08,196 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3728595972061157\n",
      "2018-11-26 13:35:08,199 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:10,564 INFO     Weight matrix 5/9 (256,256): Alpha: 2.1977208858330575, Alpha Weighted: -1.2068512868226078, D: 0.10957809989185996\n",
      "2018-11-26 13:35:10,568 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.34659960865974426\n",
      "2018-11-26 13:35:10,571 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:12,910 INFO     Weight matrix 6/9 (256,256): Alpha: 2.236766330718332, Alpha Weighted: -0.6816293313597362, D: 0.09253674286269675\n",
      "2018-11-26 13:35:12,914 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.37788042426109314\n",
      "2018-11-26 13:35:12,917 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:15,214 INFO     Weight matrix 7/9 (256,256): Alpha: 2.4304758487374443, Alpha Weighted: -0.992662760487797, D: 0.0976411124533419\n",
      "2018-11-26 13:35:15,219 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3389512896537781\n",
      "2018-11-26 13:35:15,224 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:17,549 INFO     Weight matrix 8/9 (256,256): Alpha: 2.3408555071111623, Alpha Weighted: -1.05519801909525, D: 0.10678221203238414\n",
      "2018-11-26 13:35:17,554 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.3558290898799896\n",
      "2018-11-26 13:35:17,556 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:19,888 INFO     Weight matrix 9/9 (256,256): Alpha: 2.3251373675702527, Alpha Weighted: -0.9358529004462798, D: 0.08565665297659741\n",
      "2018-11-26 13:35:19,892 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.3468456566333771\n",
      "2018-11-26 13:35:19,895 INFO Layer 261: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:35:19,898 INFO Layer 261: Skipping (Layer not supported)\n",
      "2018-11-26 13:35:19,900 INFO Layer 262: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:35:19,907 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:35:19,910 INFO Layer 262: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:35:19,914 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:35:22,358 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.7588113177154798, Alpha Weighted: -0.0965230027818899, D: 0.1435062838950758\n",
      "2018-11-26 13:35:22,362 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7399800419807434\n",
      "2018-11-26 13:35:22,364 INFO Layer 263: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:35:22,368 INFO Layer 263: Skipping (Layer not supported)\n",
      "2018-11-26 13:35:22,370 INFO Layer 264: ReLU(inplace)\n",
      "2018-11-26 13:35:22,373 INFO Layer 264: Skipping (Layer not supported)\n",
      "2018-11-26 13:35:22,376 INFO Layer 265: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:35:22,378 INFO Layer 265: Skipping (Layer not supported)\n",
      "2018-11-26 13:35:22,381 INFO Layer 266: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:35:22,388 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:35:22,391 INFO Layer 266: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:35:22,395 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:35:24,847 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.1338209835660784, Alpha Weighted: 0.09068512557163831, D: 0.12350250862436729\n",
      "2018-11-26 13:35:24,851 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7167991399765015\n",
      "2018-11-26 13:35:24,853 INFO Layer 267: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:35:24,856 INFO Layer 267: Skipping (Layer not supported)\n",
      "2018-11-26 13:35:24,858 INFO Layer 268: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:35:24,864 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:35:24,867 INFO Layer 268: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:35:24,869 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:27,173 INFO     Weight matrix 1/9 (256,256): Alpha: 1.8341777908501835, Alpha Weighted: -0.9565797861750396, D: 0.10863054777574338\n",
      "2018-11-26 13:35:27,178 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.29221129417419434\n",
      "2018-11-26 13:35:27,182 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:29,508 INFO     Weight matrix 2/9 (256,256): Alpha: 1.9563693981724715, Alpha Weighted: -0.8705816861935358, D: 0.10784497036469037\n",
      "2018-11-26 13:35:29,513 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3064097464084625\n",
      "2018-11-26 13:35:29,516 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:31,877 INFO     Weight matrix 3/9 (256,256): Alpha: 1.9280148669147024, Alpha Weighted: -1.0157094450807214, D: 0.10849097479410563\n",
      "2018-11-26 13:35:31,881 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.29655975103378296\n",
      "2018-11-26 13:35:31,885 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:34,215 INFO     Weight matrix 4/9 (256,256): Alpha: 2.1671858993889312, Alpha Weighted: -1.1008073688735516, D: 0.0925166491999031\n",
      "2018-11-26 13:35:34,219 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.27913644909858704\n",
      "2018-11-26 13:35:34,221 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:36,537 INFO     Weight matrix 5/9 (256,256): Alpha: 3.4177043548137815, Alpha Weighted: -1.3523616015334232, D: 0.09999999999999976\n",
      "2018-11-26 13:35:36,541 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.28974369168281555\n",
      "2018-11-26 13:35:36,544 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:38,863 INFO     Weight matrix 6/9 (256,256): Alpha: 2.3098942017004105, Alpha Weighted: -1.1721462770168956, D: 0.09193205536718185\n",
      "2018-11-26 13:35:38,867 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.2831743359565735\n",
      "2018-11-26 13:35:38,869 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:41,240 INFO     Weight matrix 7/9 (256,256): Alpha: 2.181630993033349, Alpha Weighted: -1.177921879864798, D: 0.11165284833788763\n",
      "2018-11-26 13:35:41,245 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.2947249710559845\n",
      "2018-11-26 13:35:41,248 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:43,580 INFO     Weight matrix 8/9 (256,256): Alpha: 2.0447813061843583, Alpha Weighted: -0.9506408016894952, D: 0.10235545661414558\n",
      "2018-11-26 13:35:43,583 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.3100013732910156\n",
      "2018-11-26 13:35:43,587 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:45,949 INFO     Weight matrix 9/9 (256,256): Alpha: 1.9813714472582384, Alpha Weighted: -0.9956320615868303, D: 0.10258836877951205\n",
      "2018-11-26 13:35:45,953 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.30095136165618896\n",
      "2018-11-26 13:35:45,955 INFO Layer 269: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:35:45,958 INFO Layer 269: Skipping (Layer not supported)\n",
      "2018-11-26 13:35:45,960 INFO Layer 270: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:35:45,964 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:35:45,966 INFO Layer 270: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:35:45,969 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:35:48,382 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.8340597471999374, Alpha Weighted: 0.043909984498447345, D: 0.1261739201597752\n",
      "2018-11-26 13:35:48,385 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6956610083580017\n",
      "2018-11-26 13:35:48,388 INFO Layer 271: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:35:48,390 INFO Layer 271: Skipping (Layer not supported)\n",
      "2018-11-26 13:35:48,393 INFO Layer 272: ReLU(inplace)\n",
      "2018-11-26 13:35:48,395 INFO Layer 272: Skipping (Layer not supported)\n",
      "2018-11-26 13:35:48,397 INFO Layer 273: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:35:48,400 INFO Layer 273: Skipping (Layer not supported)\n",
      "2018-11-26 13:35:48,402 INFO Layer 274: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:35:48,406 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:35:48,410 INFO Layer 274: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:35:48,412 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:35:50,907 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.0431723165965208, Alpha Weighted: -0.010059692346926032, D: 0.14732322639167433\n",
      "2018-11-26 13:35:50,910 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7633578181266785\n",
      "2018-11-26 13:35:50,912 INFO Layer 275: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:35:50,915 INFO Layer 275: Skipping (Layer not supported)\n",
      "2018-11-26 13:35:50,917 INFO Layer 276: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:35:50,922 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:35:50,927 INFO Layer 276: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:35:50,929 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:53,272 INFO     Weight matrix 1/9 (256,256): Alpha: 2.336095375777951, Alpha Weighted: -1.258459416314747, D: 0.0966210882901698\n",
      "2018-11-26 13:35:53,276 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.31753745675086975\n",
      "2018-11-26 13:35:53,280 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:55,654 INFO     Weight matrix 2/9 (256,256): Alpha: 2.334138259574039, Alpha Weighted: -1.1493569951339577, D: 0.1112550833398337\n",
      "2018-11-26 13:35:55,659 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3414738178253174\n",
      "2018-11-26 13:35:55,664 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:35:57,988 INFO     Weight matrix 3/9 (256,256): Alpha: 2.367658430452657, Alpha Weighted: -1.300465762407404, D: 0.10638492435684688\n",
      "2018-11-26 13:35:57,992 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.3241676986217499\n",
      "2018-11-26 13:35:57,995 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:00,315 INFO     Weight matrix 4/9 (256,256): Alpha: 2.3461679691541653, Alpha Weighted: -1.197699762115523, D: 0.08053248095947507\n",
      "2018-11-26 13:36:00,320 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.32146456837654114\n",
      "2018-11-26 13:36:00,322 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:02,713 INFO     Weight matrix 5/9 (256,256): Alpha: 3.6146778967507736, Alpha Weighted: -1.9851132277837573, D: 0.11058909624186553\n",
      "2018-11-26 13:36:02,716 INFO     Weight matrix 5/9 (256,256): Alpha 3.6146778967507736 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:36:02,719 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.33338624238967896\n",
      "2018-11-26 13:36:02,722 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:05,101 INFO     Weight matrix 6/9 (256,256): Alpha: 2.2916559381518793, Alpha Weighted: -1.1990756037100765, D: 0.10436010130676066\n",
      "2018-11-26 13:36:05,105 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.331357479095459\n",
      "2018-11-26 13:36:05,107 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:07,449 INFO     Weight matrix 7/9 (256,256): Alpha: 2.1586102407016745, Alpha Weighted: -1.2036799726135183, D: 0.10875951315704047\n",
      "2018-11-26 13:36:07,453 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3258669376373291\n",
      "2018-11-26 13:36:07,456 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:09,817 INFO     Weight matrix 8/9 (256,256): Alpha: 1.9643791050411235, Alpha Weighted: -0.9323818786597549, D: 0.1241501042337736\n",
      "2018-11-26 13:36:09,822 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.3564389646053314\n",
      "2018-11-26 13:36:09,825 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:12,189 INFO     Weight matrix 9/9 (256,256): Alpha: 1.9620574910718886, Alpha Weighted: -0.9949982700009109, D: 0.11041832290375486\n",
      "2018-11-26 13:36:12,193 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.3333340883255005\n",
      "2018-11-26 13:36:12,196 INFO Layer 277: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:36:12,198 INFO Layer 277: Skipping (Layer not supported)\n",
      "2018-11-26 13:36:12,200 INFO Layer 278: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:36:12,210 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:36:12,212 INFO Layer 278: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:36:12,217 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:36:14,656 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.465172624444918, Alpha Weighted: -0.178430367239698, D: 0.13680980532607157\n",
      "2018-11-26 13:36:14,659 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7285618185997009\n",
      "2018-11-26 13:36:14,662 INFO Layer 279: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:36:14,664 INFO Layer 279: Skipping (Layer not supported)\n",
      "2018-11-26 13:36:14,667 INFO Layer 280: ReLU(inplace)\n",
      "2018-11-26 13:36:14,669 INFO Layer 280: Skipping (Layer not supported)\n",
      "2018-11-26 13:36:14,673 INFO Layer 281: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:36:14,677 INFO Layer 281: Skipping (Layer not supported)\n",
      "2018-11-26 13:36:14,679 INFO Layer 282: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:36:14,683 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:36:14,685 INFO Layer 282: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:36:14,688 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:36:17,130 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.408289549897216, Alpha Weighted: 0.32181268102475746, D: 0.10432262259474712\n",
      "2018-11-26 13:36:17,133 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7358704209327698\n",
      "2018-11-26 13:36:17,136 INFO Layer 283: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:36:17,138 INFO Layer 283: Skipping (Layer not supported)\n",
      "2018-11-26 13:36:17,141 INFO Layer 284: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:36:17,146 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:36:17,149 INFO Layer 284: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:36:17,153 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:19,672 INFO     Weight matrix 1/9 (256,256): Alpha: 2.3277249762047667, Alpha Weighted: -1.0298837793190305, D: 0.09385639872808577\n",
      "2018-11-26 13:36:19,677 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.300698846578598\n",
      "2018-11-26 13:36:19,680 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:22,301 INFO     Weight matrix 2/9 (256,256): Alpha: 2.1782645040155955, Alpha Weighted: -1.0292589234913714, D: 0.09020251821971431\n",
      "2018-11-26 13:36:22,305 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.307706743478775\n",
      "2018-11-26 13:36:22,308 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:24,646 INFO     Weight matrix 3/9 (256,256): Alpha: 2.127063394390707, Alpha Weighted: -0.9432327680837072, D: 0.10399507790895135\n",
      "2018-11-26 13:36:24,650 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.31000229716300964\n",
      "2018-11-26 13:36:24,653 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:27,111 INFO     Weight matrix 4/9 (256,256): Alpha: 2.1789101167048575, Alpha Weighted: -1.152984204631388, D: 0.08090461842975372\n",
      "2018-11-26 13:36:27,116 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.28787705302238464\n",
      "2018-11-26 13:36:27,119 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:29,448 INFO     Weight matrix 5/9 (256,256): Alpha: 2.602579704836497, Alpha Weighted: -1.3727488803161036, D: 0.10277419236419177\n",
      "2018-11-26 13:36:29,452 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.2918441891670227\n",
      "2018-11-26 13:36:29,455 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:31,815 INFO     Weight matrix 6/9 (256,256): Alpha: 2.222228602560989, Alpha Weighted: -1.1620850284675621, D: 0.09744192738767671\n",
      "2018-11-26 13:36:31,820 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.2970074713230133\n",
      "2018-11-26 13:36:31,825 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:34,142 INFO     Weight matrix 7/9 (256,256): Alpha: 2.051487414952633, Alpha Weighted: -0.9528438418019299, D: 0.09795293440794373\n",
      "2018-11-26 13:36:34,147 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3135126531124115\n",
      "2018-11-26 13:36:34,150 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:36,470 INFO     Weight matrix 8/9 (256,256): Alpha: 2.126119538861896, Alpha Weighted: -1.083029727217298, D: 0.09474163353052922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:36:36,475 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.31239232420921326\n",
      "2018-11-26 13:36:36,479 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:38,819 INFO     Weight matrix 9/9 (256,256): Alpha: 2.119069634827028, Alpha Weighted: -0.9106678292993619, D: 0.10073472789749244\n",
      "2018-11-26 13:36:38,824 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.32095399498939514\n",
      "2018-11-26 13:36:38,826 INFO Layer 285: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:36:38,830 INFO Layer 285: Skipping (Layer not supported)\n",
      "2018-11-26 13:36:38,832 INFO Layer 286: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:36:38,838 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:36:38,841 INFO Layer 286: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:36:38,844 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:36:41,304 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.8652643023907873, Alpha Weighted: 0.022348438991179373, D: 0.1353643837918625\n",
      "2018-11-26 13:36:41,307 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7043207883834839\n",
      "2018-11-26 13:36:41,310 INFO Layer 287: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:36:41,313 INFO Layer 287: Skipping (Layer not supported)\n",
      "2018-11-26 13:36:41,318 INFO Layer 288: ReLU(inplace)\n",
      "2018-11-26 13:36:41,321 INFO Layer 288: Skipping (Layer not supported)\n",
      "2018-11-26 13:36:41,325 INFO Layer 289: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:36:41,329 INFO Layer 289: Skipping (Layer not supported)\n",
      "2018-11-26 13:36:41,333 INFO Layer 290: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:36:41,337 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:36:41,340 INFO Layer 290: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:36:41,342 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:36:43,814 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.1075910077661755, Alpha Weighted: 0.3494338892088883, D: 0.11347941485695368\n",
      "2018-11-26 13:36:43,817 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7848787307739258\n",
      "2018-11-26 13:36:43,822 INFO Layer 291: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:36:43,825 INFO Layer 291: Skipping (Layer not supported)\n",
      "2018-11-26 13:36:43,828 INFO Layer 292: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:36:43,838 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:36:43,841 INFO Layer 292: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:36:43,844 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:46,180 INFO     Weight matrix 1/9 (256,256): Alpha: 2.5658222241471442, Alpha Weighted: -1.3018904888568765, D: 0.094223030058186\n",
      "2018-11-26 13:36:46,185 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3310953378677368\n",
      "2018-11-26 13:36:46,188 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:48,523 INFO     Weight matrix 2/9 (256,256): Alpha: 2.290919693934472, Alpha Weighted: -1.0189613881035582, D: 0.10053746282700121\n",
      "2018-11-26 13:36:48,527 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.36397454142570496\n",
      "2018-11-26 13:36:48,532 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:50,865 INFO     Weight matrix 3/9 (256,256): Alpha: 2.3163908078119837, Alpha Weighted: -1.097628093752463, D: 0.08751827691603153\n",
      "2018-11-26 13:36:50,870 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.34273481369018555\n",
      "2018-11-26 13:36:50,872 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:53,195 INFO     Weight matrix 4/9 (256,256): Alpha: 2.242023690645486, Alpha Weighted: -0.9287236050919482, D: 0.08254530703709761\n",
      "2018-11-26 13:36:53,199 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.35606062412261963\n",
      "2018-11-26 13:36:53,202 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:55,554 INFO     Weight matrix 5/9 (256,256): Alpha: 2.4651262991914713, Alpha Weighted: -0.8799479539355759, D: 0.08543908245090337\n",
      "2018-11-26 13:36:55,558 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.38625866174697876\n",
      "2018-11-26 13:36:55,560 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:36:57,886 INFO     Weight matrix 6/9 (256,256): Alpha: 2.2170490325744794, Alpha Weighted: -0.83934694987136, D: 0.0805180573195019\n",
      "2018-11-26 13:36:57,890 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.3699241280555725\n",
      "2018-11-26 13:36:57,892 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:00,228 INFO     Weight matrix 7/9 (256,256): Alpha: 2.2148629077701445, Alpha Weighted: -1.031465551785745, D: 0.10384565410713537\n",
      "2018-11-26 13:37:00,234 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.34345313906669617\n",
      "2018-11-26 13:37:00,238 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:02,657 INFO     Weight matrix 8/9 (256,256): Alpha: 2.3504484873090186, Alpha Weighted: -1.0142975087669135, D: 0.10063363410758447\n",
      "2018-11-26 13:37:02,663 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.37031838297843933\n",
      "2018-11-26 13:37:02,665 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:05,009 INFO     Weight matrix 9/9 (256,256): Alpha: 2.4065124047515405, Alpha Weighted: -1.058922397761967, D: 0.09487787196553515\n",
      "2018-11-26 13:37:05,014 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.35494738817214966\n",
      "2018-11-26 13:37:05,017 INFO Layer 293: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:37:05,020 INFO Layer 293: Skipping (Layer not supported)\n",
      "2018-11-26 13:37:05,023 INFO Layer 294: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:37:05,026 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:37:05,029 INFO Layer 294: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:37:05,032 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:37:07,486 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.9313619977651189, Alpha Weighted: -0.04730132302726143, D: 0.1292927402250877\n",
      "2018-11-26 13:37:07,489 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7364515066146851\n",
      "2018-11-26 13:37:07,496 INFO Layer 295: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:37:07,498 INFO Layer 295: Skipping (Layer not supported)\n",
      "2018-11-26 13:37:07,500 INFO Layer 296: ReLU(inplace)\n",
      "2018-11-26 13:37:07,502 INFO Layer 296: Skipping (Layer not supported)\n",
      "2018-11-26 13:37:07,505 INFO Layer 297: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:37:07,508 INFO Layer 297: Skipping (Layer not supported)\n",
      "2018-11-26 13:37:07,510 INFO Layer 298: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:37:07,521 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:37:07,524 INFO Layer 298: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:37:07,527 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:37:09,961 INFO     Weight matrix 1/1 (256,1024): Alpha: 3.4706203116805936, Alpha Weighted: 0.10739093478511834, D: 0.11424121718390684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:37:09,964 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7697859406471252\n",
      "2018-11-26 13:37:09,968 INFO Layer 299: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:37:09,971 INFO Layer 299: Skipping (Layer not supported)\n",
      "2018-11-26 13:37:09,974 INFO Layer 300: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:37:09,982 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:37:09,985 INFO Layer 300: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:37:09,987 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:12,368 INFO     Weight matrix 1/9 (256,256): Alpha: 2.1708019775323155, Alpha Weighted: -1.116962286037862, D: 0.08406953972596548\n",
      "2018-11-26 13:37:12,372 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3200967609882355\n",
      "2018-11-26 13:37:12,375 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:14,715 INFO     Weight matrix 2/9 (256,256): Alpha: 2.3444076215697587, Alpha Weighted: -1.2893599405224774, D: 0.09885453450581261\n",
      "2018-11-26 13:37:14,719 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3237698972225189\n",
      "2018-11-26 13:37:14,722 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:17,030 INFO     Weight matrix 3/9 (256,256): Alpha: 2.2795439709845153, Alpha Weighted: -1.1467881132916313, D: 0.09058295806314187\n",
      "2018-11-26 13:37:17,034 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.3308679759502411\n",
      "2018-11-26 13:37:17,041 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:19,369 INFO     Weight matrix 4/9 (256,256): Alpha: 2.3169210500707695, Alpha Weighted: -1.4872600773369196, D: 0.10442448995324338\n",
      "2018-11-26 13:37:19,373 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.30284908413887024\n",
      "2018-11-26 13:37:19,377 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:21,704 INFO     Weight matrix 5/9 (256,256): Alpha: 1.9626627233417056, Alpha Weighted: -0.8280197444478243, D: 0.09831477838084757\n",
      "2018-11-26 13:37:21,708 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.3486872613430023\n",
      "2018-11-26 13:37:21,711 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:24,060 INFO     Weight matrix 6/9 (256,256): Alpha: 2.4614609439432504, Alpha Weighted: -1.4612133844774293, D: 0.10737999490836286\n",
      "2018-11-26 13:37:24,064 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.3141953945159912\n",
      "2018-11-26 13:37:24,067 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:26,397 INFO     Weight matrix 7/9 (256,256): Alpha: 2.1261702601696157, Alpha Weighted: -1.0627264852514648, D: 0.09760823287926718\n",
      "2018-11-26 13:37:26,401 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3232012987136841\n",
      "2018-11-26 13:37:26,405 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:28,729 INFO     Weight matrix 8/9 (256,256): Alpha: 2.0407188315836775, Alpha Weighted: -1.2293369404323988, D: 0.11776999605353766\n",
      "2018-11-26 13:37:28,733 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.32846006751060486\n",
      "2018-11-26 13:37:28,738 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:31,186 INFO     Weight matrix 9/9 (256,256): Alpha: 2.3391351530029914, Alpha Weighted: -1.1208877152316805, D: 0.09168416914770705\n",
      "2018-11-26 13:37:31,190 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.33049100637435913\n",
      "2018-11-26 13:37:31,192 INFO Layer 301: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:37:31,195 INFO Layer 301: Skipping (Layer not supported)\n",
      "2018-11-26 13:37:31,199 INFO Layer 302: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:37:31,204 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:37:31,206 INFO Layer 302: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:37:31,211 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:37:33,621 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.1877402367038217, Alpha Weighted: -0.09706549328150052, D: 0.14127351207272143\n",
      "2018-11-26 13:37:33,624 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7068378925323486\n",
      "2018-11-26 13:37:33,629 INFO Layer 303: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:37:33,632 INFO Layer 303: Skipping (Layer not supported)\n",
      "2018-11-26 13:37:33,635 INFO Layer 304: ReLU(inplace)\n",
      "2018-11-26 13:37:33,639 INFO Layer 304: Skipping (Layer not supported)\n",
      "2018-11-26 13:37:33,641 INFO Layer 305: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:37:33,644 INFO Layer 305: Skipping (Layer not supported)\n",
      "2018-11-26 13:37:33,647 INFO Layer 306: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:37:33,652 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:37:33,655 INFO Layer 306: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:37:33,658 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:37:36,096 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.09734280733449, Alpha Weighted: 0.04355015732071627, D: 0.13669798152381418\n",
      "2018-11-26 13:37:36,100 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7849581837654114\n",
      "2018-11-26 13:37:36,102 INFO Layer 307: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:37:36,105 INFO Layer 307: Skipping (Layer not supported)\n",
      "2018-11-26 13:37:36,107 INFO Layer 308: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:37:36,113 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:37:36,115 INFO Layer 308: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:37:36,118 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:38,442 INFO     Weight matrix 1/9 (256,256): Alpha: 2.36966989038969, Alpha Weighted: -1.0149110952451577, D: 0.09154339750097812\n",
      "2018-11-26 13:37:38,447 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3233800232410431\n",
      "2018-11-26 13:37:38,449 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:40,765 INFO     Weight matrix 2/9 (256,256): Alpha: 2.457500124125014, Alpha Weighted: -1.321591161931105, D: 0.10735144085445036\n",
      "2018-11-26 13:37:40,770 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.31032314896583557\n",
      "2018-11-26 13:37:40,772 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:43,089 INFO     Weight matrix 3/9 (256,256): Alpha: 2.2560886872375905, Alpha Weighted: -0.986713509597032, D: 0.09350825924068534\n",
      "2018-11-26 13:37:43,094 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.3311523497104645\n",
      "2018-11-26 13:37:43,097 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:45,404 INFO     Weight matrix 4/9 (256,256): Alpha: 2.410078225633451, Alpha Weighted: -1.4735242890003482, D: 0.10663245885294448\n",
      "2018-11-26 13:37:45,409 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.2963259518146515\n",
      "2018-11-26 13:37:45,414 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:47,716 INFO     Weight matrix 5/9 (256,256): Alpha: 2.1953924988120717, Alpha Weighted: -0.8451713934691188, D: 0.09769737625877217\n",
      "2018-11-26 13:37:47,721 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.31975221633911133\n",
      "2018-11-26 13:37:47,724 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:50,020 INFO     Weight matrix 6/9 (256,256): Alpha: 2.070963890042501, Alpha Weighted: -1.2249991789902923, D: 0.10718947560985215\n",
      "2018-11-26 13:37:50,024 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.30175870656967163\n",
      "2018-11-26 13:37:50,026 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:52,367 INFO     Weight matrix 7/9 (256,256): Alpha: 2.4153103413004455, Alpha Weighted: -0.9712748127269405, D: 0.10853720128407396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:37:52,371 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.32943856716156006\n",
      "2018-11-26 13:37:52,374 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:54,693 INFO     Weight matrix 8/9 (256,256): Alpha: 1.9558688996725218, Alpha Weighted: -1.055769382264052, D: 0.11290668576748808\n",
      "2018-11-26 13:37:54,698 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.31499701738357544\n",
      "2018-11-26 13:37:54,700 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:37:57,012 INFO     Weight matrix 9/9 (256,256): Alpha: 2.081725570297408, Alpha Weighted: -0.8422131717492856, D: 0.10418877073458377\n",
      "2018-11-26 13:37:57,017 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.3365161120891571\n",
      "2018-11-26 13:37:57,019 INFO Layer 309: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:37:57,025 INFO Layer 309: Skipping (Layer not supported)\n",
      "2018-11-26 13:37:57,028 INFO Layer 310: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:37:57,031 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:37:57,034 INFO Layer 310: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:37:57,037 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:37:59,431 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.6836034903430557, Alpha Weighted: 0.2921080066928639, D: 0.09321173983638636\n",
      "2018-11-26 13:37:59,434 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6974254250526428\n",
      "2018-11-26 13:37:59,437 INFO Layer 311: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:37:59,439 INFO Layer 311: Skipping (Layer not supported)\n",
      "2018-11-26 13:37:59,441 INFO Layer 312: ReLU(inplace)\n",
      "2018-11-26 13:37:59,444 INFO Layer 312: Skipping (Layer not supported)\n",
      "2018-11-26 13:37:59,446 INFO Layer 313: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:37:59,448 INFO Layer 313: Skipping (Layer not supported)\n",
      "2018-11-26 13:37:59,451 INFO Layer 314: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:37:59,455 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:37:59,457 INFO Layer 314: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:37:59,460 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:38:01,921 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.7323627907387964, Alpha Weighted: 0.18075960708137526, D: 0.11119700645221309\n",
      "2018-11-26 13:38:01,924 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7536705136299133\n",
      "2018-11-26 13:38:01,926 INFO Layer 315: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:38:01,929 INFO Layer 315: Skipping (Layer not supported)\n",
      "2018-11-26 13:38:01,932 INFO Layer 316: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:38:01,942 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:38:01,945 INFO Layer 316: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:38:01,948 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:04,278 INFO     Weight matrix 1/9 (256,256): Alpha: 1.994950657614883, Alpha Weighted: -0.7745127656738926, D: 0.09496264604594956\n",
      "2018-11-26 13:38:04,283 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3136378526687622\n",
      "2018-11-26 13:38:04,285 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:06,616 INFO     Weight matrix 2/9 (256,256): Alpha: 1.9277223690687009, Alpha Weighted: -1.031182261340349, D: 0.10222265337341324\n",
      "2018-11-26 13:38:06,620 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3066309988498688\n",
      "2018-11-26 13:38:06,623 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:08,977 INFO     Weight matrix 3/9 (256,256): Alpha: 2.406855633990353, Alpha Weighted: -0.8711917626812498, D: 0.10595653565994168\n",
      "2018-11-26 13:38:08,981 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.3199622631072998\n",
      "2018-11-26 13:38:08,984 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:11,365 INFO     Weight matrix 4/9 (256,256): Alpha: 1.942114673277079, Alpha Weighted: -1.0590441738797411, D: 0.10592428485421834\n",
      "2018-11-26 13:38:11,369 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.2916516065597534\n",
      "2018-11-26 13:38:11,372 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:13,696 INFO     Weight matrix 5/9 (256,256): Alpha: 3.5530902913705766, Alpha Weighted: -1.4052259415264627, D: 0.10644488291880883\n",
      "2018-11-26 13:38:13,698 INFO     Weight matrix 5/9 (256,256): Alpha 3.5530902913705766 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:38:13,704 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.3177492320537567\n",
      "2018-11-26 13:38:13,707 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:16,082 INFO     Weight matrix 6/9 (256,256): Alpha: 2.11637330760085, Alpha Weighted: -1.123360575839208, D: 0.10400527941275184\n",
      "2018-11-26 13:38:16,086 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.2979333996772766\n",
      "2018-11-26 13:38:16,090 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:18,514 INFO     Weight matrix 7/9 (256,256): Alpha: 2.1303219661399773, Alpha Weighted: -0.8388313779808374, D: 0.08669423463763731\n",
      "2018-11-26 13:38:18,518 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3103311061859131\n",
      "2018-11-26 13:38:18,521 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:21,143 INFO     Weight matrix 8/9 (256,256): Alpha: 2.040164475706624, Alpha Weighted: -1.0813910845583605, D: 0.10820086979723603\n",
      "2018-11-26 13:38:21,148 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.30244702100753784\n",
      "2018-11-26 13:38:21,151 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:23,598 INFO     Weight matrix 9/9 (256,256): Alpha: 2.25100968374942, Alpha Weighted: -0.7789449825740637, D: 0.1013559732741966\n",
      "2018-11-26 13:38:23,602 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.3179629445075989\n",
      "2018-11-26 13:38:23,605 INFO Layer 317: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:38:23,608 INFO Layer 317: Skipping (Layer not supported)\n",
      "2018-11-26 13:38:23,611 INFO Layer 318: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:38:23,616 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:38:23,618 INFO Layer 318: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:38:23,624 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:38:26,054 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.8550303651332525, Alpha Weighted: 0.0384138345790712, D: 0.11970710152558706\n",
      "2018-11-26 13:38:26,057 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6846080422401428\n",
      "2018-11-26 13:38:26,059 INFO Layer 319: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:38:26,062 INFO Layer 319: Skipping (Layer not supported)\n",
      "2018-11-26 13:38:26,065 INFO Layer 320: ReLU(inplace)\n",
      "2018-11-26 13:38:26,067 INFO Layer 320: Skipping (Layer not supported)\n",
      "2018-11-26 13:38:26,069 INFO Layer 321: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:38:26,073 INFO Layer 321: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:38:26,075 INFO Layer 322: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:38:26,080 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:38:26,082 INFO Layer 322: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:38:26,085 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:38:28,515 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.9434497396398953, Alpha Weighted: 0.06035152753861906, D: 0.12703284493582673\n",
      "2018-11-26 13:38:28,517 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7549086213111877\n",
      "2018-11-26 13:38:28,522 INFO Layer 323: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:38:28,525 INFO Layer 323: Skipping (Layer not supported)\n",
      "2018-11-26 13:38:28,528 INFO Layer 324: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:38:28,534 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:38:28,536 INFO Layer 324: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:38:28,539 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:30,885 INFO     Weight matrix 1/9 (256,256): Alpha: 2.256487335036926, Alpha Weighted: -0.9729606158802249, D: 0.09464400906710058\n",
      "2018-11-26 13:38:30,890 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3094506859779358\n",
      "2018-11-26 13:38:30,892 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:33,226 INFO     Weight matrix 2/9 (256,256): Alpha: 2.518265216154983, Alpha Weighted: -1.5204245148818567, D: 0.10915116306485068\n",
      "2018-11-26 13:38:33,230 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.2931881546974182\n",
      "2018-11-26 13:38:33,233 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:35,529 INFO     Weight matrix 3/9 (256,256): Alpha: 2.0800365079150387, Alpha Weighted: -0.8588567462315448, D: 0.08666562657417454\n",
      "2018-11-26 13:38:35,534 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.3138696849346161\n",
      "2018-11-26 13:38:35,537 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:37,852 INFO     Weight matrix 4/9 (256,256): Alpha: 2.2284271282236183, Alpha Weighted: -1.3422194882023075, D: 0.10063427833609595\n",
      "2018-11-26 13:38:37,858 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.2858026921749115\n",
      "2018-11-26 13:38:37,860 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:40,181 INFO     Weight matrix 5/9 (256,256): Alpha: 1.8540292848949076, Alpha Weighted: -1.1934818663297437, D: 0.1234317154344518\n",
      "2018-11-26 13:38:40,187 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.29225990176200867\n",
      "2018-11-26 13:38:40,190 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:42,507 INFO     Weight matrix 6/9 (256,256): Alpha: 2.1845305347520956, Alpha Weighted: -1.3002851831753839, D: 0.08851015194023681\n",
      "2018-11-26 13:38:42,512 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.28743889927864075\n",
      "2018-11-26 13:38:42,516 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:44,838 INFO     Weight matrix 7/9 (256,256): Alpha: 2.18745195608955, Alpha Weighted: -0.9528945832082015, D: 0.10853559138259228\n",
      "2018-11-26 13:38:44,843 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.31174036860466003\n",
      "2018-11-26 13:38:44,846 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:47,170 INFO     Weight matrix 8/9 (256,256): Alpha: 2.2455108832417174, Alpha Weighted: -1.3115076287604532, D: 0.11575129602150003\n",
      "2018-11-26 13:38:47,174 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.3037661910057068\n",
      "2018-11-26 13:38:47,176 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:49,481 INFO     Weight matrix 9/9 (256,256): Alpha: 2.324026778388971, Alpha Weighted: -0.9660107051940711, D: 0.09693643966403176\n",
      "2018-11-26 13:38:49,486 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.3147639036178589\n",
      "2018-11-26 13:38:49,489 INFO Layer 325: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:38:49,492 INFO Layer 325: Skipping (Layer not supported)\n",
      "2018-11-26 13:38:49,495 INFO Layer 326: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:38:49,503 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:38:49,505 INFO Layer 326: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:38:49,507 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:38:51,923 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.9556801395591386, Alpha Weighted: -0.19166491039445632, D: 0.1317283262830623\n",
      "2018-11-26 13:38:51,927 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.6778208017349243\n",
      "2018-11-26 13:38:51,930 INFO Layer 327: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:38:51,933 INFO Layer 327: Skipping (Layer not supported)\n",
      "2018-11-26 13:38:51,936 INFO Layer 328: ReLU(inplace)\n",
      "2018-11-26 13:38:51,938 INFO Layer 328: Skipping (Layer not supported)\n",
      "2018-11-26 13:38:51,941 INFO Layer 329: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:38:51,943 INFO Layer 329: Skipping (Layer not supported)\n",
      "2018-11-26 13:38:51,946 INFO Layer 330: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:38:51,950 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:38:51,952 INFO Layer 330: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:38:51,955 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:38:54,380 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.9656835054563078, Alpha Weighted: 0.06694178049496388, D: 0.12286344482602218\n",
      "2018-11-26 13:38:54,385 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7726577520370483\n",
      "2018-11-26 13:38:54,387 INFO Layer 331: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:38:54,389 INFO Layer 331: Skipping (Layer not supported)\n",
      "2018-11-26 13:38:54,392 INFO Layer 332: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:38:54,398 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:38:54,404 INFO Layer 332: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:38:54,406 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:56,761 INFO     Weight matrix 1/9 (256,256): Alpha: 2.0681668306068235, Alpha Weighted: -0.779931395172024, D: 0.09781625974275177\n",
      "2018-11-26 13:38:56,766 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3432174623012543\n",
      "2018-11-26 13:38:56,768 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:38:59,082 INFO     Weight matrix 2/9 (256,256): Alpha: 2.0461577545110066, Alpha Weighted: -1.2579448097427877, D: 0.11262576770321975\n",
      "2018-11-26 13:38:59,086 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3050466775894165\n",
      "2018-11-26 13:38:59,090 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:01,438 INFO     Weight matrix 3/9 (256,256): Alpha: 1.93874804589348, Alpha Weighted: -0.7089941061405977, D: 0.10235751629772488\n",
      "2018-11-26 13:39:01,442 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.3507935404777527\n",
      "2018-11-26 13:39:01,445 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:03,758 INFO     Weight matrix 4/9 (256,256): Alpha: 2.001218369369331, Alpha Weighted: -0.9217152944212593, D: 0.10361261411778167\n",
      "2018-11-26 13:39:03,761 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.34632381796836853\n",
      "2018-11-26 13:39:03,764 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:06,112 INFO     Weight matrix 5/9 (256,256): Alpha: 2.3033305062024247, Alpha Weighted: -1.091921799852975, D: 0.11892286699102128\n",
      "2018-11-26 13:39:06,116 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.32522088289260864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:39:06,119 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:08,461 INFO     Weight matrix 6/9 (256,256): Alpha: 1.9441993307214442, Alpha Weighted: -0.8972079321216465, D: 0.09420074037822124\n",
      "2018-11-26 13:39:08,466 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.3517848551273346\n",
      "2018-11-26 13:39:08,469 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:10,782 INFO     Weight matrix 7/9 (256,256): Alpha: 2.0405743988048854, Alpha Weighted: -0.7953677607948728, D: 0.09926433356219388\n",
      "2018-11-26 13:39:10,787 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3510674238204956\n",
      "2018-11-26 13:39:10,790 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:13,120 INFO     Weight matrix 8/9 (256,256): Alpha: 2.2974883431752504, Alpha Weighted: -1.324930104046708, D: 0.11269425288936141\n",
      "2018-11-26 13:39:13,124 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.31786638498306274\n",
      "2018-11-26 13:39:13,128 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:15,467 INFO     Weight matrix 9/9 (256,256): Alpha: 1.9788410042958366, Alpha Weighted: -0.7857768301292718, D: 0.10631601801328394\n",
      "2018-11-26 13:39:15,472 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.3564631938934326\n",
      "2018-11-26 13:39:15,475 INFO Layer 333: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:39:15,478 INFO Layer 333: Skipping (Layer not supported)\n",
      "2018-11-26 13:39:15,480 INFO Layer 334: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:39:15,485 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:39:15,488 INFO Layer 334: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:39:15,491 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:39:17,891 INFO     Weight matrix 1/1 (256,1024): Alpha: 1.7536722392464759, Alpha Weighted: 0.005448984910623735, D: 0.14077821184033695\n",
      "2018-11-26 13:39:17,894 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7365842461585999\n",
      "2018-11-26 13:39:17,897 INFO Layer 335: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:39:17,899 INFO Layer 335: Skipping (Layer not supported)\n",
      "2018-11-26 13:39:17,902 INFO Layer 336: ReLU(inplace)\n",
      "2018-11-26 13:39:17,905 INFO Layer 336: Skipping (Layer not supported)\n",
      "2018-11-26 13:39:17,907 INFO Layer 337: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:39:17,910 INFO Layer 337: Skipping (Layer not supported)\n",
      "2018-11-26 13:39:17,912 INFO Layer 338: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:39:17,916 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:39:17,928 INFO Layer 338: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:39:17,931 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:39:20,400 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.000358188534436, Alpha Weighted: 0.36165410334832954, D: 0.10479790713010007\n",
      "2018-11-26 13:39:20,403 INFO     Weight matrix 1/1 (256,1024): Alpha 5.000358188534436 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:39:20,406 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.830201268196106\n",
      "2018-11-26 13:39:20,408 INFO Layer 339: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:39:20,411 INFO Layer 339: Skipping (Layer not supported)\n",
      "2018-11-26 13:39:20,413 INFO Layer 340: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:39:20,418 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:39:20,420 INFO Layer 340: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:39:20,423 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:22,792 INFO     Weight matrix 1/9 (256,256): Alpha: 2.3030649171517314, Alpha Weighted: -1.0096287930130143, D: 0.10351766651977412\n",
      "2018-11-26 13:39:22,797 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.36135801672935486\n",
      "2018-11-26 13:39:22,799 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:25,146 INFO     Weight matrix 2/9 (256,256): Alpha: 2.325774469672643, Alpha Weighted: -1.3624356161314297, D: 0.12768566536529902\n",
      "2018-11-26 13:39:25,151 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3917856514453888\n",
      "2018-11-26 13:39:25,154 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:27,506 INFO     Weight matrix 3/9 (256,256): Alpha: 2.3547909973683625, Alpha Weighted: -1.070529407499458, D: 0.09686983877377242\n",
      "2018-11-26 13:39:27,510 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.3693417012691498\n",
      "2018-11-26 13:39:27,512 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:29,886 INFO     Weight matrix 4/9 (256,256): Alpha: 3.0601569214049578, Alpha Weighted: -2.0751326877738783, D: 0.09377406243955122\n",
      "2018-11-26 13:39:29,892 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3170003890991211\n",
      "2018-11-26 13:39:29,895 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:32,279 INFO     Weight matrix 5/9 (256,256): Alpha: 3.6247689189567116, Alpha Weighted: -1.3471005752263336, D: 0.07668261718506147\n",
      "2018-11-26 13:39:32,282 INFO     Weight matrix 5/9 (256,256): Alpha 3.6247689189567116 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:39:32,288 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.38676735758781433\n",
      "2018-11-26 13:39:32,290 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:34,671 INFO     Weight matrix 6/9 (256,256): Alpha: 3.3435357753892885, Alpha Weighted: -2.229499423255189, D: 0.09208964173467282\n",
      "2018-11-26 13:39:34,674 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.32957926392555237\n",
      "2018-11-26 13:39:34,677 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:37,015 INFO     Weight matrix 7/9 (256,256): Alpha: 2.5755447499228747, Alpha Weighted: -1.1356788746025228, D: 0.09306003249701655\n",
      "2018-11-26 13:39:37,019 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3685499429702759\n",
      "2018-11-26 13:39:37,021 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:39,355 INFO     Weight matrix 8/9 (256,256): Alpha: 2.0535281587886676, Alpha Weighted: -1.15261373466158, D: 0.13535190065189984\n",
      "2018-11-26 13:39:39,359 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.39911016821861267\n",
      "2018-11-26 13:39:39,362 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:41,708 INFO     Weight matrix 9/9 (256,256): Alpha: 2.9712656266159803, Alpha Weighted: -1.3520178146120578, D: 0.08815263954449874\n",
      "2018-11-26 13:39:41,712 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.37689027190208435\n",
      "2018-11-26 13:39:41,715 INFO Layer 341: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:39:41,717 INFO Layer 341: Skipping (Layer not supported)\n",
      "2018-11-26 13:39:41,720 INFO Layer 342: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:39:41,724 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:39:41,726 INFO Layer 342: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:39:41,729 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:39:44,177 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.373003710995841, Alpha Weighted: 0.4876243935610582, D: 0.10306572378938572\n",
      "2018-11-26 13:39:44,179 INFO     Weight matrix 1/1 (256,1024): Alpha 5.373003710995841 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:39:44,183 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7659279704093933\n",
      "2018-11-26 13:39:44,185 INFO Layer 343: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:39:44,189 INFO Layer 343: Skipping (Layer not supported)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:39:44,192 INFO Layer 344: ReLU(inplace)\n",
      "2018-11-26 13:39:44,194 INFO Layer 344: Skipping (Layer not supported)\n",
      "2018-11-26 13:39:44,197 INFO Layer 345: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:39:44,202 INFO Layer 345: Skipping (Layer not supported)\n",
      "2018-11-26 13:39:44,205 INFO Layer 346: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:39:44,208 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:39:44,211 INFO Layer 346: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:39:44,214 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:39:46,683 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.5912870921674633, Alpha Weighted: 0.5367403229882626, D: 0.10415695792290469\n",
      "2018-11-26 13:39:46,686 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8567227125167847\n",
      "2018-11-26 13:39:46,689 INFO Layer 347: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:39:46,691 INFO Layer 347: Skipping (Layer not supported)\n",
      "2018-11-26 13:39:46,694 INFO Layer 348: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:39:46,699 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:39:46,702 INFO Layer 348: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:39:46,705 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:49,168 INFO     Weight matrix 1/9 (256,256): Alpha: 2.883394480701596, Alpha Weighted: -1.3241310380361315, D: 0.07341807707937498\n",
      "2018-11-26 13:39:49,173 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3390604853630066\n",
      "2018-11-26 13:39:49,176 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:51,657 INFO     Weight matrix 2/9 (256,256): Alpha: 2.796458254206665, Alpha Weighted: -1.5905458709190154, D: 0.12557387968590744\n",
      "2018-11-26 13:39:51,662 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.38332509994506836\n",
      "2018-11-26 13:39:51,665 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:54,114 INFO     Weight matrix 3/9 (256,256): Alpha: 2.7785445884683013, Alpha Weighted: -1.1758169193044827, D: 0.07150545498315397\n",
      "2018-11-26 13:39:54,119 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.3530733287334442\n",
      "2018-11-26 13:39:54,121 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:56,476 INFO     Weight matrix 4/9 (256,256): Alpha: 2.921913760992017, Alpha Weighted: -1.9204249952394141, D: 0.1078439240368661\n",
      "2018-11-26 13:39:56,483 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.33685657382011414\n",
      "2018-11-26 13:39:56,486 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:39:58,851 INFO     Weight matrix 5/9 (256,256): Alpha: 1.9614193608948514, Alpha Weighted: -0.4278423153047678, D: 0.10750748891351192\n",
      "2018-11-26 13:39:58,855 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.4849810302257538\n",
      "2018-11-26 13:39:58,858 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:01,334 INFO     Weight matrix 6/9 (256,256): Alpha: 2.322195612593239, Alpha Weighted: -1.497802976534037, D: 0.13449096730053606\n",
      "2018-11-26 13:40:01,339 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.35970067977905273\n",
      "2018-11-26 13:40:01,343 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:03,707 INFO     Weight matrix 7/9 (256,256): Alpha: 3.0175924462177477, Alpha Weighted: -1.3350393105771141, D: 0.07577399006640617\n",
      "2018-11-26 13:40:03,710 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.34962788224220276\n",
      "2018-11-26 13:40:03,713 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:06,065 INFO     Weight matrix 8/9 (256,256): Alpha: 2.210289041037721, Alpha Weighted: -1.2137471373469686, D: 0.1365127169935113\n",
      "2018-11-26 13:40:06,070 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.40649259090423584\n",
      "2018-11-26 13:40:06,073 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:08,439 INFO     Weight matrix 9/9 (256,256): Alpha: 3.3195972589750826, Alpha Weighted: -1.3418561613148723, D: 0.08423355910820918\n",
      "2018-11-26 13:40:08,443 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.3664288818836212\n",
      "2018-11-26 13:40:08,446 INFO Layer 349: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:40:08,449 INFO Layer 349: Skipping (Layer not supported)\n",
      "2018-11-26 13:40:08,452 INFO Layer 350: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:40:08,457 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:40:08,459 INFO Layer 350: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:40:08,461 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:40:11,123 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.8045347378939995, Alpha Weighted: 0.2938255178382826, D: 0.12012226962492478\n",
      "2018-11-26 13:40:11,126 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.795983612537384\n",
      "2018-11-26 13:40:11,129 INFO Layer 351: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:40:11,132 INFO Layer 351: Skipping (Layer not supported)\n",
      "2018-11-26 13:40:11,135 INFO Layer 352: ReLU(inplace)\n",
      "2018-11-26 13:40:11,137 INFO Layer 352: Skipping (Layer not supported)\n",
      "2018-11-26 13:40:11,141 INFO Layer 353: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:40:11,147 INFO Layer 353: Skipping (Layer not supported)\n",
      "2018-11-26 13:40:11,150 INFO Layer 354: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:40:11,159 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:40:11,162 INFO Layer 354: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:40:11,166 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:40:13,778 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.785703277149398, Alpha Weighted: 0.5424206557296644, D: 0.09562012406439224\n",
      "2018-11-26 13:40:13,780 INFO     Weight matrix 1/1 (256,1024): Alpha 4.785703277149398 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:40:13,785 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8585711717605591\n",
      "2018-11-26 13:40:13,789 INFO Layer 355: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:40:13,793 INFO Layer 355: Skipping (Layer not supported)\n",
      "2018-11-26 13:40:13,796 INFO Layer 356: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:40:13,803 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:40:13,806 INFO Layer 356: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:40:13,808 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:16,150 INFO     Weight matrix 1/9 (256,256): Alpha: 2.9306452591872434, Alpha Weighted: -1.472428614826436, D: 0.07264883932889454\n",
      "2018-11-26 13:40:16,154 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.35746610164642334\n",
      "2018-11-26 13:40:16,157 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:18,533 INFO     Weight matrix 2/9 (256,256): Alpha: 2.9601658922519003, Alpha Weighted: -1.7824367883505872, D: 0.1266727119823352\n",
      "2018-11-26 13:40:18,538 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3995648920536041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:40:18,541 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:21,279 INFO     Weight matrix 3/9 (256,256): Alpha: 2.966821621839342, Alpha Weighted: -1.4144815052345567, D: 0.10017605936363672\n",
      "2018-11-26 13:40:21,284 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.3680325448513031\n",
      "2018-11-26 13:40:21,288 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:23,715 INFO     Weight matrix 4/9 (256,256): Alpha: 3.3076554031320353, Alpha Weighted: -2.1143413683492858, D: 0.073636943398939\n",
      "2018-11-26 13:40:23,720 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.34312498569488525\n",
      "2018-11-26 13:40:23,723 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:26,053 INFO     Weight matrix 5/9 (256,256): Alpha: 2.1513427748782457, Alpha Weighted: -0.8836145515832318, D: 0.11949211145873051\n",
      "2018-11-26 13:40:26,057 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.43578654527664185\n",
      "2018-11-26 13:40:26,061 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:28,446 INFO     Weight matrix 6/9 (256,256): Alpha: 3.472892165791977, Alpha Weighted: -2.220353023833114, D: 0.08997876143618888\n",
      "2018-11-26 13:40:28,451 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.35823482275009155\n",
      "2018-11-26 13:40:28,453 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:30,869 INFO     Weight matrix 7/9 (256,256): Alpha: 3.174087832226053, Alpha Weighted: -1.6585561761799505, D: 0.09444387840175583\n",
      "2018-11-26 13:40:30,873 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.3692941963672638\n",
      "2018-11-26 13:40:30,875 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:33,218 INFO     Weight matrix 8/9 (256,256): Alpha: 3.197747057488677, Alpha Weighted: -1.784900645331753, D: 0.14285869524903172\n",
      "2018-11-26 13:40:33,222 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.4183518886566162\n",
      "2018-11-26 13:40:33,227 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:35,572 INFO     Weight matrix 9/9 (256,256): Alpha: 3.353838341248305, Alpha Weighted: -1.638104244111653, D: 0.08202688270748698\n",
      "2018-11-26 13:40:35,577 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.38567838072776794\n",
      "2018-11-26 13:40:35,579 INFO Layer 357: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:40:35,582 INFO Layer 357: Skipping (Layer not supported)\n",
      "2018-11-26 13:40:35,584 INFO Layer 358: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:40:35,588 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:40:35,591 INFO Layer 358: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:40:35,593 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:40:38,048 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.334962961356717, Alpha Weighted: 0.6563850547383878, D: 0.07692307692307654\n",
      "2018-11-26 13:40:38,050 INFO     Weight matrix 1/1 (256,1024): Alpha 5.334962961356717 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:40:38,054 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7895104885101318\n",
      "2018-11-26 13:40:38,057 INFO Layer 359: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:40:38,059 INFO Layer 359: Skipping (Layer not supported)\n",
      "2018-11-26 13:40:38,062 INFO Layer 360: ReLU(inplace)\n",
      "2018-11-26 13:40:38,064 INFO Layer 360: Skipping (Layer not supported)\n",
      "2018-11-26 13:40:38,067 INFO Layer 361: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:40:38,069 INFO Layer 361: Skipping (Layer not supported)\n",
      "2018-11-26 13:40:38,071 INFO Layer 362: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:40:38,075 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:40:38,076 INFO Layer 362: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:40:38,079 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:40:40,554 INFO     Weight matrix 1/1 (256,1024): Alpha: 6.25211099016424, Alpha Weighted: 1.1858598562585836, D: 0.09184069312350163\n",
      "2018-11-26 13:40:40,556 INFO     Weight matrix 1/1 (256,1024): Alpha 6.25211099016424 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:40:40,561 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.9082599878311157\n",
      "2018-11-26 13:40:40,563 INFO Layer 363: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:40:40,565 INFO Layer 363: Skipping (Layer not supported)\n",
      "2018-11-26 13:40:40,567 INFO Layer 364: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:40:40,572 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:40:40,577 INFO Layer 364: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:40:40,581 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:42,980 INFO     Weight matrix 1/9 (256,256): Alpha: 4.113696266073122, Alpha Weighted: -1.9808593799851018, D: 0.06756732259287268\n",
      "2018-11-26 13:40:42,983 INFO     Weight matrix 1/9 (256,256): Alpha 4.113696266073122 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:40:42,987 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3829326927661896\n",
      "2018-11-26 13:40:42,990 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:45,365 INFO     Weight matrix 2/9 (256,256): Alpha: 3.275676140735927, Alpha Weighted: -1.9403268669157647, D: 0.14978023534549434\n",
      "2018-11-26 13:40:45,369 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.45461028814315796\n",
      "2018-11-26 13:40:45,372 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:47,707 INFO     Weight matrix 3/9 (256,256): Alpha: 4.640664265563865, Alpha Weighted: -2.1510363686490774, D: 0.07845643186859957\n",
      "2018-11-26 13:40:47,710 INFO     Weight matrix 3/9 (256,256): Alpha 4.640664265563865 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:40:47,714 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.4026219844818115\n",
      "2018-11-26 13:40:47,717 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:50,103 INFO     Weight matrix 4/9 (256,256): Alpha: 5.579477082663854, Alpha Weighted: -3.568059421171899, D: 0.07548366004644697\n",
      "2018-11-26 13:40:50,105 INFO     Weight matrix 4/9 (256,256): Alpha 5.579477082663854 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:40:50,110 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3785143196582794\n",
      "2018-11-26 13:40:50,114 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:52,469 INFO     Weight matrix 5/9 (256,256): Alpha: 4.410295920318585, Alpha Weighted: -2.2031482767156354, D: 0.1325587820369415\n",
      "2018-11-26 13:40:52,471 INFO     Weight matrix 5/9 (256,256): Alpha 4.410295920318585 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:40:52,476 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.468108206987381\n",
      "2018-11-26 13:40:52,479 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:54,877 INFO     Weight matrix 6/9 (256,256): Alpha: 5.224821522366641, Alpha Weighted: -3.1622827463231764, D: 0.06534078188479012\n",
      "2018-11-26 13:40:54,879 INFO     Weight matrix 6/9 (256,256): Alpha 5.224821522366641 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:40:54,883 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.4034837782382965\n",
      "2018-11-26 13:40:54,889 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:40:57,241 INFO     Weight matrix 7/9 (256,256): Alpha: 4.724705598101673, Alpha Weighted: -2.141945740917052, D: 0.08333333333333293\n",
      "2018-11-26 13:40:57,244 INFO     Weight matrix 7/9 (256,256): Alpha 4.724705598101673 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:40:57,249 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.401591956615448\n",
      "2018-11-26 13:40:57,252 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:40:59,570 INFO     Weight matrix 8/9 (256,256): Alpha: 2.866731805980056, Alpha Weighted: -1.6299163951794946, D: 0.1570033999048419\n",
      "2018-11-26 13:40:59,574 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.4766421318054199\n",
      "2018-11-26 13:40:59,577 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:01,985 INFO     Weight matrix 9/9 (256,256): Alpha: 4.7587550335119415, Alpha Weighted: -1.958079808897262, D: 0.08333333333333293\n",
      "2018-11-26 13:41:01,987 INFO     Weight matrix 9/9 (256,256): Alpha 4.7587550335119415 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:01,992 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4236713945865631\n",
      "2018-11-26 13:41:01,995 INFO Layer 365: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:41:02,000 INFO Layer 365: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:02,004 INFO Layer 366: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:41:02,008 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:41:02,012 INFO Layer 366: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:41:02,015 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:41:04,486 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.937839624552832, Alpha Weighted: 0.42164250271169407, D: 0.058532149454658455\n",
      "2018-11-26 13:41:04,489 INFO     Weight matrix 1/1 (256,1024): Alpha 5.937839624552832 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:04,495 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8141399025917053\n",
      "2018-11-26 13:41:04,498 INFO Layer 367: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:41:04,501 INFO Layer 367: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:04,505 INFO Layer 368: ReLU(inplace)\n",
      "2018-11-26 13:41:04,507 INFO Layer 368: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:04,510 INFO Layer 369: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:41:04,512 INFO Layer 369: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:04,514 INFO Layer 370: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:41:04,519 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:41:04,521 INFO Layer 370: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:41:04,524 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:41:07,002 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.808619117748233, Alpha Weighted: 0.9935994102192495, D: 0.08309761309451702\n",
      "2018-11-26 13:41:07,005 INFO     Weight matrix 1/1 (256,1024): Alpha 4.808619117748233 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:07,010 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8745169043540955\n",
      "2018-11-26 13:41:07,012 INFO Layer 371: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:41:07,015 INFO Layer 371: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:07,017 INFO Layer 372: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:41:07,022 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:41:07,025 INFO Layer 372: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:41:07,028 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:09,364 INFO     Weight matrix 1/9 (256,256): Alpha: 3.096874058382815, Alpha Weighted: -1.562896920882465, D: 0.08463474088232481\n",
      "2018-11-26 13:41:09,368 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.36134666204452515\n",
      "2018-11-26 13:41:09,371 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:11,705 INFO     Weight matrix 2/9 (256,256): Alpha: 3.1200034249076594, Alpha Weighted: -1.625436697918743, D: 0.10011585645666632\n",
      "2018-11-26 13:41:11,709 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3989124894142151\n",
      "2018-11-26 13:41:11,716 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:14,092 INFO     Weight matrix 3/9 (256,256): Alpha: 3.2286068975017885, Alpha Weighted: -1.7677441095539004, D: 0.0933212355570206\n",
      "2018-11-26 13:41:14,096 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.37521520256996155\n",
      "2018-11-26 13:41:14,100 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:16,437 INFO     Weight matrix 4/9 (256,256): Alpha: 3.3792789290497702, Alpha Weighted: -2.23859814214082, D: 0.08493943465113685\n",
      "2018-11-26 13:41:16,442 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.33562013506889343\n",
      "2018-11-26 13:41:16,444 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:18,765 INFO     Weight matrix 5/9 (256,256): Alpha: 2.7708169629975155, Alpha Weighted: -0.6632342806455669, D: 0.08698306547716461\n",
      "2018-11-26 13:41:18,769 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.45185813307762146\n",
      "2018-11-26 13:41:18,772 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:21,113 INFO     Weight matrix 6/9 (256,256): Alpha: 4.198490611275228, Alpha Weighted: -2.791718069097738, D: 0.07998042976382458\n",
      "2018-11-26 13:41:21,116 INFO     Weight matrix 6/9 (256,256): Alpha 4.198490611275228 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:21,120 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.35684168338775635\n",
      "2018-11-26 13:41:21,124 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:23,492 INFO     Weight matrix 7/9 (256,256): Alpha: 3.40242342849928, Alpha Weighted: -1.9147392755669155, D: 0.06959126800298865\n",
      "2018-11-26 13:41:23,496 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.36878663301467896\n",
      "2018-11-26 13:41:23,499 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:25,948 INFO     Weight matrix 8/9 (256,256): Alpha: 3.4268736220305587, Alpha Weighted: -1.8214055320916935, D: 0.11094287097708394\n",
      "2018-11-26 13:41:25,952 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.4152119755744934\n",
      "2018-11-26 13:41:25,955 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:28,321 INFO     Weight matrix 9/9 (256,256): Alpha: 3.5425961250430333, Alpha Weighted: -2.001288288515917, D: 0.10513637820209773\n",
      "2018-11-26 13:41:28,324 INFO     Weight matrix 9/9 (256,256): Alpha 3.5425961250430333 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:28,329 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.39044544100761414\n",
      "2018-11-26 13:41:28,334 INFO Layer 373: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:41:28,338 INFO Layer 373: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:28,340 INFO Layer 374: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:41:28,345 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:41:28,348 INFO Layer 374: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:41:28,351 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:41:30,834 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.126028159167187, Alpha Weighted: 0.9967273721287861, D: 0.04761904761904745\n",
      "2018-11-26 13:41:30,837 INFO     Weight matrix 1/1 (256,1024): Alpha 4.126028159167187 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:30,844 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7971733212471008\n",
      "2018-11-26 13:41:30,846 INFO Layer 375: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:41:30,848 INFO Layer 375: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:30,850 INFO Layer 376: ReLU(inplace)\n",
      "2018-11-26 13:41:30,853 INFO Layer 376: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:30,856 INFO Layer 377: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:41:30,859 INFO Layer 377: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:30,861 INFO Layer 378: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:41:30,865 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:41:30,868 INFO Layer 378: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:41:30,871 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:41:33,358 INFO     Weight matrix 1/1 (256,1024): Alpha: 4.988080785972596, Alpha Weighted: 1.464737888055083, D: 0.07319002166957866\n",
      "2018-11-26 13:41:33,361 INFO     Weight matrix 1/1 (256,1024): Alpha 4.988080785972596 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:33,364 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.9317461252212524\n",
      "2018-11-26 13:41:33,368 INFO Layer 379: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:41:33,375 INFO Layer 379: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:33,377 INFO Layer 380: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:41:33,384 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:41:33,389 INFO Layer 380: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:41:33,392 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:35,776 INFO     Weight matrix 1/9 (256,256): Alpha: 4.285532234306578, Alpha Weighted: -2.9825492439731476, D: 0.12962603086263247\n",
      "2018-11-26 13:41:35,778 INFO     Weight matrix 1/9 (256,256): Alpha 4.285532234306578 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:35,785 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.3948020339012146\n",
      "2018-11-26 13:41:35,787 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:38,149 INFO     Weight matrix 2/9 (256,256): Alpha: 4.089282381605161, Alpha Weighted: -2.236780877957601, D: 0.1136944080359138\n",
      "2018-11-26 13:41:38,151 INFO     Weight matrix 2/9 (256,256): Alpha 4.089282381605161 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:38,156 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.44941043853759766\n",
      "2018-11-26 13:41:38,159 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:40,530 INFO     Weight matrix 3/9 (256,256): Alpha: 4.793447178883035, Alpha Weighted: -3.2704371608233127, D: 0.13634937261977942\n",
      "2018-11-26 13:41:40,533 INFO     Weight matrix 3/9 (256,256): Alpha 4.793447178883035 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:40,537 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.4214509129524231\n",
      "2018-11-26 13:41:40,542 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:42,939 INFO     Weight matrix 4/9 (256,256): Alpha: 6.204044699429607, Alpha Weighted: -4.47756378880581, D: 0.09999999999999976\n",
      "2018-11-26 13:41:42,941 INFO     Weight matrix 4/9 (256,256): Alpha 6.204044699429607 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:42,946 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3904944360256195\n",
      "2018-11-26 13:41:42,949 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:45,323 INFO     Weight matrix 5/9 (256,256): Alpha: 4.372580891671582, Alpha Weighted: -1.5054498977551498, D: 0.0588235294117645\n",
      "2018-11-26 13:41:45,326 INFO     Weight matrix 5/9 (256,256): Alpha 4.372580891671582 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:45,333 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.4592010974884033\n",
      "2018-11-26 13:41:45,337 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:47,713 INFO     Weight matrix 6/9 (256,256): Alpha: 7.164670075815612, Alpha Weighted: -4.6303231231076305, D: 0.09999999999999976\n",
      "2018-11-26 13:41:47,716 INFO     Weight matrix 6/9 (256,256): Alpha 7.164670075815612 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:47,720 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.426939457654953\n",
      "2018-11-26 13:41:47,723 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:50,080 INFO     Weight matrix 7/9 (256,256): Alpha: 7.081236920606629, Alpha Weighted: -4.872102626210831, D: 0.11560875188324493\n",
      "2018-11-26 13:41:50,082 INFO     Weight matrix 7/9 (256,256): Alpha 7.081236920606629 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:50,086 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.41561758518218994\n",
      "2018-11-26 13:41:50,090 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:52,465 INFO     Weight matrix 8/9 (256,256): Alpha: 4.137978772528146, Alpha Weighted: -2.104787115699322, D: 0.12562336387189554\n",
      "2018-11-26 13:41:52,467 INFO     Weight matrix 8/9 (256,256): Alpha 4.137978772528146 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:52,474 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.48035988211631775\n",
      "2018-11-26 13:41:52,477 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:41:54,864 INFO     Weight matrix 9/9 (256,256): Alpha: 5.054767363987293, Alpha Weighted: -3.045056360200229, D: 0.14148253398829558\n",
      "2018-11-26 13:41:54,867 INFO     Weight matrix 9/9 (256,256): Alpha 5.054767363987293 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:54,871 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.4495648145675659\n",
      "2018-11-26 13:41:54,874 INFO Layer 381: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:41:54,876 INFO Layer 381: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:54,878 INFO Layer 382: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:41:54,883 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:41:54,885 INFO Layer 382: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:41:54,888 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:41:57,386 INFO     Weight matrix 1/1 (256,1024): Alpha: 5.484931185728635, Alpha Weighted: 1.5849998183038938, D: 0.07764994419568766\n",
      "2018-11-26 13:41:57,389 INFO     Weight matrix 1/1 (256,1024): Alpha 5.484931185728635 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:41:57,395 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8324913382530212\n",
      "2018-11-26 13:41:57,398 INFO Layer 383: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:41:57,402 INFO Layer 383: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:57,405 INFO Layer 384: ReLU(inplace)\n",
      "2018-11-26 13:41:57,409 INFO Layer 384: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:57,412 INFO Layer 385: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:41:57,414 INFO Layer 385: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:57,417 INFO Layer 386: Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:41:57,425 INFO Pytorch tensor shape detected: 256x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:41:57,428 INFO Layer 386: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:41:57,430 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:41:59,883 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.688407781414938, Alpha Weighted: 0.6287320780728163, D: 0.1075366898787069\n",
      "2018-11-26 13:41:59,887 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.8871994018554688\n",
      "2018-11-26 13:41:59,891 INFO Layer 387: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:41:59,893 INFO Layer 387: Skipping (Layer not supported)\n",
      "2018-11-26 13:41:59,896 INFO Layer 388: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:41:59,900 INFO Pytorch tensor shape detected: 256x256 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:41:59,907 INFO Layer 388: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:41:59,910 INFO     Weight matrix 1/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:42:02,268 INFO     Weight matrix 1/9 (256,256): Alpha: 2.720555753873851, Alpha Weighted: -1.1780749862195998, D: 0.07891206474275758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:42:02,273 INFO     Weight matrix 1/9 (256,256): Lognorm: 0.35734614729881287\n",
      "2018-11-26 13:42:02,276 INFO     Weight matrix 2/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:42:04,642 INFO     Weight matrix 2/9 (256,256): Alpha: 3.5334835775286106, Alpha Weighted: -1.3936554188270223, D: 0.0649452174713081\n",
      "2018-11-26 13:42:04,645 INFO     Weight matrix 2/9 (256,256): Alpha 3.5334835775286106 is in the danger zone (1.5,3.5)\n",
      "2018-11-26 13:42:04,650 INFO     Weight matrix 2/9 (256,256): Lognorm: 0.3777443766593933\n",
      "2018-11-26 13:42:04,652 INFO     Weight matrix 3/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:42:07,012 INFO     Weight matrix 3/9 (256,256): Alpha: 3.1003501444033605, Alpha Weighted: -1.2776531462647411, D: 0.07572500706705687\n",
      "2018-11-26 13:42:07,016 INFO     Weight matrix 3/9 (256,256): Lognorm: 0.36738309264183044\n",
      "2018-11-26 13:42:07,019 INFO     Weight matrix 4/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:42:09,380 INFO     Weight matrix 4/9 (256,256): Alpha: 3.2421888179781093, Alpha Weighted: -1.7570624471941765, D: 0.07914453555998335\n",
      "2018-11-26 13:42:09,385 INFO     Weight matrix 4/9 (256,256): Lognorm: 0.3357001543045044\n",
      "2018-11-26 13:42:09,388 INFO     Weight matrix 5/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:42:11,715 INFO     Weight matrix 5/9 (256,256): Alpha: 2.192867699642581, Alpha Weighted: -0.5702766782098324, D: 0.07948141979786927\n",
      "2018-11-26 13:42:11,719 INFO     Weight matrix 5/9 (256,256): Lognorm: 0.44160276651382446\n",
      "2018-11-26 13:42:11,722 INFO     Weight matrix 6/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:42:14,073 INFO     Weight matrix 6/9 (256,256): Alpha: 3.032928226332948, Alpha Weighted: -1.6098489710264532, D: 0.0978842800123374\n",
      "2018-11-26 13:42:14,078 INFO     Weight matrix 6/9 (256,256): Lognorm: 0.3601471185684204\n",
      "2018-11-26 13:42:14,081 INFO     Weight matrix 7/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:42:16,442 INFO     Weight matrix 7/9 (256,256): Alpha: 3.235877807742147, Alpha Weighted: -1.2745578044309342, D: 0.08019927407411509\n",
      "2018-11-26 13:42:16,446 INFO     Weight matrix 7/9 (256,256): Lognorm: 0.36715587973594666\n",
      "2018-11-26 13:42:16,449 INFO     Weight matrix 8/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:42:18,833 INFO     Weight matrix 8/9 (256,256): Alpha: 3.391612465380046, Alpha Weighted: -1.500864914671851, D: 0.09299822930978174\n",
      "2018-11-26 13:42:18,839 INFO     Weight matrix 8/9 (256,256): Lognorm: 0.39945322275161743\n",
      "2018-11-26 13:42:18,842 INFO     Weight matrix 9/9 (256,256): Analyzing ...\n",
      "2018-11-26 13:42:21,378 INFO     Weight matrix 9/9 (256,256): Alpha: 3.3315078089596923, Alpha Weighted: -1.2470955769973964, D: 0.08756386153516149\n",
      "2018-11-26 13:42:21,382 INFO     Weight matrix 9/9 (256,256): Lognorm: 0.3916449546813965\n",
      "2018-11-26 13:42:21,386 INFO Layer 389: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:42:21,390 INFO Layer 389: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:21,393 INFO Layer 390: Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:42:21,400 INFO Pytorch tensor shape detected: 1024x256 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:42:21,404 INFO Layer 390: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:42:21,407 INFO     Weight matrix 1/1 (256,1024): Analyzing ...\n",
      "2018-11-26 13:42:24,006 INFO     Weight matrix 1/1 (256,1024): Alpha: 2.824441356111112, Alpha Weighted: 0.9027964683765938, D: 0.0789285209554964\n",
      "2018-11-26 13:42:24,009 INFO     Weight matrix 1/1 (256,1024): Lognorm: 0.7910041809082031\n",
      "2018-11-26 13:42:24,014 INFO Layer 391: BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:42:24,016 INFO Layer 391: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,019 INFO Layer 392: ReLU(inplace)\n",
      "2018-11-26 13:42:24,022 INFO Layer 392: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,027 INFO Layer 393: Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:42:24,030 INFO Layer 393: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,033 INFO Layer 394: Bottleneck(\n",
      "  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "2018-11-26 13:42:24,038 INFO Layer 394: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,041 INFO Layer 395: Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:42:24,047 INFO Pytorch tensor shape detected: 512x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:42:24,050 INFO Layer 395: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:42:24,053 INFO     Weight matrix 1/1 (512,1024): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,056 INFO Layer 396: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:42:24,058 INFO Layer 396: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,063 INFO Layer 397: Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:42:24,110 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:42:24,113 INFO Layer 397: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:42:24,115 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,119 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,122 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,130 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,134 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,137 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,140 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:42:24,143 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,146 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,148 INFO Layer 398: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:42:24,150 INFO Layer 398: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,153 INFO Layer 399: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:42:24,168 INFO Pytorch tensor shape detected: 2048x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:42:24,170 INFO Layer 399: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:42:24,173 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,175 INFO Layer 400: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:42:24,178 INFO Layer 400: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,181 INFO Layer 401: ReLU(inplace)\n",
      "2018-11-26 13:42:24,184 INFO Layer 401: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,187 INFO Layer 402: Sequential(\n",
      "  (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "2018-11-26 13:42:24,189 INFO Layer 402: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,192 INFO Layer 403: Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "2018-11-26 13:42:24,213 INFO Pytorch tensor shape detected: 2048x1024 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:42:24,217 INFO Layer 403: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:42:24,219 INFO     Weight matrix 1/1 (1024,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,222 INFO Layer 404: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:42:24,225 INFO Layer 404: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,227 INFO Layer 405: Bottleneck(\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:42:24,231 INFO Layer 405: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,234 INFO Layer 406: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:42:24,248 INFO Pytorch tensor shape detected: 512x2048 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:42:24,253 INFO Layer 406: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:42:24,259 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,261 INFO Layer 407: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:42:24,264 INFO Layer 407: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,266 INFO Layer 408: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:42:24,288 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:42:24,291 INFO Layer 408: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:42:24,294 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,300 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,302 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,304 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,307 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,310 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,313 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,316 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,318 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,321 INFO Layer 409: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:42:24,324 INFO Layer 409: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,326 INFO Layer 410: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:42:24,339 INFO Pytorch tensor shape detected: 2048x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:42:24,342 INFO Layer 410: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:42:24,345 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,348 INFO Layer 411: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:42:24,351 INFO Layer 411: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,353 INFO Layer 412: ReLU(inplace)\n",
      "2018-11-26 13:42:24,355 INFO Layer 412: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,358 INFO Layer 413: Bottleneck(\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      ")\n",
      "2018-11-26 13:42:24,361 INFO Layer 413: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,364 INFO Layer 414: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:42:24,382 INFO Pytorch tensor shape detected: 512x2048 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:42:24,386 INFO Layer 414: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:42:24,389 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,392 INFO Layer 415: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:42:24,393 INFO Layer 415: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,400 INFO Layer 416: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "2018-11-26 13:42:24,427 INFO Pytorch tensor shape detected: 512x512 (NxM), 3x3 (i,j)\n",
      "2018-11-26 13:42:24,430 INFO Layer 416: Analyzing 9 weight matrices...\n",
      "2018-11-26 13:42:24,434 INFO     Weight matrix 1/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,436 INFO     Weight matrix 2/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,441 INFO     Weight matrix 3/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,444 INFO     Weight matrix 4/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,449 INFO     Weight matrix 5/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,452 INFO     Weight matrix 6/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,455 INFO     Weight matrix 7/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,460 INFO     Weight matrix 8/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,463 INFO     Weight matrix 9/9 (512,512): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,466 INFO Layer 417: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:42:24,470 INFO Layer 417: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,473 INFO Layer 418: Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "2018-11-26 13:42:24,491 INFO Pytorch tensor shape detected: 2048x512 (NxM), 1x1 (i,j)\n",
      "2018-11-26 13:42:24,496 INFO Layer 418: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:42:24,499 INFO     Weight matrix 1/1 (512,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,502 INFO Layer 419: BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "2018-11-26 13:42:24,506 INFO Layer 419: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,512 INFO Layer 420: ReLU(inplace)\n",
      "2018-11-26 13:42:24,514 INFO Layer 420: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,517 INFO Layer 421: AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "2018-11-26 13:42:24,520 INFO Layer 421: Skipping (Layer not supported)\n",
      "2018-11-26 13:42:24,523 INFO Layer 422: Linear(in_features=2048, out_features=1000, bias=True)\n",
      "2018-11-26 13:42:24,548 INFO Layer 422: Analyzing 1 weight matrices...\n",
      "2018-11-26 13:42:24,551 INFO     Weight matrix 1/1 (1000,2048): Skipping: too big (testing) (>256)\n",
      "2018-11-26 13:42:24,555 INFO ### Printing results ###\n",
      "2018-11-26 13:42:24,557 DEBUG Layer 7: Lognorm: 0.5928643345832825\n",
      "2018-11-26 13:42:24,560 DEBUG Layer 9: Lognorm compound: 0.1780360479735666\n",
      "2018-11-26 13:42:24,562 DEBUG Layer 11: Lognorm: 0.6120220422744751\n",
      "2018-11-26 13:42:24,565 DEBUG Layer 15: Lognorm: 0.8432208895683289\n",
      "2018-11-26 13:42:24,567 DEBUG Layer 18: Lognorm: 0.5337738990783691\n",
      "2018-11-26 13:42:24,571 DEBUG Layer 20: Lognorm compound: 0.13634424284100533\n",
      "2018-11-26 13:42:24,573 DEBUG Layer 22: Lognorm: 0.5406745672225952\n",
      "2018-11-26 13:42:24,575 DEBUG Layer 26: Lognorm: 0.5374316573143005\n",
      "2018-11-26 13:42:24,577 DEBUG Layer 28: Lognorm compound: 0.21876646909448835\n",
      "2018-11-26 13:42:24,581 DEBUG Layer 30: Lognorm: 0.5174378752708435\n",
      "2018-11-26 13:42:24,583 DEBUG Layer 35: Lognorm: 0.726112425327301\n",
      "2018-11-26 13:42:24,586 DEBUG Layer 37: Lognorm compound: 0.4103976355658637\n",
      "2018-11-26 13:42:24,588 DEBUG Layer 39: Lognorm: 0.822799026966095\n",
      "2018-11-26 13:42:24,591 DEBUG Layer 43: Lognorm: 0.8873290419578552\n",
      "2018-11-26 13:42:24,594 DEBUG Layer 46: Lognorm: 0.5109164714813232\n",
      "2018-11-26 13:42:24,598 DEBUG Layer 48: Lognorm compound: 0.1902470849454403\n",
      "2018-11-26 13:42:24,602 DEBUG Layer 50: Lognorm: 0.5689065456390381\n",
      "2018-11-26 13:42:24,610 DEBUG Layer 54: Lognorm: 0.5885189175605774\n",
      "2018-11-26 13:42:24,613 DEBUG Layer 56: Lognorm compound: 0.25876738793320125\n",
      "2018-11-26 13:42:24,615 DEBUG Layer 58: Lognorm: 0.6500002145767212\n",
      "2018-11-26 13:42:24,618 DEBUG Layer 62: Lognorm: 0.6058210730552673\n",
      "2018-11-26 13:42:24,621 DEBUG Layer 64: Lognorm compound: 0.22089218265480465\n",
      "2018-11-26 13:42:24,624 DEBUG Layer 66: Lognorm: 0.5825130939483643\n",
      "2018-11-26 13:42:24,627 DEBUG Layer 70: Lognorm: 0.624896228313446\n",
      "2018-11-26 13:42:24,629 DEBUG Layer 72: Lognorm compound: 0.2782938712173038\n",
      "2018-11-26 13:42:24,632 DEBUG Layer 74: Lognorm: 0.6439647674560547\n",
      "2018-11-26 13:42:24,634 DEBUG Layer 78: Lognorm: 0.6281276941299438\n",
      "2018-11-26 13:42:24,637 DEBUG Layer 80: Lognorm compound: 0.26155414680639905\n",
      "2018-11-26 13:42:24,642 DEBUG Layer 82: Lognorm: 0.6274072527885437\n",
      "2018-11-26 13:42:24,646 DEBUG Layer 86: Lognorm: 0.6829442977905273\n",
      "2018-11-26 13:42:24,649 DEBUG Layer 88: Lognorm compound: 0.33418139318625134\n",
      "2018-11-26 13:42:24,652 DEBUG Layer 90: Lognorm: 0.6469484567642212\n",
      "2018-11-26 13:42:24,654 DEBUG Layer 94: Lognorm: 0.7136598229408264\n",
      "2018-11-26 13:42:24,656 DEBUG Layer 96: Lognorm compound: 0.2942166262202793\n",
      "2018-11-26 13:42:24,658 DEBUG Layer 98: Lognorm: 0.5965591073036194\n",
      "2018-11-26 13:42:24,661 DEBUG Layer 103: Lognorm: 0.9734541773796082\n",
      "2018-11-26 13:42:24,663 DEBUG Layer 105: Lognorm compound: 0.5617394414212968\n",
      "2018-11-26 13:42:24,666 DEBUG Layer 107: Lognorm: 0.9785140752792358\n",
      "2018-11-26 13:42:24,668 DEBUG Layer 114: Lognorm: 0.4623584449291229\n",
      "2018-11-26 13:42:24,670 DEBUG Layer 116: Lognorm compound: 0.0813721959065232\n",
      "2018-11-26 13:42:24,673 DEBUG Layer 118: Lognorm: 0.49823620915412903\n",
      "2018-11-26 13:42:24,675 DEBUG Layer 122: Lognorm: 0.5266568660736084\n",
      "2018-11-26 13:42:24,677 DEBUG Layer 124: Lognorm compound: 0.15850946307182312\n",
      "2018-11-26 13:42:24,679 DEBUG Layer 126: Lognorm: 0.5557334423065186\n",
      "2018-11-26 13:42:24,682 DEBUG Layer 130: Lognorm: 0.6023969650268555\n",
      "2018-11-26 13:42:24,685 DEBUG Layer 132: Lognorm compound: 0.22536986569563547\n",
      "2018-11-26 13:42:24,688 DEBUG Layer 134: Lognorm: 0.6498120427131653\n",
      "2018-11-26 13:42:24,691 DEBUG Layer 138: Lognorm: 0.6821037530899048\n",
      "2018-11-26 13:42:24,695 DEBUG Layer 140: Lognorm compound: 0.3024652832084232\n",
      "2018-11-26 13:42:24,698 DEBUG Layer 142: Lognorm: 0.718032717704773\n",
      "2018-11-26 13:42:24,700 DEBUG Layer 146: Lognorm: 0.7076888680458069\n",
      "2018-11-26 13:42:24,704 DEBUG Layer 148: Lognorm compound: 0.3107011781798469\n",
      "2018-11-26 13:42:24,708 DEBUG Layer 150: Lognorm: 0.7038215398788452\n",
      "2018-11-26 13:42:24,712 DEBUG Layer 154: Lognorm: 0.6695762872695923\n",
      "2018-11-26 13:42:24,715 DEBUG Layer 156: Lognorm compound: 0.27698512375354767\n",
      "2018-11-26 13:42:24,718 DEBUG Layer 158: Lognorm: 0.7139934301376343\n",
      "2018-11-26 13:42:24,720 DEBUG Layer 162: Lognorm: 0.5743681788444519\n",
      "2018-11-26 13:42:24,723 DEBUG Layer 164: Lognorm compound: 0.2140560895204544\n",
      "2018-11-26 13:42:24,725 DEBUG Layer 166: Lognorm: 0.664386510848999\n",
      "2018-11-26 13:42:24,728 DEBUG Layer 170: Lognorm: 0.6670804619789124\n",
      "2018-11-26 13:42:24,731 DEBUG Layer 172: Lognorm compound: 0.2698149101601707\n",
      "2018-11-26 13:42:24,735 DEBUG Layer 174: Lognorm: 0.7012448310852051\n",
      "2018-11-26 13:42:24,737 DEBUG Layer 178: Lognorm: 0.7270463109016418\n",
      "2018-11-26 13:42:24,740 DEBUG Layer 180: Lognorm compound: 0.33880453639560276\n",
      "2018-11-26 13:42:24,743 DEBUG Layer 182: Lognorm: 0.7489341497421265\n",
      "2018-11-26 13:42:24,746 DEBUG Layer 186: Lognorm: 0.6206818222999573\n",
      "2018-11-26 13:42:24,749 DEBUG Layer 188: Lognorm compound: 0.24333814448780483\n",
      "2018-11-26 13:42:24,752 DEBUG Layer 190: Lognorm: 0.6538853645324707\n",
      "2018-11-26 13:42:24,757 DEBUG Layer 194: Lognorm: 0.6611976027488708\n",
      "2018-11-26 13:42:24,760 DEBUG Layer 196: Lognorm compound: 0.32369720935821533\n",
      "2018-11-26 13:42:24,763 DEBUG Layer 198: Lognorm: 0.6972013711929321\n",
      "2018-11-26 13:42:24,765 DEBUG Layer 202: Lognorm: 0.726108968257904\n",
      "2018-11-26 13:42:24,768 DEBUG Layer 204: Lognorm compound: 0.341280460357666\n",
      "2018-11-26 13:42:24,770 DEBUG Layer 206: Lognorm: 0.7455472350120544\n",
      "2018-11-26 13:42:24,772 DEBUG Layer 210: Lognorm: 0.7007266879081726\n",
      "2018-11-26 13:42:24,774 DEBUG Layer 212: Lognorm compound: 0.348050014840232\n",
      "2018-11-26 13:42:24,777 DEBUG Layer 214: Lognorm: 0.7326050400733948\n",
      "2018-11-26 13:42:24,783 DEBUG Layer 218: Lognorm: 0.7854442596435547\n",
      "2018-11-26 13:42:24,788 DEBUG Layer 220: Lognorm compound: 0.3454178770383199\n",
      "2018-11-26 13:42:24,792 DEBUG Layer 222: Lognorm: 0.758399248123169\n",
      "2018-11-26 13:42:24,797 DEBUG Layer 226: Lognorm: 0.8030890822410583\n",
      "2018-11-26 13:42:24,800 DEBUG Layer 228: Lognorm compound: 0.38009510106510586\n",
      "2018-11-26 13:42:24,803 DEBUG Layer 230: Lognorm: 0.7744672298431396\n",
      "2018-11-26 13:42:24,807 DEBUG Layer 234: Lognorm: 0.7655656933784485\n",
      "2018-11-26 13:42:24,809 DEBUG Layer 236: Lognorm compound: 0.35350341267055935\n",
      "2018-11-26 13:42:24,811 DEBUG Layer 238: Lognorm: 0.7425299286842346\n",
      "2018-11-26 13:42:24,814 DEBUG Layer 242: Lognorm: 0.716942548751831\n",
      "2018-11-26 13:42:24,817 DEBUG Layer 244: Lognorm compound: 0.3243391149573856\n",
      "2018-11-26 13:42:24,819 DEBUG Layer 246: Lognorm: 0.7167928218841553\n",
      "2018-11-26 13:42:24,823 DEBUG Layer 250: Lognorm: 0.6992054581642151\n",
      "2018-11-26 13:42:24,825 DEBUG Layer 252: Lognorm compound: 0.3024851348665025\n",
      "2018-11-26 13:42:24,829 DEBUG Layer 254: Lognorm: 0.6795777678489685\n",
      "2018-11-26 13:42:24,831 DEBUG Layer 258: Lognorm: 0.7454421520233154\n",
      "2018-11-26 13:42:24,834 DEBUG Layer 260: Lognorm compound: 0.3501363264189826\n",
      "2018-11-26 13:42:24,837 DEBUG Layer 262: Lognorm: 0.7399800419807434\n",
      "2018-11-26 13:42:24,839 DEBUG Layer 266: Lognorm: 0.7167991399765015\n",
      "2018-11-26 13:42:24,842 DEBUG Layer 268: Lognorm compound: 0.2947681082619561\n",
      "2018-11-26 13:42:24,844 DEBUG Layer 270: Lognorm: 0.6956610083580017\n",
      "2018-11-26 13:42:24,846 DEBUG Layer 274: Lognorm: 0.7633578181266785\n",
      "2018-11-26 13:42:24,849 DEBUG Layer 276: Lognorm compound: 0.3316696948475308\n",
      "2018-11-26 13:42:24,852 DEBUG Layer 278: Lognorm: 0.7285618185997009\n",
      "2018-11-26 13:42:24,855 DEBUG Layer 282: Lognorm: 0.7358704209327698\n",
      "2018-11-26 13:42:24,857 DEBUG Layer 284: Lognorm compound: 0.304666174782647\n",
      "2018-11-26 13:42:24,859 DEBUG Layer 286: Lognorm: 0.7043207883834839\n",
      "2018-11-26 13:42:24,862 DEBUG Layer 290: Lognorm: 0.7848787307739258\n",
      "2018-11-26 13:42:24,866 DEBUG Layer 292: Lognorm compound: 0.3576407796806759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:42:24,869 DEBUG Layer 294: Lognorm: 0.7364515066146851\n",
      "2018-11-26 13:42:24,871 DEBUG Layer 298: Lognorm: 0.7697859406471252\n",
      "2018-11-26 13:42:24,875 DEBUG Layer 300: Lognorm compound: 0.3247354163063897\n",
      "2018-11-26 13:42:24,880 DEBUG Layer 302: Lognorm: 0.7068378925323486\n",
      "2018-11-26 13:42:24,882 DEBUG Layer 306: Lognorm: 0.7849581837654114\n",
      "2018-11-26 13:42:24,884 DEBUG Layer 308: Lognorm compound: 0.31818267703056335\n",
      "2018-11-26 13:42:24,886 DEBUG Layer 310: Lognorm: 0.6974254250526428\n",
      "2018-11-26 13:42:24,889 DEBUG Layer 314: Lognorm: 0.7536705136299133\n",
      "2018-11-26 13:42:24,892 DEBUG Layer 316: Lognorm compound: 0.3087007138464186\n",
      "2018-11-26 13:42:24,895 DEBUG Layer 318: Lognorm: 0.6846080422401428\n",
      "2018-11-26 13:42:24,901 DEBUG Layer 322: Lognorm: 0.7549086213111877\n",
      "2018-11-26 13:42:24,904 DEBUG Layer 324: Lognorm compound: 0.301364498005973\n",
      "2018-11-26 13:42:24,907 DEBUG Layer 326: Lognorm: 0.6778208017349243\n",
      "2018-11-26 13:42:24,910 DEBUG Layer 330: Lognorm: 0.7726577520370483\n",
      "2018-11-26 13:42:24,913 DEBUG Layer 332: Lognorm compound: 0.3386426932281918\n",
      "2018-11-26 13:42:24,916 DEBUG Layer 334: Lognorm: 0.7365842461585999\n",
      "2018-11-26 13:42:24,919 DEBUG Layer 338: Lognorm: 0.830201268196106\n",
      "2018-11-26 13:42:24,921 DEBUG Layer 340: Lognorm compound: 0.3667091959052616\n",
      "2018-11-26 13:42:24,925 DEBUG Layer 342: Lognorm: 0.7659279704093933\n",
      "2018-11-26 13:42:24,927 DEBUG Layer 346: Lognorm: 0.8567227125167847\n",
      "2018-11-26 13:42:24,930 DEBUG Layer 348: Lognorm compound: 0.3755051725440555\n",
      "2018-11-26 13:42:24,933 DEBUG Layer 350: Lognorm: 0.795983612537384\n",
      "2018-11-26 13:42:24,937 DEBUG Layer 354: Lognorm: 0.8585711717605591\n",
      "2018-11-26 13:42:24,941 DEBUG Layer 356: Lognorm compound: 0.3817260397805108\n",
      "2018-11-26 13:42:24,944 DEBUG Layer 358: Lognorm: 0.7895104885101318\n",
      "2018-11-26 13:42:24,947 DEBUG Layer 362: Lognorm: 0.9082599878311157\n",
      "2018-11-26 13:42:24,950 DEBUG Layer 364: Lognorm compound: 0.42135297258694965\n",
      "2018-11-26 13:42:24,953 DEBUG Layer 366: Lognorm: 0.8141399025917053\n",
      "2018-11-26 13:42:24,957 DEBUG Layer 370: Lognorm: 0.8745169043540955\n",
      "2018-11-26 13:42:24,960 DEBUG Layer 372: Lognorm compound: 0.3838042616844177\n",
      "2018-11-26 13:42:24,963 DEBUG Layer 374: Lognorm: 0.7971733212471008\n",
      "2018-11-26 13:42:24,966 DEBUG Layer 378: Lognorm: 0.9317461252212524\n",
      "2018-11-26 13:42:24,968 DEBUG Layer 380: Lognorm compound: 0.4319822953806983\n",
      "2018-11-26 13:42:24,971 DEBUG Layer 382: Lognorm: 0.8324913382530212\n",
      "2018-11-26 13:42:24,975 DEBUG Layer 386: Lognorm: 0.8871994018554688\n",
      "2018-11-26 13:42:24,980 DEBUG Layer 388: Lognorm compound: 0.3775753014617496\n",
      "2018-11-26 13:42:24,984 DEBUG Layer 390: Lognorm: 0.7910041809082031\n",
      "2018-11-26 13:42:24,989 INFO LogNorm: min: -0.02132391557097435, max: 0.9785140752792358, avg: 0.3820621371269226\n",
      "2018-11-26 13:42:24,991 INFO LogNorm compound: min: 0.0813721959065232, max: 0.9785140752792358, avg: 0.5780920999615997\n",
      "2018-11-26 13:42:24,994 DEBUG Layer 7: Alpha: 1.3111378014317996\n",
      "2018-11-26 13:42:24,997 DEBUG Layer 9: Alpha compound: 2.1196524589582615\n",
      "2018-11-26 13:42:25,001 DEBUG Layer 11: Alpha: 3.5175179565482733\n",
      "2018-11-26 13:42:25,005 DEBUG Layer 15: Alpha: 2.8531390582331717\n",
      "2018-11-26 13:42:25,008 DEBUG Layer 18: Alpha: 1.5846334995950602\n",
      "2018-11-26 13:42:25,010 DEBUG Layer 20: Alpha compound: 1.9526775956637945\n",
      "2018-11-26 13:42:25,012 DEBUG Layer 22: Alpha: 4.054514446416214\n",
      "2018-11-26 13:42:25,020 DEBUG Layer 26: Alpha: 1.865161718770696\n",
      "2018-11-26 13:42:25,022 DEBUG Layer 28: Alpha compound: 1.8085064074656974\n",
      "2018-11-26 13:42:25,024 DEBUG Layer 30: Alpha: 9.386195486708251\n",
      "2018-11-26 13:42:25,026 DEBUG Layer 35: Alpha: 1.6002481924227092\n",
      "2018-11-26 13:42:25,029 DEBUG Layer 37: Alpha compound: 1.9711678500715375\n",
      "2018-11-26 13:42:25,031 DEBUG Layer 39: Alpha: 2.6384253732388663\n",
      "2018-11-26 13:42:25,034 DEBUG Layer 43: Alpha: 1.5379124675860336\n",
      "2018-11-26 13:42:25,036 DEBUG Layer 46: Alpha: 1.622841610957761\n",
      "2018-11-26 13:42:25,039 DEBUG Layer 48: Alpha compound: 1.4731403547781217\n",
      "2018-11-26 13:42:25,042 DEBUG Layer 50: Alpha: 4.124810720239806\n",
      "2018-11-26 13:42:25,045 DEBUG Layer 54: Alpha: 1.6168132855905422\n",
      "2018-11-26 13:42:25,047 DEBUG Layer 56: Alpha compound: 1.9089925740757014\n",
      "2018-11-26 13:42:25,049 DEBUG Layer 58: Alpha: 6.164983783519854\n",
      "2018-11-26 13:42:25,052 DEBUG Layer 62: Alpha: 1.6813964994651238\n",
      "2018-11-26 13:42:25,056 DEBUG Layer 64: Alpha compound: 1.8628098620899922\n",
      "2018-11-26 13:42:25,058 DEBUG Layer 66: Alpha: 1.4774061775884624\n",
      "2018-11-26 13:42:25,061 DEBUG Layer 70: Alpha: 3.742374458849538\n",
      "2018-11-26 13:42:25,067 DEBUG Layer 72: Alpha compound: 1.8956458583844302\n",
      "2018-11-26 13:42:25,069 DEBUG Layer 74: Alpha: 1.6178181284725142\n",
      "2018-11-26 13:42:25,074 DEBUG Layer 78: Alpha: 1.6000308270072654\n",
      "2018-11-26 13:42:25,077 DEBUG Layer 80: Alpha compound: 1.9103176703797067\n",
      "2018-11-26 13:42:25,080 DEBUG Layer 82: Alpha: 1.6280600816900483\n",
      "2018-11-26 13:42:25,086 DEBUG Layer 86: Alpha: 1.6867438565277113\n",
      "2018-11-26 13:42:25,090 DEBUG Layer 88: Alpha compound: 2.051414455281972\n",
      "2018-11-26 13:42:25,093 DEBUG Layer 90: Alpha: 1.5923654268655434\n",
      "2018-11-26 13:42:25,095 DEBUG Layer 94: Alpha: 2.5603311475795683\n",
      "2018-11-26 13:42:25,098 DEBUG Layer 96: Alpha compound: 2.021076173142026\n",
      "2018-11-26 13:42:25,104 DEBUG Layer 98: Alpha: 3.50776265645448\n",
      "2018-11-26 13:42:25,106 DEBUG Layer 103: Alpha: 4.587098140023352\n",
      "2018-11-26 13:42:25,114 DEBUG Layer 105: Alpha compound: 3.657163792133013\n",
      "2018-11-26 13:42:25,116 DEBUG Layer 107: Alpha: 6.868421632536605\n",
      "2018-11-26 13:42:25,118 DEBUG Layer 114: Alpha: 1.6361684688078217\n",
      "2018-11-26 13:42:25,121 DEBUG Layer 116: Alpha compound: 1.4679958067091348\n",
      "2018-11-26 13:42:25,123 DEBUG Layer 118: Alpha: 1.4465828550231477\n",
      "2018-11-26 13:42:25,126 DEBUG Layer 122: Alpha: 1.767897509169574\n",
      "2018-11-26 13:42:25,128 DEBUG Layer 124: Alpha compound: 1.7441021324851702\n",
      "2018-11-26 13:42:25,130 DEBUG Layer 126: Alpha: 1.6670557855921913\n",
      "2018-11-26 13:42:25,132 DEBUG Layer 130: Alpha: 2.077725520625744\n",
      "2018-11-26 13:42:25,134 DEBUG Layer 132: Alpha compound: 1.8685634686330306\n",
      "2018-11-26 13:42:25,137 DEBUG Layer 134: Alpha: 1.5691945863074666\n",
      "2018-11-26 13:42:25,139 DEBUG Layer 138: Alpha: 1.7230241771370847\n",
      "2018-11-26 13:42:25,141 DEBUG Layer 140: Alpha compound: 1.9207452151149498\n",
      "2018-11-26 13:42:25,144 DEBUG Layer 142: Alpha: 1.796159506306808\n",
      "2018-11-26 13:42:25,148 DEBUG Layer 146: Alpha: 1.9788403505293908\n",
      "2018-11-26 13:42:25,151 DEBUG Layer 148: Alpha compound: 2.211380112851076\n",
      "2018-11-26 13:42:25,154 DEBUG Layer 150: Alpha: 3.6832288608324273\n",
      "2018-11-26 13:42:25,157 DEBUG Layer 154: Alpha: 1.7938326555859698\n",
      "2018-11-26 13:42:25,162 DEBUG Layer 156: Alpha compound: 2.043604079729395\n",
      "2018-11-26 13:42:25,168 DEBUG Layer 158: Alpha: 1.879154728869225\n",
      "2018-11-26 13:42:25,170 DEBUG Layer 162: Alpha: 1.8730054360230746\n",
      "2018-11-26 13:42:25,173 DEBUG Layer 164: Alpha compound: 2.0398855609878326\n",
      "2018-11-26 13:42:25,178 DEBUG Layer 166: Alpha: 3.837285486289572\n",
      "2018-11-26 13:42:25,180 DEBUG Layer 170: Alpha: 3.0737106863986097\n",
      "2018-11-26 13:42:25,182 DEBUG Layer 172: Alpha compound: 2.411783881847102\n",
      "2018-11-26 13:42:25,185 DEBUG Layer 174: Alpha: 5.947768431497339\n",
      "2018-11-26 13:42:25,189 DEBUG Layer 178: Alpha: 1.9926658517242501\n",
      "2018-11-26 13:42:25,195 DEBUG Layer 180: Alpha compound: 2.12548478663284\n",
      "2018-11-26 13:42:25,197 DEBUG Layer 182: Alpha: 3.99265189779358\n",
      "2018-11-26 13:42:25,200 DEBUG Layer 186: Alpha: 1.8894786863989337\n",
      "2018-11-26 13:42:25,204 DEBUG Layer 188: Alpha compound: 2.014743339679939\n",
      "2018-11-26 13:42:25,207 DEBUG Layer 190: Alpha: 1.9687286833878763\n",
      "2018-11-26 13:42:25,209 DEBUG Layer 194: Alpha: 1.7882470175214755\n",
      "2018-11-26 13:42:25,212 DEBUG Layer 196: Alpha compound: 1.9234449467729116\n",
      "2018-11-26 13:42:25,214 DEBUG Layer 198: Alpha: 1.688899193280236\n",
      "2018-11-26 13:42:25,217 DEBUG Layer 202: Alpha: 1.9354722979919479\n",
      "2018-11-26 13:42:25,220 DEBUG Layer 204: Alpha compound: 2.2168558625628143\n",
      "2018-11-26 13:42:25,222 DEBUG Layer 206: Alpha: 1.899464426852899\n",
      "2018-11-26 13:42:25,224 DEBUG Layer 210: Alpha: 1.8103305454503325\n",
      "2018-11-26 13:42:25,227 DEBUG Layer 212: Alpha compound: 2.1275528472681478\n",
      "2018-11-26 13:42:25,230 DEBUG Layer 214: Alpha: 3.666518239626001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:42:25,233 DEBUG Layer 218: Alpha: 2.0618652260958665\n",
      "2018-11-26 13:42:25,235 DEBUG Layer 220: Alpha compound: 3.30452860436082\n",
      "2018-11-26 13:42:25,238 DEBUG Layer 222: Alpha: 5.019555906853422\n",
      "2018-11-26 13:42:25,241 DEBUG Layer 226: Alpha: 2.305183108263292\n",
      "2018-11-26 13:42:25,244 DEBUG Layer 228: Alpha compound: 2.607186621323344\n",
      "2018-11-26 13:42:25,248 DEBUG Layer 230: Alpha: 3.076908498536858\n",
      "2018-11-26 13:42:25,251 DEBUG Layer 234: Alpha: 2.516305723832419\n",
      "2018-11-26 13:42:25,255 DEBUG Layer 236: Alpha compound: 2.734893960135018\n",
      "2018-11-26 13:42:25,258 DEBUG Layer 238: Alpha: 4.7691523748677165\n",
      "2018-11-26 13:42:25,261 DEBUG Layer 242: Alpha: 1.904988048103038\n",
      "2018-11-26 13:42:25,264 DEBUG Layer 244: Alpha compound: 2.090001273438105\n",
      "2018-11-26 13:42:25,266 DEBUG Layer 246: Alpha: 1.9620703781779296\n",
      "2018-11-26 13:42:25,269 DEBUG Layer 250: Alpha: 1.8516724217220992\n",
      "2018-11-26 13:42:25,272 DEBUG Layer 252: Alpha compound: 2.1657946947700637\n",
      "2018-11-26 13:42:25,275 DEBUG Layer 254: Alpha: 1.8506632151430722\n",
      "2018-11-26 13:42:25,277 DEBUG Layer 258: Alpha: 1.9540719209873008\n",
      "2018-11-26 13:42:25,279 DEBUG Layer 260: Alpha compound: 2.222148154842909\n",
      "2018-11-26 13:42:25,282 DEBUG Layer 262: Alpha: 1.7588113177154798\n",
      "2018-11-26 13:42:25,285 DEBUG Layer 266: Alpha: 3.1338209835660784\n",
      "2018-11-26 13:42:25,289 DEBUG Layer 268: Alpha compound: 2.2023478064796027\n",
      "2018-11-26 13:42:25,291 DEBUG Layer 270: Alpha: 1.8340597471999374\n",
      "2018-11-26 13:42:25,293 DEBUG Layer 274: Alpha: 2.0431723165965208\n",
      "2018-11-26 13:42:25,295 DEBUG Layer 276: Alpha compound: 2.3750489674084614\n",
      "2018-11-26 13:42:25,298 DEBUG Layer 278: Alpha: 2.465172624444918\n",
      "2018-11-26 13:42:25,300 DEBUG Layer 282: Alpha: 2.408289549897216\n",
      "2018-11-26 13:42:25,303 DEBUG Layer 284: Alpha compound: 2.214827543039441\n",
      "2018-11-26 13:42:25,306 DEBUG Layer 286: Alpha: 1.8652643023907873\n",
      "2018-11-26 13:42:25,309 DEBUG Layer 290: Alpha: 2.1075910077661755\n",
      "2018-11-26 13:42:25,314 DEBUG Layer 292: Alpha compound: 2.3410172831261935\n",
      "2018-11-26 13:42:25,316 DEBUG Layer 294: Alpha: 1.9313619977651189\n",
      "2018-11-26 13:42:25,319 DEBUG Layer 298: Alpha: 3.4706203116805936\n",
      "2018-11-26 13:42:25,321 DEBUG Layer 300: Alpha compound: 2.226869170244289\n",
      "2018-11-26 13:42:25,325 DEBUG Layer 302: Alpha: 2.1877402367038217\n",
      "2018-11-26 13:42:25,327 DEBUG Layer 306: Alpha: 2.09734280733449\n",
      "2018-11-26 13:42:25,330 DEBUG Layer 308: Alpha compound: 2.245844236390077\n",
      "2018-11-26 13:42:25,333 DEBUG Layer 310: Alpha: 2.6836034903430557\n",
      "2018-11-26 13:42:25,336 DEBUG Layer 314: Alpha: 2.7323627907387964\n",
      "2018-11-26 13:42:25,338 DEBUG Layer 316: Alpha compound: 2.262511450946496\n",
      "2018-11-26 13:42:25,341 DEBUG Layer 318: Alpha: 1.8550303651332525\n",
      "2018-11-26 13:42:25,346 DEBUG Layer 322: Alpha: 2.9434497396398953\n",
      "2018-11-26 13:42:25,350 DEBUG Layer 324: Alpha compound: 2.208751736077534\n",
      "2018-11-26 13:42:25,352 DEBUG Layer 326: Alpha: 1.9556801395591386\n",
      "2018-11-26 13:42:25,355 DEBUG Layer 330: Alpha: 1.9656835054563078\n",
      "2018-11-26 13:42:25,359 DEBUG Layer 332: Alpha compound: 2.068747175953387\n",
      "2018-11-26 13:42:25,365 DEBUG Layer 334: Alpha: 1.7536722392464759\n",
      "2018-11-26 13:42:25,367 DEBUG Layer 338: Alpha: 5.000358188534436\n",
      "2018-11-26 13:42:25,369 DEBUG Layer 340: Alpha compound: 2.734714503919024\n",
      "2018-11-26 13:42:25,373 DEBUG Layer 342: Alpha: 5.373003710995841\n",
      "2018-11-26 13:42:25,376 DEBUG Layer 346: Alpha: 2.5912870921674633\n",
      "2018-11-26 13:42:25,379 DEBUG Layer 348: Alpha compound: 2.690156089343025\n",
      "2018-11-26 13:42:25,384 DEBUG Layer 350: Alpha: 2.8045347378939995\n",
      "2018-11-26 13:42:25,387 DEBUG Layer 354: Alpha: 4.785703277149398\n",
      "2018-11-26 13:42:25,390 DEBUG Layer 356: Alpha compound: 3.0572440386715307\n",
      "2018-11-26 13:42:25,392 DEBUG Layer 358: Alpha: 5.334962961356717\n",
      "2018-11-26 13:42:25,394 DEBUG Layer 362: Alpha: 6.25211099016424\n",
      "2018-11-26 13:42:25,397 DEBUG Layer 364: Alpha compound: 4.399424848368407\n",
      "2018-11-26 13:42:25,400 DEBUG Layer 366: Alpha: 5.937839624552832\n",
      "2018-11-26 13:42:25,403 DEBUG Layer 370: Alpha: 4.808619117748233\n",
      "2018-11-26 13:42:25,405 DEBUG Layer 372: Alpha compound: 3.3517737844097386\n",
      "2018-11-26 13:42:25,407 DEBUG Layer 374: Alpha: 4.126028159167187\n",
      "2018-11-26 13:42:25,410 DEBUG Layer 378: Alpha: 4.988080785972596\n",
      "2018-11-26 13:42:25,415 DEBUG Layer 380: Alpha compound: 5.242615613203738\n",
      "2018-11-26 13:42:25,418 DEBUG Layer 382: Alpha: 5.484931185728635\n",
      "2018-11-26 13:42:25,420 DEBUG Layer 386: Alpha: 2.688407781414938\n",
      "2018-11-26 13:42:25,422 DEBUG Layer 388: Alpha compound: 3.0868191446490383\n",
      "2018-11-26 13:42:25,424 DEBUG Layer 390: Alpha: 2.824441356111112\n",
      "2018-11-26 13:42:25,427 INFO Alpha: min: 1.3111378014317996, max: 9.386195486708251, avg: 2.4422244233858392\n",
      "2018-11-26 13:42:25,429 INFO Alpha compound: min: 1.3111378014317996, max: 9.386195486708251, avg: 2.677333464187831\n",
      "2018-11-26 13:42:25,432 DEBUG Layer 7: Alpha Weigthed: 0.3823579733303639\n",
      "2018-11-26 13:42:25,435 DEBUG Layer 9: Alpha Weighted compound: -0.1558826896884985\n",
      "2018-11-26 13:42:25,438 DEBUG Layer 11: Alpha Weigthed: 1.7675651347431802\n",
      "2018-11-26 13:42:25,447 DEBUG Layer 15: Alpha Weigthed: 2.0171496361487833\n",
      "2018-11-26 13:42:25,450 DEBUG Layer 18: Alpha Weigthed: 0.2646658066960755\n",
      "2018-11-26 13:42:25,452 DEBUG Layer 20: Alpha Weighted compound: -1.014240216981471\n",
      "2018-11-26 13:42:25,454 DEBUG Layer 22: Alpha Weigthed: 0.553318941848482\n",
      "2018-11-26 13:42:25,457 DEBUG Layer 26: Alpha Weigthed: 0.24284691589151589\n",
      "2018-11-26 13:42:25,459 DEBUG Layer 28: Alpha Weighted compound: -0.691314999575719\n",
      "2018-11-26 13:42:25,466 DEBUG Layer 30: Alpha Weigthed: -1.0441823418441443\n",
      "2018-11-26 13:42:25,468 DEBUG Layer 35: Alpha Weigthed: 0.594926550864705\n",
      "2018-11-26 13:42:25,472 DEBUG Layer 37: Alpha Weighted compound: -0.32046335322167174\n",
      "2018-11-26 13:42:25,474 DEBUG Layer 39: Alpha Weigthed: 0.8260565706914399\n",
      "2018-11-26 13:42:25,479 DEBUG Layer 43: Alpha Weigthed: 1.214849132326766\n",
      "2018-11-26 13:42:25,482 DEBUG Layer 46: Alpha Weigthed: 0.5646565366299456\n",
      "2018-11-26 13:42:25,485 DEBUG Layer 48: Alpha Weighted compound: -0.19219986452305968\n",
      "2018-11-26 13:42:25,488 DEBUG Layer 50: Alpha Weigthed: 1.1189768927096695\n",
      "2018-11-26 13:42:25,491 DEBUG Layer 54: Alpha Weigthed: 0.10231469331911724\n",
      "2018-11-26 13:42:25,496 DEBUG Layer 56: Alpha Weighted compound: -0.7068648751562477\n",
      "2018-11-26 13:42:25,498 DEBUG Layer 58: Alpha Weigthed: -0.49399208733265787\n",
      "2018-11-26 13:42:25,503 DEBUG Layer 62: Alpha Weigthed: 0.5574673636920158\n",
      "2018-11-26 13:42:25,509 DEBUG Layer 64: Alpha Weighted compound: -0.5264225879123856\n",
      "2018-11-26 13:42:25,512 DEBUG Layer 66: Alpha Weigthed: -0.11019318466202829\n",
      "2018-11-26 13:42:25,515 DEBUG Layer 70: Alpha Weigthed: 0.5632357748968362\n",
      "2018-11-26 13:42:25,518 DEBUG Layer 72: Alpha Weighted compound: -0.6047784128280207\n",
      "2018-11-26 13:42:25,521 DEBUG Layer 74: Alpha Weigthed: 0.014351366709810057\n",
      "2018-11-26 13:42:25,526 DEBUG Layer 78: Alpha Weigthed: 0.249994135361749\n",
      "2018-11-26 13:42:25,528 DEBUG Layer 80: Alpha Weighted compound: -0.5052856904840936\n",
      "2018-11-26 13:42:25,531 DEBUG Layer 82: Alpha Weigthed: -0.04124898077877864\n",
      "2018-11-26 13:42:25,535 DEBUG Layer 86: Alpha Weigthed: 0.27349419835701394\n",
      "2018-11-26 13:42:25,538 DEBUG Layer 88: Alpha Weighted compound: -0.6280466901882108\n",
      "2018-11-26 13:42:25,541 DEBUG Layer 90: Alpha Weigthed: -0.00943170599899397\n",
      "2018-11-26 13:42:25,544 DEBUG Layer 94: Alpha Weigthed: 0.3832165642014882\n",
      "2018-11-26 13:42:25,547 DEBUG Layer 96: Alpha Weighted compound: -1.0708233536635232\n",
      "2018-11-26 13:42:25,551 DEBUG Layer 98: Alpha Weigthed: 0.12432218376795329\n",
      "2018-11-26 13:42:25,556 DEBUG Layer 103: Alpha Weigthed: 2.324607893323734\n",
      "2018-11-26 13:42:25,560 DEBUG Layer 105: Alpha Weighted compound: -1.4429205386842674\n",
      "2018-11-26 13:42:25,563 DEBUG Layer 107: Alpha Weigthed: 2.2366769861147766\n",
      "2018-11-26 13:42:25,566 DEBUG Layer 114: Alpha Weigthed: 0.4079548793566238\n",
      "2018-11-26 13:42:25,569 DEBUG Layer 116: Alpha Weighted compound: -0.5792020466118888\n",
      "2018-11-26 13:42:25,572 DEBUG Layer 118: Alpha Weigthed: -0.20929974598324294\n",
      "2018-11-26 13:42:25,575 DEBUG Layer 122: Alpha Weigthed: 0.42756348995963284\n",
      "2018-11-26 13:42:25,579 DEBUG Layer 124: Alpha Weighted compound: -0.5283283417093783\n",
      "2018-11-26 13:42:25,582 DEBUG Layer 126: Alpha Weigthed: -0.07372281555236648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-26 13:42:25,584 DEBUG Layer 130: Alpha Weigthed: 0.5918827809248614\n",
      "2018-11-26 13:42:25,588 DEBUG Layer 132: Alpha Weighted compound: -0.5976609656735529\n",
      "2018-11-26 13:42:25,590 DEBUG Layer 134: Alpha Weigthed: -0.013237431743550679\n",
      "2018-11-26 13:42:25,592 DEBUG Layer 138: Alpha Weigthed: 0.15936021255529134\n",
      "2018-11-26 13:42:25,595 DEBUG Layer 140: Alpha Weighted compound: -0.9193891549117479\n",
      "2018-11-26 13:42:25,599 DEBUG Layer 142: Alpha Weigthed: -0.001586218938883909\n",
      "2018-11-26 13:42:25,602 DEBUG Layer 146: Alpha Weigthed: 0.3011154525729266\n",
      "2018-11-26 13:42:25,604 DEBUG Layer 148: Alpha Weighted compound: -1.1755353158305353\n",
      "2018-11-26 13:42:25,607 DEBUG Layer 150: Alpha Weigthed: 0.2814701329356637\n",
      "2018-11-26 13:42:25,609 DEBUG Layer 154: Alpha Weigthed: -0.10441704828777558\n",
      "2018-11-26 13:42:25,612 DEBUG Layer 156: Alpha Weighted compound: -1.0236763127539565\n",
      "2018-11-26 13:42:25,614 DEBUG Layer 158: Alpha Weigthed: 0.09730791077837161\n",
      "2018-11-26 13:42:25,616 DEBUG Layer 162: Alpha Weigthed: 0.018352645051409423\n",
      "2018-11-26 13:42:25,619 DEBUG Layer 164: Alpha Weighted compound: -0.9513338610117148\n",
      "2018-11-26 13:42:25,621 DEBUG Layer 166: Alpha Weigthed: -0.02650448187341823\n",
      "2018-11-26 13:42:25,624 DEBUG Layer 170: Alpha Weigthed: -0.030464862793237176\n",
      "2018-11-26 13:42:25,628 DEBUG Layer 172: Alpha Weighted compound: -1.496892305530254\n",
      "2018-11-26 13:42:25,630 DEBUG Layer 174: Alpha Weigthed: -0.12483188901654398\n",
      "2018-11-26 13:42:25,632 DEBUG Layer 178: Alpha Weigthed: 0.2179593929694965\n",
      "2018-11-26 13:42:25,635 DEBUG Layer 180: Alpha Weighted compound: -0.9105630185316151\n",
      "2018-11-26 13:42:25,638 DEBUG Layer 182: Alpha Weigthed: 0.036854017515743784\n",
      "2018-11-26 13:42:25,640 DEBUG Layer 186: Alpha Weigthed: 0.1253190430587101\n",
      "2018-11-26 13:42:25,642 DEBUG Layer 188: Alpha Weighted compound: -0.8754286741691312\n",
      "2018-11-26 13:42:25,646 DEBUG Layer 190: Alpha Weigthed: -0.08844496843813021\n",
      "2018-11-26 13:42:25,650 DEBUG Layer 194: Alpha Weigthed: 0.2936078975757856\n",
      "2018-11-26 13:42:25,654 DEBUG Layer 196: Alpha Weighted compound: -0.5783190328683454\n",
      "2018-11-26 13:42:25,657 DEBUG Layer 198: Alpha Weigthed: 0.10430507555160122\n",
      "2018-11-26 13:42:25,659 DEBUG Layer 202: Alpha Weigthed: 0.07651470995834105\n",
      "2018-11-26 13:42:25,669 DEBUG Layer 204: Alpha Weighted compound: -1.1211826257825572\n",
      "2018-11-26 13:42:25,672 DEBUG Layer 206: Alpha Weigthed: -0.11752537872393803\n",
      "2018-11-26 13:42:25,674 DEBUG Layer 210: Alpha Weigthed: 0.2922004698373378\n",
      "2018-11-26 13:42:25,677 DEBUG Layer 212: Alpha Weighted compound: -0.8404699540500394\n",
      "2018-11-26 13:42:25,679 DEBUG Layer 214: Alpha Weigthed: -0.0019963829491094266\n",
      "2018-11-26 13:42:25,681 DEBUG Layer 218: Alpha Weigthed: 0.12251477361360692\n",
      "2018-11-26 13:42:25,683 DEBUG Layer 220: Alpha Weighted compound: -1.849009173318795\n",
      "2018-11-26 13:42:25,686 DEBUG Layer 222: Alpha Weigthed: 0.6146982955126611\n",
      "2018-11-26 13:42:25,689 DEBUG Layer 226: Alpha Weigthed: 0.29280085797490846\n",
      "2018-11-26 13:42:25,691 DEBUG Layer 228: Alpha Weighted compound: -1.3789179271455467\n",
      "2018-11-26 13:42:25,693 DEBUG Layer 230: Alpha Weigthed: -0.039446479366277855\n",
      "2018-11-26 13:42:25,696 DEBUG Layer 234: Alpha Weigthed: 0.08678285793668145\n",
      "2018-11-26 13:42:25,698 DEBUG Layer 236: Alpha Weighted compound: -1.3525830816975173\n",
      "2018-11-26 13:42:25,701 DEBUG Layer 238: Alpha Weigthed: 0.4435144453590484\n",
      "2018-11-26 13:42:25,704 DEBUG Layer 242: Alpha Weigthed: -0.057254851305566616\n",
      "2018-11-26 13:42:25,708 DEBUG Layer 244: Alpha Weighted compound: -0.9737113861989369\n",
      "2018-11-26 13:42:25,711 DEBUG Layer 246: Alpha Weigthed: 0.07557437707384575\n",
      "2018-11-26 13:42:25,713 DEBUG Layer 250: Alpha Weigthed: 0.10291285154390853\n",
      "2018-11-26 13:42:25,716 DEBUG Layer 252: Alpha Weighted compound: -0.9109335429204783\n",
      "2018-11-26 13:42:25,719 DEBUG Layer 254: Alpha Weigthed: -0.17918036553114275\n",
      "2018-11-26 13:42:25,723 DEBUG Layer 258: Alpha Weigthed: 0.2661217591131321\n",
      "2018-11-26 13:42:25,726 DEBUG Layer 260: Alpha Weighted compound: -0.943778655125093\n",
      "2018-11-26 13:42:25,728 DEBUG Layer 262: Alpha Weigthed: -0.0965230027818899\n",
      "2018-11-26 13:42:25,731 DEBUG Layer 266: Alpha Weigthed: 0.09068512557163831\n",
      "2018-11-26 13:42:25,734 DEBUG Layer 268: Alpha Weighted compound: -1.0658201008904766\n",
      "2018-11-26 13:42:25,736 DEBUG Layer 270: Alpha Weigthed: 0.043909984498447345\n",
      "2018-11-26 13:42:25,740 DEBUG Layer 274: Alpha Weigthed: -0.010059692346926032\n",
      "2018-11-26 13:42:25,743 DEBUG Layer 276: Alpha Weighted compound: -1.2468034320821832\n",
      "2018-11-26 13:42:25,745 DEBUG Layer 278: Alpha Weigthed: -0.178430367239698\n",
      "2018-11-26 13:42:25,749 DEBUG Layer 282: Alpha Weigthed: 0.32181268102475746\n",
      "2018-11-26 13:42:25,751 DEBUG Layer 284: Alpha Weighted compound: -1.0707483314030837\n",
      "2018-11-26 13:42:25,754 DEBUG Layer 286: Alpha Weigthed: 0.022348438991179373\n",
      "2018-11-26 13:42:25,756 DEBUG Layer 290: Alpha Weigthed: 0.3494338892088883\n",
      "2018-11-26 13:42:25,759 DEBUG Layer 292: Alpha Weighted compound: -1.0190204375473784\n",
      "2018-11-26 13:42:25,761 DEBUG Layer 294: Alpha Weigthed: -0.04730132302726143\n",
      "2018-11-26 13:42:25,764 DEBUG Layer 298: Alpha Weigthed: 0.10739093478511834\n",
      "2018-11-26 13:42:25,769 DEBUG Layer 300: Alpha Weighted compound: -1.1936171874477433\n",
      "2018-11-26 13:42:25,771 DEBUG Layer 302: Alpha Weigthed: -0.09706549328150052\n",
      "2018-11-26 13:42:25,773 DEBUG Layer 306: Alpha Weigthed: 0.04355015732071627\n",
      "2018-11-26 13:42:25,775 DEBUG Layer 308: Alpha Weighted compound: -1.0817964438859258\n",
      "2018-11-26 13:42:25,778 DEBUG Layer 310: Alpha Weigthed: 0.2921080066928639\n",
      "2018-11-26 13:42:25,781 DEBUG Layer 314: Alpha Weigthed: 0.18075960708137526\n",
      "2018-11-26 13:42:25,785 DEBUG Layer 316: Alpha Weighted compound: -0.9959649917837962\n",
      "2018-11-26 13:42:25,789 DEBUG Layer 318: Alpha Weigthed: 0.0384138345790712\n",
      "2018-11-26 13:42:25,792 DEBUG Layer 322: Alpha Weigthed: 0.06035152753861906\n",
      "2018-11-26 13:42:25,794 DEBUG Layer 324: Alpha Weighted compound: -1.1576268146515318\n",
      "2018-11-26 13:42:25,796 DEBUG Layer 326: Alpha Weigthed: -0.19166491039445632\n",
      "2018-11-26 13:42:25,799 DEBUG Layer 330: Alpha Weigthed: 0.06694178049496388\n",
      "2018-11-26 13:42:25,801 DEBUG Layer 332: Alpha Weighted compound: -0.9515322258246827\n",
      "2018-11-26 13:42:25,804 DEBUG Layer 334: Alpha Weigthed: 0.005448984910623735\n",
      "2018-11-26 13:42:25,806 DEBUG Layer 338: Alpha Weigthed: 0.36165410334832954\n",
      "2018-11-26 13:42:25,809 DEBUG Layer 340: Alpha Weighted compound: -1.414959658530607\n",
      "2018-11-26 13:42:25,811 DEBUG Layer 342: Alpha Weigthed: 0.4876243935610582\n",
      "2018-11-26 13:42:25,813 DEBUG Layer 346: Alpha Weigthed: 0.5367403229882626\n",
      "2018-11-26 13:42:25,816 DEBUG Layer 348: Alpha Weighted compound: -1.3141340805085338\n",
      "2018-11-26 13:42:25,818 DEBUG Layer 350: Alpha Weigthed: 0.2938255178382826\n",
      "2018-11-26 13:42:25,820 DEBUG Layer 354: Alpha Weigthed: 0.5424206557296644\n",
      "2018-11-26 13:42:25,823 DEBUG Layer 356: Alpha Weighted compound: -1.6632463242000628\n",
      "2018-11-26 13:42:25,825 DEBUG Layer 358: Alpha Weigthed: 0.6563850547383878\n",
      "2018-11-26 13:42:25,827 DEBUG Layer 362: Alpha Weigthed: 1.1858598562585836\n",
      "2018-11-26 13:42:25,830 DEBUG Layer 364: Alpha Weighted compound: -2.3039616671949408\n",
      "2018-11-26 13:42:25,832 DEBUG Layer 366: Alpha Weigthed: 0.42164250271169407\n",
      "2018-11-26 13:42:25,835 DEBUG Layer 370: Alpha Weigthed: 0.9935994102192495\n",
      "2018-11-26 13:42:25,837 DEBUG Layer 372: Alpha Weighted compound: -1.82078459071264\n",
      "2018-11-26 13:42:25,840 DEBUG Layer 374: Alpha Weigthed: 0.9967273721287861\n",
      "2018-11-26 13:42:25,853 DEBUG Layer 378: Alpha Weigthed: 1.464737888055083\n",
      "2018-11-26 13:42:25,856 DEBUG Layer 380: Alpha Weighted compound: -3.236116688281448\n",
      "2018-11-26 13:42:25,859 DEBUG Layer 382: Alpha Weigthed: 1.5849998183038938\n",
      "2018-11-26 13:42:25,862 DEBUG Layer 386: Alpha Weigthed: 0.6287320780728163\n",
      "2018-11-26 13:42:25,865 DEBUG Layer 388: Alpha Weighted compound: -1.3121211048713342\n",
      "2018-11-26 13:42:25,868 DEBUG Layer 390: Alpha Weigthed: 0.9027964683765938\n",
      "2018-11-26 13:42:25,874 INFO Alpha Weighted: min: -4.872102626210831, max: 2.324607893323734, avg: -0.8021639317762796\n",
      "2018-11-26 13:42:25,879 INFO Alpha Weighted compound: min: -3.236116688281448, max: 2.324607893323734, avg: -0.13012432701658871\n"
     ]
    }
   ],
   "source": [
    "w_alphas_4model = {}\n",
    "w_alphas_4model_alpha_weighted_compound = {}\n",
    "w_alphas_4model_alpha = {}\n",
    "w_alphas_4model_alpha_compound = {}\n",
    "w_alphas_4model_lognorm = {}\n",
    "w_alphas_4model_lognorm_compound = {}\n",
    "        \n",
    "#counts_4model = {}\n",
    "#models = [m.lower().replace('-','') for m in df['model'].values]\n",
    "model_names = []\n",
    "\n",
    "def update_model(model_name, model):\n",
    "    print(model_name)\n",
    "    results = calc_model_weighted_alphas(model)\n",
    "    w_alphas_4model[model_name] = [results[\"alpha_weighted\"]]\n",
    "    w_alphas_4model_alpha_weighted_compound[model_name] = [results[\"alpha_weighted_compound\"]]\n",
    "    w_alphas_4model_alpha[model_name] = [results[\"alpha\"]]\n",
    "    w_alphas_4model_alpha_compound[model_name] = [results[\"alpha_compound\"]]\n",
    "    w_alphas_4model_lognorm[model_name] = [results[\"lognorm\"]]\n",
    "    w_alphas_4model_lognorm_compound[model_name] = [results[\"lognorm_compound\"]]\n",
    "    #counts_4model[model_name] = count_layers(model)\n",
    "    model_names.append(model_name)\n",
    "    \n",
    "    \n",
    "try:\n",
    "    model_name = 'vgg11'\n",
    "    model = models.vgg11(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "\n",
    "    model_name = 'vgg11_bn'\n",
    "    model = models.vgg11_bn(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "    \n",
    "    model_name = 'vgg13'\n",
    "    model = models.vgg13(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "   \n",
    "    model_name = 'vgg13_bn'\n",
    "    model = models.vgg13_bn(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "    \n",
    "    model_name = 'vgg16'\n",
    "    model = models.vgg16(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "   \n",
    "    model_name = 'vgg16_bn'\n",
    "    model = models.vgg16_bn(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "    \n",
    "    model_name = 'vgg19'\n",
    "    model = models.vgg19(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "   \n",
    "    model_name = 'vgg19_bn'\n",
    "    model = models.vgg19_bn(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "\n",
    "    model_name = 'squeezenet1_0'\n",
    "    model = models.squeezenet1_0(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "    \n",
    "    model_name = 'squeezenet1_1'\n",
    "    model = models.squeezenet1_1(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "    \n",
    "    model_name = 'densenet121'\n",
    "    model = models.densenet121(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "    \n",
    "    model_name = 'densenet161'\n",
    "    model = models.densenet161(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "    \n",
    "    model_name = 'densenet169'\n",
    "    model = models.densenet169(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "    \n",
    "    model_name = 'densenet201'\n",
    "    model = models.densenet201(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "    \n",
    "    model_name = 'resnet18'\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "    \n",
    "    model_name = 'resnet34'\n",
    "    model = models.resnet34(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "        \n",
    "    model_name = 'resnet50'\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "\n",
    "    model_name = 'resnet101'\n",
    "    model = models.resnet101(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "\n",
    "    model_name = 'resnet152'\n",
    "    model = models.resnet152(pretrained=True)\n",
    "    update_model(model_name, model)\n",
    "    \n",
    "    \n",
    "except Exception as e: \n",
    "\n",
    "    print(\"skipping \", model_name)\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:44:30.055917Z",
     "start_time": "2018-11-26T22:44:30.013474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>platform</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ResNet152</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>78.428</td>\n",
       "      <td>94.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DenseNet161</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.560</td>\n",
       "      <td>93.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ResNet101</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.438</td>\n",
       "      <td>93.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>InceptionV3</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.294</td>\n",
       "      <td>93.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DenseNet201</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.152</td>\n",
       "      <td>93.548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model platform    acc1    acc5\n",
       "27    ResNet152  Pytorch  78.428  94.110\n",
       "34  DenseNet161  Pytorch  77.560  93.798\n",
       "35    ResNet101  Pytorch  77.438  93.672\n",
       "37  InceptionV3  Pytorch  77.294  93.454\n",
       "38  DenseNet201  Pytorch  77.152  93.548"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:44:31.147158Z",
     "start_time": "2018-11-26T22:44:31.074779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>platform</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc5</th>\n",
       "      <th>modelname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ResNet152</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>78.428</td>\n",
       "      <td>94.110</td>\n",
       "      <td>resnet152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DenseNet161</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.560</td>\n",
       "      <td>93.798</td>\n",
       "      <td>densenet161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ResNet101</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.438</td>\n",
       "      <td>93.672</td>\n",
       "      <td>resnet101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>InceptionV3</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.294</td>\n",
       "      <td>93.454</td>\n",
       "      <td>inceptionv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DenseNet201</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.152</td>\n",
       "      <td>93.548</td>\n",
       "      <td>densenet201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DenseNet169</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>76.026</td>\n",
       "      <td>92.992</td>\n",
       "      <td>densenet169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ResNet50</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>76.002</td>\n",
       "      <td>92.980</td>\n",
       "      <td>resnet50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DenseNet121</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>74.646</td>\n",
       "      <td>92.136</td>\n",
       "      <td>densenet121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>VGG19_BN</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>74.266</td>\n",
       "      <td>92.066</td>\n",
       "      <td>vgg19_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ResNet34</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>73.554</td>\n",
       "      <td>91.456</td>\n",
       "      <td>resnet34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>VGG16_BN</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>73.518</td>\n",
       "      <td>91.608</td>\n",
       "      <td>vgg16_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>VGG19</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>72.080</td>\n",
       "      <td>90.822</td>\n",
       "      <td>vgg19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>VGG16</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>71.636</td>\n",
       "      <td>90.354</td>\n",
       "      <td>vgg16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>VGG13_BN</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>71.508</td>\n",
       "      <td>90.494</td>\n",
       "      <td>vgg13_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>VGG11_BN</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>70.452</td>\n",
       "      <td>89.818</td>\n",
       "      <td>vgg11_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>70.142</td>\n",
       "      <td>89.274</td>\n",
       "      <td>resnet18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>VGG13</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>69.662</td>\n",
       "      <td>89.264</td>\n",
       "      <td>vgg13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>VGG11</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>68.970</td>\n",
       "      <td>88.746</td>\n",
       "      <td>vgg11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SqueezeNet1_1</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>58.250</td>\n",
       "      <td>80.800</td>\n",
       "      <td>squeezenet1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SqueezeNet1_0</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>58.108</td>\n",
       "      <td>80.428</td>\n",
       "      <td>squeezenet1_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Alexnet</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>56.432</td>\n",
       "      <td>79.194</td>\n",
       "      <td>alexnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PNASNet-5-Large</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>82.736</td>\n",
       "      <td>95.992</td>\n",
       "      <td>pnasnet5large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NASNet-A-Large</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>82.566</td>\n",
       "      <td>96.086</td>\n",
       "      <td>nasnetalarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SENet154</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>81.304</td>\n",
       "      <td>95.498</td>\n",
       "      <td>senet154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PolyNet</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>81.002</td>\n",
       "      <td>95.624</td>\n",
       "      <td>polynet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SE-ResNeXt101_32x4d</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>80.236</td>\n",
       "      <td>95.028</td>\n",
       "      <td>seresnext101_32x4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>InceptionResNetV2</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>80.170</td>\n",
       "      <td>95.234</td>\n",
       "      <td>inceptionresnetv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>InceptionV4</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>80.062</td>\n",
       "      <td>94.926</td>\n",
       "      <td>inceptionv4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DualPathNet107_5k</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.746</td>\n",
       "      <td>94.684</td>\n",
       "      <td>dualpathnet107_5k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DualPathNet131</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.432</td>\n",
       "      <td>94.574</td>\n",
       "      <td>dualpathnet131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DualPathNet92_5k</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.400</td>\n",
       "      <td>94.620</td>\n",
       "      <td>dualpathnet92_5k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DualPathNet98</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.224</td>\n",
       "      <td>94.488</td>\n",
       "      <td>dualpathnet98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SE-ResNeXt50_32x4d</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.076</td>\n",
       "      <td>94.434</td>\n",
       "      <td>seresnext50_32x4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ResNeXt101_64x4d</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.956</td>\n",
       "      <td>94.252</td>\n",
       "      <td>resnext101_64x4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Xception</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.888</td>\n",
       "      <td>94.292</td>\n",
       "      <td>xception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SE-ResNet152</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.658</td>\n",
       "      <td>94.374</td>\n",
       "      <td>seresnet152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SE-ResNet101</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.396</td>\n",
       "      <td>94.258</td>\n",
       "      <td>seresnet101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ResNeXt101_32x4d</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.188</td>\n",
       "      <td>93.886</td>\n",
       "      <td>resnext101_32x4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SE-ResNet50</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>77.636</td>\n",
       "      <td>93.752</td>\n",
       "      <td>seresnet50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FBResNet152</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>77.386</td>\n",
       "      <td>93.594</td>\n",
       "      <td>fbresnet152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DualPathNet68b_5k</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>77.034</td>\n",
       "      <td>93.590</td>\n",
       "      <td>dualpathnet68b_5k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>CaffeResnet101</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>76.200</td>\n",
       "      <td>92.766</td>\n",
       "      <td>cafferesnet101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DualPathNet68</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>75.868</td>\n",
       "      <td>92.774</td>\n",
       "      <td>dualpathnet68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NASNet-A-Mobile</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>74.080</td>\n",
       "      <td>91.740</td>\n",
       "      <td>nasnetamobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>BNInception</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>73.522</td>\n",
       "      <td>91.560</td>\n",
       "      <td>bninception</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model    platform    acc1    acc5           modelname\n",
       "27            ResNet152     Pytorch  78.428  94.110           resnet152\n",
       "34          DenseNet161     Pytorch  77.560  93.798         densenet161\n",
       "35            ResNet101     Pytorch  77.438  93.672           resnet101\n",
       "37          InceptionV3     Pytorch  77.294  93.454         inceptionv3\n",
       "38          DenseNet201     Pytorch  77.152  93.548         densenet201\n",
       "42          DenseNet169     Pytorch  76.026  92.992         densenet169\n",
       "43             ResNet50     Pytorch  76.002  92.980            resnet50\n",
       "45          DenseNet121     Pytorch  74.646  92.136         densenet121\n",
       "46             VGG19_BN     Pytorch  74.266  92.066            vgg19_bn\n",
       "49             ResNet34     Pytorch  73.554  91.456            resnet34\n",
       "51             VGG16_BN     Pytorch  73.518  91.608            vgg16_bn\n",
       "52                VGG19     Pytorch  72.080  90.822               vgg19\n",
       "53                VGG16     Pytorch  71.636  90.354               vgg16\n",
       "54             VGG13_BN     Pytorch  71.508  90.494            vgg13_bn\n",
       "55             VGG11_BN     Pytorch  70.452  89.818            vgg11_bn\n",
       "56             ResNet18     Pytorch  70.142  89.274            resnet18\n",
       "57                VGG13     Pytorch  69.662  89.264               vgg13\n",
       "58                VGG11     Pytorch  68.970  88.746               vgg11\n",
       "59        SqueezeNet1_1     Pytorch  58.250  80.800       squeezenet1_1\n",
       "60        SqueezeNet1_0     Pytorch  58.108  80.428       squeezenet1_0\n",
       "61              Alexnet     Pytorch  56.432  79.194             alexnet\n",
       "1       PNASNet-5-Large  ourporting  82.736  95.992       pnasnet5large\n",
       "3        NASNet-A-Large  ourporting  82.566  96.086        nasnetalarge\n",
       "5              SENet154  ourporting  81.304  95.498            senet154\n",
       "7               PolyNet  ourporting  81.002  95.624             polynet\n",
       "10  SE-ResNeXt101_32x4d  ourporting  80.236  95.028  seresnext101_32x4d\n",
       "12    InceptionResNetV2  ourporting  80.170  95.234   inceptionresnetv2\n",
       "13          InceptionV4  ourporting  80.062  94.926         inceptionv4\n",
       "14    DualPathNet107_5k  ourporting  79.746  94.684   dualpathnet107_5k\n",
       "16       DualPathNet131  ourporting  79.432  94.574      dualpathnet131\n",
       "17     DualPathNet92_5k  ourporting  79.400  94.620    dualpathnet92_5k\n",
       "18        DualPathNet98  ourporting  79.224  94.488       dualpathnet98\n",
       "19   SE-ResNeXt50_32x4d  ourporting  79.076  94.434   seresnext50_32x4d\n",
       "22     ResNeXt101_64x4d  ourporting  78.956  94.252    resnext101_64x4d\n",
       "23             Xception  ourporting  78.888  94.292            xception\n",
       "26         SE-ResNet152  ourporting  78.658  94.374         seresnet152\n",
       "28         SE-ResNet101  ourporting  78.396  94.258         seresnet101\n",
       "30     ResNeXt101_32x4d  ourporting  78.188  93.886    resnext101_32x4d\n",
       "33          SE-ResNet50  ourporting  77.636  93.752          seresnet50\n",
       "36          FBResNet152  ourporting  77.386  93.594         fbresnet152\n",
       "39    DualPathNet68b_5k  ourporting  77.034  93.590   dualpathnet68b_5k\n",
       "41       CaffeResnet101  ourporting  76.200  92.766      cafferesnet101\n",
       "44        DualPathNet68  ourporting  75.868  92.774       dualpathnet68\n",
       "48      NASNet-A-Mobile  ourporting  74.080  91.740       nasnetamobile\n",
       "50          BNInception  ourporting  73.522  91.560         bninception"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['modelname'] = df['model'].apply(lambda x: x.lower().replace('-',''))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:44:32.216870Z",
     "start_time": "2018-11-26T22:44:32.193073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27             resnet152\n",
       "34           densenet161\n",
       "35             resnet101\n",
       "37           inceptionv3\n",
       "38           densenet201\n",
       "42           densenet169\n",
       "43              resnet50\n",
       "45           densenet121\n",
       "46              vgg19_bn\n",
       "49              resnet34\n",
       "51              vgg16_bn\n",
       "52                 vgg19\n",
       "53                 vgg16\n",
       "54              vgg13_bn\n",
       "55              vgg11_bn\n",
       "56              resnet18\n",
       "57                 vgg13\n",
       "58                 vgg11\n",
       "59         squeezenet1_1\n",
       "60         squeezenet1_0\n",
       "61               alexnet\n",
       "1          pnasnet5large\n",
       "3           nasnetalarge\n",
       "5               senet154\n",
       "7                polynet\n",
       "10    seresnext101_32x4d\n",
       "12     inceptionresnetv2\n",
       "13           inceptionv4\n",
       "14     dualpathnet107_5k\n",
       "16        dualpathnet131\n",
       "17      dualpathnet92_5k\n",
       "18         dualpathnet98\n",
       "19     seresnext50_32x4d\n",
       "22      resnext101_64x4d\n",
       "23              xception\n",
       "26           seresnet152\n",
       "28           seresnet101\n",
       "30      resnext101_32x4d\n",
       "33            seresnet50\n",
       "36           fbresnet152\n",
       "39     dualpathnet68b_5k\n",
       "41        cafferesnet101\n",
       "44         dualpathnet68\n",
       "48         nasnetamobile\n",
       "50           bninception\n",
       "Name: modelname, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['modelname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:44:42.861255Z",
     "start_time": "2018-11-26T22:44:42.845453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vgg11': [1.19819587497525],\n",
       " 'vgg11_bn': [0.9891611957397056],\n",
       " 'vgg13': [1.0943638733440382],\n",
       " 'vgg13_bn': [0.8176188256941758],\n",
       " 'vgg16': [0.8957290672189769],\n",
       " 'vgg16_bn': [0.47535733440982914],\n",
       " 'vgg19': [0.7002160694567952],\n",
       " 'vgg19_bn': [0.18828493796685364],\n",
       " 'squeezenet1_0': [1.8380885802802895],\n",
       " 'squeezenet1_1': [1.4435361290900248],\n",
       " 'densenet121': [1.1105696924003263],\n",
       " 'densenet161': [0.6934332647302267],\n",
       " 'densenet169': [0.559491335883485],\n",
       " 'densenet201': [0.3950056706870469],\n",
       " 'resnet18': [0.3906661929923877],\n",
       " 'resnet34': [-0.4285858853645758],\n",
       " 'resnet50': [0.03924750757577274],\n",
       " 'resnet101': [-0.6140440994909098],\n",
       " 'resnet152': [-0.8021639317762796]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_alphas_4model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:44:45.204204Z",
     "start_time": "2018-11-26T22:44:45.190705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'squeezenet1_0', 'squeezenet1_1', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_alphas_4model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:44:47.497907Z",
     "start_time": "2018-11-26T22:44:47.481702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.19819587497525"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_alphas_4model['vgg11'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:44:49.430085Z",
     "start_time": "2018-11-26T22:44:49.414264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vgg11': [1.1981958749752497],\n",
       " 'vgg11_bn': [0.9891611957397056],\n",
       " 'vgg13': [1.0943638733440382],\n",
       " 'vgg13_bn': [0.8176188256941758],\n",
       " 'vgg16': [0.8957290672189769],\n",
       " 'vgg16_bn': [0.4753573344098291],\n",
       " 'vgg19': [0.7002160694567952],\n",
       " 'vgg19_bn': [0.1882849379668536],\n",
       " 'squeezenet1_0': [3.60832672465874],\n",
       " 'squeezenet1_1': [3.371930224138348],\n",
       " 'densenet121': [1.1105696924003263],\n",
       " 'densenet161': [0.6934332647302267],\n",
       " 'densenet169': [0.559491335883485],\n",
       " 'densenet201': [0.3950056706870469],\n",
       " 'resnet18': [0.551725907309536],\n",
       " 'resnet34': [-0.2972084352830778],\n",
       " 'resnet50': [1.003215963933486],\n",
       " 'resnet101': [0.08751584794043292],\n",
       " 'resnet152': [-0.13012432701658871]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_alphas_4model_alpha_weighted_compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:44:54.267135Z",
     "start_time": "2018-11-26T22:44:54.246809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vgg11': [0.8541991],\n",
       " 'vgg11_bn': [0.77639276],\n",
       " 'vgg13': [0.76070833],\n",
       " 'vgg13_bn': [0.6695178],\n",
       " 'vgg16': [0.73495764],\n",
       " 'vgg16_bn': [0.6321088],\n",
       " 'vgg19': [0.7228154],\n",
       " 'vgg19_bn': [0.579767],\n",
       " 'squeezenet1_0': [0.7795777],\n",
       " 'squeezenet1_1': [0.7426441],\n",
       " 'densenet121': [0.78310287],\n",
       " 'densenet161': [0.72554755],\n",
       " 'densenet169': [0.72277504],\n",
       " 'densenet201': [0.702473],\n",
       " 'resnet18': [0.6320621],\n",
       " 'resnet34': [0.52999717],\n",
       " 'resnet50': [0.5391178],\n",
       " 'resnet101': [0.43045926],\n",
       " 'resnet152': [0.38206214]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_alphas_4model_lognorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:44:56.936373Z",
     "start_time": "2018-11-26T22:44:56.921130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vgg11': [0.854199061791102],\n",
       " 'vgg11_bn': [0.7763927396800783],\n",
       " 'vgg13': [0.7607083530337722],\n",
       " 'vgg13_bn': [0.6695177130125188],\n",
       " 'vgg16': [0.7349576202649919],\n",
       " 'vgg16_bn': [0.6321087796536703],\n",
       " 'vgg19': [0.7228153952293925],\n",
       " 'vgg19_bn': [0.5797670655366447],\n",
       " 'squeezenet1_0': [0.956530460604915],\n",
       " 'squeezenet1_1': [0.9343577557139926],\n",
       " 'densenet121': [0.7831028774380684],\n",
       " 'densenet161': [0.7255475411686716],\n",
       " 'densenet169': [0.7227750966946284],\n",
       " 'densenet201': [0.7024730271100998],\n",
       " 'resnet18': [0.6743103071219392],\n",
       " 'resnet34': [0.5608402093803442],\n",
       " 'resnet50': [0.7219960650575517],\n",
       " 'resnet101': [0.6224833149207049],\n",
       " 'resnet152': [0.5780920999615997]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_alphas_4model_lognorm_compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:45:01.520830Z",
     "start_time": "2018-11-26T22:45:01.483359Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_w_alphas = {}\n",
    "len_w_alphas = {}\n",
    "alpha_weighted_compound = {}\n",
    "aa_alpha = {}\n",
    "aa_alpha_compound = {}\n",
    "aa_lognorm = {}\n",
    "aa_lognorm_compound = {}\n",
    "\n",
    "for model_name in df['modelname'].values:\n",
    "    avg_w_alphas[model_name] = 0.0\n",
    "    len_w_alphas[model_name] = 0.0\n",
    "    alpha_weighted_compound[model_name] = 0.0\n",
    "    aa_alpha[model_name] = 0.0\n",
    "    aa_alpha_compound[model_name] = 0.0\n",
    "    aa_lognorm[model_name] = 0.0\n",
    "    aa_lognorm_compound[model_name] = 0.0\n",
    "    \n",
    "    if(model_name in w_alphas_4model):\n",
    "        avg_w_alphas[model_name] = np.average(w_alphas_4model[model_name])\n",
    "        len_w_alphas[model_name] = len(w_alphas_4model[model_name])\n",
    "    \n",
    "    if(model_name in w_alphas_4model_alpha_weighted_compound):\n",
    "        alpha_weighted_compound[model_name] = np.average(w_alphas_4model_alpha_weighted_compound[model_name])\n",
    "    \n",
    "    if(model_name in w_alphas_4model_alpha):\n",
    "        aa_alpha[model_name] = np.average(w_alphas_4model_alpha[model_name])\n",
    "    \n",
    "    if(model_name in w_alphas_4model_alpha_compound):\n",
    "        aa_alpha_compound[model_name] = np.average(w_alphas_4model_alpha_compound[model_name])\n",
    "    \n",
    "    if(model_name in w_alphas_4model_lognorm):\n",
    "        aa_lognorm[model_name] = np.average(w_alphas_4model_lognorm[model_name])\n",
    "    \n",
    "    if(model_name in w_alphas_4model_lognorm_compound):\n",
    "        aa_lognorm_compound[model_name] = np.average(w_alphas_4model_lognorm_compound[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:45:04.266022Z",
     "start_time": "2018-11-26T22:45:04.223975Z"
    }
   },
   "outputs": [],
   "source": [
    "df['avg_w_alphas'] = df['modelname'].apply(lambda x: avg_w_alphas[x] )\n",
    "df['num_layers'] = df['modelname'].apply(lambda x: int(len_w_alphas[x]) )\n",
    "df['alpha_weighted_compound'] = df['modelname'].apply(lambda x: alpha_weighted_compound[x] )\n",
    "df['alpha'] = df['modelname'].apply(lambda x: aa_alpha[x] )\n",
    "df['alpha_compound'] = df['modelname'].apply(lambda x: aa_alpha_compound[x] )\n",
    "df['lognorm'] = df['modelname'].apply(lambda x: aa_lognorm[x] )\n",
    "df['lognorm_compound'] = df['modelname'].apply(lambda x: aa_lognorm_compound[x] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:45:16.017791Z",
     "start_time": "2018-11-26T22:45:15.900967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>platform</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc5</th>\n",
       "      <th>modelname</th>\n",
       "      <th>avg_w_alphas</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>alpha_weighted_compound</th>\n",
       "      <th>alpha</th>\n",
       "      <th>alpha_compound</th>\n",
       "      <th>lognorm</th>\n",
       "      <th>lognorm_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Alexnet</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>56.432</td>\n",
       "      <td>79.194</td>\n",
       "      <td>alexnet</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>BNInception</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>73.522</td>\n",
       "      <td>91.560</td>\n",
       "      <td>bninception</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>CaffeResnet101</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>76.200</td>\n",
       "      <td>92.766</td>\n",
       "      <td>cafferesnet101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DenseNet121</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>74.646</td>\n",
       "      <td>92.136</td>\n",
       "      <td>densenet121</td>\n",
       "      <td>1.110570</td>\n",
       "      <td>1</td>\n",
       "      <td>1.110570</td>\n",
       "      <td>4.273254</td>\n",
       "      <td>4.273254</td>\n",
       "      <td>0.783103</td>\n",
       "      <td>0.783103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DenseNet161</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.560</td>\n",
       "      <td>93.798</td>\n",
       "      <td>densenet161</td>\n",
       "      <td>0.693433</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693433</td>\n",
       "      <td>3.619427</td>\n",
       "      <td>3.619427</td>\n",
       "      <td>0.725548</td>\n",
       "      <td>0.725548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DenseNet169</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>76.026</td>\n",
       "      <td>92.992</td>\n",
       "      <td>densenet169</td>\n",
       "      <td>0.559491</td>\n",
       "      <td>1</td>\n",
       "      <td>0.559491</td>\n",
       "      <td>4.285921</td>\n",
       "      <td>4.285921</td>\n",
       "      <td>0.722775</td>\n",
       "      <td>0.722775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DenseNet201</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.152</td>\n",
       "      <td>93.548</td>\n",
       "      <td>densenet201</td>\n",
       "      <td>0.395006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395006</td>\n",
       "      <td>4.120117</td>\n",
       "      <td>4.120117</td>\n",
       "      <td>0.702473</td>\n",
       "      <td>0.702473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DualPathNet107_5k</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.746</td>\n",
       "      <td>94.684</td>\n",
       "      <td>dualpathnet107_5k</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DualPathNet131</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.432</td>\n",
       "      <td>94.574</td>\n",
       "      <td>dualpathnet131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DualPathNet68</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>75.868</td>\n",
       "      <td>92.774</td>\n",
       "      <td>dualpathnet68</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DualPathNet68b_5k</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>77.034</td>\n",
       "      <td>93.590</td>\n",
       "      <td>dualpathnet68b_5k</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DualPathNet92_5k</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.400</td>\n",
       "      <td>94.620</td>\n",
       "      <td>dualpathnet92_5k</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DualPathNet98</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.224</td>\n",
       "      <td>94.488</td>\n",
       "      <td>dualpathnet98</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FBResNet152</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>77.386</td>\n",
       "      <td>93.594</td>\n",
       "      <td>fbresnet152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>InceptionResNetV2</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>80.170</td>\n",
       "      <td>95.234</td>\n",
       "      <td>inceptionresnetv2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>InceptionV3</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.294</td>\n",
       "      <td>93.454</td>\n",
       "      <td>inceptionv3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>InceptionV4</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>80.062</td>\n",
       "      <td>94.926</td>\n",
       "      <td>inceptionv4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NASNet-A-Large</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>82.566</td>\n",
       "      <td>96.086</td>\n",
       "      <td>nasnetalarge</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NASNet-A-Mobile</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>74.080</td>\n",
       "      <td>91.740</td>\n",
       "      <td>nasnetamobile</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PNASNet-5-Large</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>82.736</td>\n",
       "      <td>95.992</td>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PolyNet</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>81.002</td>\n",
       "      <td>95.624</td>\n",
       "      <td>polynet</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ResNeXt101_32x4d</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.188</td>\n",
       "      <td>93.886</td>\n",
       "      <td>resnext101_32x4d</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ResNeXt101_64x4d</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.956</td>\n",
       "      <td>94.252</td>\n",
       "      <td>resnext101_64x4d</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ResNet101</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.438</td>\n",
       "      <td>93.672</td>\n",
       "      <td>resnet101</td>\n",
       "      <td>-0.614044</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087516</td>\n",
       "      <td>2.534792</td>\n",
       "      <td>2.943638</td>\n",
       "      <td>0.430459</td>\n",
       "      <td>0.622483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ResNet152</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>78.428</td>\n",
       "      <td>94.110</td>\n",
       "      <td>resnet152</td>\n",
       "      <td>-0.802164</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.130124</td>\n",
       "      <td>2.442224</td>\n",
       "      <td>2.677333</td>\n",
       "      <td>0.382062</td>\n",
       "      <td>0.578092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>70.142</td>\n",
       "      <td>89.274</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>0.390666</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551726</td>\n",
       "      <td>3.025152</td>\n",
       "      <td>3.030234</td>\n",
       "      <td>0.632062</td>\n",
       "      <td>0.674310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ResNet34</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>73.554</td>\n",
       "      <td>91.456</td>\n",
       "      <td>resnet34</td>\n",
       "      <td>-0.428586</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.297208</td>\n",
       "      <td>2.934657</td>\n",
       "      <td>2.895109</td>\n",
       "      <td>0.529997</td>\n",
       "      <td>0.560840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ResNet50</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>76.002</td>\n",
       "      <td>92.980</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.039248</td>\n",
       "      <td>1</td>\n",
       "      <td>1.003216</td>\n",
       "      <td>2.703466</td>\n",
       "      <td>3.894256</td>\n",
       "      <td>0.539118</td>\n",
       "      <td>0.721996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SE-ResNeXt101_32x4d</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>80.236</td>\n",
       "      <td>95.028</td>\n",
       "      <td>seresnext101_32x4d</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SE-ResNeXt50_32x4d</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.076</td>\n",
       "      <td>94.434</td>\n",
       "      <td>seresnext50_32x4d</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SE-ResNet101</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.396</td>\n",
       "      <td>94.258</td>\n",
       "      <td>seresnet101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SE-ResNet152</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.658</td>\n",
       "      <td>94.374</td>\n",
       "      <td>seresnet152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SE-ResNet50</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>77.636</td>\n",
       "      <td>93.752</td>\n",
       "      <td>seresnet50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SENet154</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>81.304</td>\n",
       "      <td>95.498</td>\n",
       "      <td>senet154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SqueezeNet1_0</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>58.108</td>\n",
       "      <td>80.428</td>\n",
       "      <td>squeezenet1_0</td>\n",
       "      <td>1.838089</td>\n",
       "      <td>1</td>\n",
       "      <td>3.608327</td>\n",
       "      <td>3.646238</td>\n",
       "      <td>4.488309</td>\n",
       "      <td>0.779578</td>\n",
       "      <td>0.956530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SqueezeNet1_1</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>58.250</td>\n",
       "      <td>80.800</td>\n",
       "      <td>squeezenet1_1</td>\n",
       "      <td>1.443536</td>\n",
       "      <td>1</td>\n",
       "      <td>3.371930</td>\n",
       "      <td>3.506684</td>\n",
       "      <td>4.492793</td>\n",
       "      <td>0.742644</td>\n",
       "      <td>0.934358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>VGG11</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>68.970</td>\n",
       "      <td>88.746</td>\n",
       "      <td>vgg11</td>\n",
       "      <td>1.198196</td>\n",
       "      <td>1</td>\n",
       "      <td>1.198196</td>\n",
       "      <td>2.090732</td>\n",
       "      <td>2.090732</td>\n",
       "      <td>0.854199</td>\n",
       "      <td>0.854199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>VGG11_BN</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>70.452</td>\n",
       "      <td>89.818</td>\n",
       "      <td>vgg11_bn</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989161</td>\n",
       "      <td>2.288182</td>\n",
       "      <td>2.288182</td>\n",
       "      <td>0.776393</td>\n",
       "      <td>0.776393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>VGG13</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>69.662</td>\n",
       "      <td>89.264</td>\n",
       "      <td>vgg13</td>\n",
       "      <td>1.094364</td>\n",
       "      <td>1</td>\n",
       "      <td>1.094364</td>\n",
       "      <td>2.388385</td>\n",
       "      <td>2.388385</td>\n",
       "      <td>0.760708</td>\n",
       "      <td>0.760708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>VGG13_BN</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>71.508</td>\n",
       "      <td>90.494</td>\n",
       "      <td>vgg13_bn</td>\n",
       "      <td>0.817619</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817619</td>\n",
       "      <td>2.715187</td>\n",
       "      <td>2.715187</td>\n",
       "      <td>0.669518</td>\n",
       "      <td>0.669518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>VGG16</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>71.636</td>\n",
       "      <td>90.354</td>\n",
       "      <td>vgg16</td>\n",
       "      <td>0.895729</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895729</td>\n",
       "      <td>2.516576</td>\n",
       "      <td>2.516576</td>\n",
       "      <td>0.734958</td>\n",
       "      <td>0.734958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>VGG16_BN</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>73.518</td>\n",
       "      <td>91.608</td>\n",
       "      <td>vgg16_bn</td>\n",
       "      <td>0.475357</td>\n",
       "      <td>1</td>\n",
       "      <td>0.475357</td>\n",
       "      <td>2.682115</td>\n",
       "      <td>2.682115</td>\n",
       "      <td>0.632109</td>\n",
       "      <td>0.632109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>VGG19</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>72.080</td>\n",
       "      <td>90.822</td>\n",
       "      <td>vgg19</td>\n",
       "      <td>0.700216</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700216</td>\n",
       "      <td>2.436634</td>\n",
       "      <td>2.436634</td>\n",
       "      <td>0.722815</td>\n",
       "      <td>0.722815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>VGG19_BN</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>74.266</td>\n",
       "      <td>92.066</td>\n",
       "      <td>vgg19_bn</td>\n",
       "      <td>0.188285</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188285</td>\n",
       "      <td>2.492108</td>\n",
       "      <td>2.492108</td>\n",
       "      <td>0.579767</td>\n",
       "      <td>0.579767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Xception</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.888</td>\n",
       "      <td>94.292</td>\n",
       "      <td>xception</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model    platform    acc1    acc5           modelname  \\\n",
       "61              Alexnet     Pytorch  56.432  79.194             alexnet   \n",
       "50          BNInception  ourporting  73.522  91.560         bninception   \n",
       "41       CaffeResnet101  ourporting  76.200  92.766      cafferesnet101   \n",
       "45          DenseNet121     Pytorch  74.646  92.136         densenet121   \n",
       "34          DenseNet161     Pytorch  77.560  93.798         densenet161   \n",
       "42          DenseNet169     Pytorch  76.026  92.992         densenet169   \n",
       "38          DenseNet201     Pytorch  77.152  93.548         densenet201   \n",
       "14    DualPathNet107_5k  ourporting  79.746  94.684   dualpathnet107_5k   \n",
       "16       DualPathNet131  ourporting  79.432  94.574      dualpathnet131   \n",
       "44        DualPathNet68  ourporting  75.868  92.774       dualpathnet68   \n",
       "39    DualPathNet68b_5k  ourporting  77.034  93.590   dualpathnet68b_5k   \n",
       "17     DualPathNet92_5k  ourporting  79.400  94.620    dualpathnet92_5k   \n",
       "18        DualPathNet98  ourporting  79.224  94.488       dualpathnet98   \n",
       "36          FBResNet152  ourporting  77.386  93.594         fbresnet152   \n",
       "12    InceptionResNetV2  ourporting  80.170  95.234   inceptionresnetv2   \n",
       "37          InceptionV3     Pytorch  77.294  93.454         inceptionv3   \n",
       "13          InceptionV4  ourporting  80.062  94.926         inceptionv4   \n",
       "3        NASNet-A-Large  ourporting  82.566  96.086        nasnetalarge   \n",
       "48      NASNet-A-Mobile  ourporting  74.080  91.740       nasnetamobile   \n",
       "1       PNASNet-5-Large  ourporting  82.736  95.992       pnasnet5large   \n",
       "7               PolyNet  ourporting  81.002  95.624             polynet   \n",
       "30     ResNeXt101_32x4d  ourporting  78.188  93.886    resnext101_32x4d   \n",
       "22     ResNeXt101_64x4d  ourporting  78.956  94.252    resnext101_64x4d   \n",
       "35            ResNet101     Pytorch  77.438  93.672           resnet101   \n",
       "27            ResNet152     Pytorch  78.428  94.110           resnet152   \n",
       "56             ResNet18     Pytorch  70.142  89.274            resnet18   \n",
       "49             ResNet34     Pytorch  73.554  91.456            resnet34   \n",
       "43             ResNet50     Pytorch  76.002  92.980            resnet50   \n",
       "10  SE-ResNeXt101_32x4d  ourporting  80.236  95.028  seresnext101_32x4d   \n",
       "19   SE-ResNeXt50_32x4d  ourporting  79.076  94.434   seresnext50_32x4d   \n",
       "28         SE-ResNet101  ourporting  78.396  94.258         seresnet101   \n",
       "26         SE-ResNet152  ourporting  78.658  94.374         seresnet152   \n",
       "33          SE-ResNet50  ourporting  77.636  93.752          seresnet50   \n",
       "5              SENet154  ourporting  81.304  95.498            senet154   \n",
       "60        SqueezeNet1_0     Pytorch  58.108  80.428       squeezenet1_0   \n",
       "59        SqueezeNet1_1     Pytorch  58.250  80.800       squeezenet1_1   \n",
       "58                VGG11     Pytorch  68.970  88.746               vgg11   \n",
       "55             VGG11_BN     Pytorch  70.452  89.818            vgg11_bn   \n",
       "57                VGG13     Pytorch  69.662  89.264               vgg13   \n",
       "54             VGG13_BN     Pytorch  71.508  90.494            vgg13_bn   \n",
       "53                VGG16     Pytorch  71.636  90.354               vgg16   \n",
       "51             VGG16_BN     Pytorch  73.518  91.608            vgg16_bn   \n",
       "52                VGG19     Pytorch  72.080  90.822               vgg19   \n",
       "46             VGG19_BN     Pytorch  74.266  92.066            vgg19_bn   \n",
       "23             Xception  ourporting  78.888  94.292            xception   \n",
       "\n",
       "    avg_w_alphas  num_layers  alpha_weighted_compound     alpha  \\\n",
       "61      0.000000           0                 0.000000  0.000000   \n",
       "50      0.000000           0                 0.000000  0.000000   \n",
       "41      0.000000           0                 0.000000  0.000000   \n",
       "45      1.110570           1                 1.110570  4.273254   \n",
       "34      0.693433           1                 0.693433  3.619427   \n",
       "42      0.559491           1                 0.559491  4.285921   \n",
       "38      0.395006           1                 0.395006  4.120117   \n",
       "14      0.000000           0                 0.000000  0.000000   \n",
       "16      0.000000           0                 0.000000  0.000000   \n",
       "44      0.000000           0                 0.000000  0.000000   \n",
       "39      0.000000           0                 0.000000  0.000000   \n",
       "17      0.000000           0                 0.000000  0.000000   \n",
       "18      0.000000           0                 0.000000  0.000000   \n",
       "36      0.000000           0                 0.000000  0.000000   \n",
       "12      0.000000           0                 0.000000  0.000000   \n",
       "37      0.000000           0                 0.000000  0.000000   \n",
       "13      0.000000           0                 0.000000  0.000000   \n",
       "3       0.000000           0                 0.000000  0.000000   \n",
       "48      0.000000           0                 0.000000  0.000000   \n",
       "1       0.000000           0                 0.000000  0.000000   \n",
       "7       0.000000           0                 0.000000  0.000000   \n",
       "30      0.000000           0                 0.000000  0.000000   \n",
       "22      0.000000           0                 0.000000  0.000000   \n",
       "35     -0.614044           1                 0.087516  2.534792   \n",
       "27     -0.802164           1                -0.130124  2.442224   \n",
       "56      0.390666           1                 0.551726  3.025152   \n",
       "49     -0.428586           1                -0.297208  2.934657   \n",
       "43      0.039248           1                 1.003216  2.703466   \n",
       "10      0.000000           0                 0.000000  0.000000   \n",
       "19      0.000000           0                 0.000000  0.000000   \n",
       "28      0.000000           0                 0.000000  0.000000   \n",
       "26      0.000000           0                 0.000000  0.000000   \n",
       "33      0.000000           0                 0.000000  0.000000   \n",
       "5       0.000000           0                 0.000000  0.000000   \n",
       "60      1.838089           1                 3.608327  3.646238   \n",
       "59      1.443536           1                 3.371930  3.506684   \n",
       "58      1.198196           1                 1.198196  2.090732   \n",
       "55      0.989161           1                 0.989161  2.288182   \n",
       "57      1.094364           1                 1.094364  2.388385   \n",
       "54      0.817619           1                 0.817619  2.715187   \n",
       "53      0.895729           1                 0.895729  2.516576   \n",
       "51      0.475357           1                 0.475357  2.682115   \n",
       "52      0.700216           1                 0.700216  2.436634   \n",
       "46      0.188285           1                 0.188285  2.492108   \n",
       "23      0.000000           0                 0.000000  0.000000   \n",
       "\n",
       "    alpha_compound   lognorm  lognorm_compound  \n",
       "61        0.000000  0.000000          0.000000  \n",
       "50        0.000000  0.000000          0.000000  \n",
       "41        0.000000  0.000000          0.000000  \n",
       "45        4.273254  0.783103          0.783103  \n",
       "34        3.619427  0.725548          0.725548  \n",
       "42        4.285921  0.722775          0.722775  \n",
       "38        4.120117  0.702473          0.702473  \n",
       "14        0.000000  0.000000          0.000000  \n",
       "16        0.000000  0.000000          0.000000  \n",
       "44        0.000000  0.000000          0.000000  \n",
       "39        0.000000  0.000000          0.000000  \n",
       "17        0.000000  0.000000          0.000000  \n",
       "18        0.000000  0.000000          0.000000  \n",
       "36        0.000000  0.000000          0.000000  \n",
       "12        0.000000  0.000000          0.000000  \n",
       "37        0.000000  0.000000          0.000000  \n",
       "13        0.000000  0.000000          0.000000  \n",
       "3         0.000000  0.000000          0.000000  \n",
       "48        0.000000  0.000000          0.000000  \n",
       "1         0.000000  0.000000          0.000000  \n",
       "7         0.000000  0.000000          0.000000  \n",
       "30        0.000000  0.000000          0.000000  \n",
       "22        0.000000  0.000000          0.000000  \n",
       "35        2.943638  0.430459          0.622483  \n",
       "27        2.677333  0.382062          0.578092  \n",
       "56        3.030234  0.632062          0.674310  \n",
       "49        2.895109  0.529997          0.560840  \n",
       "43        3.894256  0.539118          0.721996  \n",
       "10        0.000000  0.000000          0.000000  \n",
       "19        0.000000  0.000000          0.000000  \n",
       "28        0.000000  0.000000          0.000000  \n",
       "26        0.000000  0.000000          0.000000  \n",
       "33        0.000000  0.000000          0.000000  \n",
       "5         0.000000  0.000000          0.000000  \n",
       "60        4.488309  0.779578          0.956530  \n",
       "59        4.492793  0.742644          0.934358  \n",
       "58        2.090732  0.854199          0.854199  \n",
       "55        2.288182  0.776393          0.776393  \n",
       "57        2.388385  0.760708          0.760708  \n",
       "54        2.715187  0.669518          0.669518  \n",
       "53        2.516576  0.734958          0.734958  \n",
       "51        2.682115  0.632109          0.632109  \n",
       "52        2.436634  0.722815          0.722815  \n",
       "46        2.492108  0.579767          0.579767  \n",
       "23        0.000000  0.000000          0.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T21:33:30.176440Z",
     "start_time": "2018-10-22T21:33:30.058643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>platform</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc5</th>\n",
       "      <th>modelname</th>\n",
       "      <th>avg_w_alphas</th>\n",
       "      <th>num_layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Alexnet</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>56.432</td>\n",
       "      <td>79.194</td>\n",
       "      <td>alexnet</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>BNInception</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>73.522</td>\n",
       "      <td>91.560</td>\n",
       "      <td>bninception</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>CaffeResnet101</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>76.200</td>\n",
       "      <td>92.766</td>\n",
       "      <td>cafferesnet101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DenseNet121</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>74.646</td>\n",
       "      <td>92.136</td>\n",
       "      <td>densenet121</td>\n",
       "      <td>1.248708</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>DenseNet161</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.560</td>\n",
       "      <td>93.798</td>\n",
       "      <td>densenet161</td>\n",
       "      <td>0.838195</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DenseNet169</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>76.026</td>\n",
       "      <td>92.992</td>\n",
       "      <td>densenet169</td>\n",
       "      <td>0.678617</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DenseNet201</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.152</td>\n",
       "      <td>93.548</td>\n",
       "      <td>densenet201</td>\n",
       "      <td>0.501668</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DualPathNet107_5k</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.746</td>\n",
       "      <td>94.684</td>\n",
       "      <td>dualpathnet107_5k</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DualPathNet131</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.432</td>\n",
       "      <td>94.574</td>\n",
       "      <td>dualpathnet131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DualPathNet68</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>75.868</td>\n",
       "      <td>92.774</td>\n",
       "      <td>dualpathnet68</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DualPathNet68b_5k</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>77.034</td>\n",
       "      <td>93.590</td>\n",
       "      <td>dualpathnet68b_5k</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DualPathNet92_5k</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.400</td>\n",
       "      <td>94.620</td>\n",
       "      <td>dualpathnet92_5k</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DualPathNet98</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.224</td>\n",
       "      <td>94.488</td>\n",
       "      <td>dualpathnet98</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>FBResNet152</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>77.386</td>\n",
       "      <td>93.594</td>\n",
       "      <td>fbresnet152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>InceptionResNetV2</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>80.170</td>\n",
       "      <td>95.234</td>\n",
       "      <td>inceptionresnetv2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>InceptionV3</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.294</td>\n",
       "      <td>93.454</td>\n",
       "      <td>inceptionv3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>InceptionV4</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>80.062</td>\n",
       "      <td>94.926</td>\n",
       "      <td>inceptionv4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NASNet-A-Large</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>82.566</td>\n",
       "      <td>96.086</td>\n",
       "      <td>nasnetalarge</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NASNet-A-Mobile</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>74.080</td>\n",
       "      <td>91.740</td>\n",
       "      <td>nasnetamobile</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PNASNet-5-Large</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>82.736</td>\n",
       "      <td>95.992</td>\n",
       "      <td>pnasnet5large</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PolyNet</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>81.002</td>\n",
       "      <td>95.624</td>\n",
       "      <td>polynet</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ResNeXt101_32x4d</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.188</td>\n",
       "      <td>93.886</td>\n",
       "      <td>resnext101_32x4d</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ResNeXt101_64x4d</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.956</td>\n",
       "      <td>94.252</td>\n",
       "      <td>resnext101_64x4d</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ResNet101</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.438</td>\n",
       "      <td>93.672</td>\n",
       "      <td>resnet101</td>\n",
       "      <td>-0.616471</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ResNet152</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>78.428</td>\n",
       "      <td>94.110</td>\n",
       "      <td>resnet152</td>\n",
       "      <td>-0.789808</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>70.142</td>\n",
       "      <td>89.274</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>0.610676</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ResNet34</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>73.554</td>\n",
       "      <td>91.456</td>\n",
       "      <td>resnet34</td>\n",
       "      <td>-0.393656</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ResNet50</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>76.002</td>\n",
       "      <td>92.980</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>0.140391</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SE-ResNeXt101_32x4d</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>80.236</td>\n",
       "      <td>95.028</td>\n",
       "      <td>seresnext101_32x4d</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SE-ResNeXt50_32x4d</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>79.076</td>\n",
       "      <td>94.434</td>\n",
       "      <td>seresnext50_32x4d</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SE-ResNet101</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.396</td>\n",
       "      <td>94.258</td>\n",
       "      <td>seresnet101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SE-ResNet152</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.658</td>\n",
       "      <td>94.374</td>\n",
       "      <td>seresnet152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SE-ResNet50</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>77.636</td>\n",
       "      <td>93.752</td>\n",
       "      <td>seresnet50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SENet154</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>81.304</td>\n",
       "      <td>95.498</td>\n",
       "      <td>senet154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SqueezeNet1_0</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>58.108</td>\n",
       "      <td>80.428</td>\n",
       "      <td>squeezenet1_0</td>\n",
       "      <td>1.942516</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SqueezeNet1_1</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>58.250</td>\n",
       "      <td>80.800</td>\n",
       "      <td>squeezenet1_1</td>\n",
       "      <td>1.560409</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>VGG11</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>68.970</td>\n",
       "      <td>88.746</td>\n",
       "      <td>vgg11</td>\n",
       "      <td>1.843995</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>VGG11_BN</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>70.452</td>\n",
       "      <td>89.818</td>\n",
       "      <td>vgg11_bn</td>\n",
       "      <td>1.597647</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>VGG13</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>69.662</td>\n",
       "      <td>89.264</td>\n",
       "      <td>vgg13</td>\n",
       "      <td>1.645383</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>VGG13_BN</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>71.508</td>\n",
       "      <td>90.494</td>\n",
       "      <td>vgg13_bn</td>\n",
       "      <td>1.355124</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>VGG16</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>71.636</td>\n",
       "      <td>90.354</td>\n",
       "      <td>vgg16</td>\n",
       "      <td>1.405073</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>VGG16_BN</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>73.518</td>\n",
       "      <td>91.608</td>\n",
       "      <td>vgg16_bn</td>\n",
       "      <td>1.082041</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>VGG19</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>72.080</td>\n",
       "      <td>90.822</td>\n",
       "      <td>vgg19</td>\n",
       "      <td>1.158888</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>VGG19_BN</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>74.266</td>\n",
       "      <td>92.066</td>\n",
       "      <td>vgg19_bn</td>\n",
       "      <td>0.811058</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Xception</td>\n",
       "      <td>ourporting</td>\n",
       "      <td>78.888</td>\n",
       "      <td>94.292</td>\n",
       "      <td>xception</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model    platform    acc1    acc5           modelname  \\\n",
       "61              Alexnet     Pytorch  56.432  79.194             alexnet   \n",
       "50          BNInception  ourporting  73.522  91.560         bninception   \n",
       "41       CaffeResnet101  ourporting  76.200  92.766      cafferesnet101   \n",
       "45          DenseNet121     Pytorch  74.646  92.136         densenet121   \n",
       "34          DenseNet161     Pytorch  77.560  93.798         densenet161   \n",
       "42          DenseNet169     Pytorch  76.026  92.992         densenet169   \n",
       "38          DenseNet201     Pytorch  77.152  93.548         densenet201   \n",
       "14    DualPathNet107_5k  ourporting  79.746  94.684   dualpathnet107_5k   \n",
       "16       DualPathNet131  ourporting  79.432  94.574      dualpathnet131   \n",
       "44        DualPathNet68  ourporting  75.868  92.774       dualpathnet68   \n",
       "39    DualPathNet68b_5k  ourporting  77.034  93.590   dualpathnet68b_5k   \n",
       "17     DualPathNet92_5k  ourporting  79.400  94.620    dualpathnet92_5k   \n",
       "18        DualPathNet98  ourporting  79.224  94.488       dualpathnet98   \n",
       "36          FBResNet152  ourporting  77.386  93.594         fbresnet152   \n",
       "12    InceptionResNetV2  ourporting  80.170  95.234   inceptionresnetv2   \n",
       "37          InceptionV3     Pytorch  77.294  93.454         inceptionv3   \n",
       "13          InceptionV4  ourporting  80.062  94.926         inceptionv4   \n",
       "3        NASNet-A-Large  ourporting  82.566  96.086        nasnetalarge   \n",
       "48      NASNet-A-Mobile  ourporting  74.080  91.740       nasnetamobile   \n",
       "1       PNASNet-5-Large  ourporting  82.736  95.992       pnasnet5large   \n",
       "7               PolyNet  ourporting  81.002  95.624             polynet   \n",
       "30     ResNeXt101_32x4d  ourporting  78.188  93.886    resnext101_32x4d   \n",
       "22     ResNeXt101_64x4d  ourporting  78.956  94.252    resnext101_64x4d   \n",
       "35            ResNet101     Pytorch  77.438  93.672           resnet101   \n",
       "27            ResNet152     Pytorch  78.428  94.110           resnet152   \n",
       "56             ResNet18     Pytorch  70.142  89.274            resnet18   \n",
       "49             ResNet34     Pytorch  73.554  91.456            resnet34   \n",
       "43             ResNet50     Pytorch  76.002  92.980            resnet50   \n",
       "10  SE-ResNeXt101_32x4d  ourporting  80.236  95.028  seresnext101_32x4d   \n",
       "19   SE-ResNeXt50_32x4d  ourporting  79.076  94.434   seresnext50_32x4d   \n",
       "28         SE-ResNet101  ourporting  78.396  94.258         seresnet101   \n",
       "26         SE-ResNet152  ourporting  78.658  94.374         seresnet152   \n",
       "33          SE-ResNet50  ourporting  77.636  93.752          seresnet50   \n",
       "5              SENet154  ourporting  81.304  95.498            senet154   \n",
       "60        SqueezeNet1_0     Pytorch  58.108  80.428       squeezenet1_0   \n",
       "59        SqueezeNet1_1     Pytorch  58.250  80.800       squeezenet1_1   \n",
       "58                VGG11     Pytorch  68.970  88.746               vgg11   \n",
       "55             VGG11_BN     Pytorch  70.452  89.818            vgg11_bn   \n",
       "57                VGG13     Pytorch  69.662  89.264               vgg13   \n",
       "54             VGG13_BN     Pytorch  71.508  90.494            vgg13_bn   \n",
       "53                VGG16     Pytorch  71.636  90.354               vgg16   \n",
       "51             VGG16_BN     Pytorch  73.518  91.608            vgg16_bn   \n",
       "52                VGG19     Pytorch  72.080  90.822               vgg19   \n",
       "46             VGG19_BN     Pytorch  74.266  92.066            vgg19_bn   \n",
       "23             Xception  ourporting  78.888  94.292            xception   \n",
       "\n",
       "    avg_w_alphas  num_layers  \n",
       "61      0.000000           0  \n",
       "50      0.000000           0  \n",
       "41      0.000000           0  \n",
       "45      1.248708          62  \n",
       "34      0.838195          82  \n",
       "42      0.678617          86  \n",
       "38      0.501668         102  \n",
       "14      0.000000           0  \n",
       "16      0.000000           0  \n",
       "44      0.000000           0  \n",
       "39      0.000000           0  \n",
       "17      0.000000           0  \n",
       "18      0.000000           0  \n",
       "36      0.000000           0  \n",
       "12      0.000000           0  \n",
       "37      0.000000           0  \n",
       "13      0.000000           0  \n",
       "3       0.000000           0  \n",
       "48      0.000000           0  \n",
       "1       0.000000           0  \n",
       "7       0.000000           0  \n",
       "30      0.000000           0  \n",
       "22      0.000000           0  \n",
       "35     -0.616471         368  \n",
       "27     -0.789808         555  \n",
       "56      0.610676         148  \n",
       "49     -0.393656         292  \n",
       "43      0.140391         181  \n",
       "10      0.000000           0  \n",
       "19      0.000000           0  \n",
       "28      0.000000           0  \n",
       "26      0.000000           0  \n",
       "33      0.000000           0  \n",
       "5       0.000000           0  \n",
       "60      1.942516          23  \n",
       "59      1.560409          23  \n",
       "58      1.843995          66  \n",
       "55      1.597647          66  \n",
       "57      1.645383          84  \n",
       "54      1.355124          84  \n",
       "53      1.405073         111  \n",
       "51      1.082041         111  \n",
       "52      1.158888         138  \n",
       "46      0.811058         138  \n",
       "23      0.000000           0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:45:44.251928Z",
     "start_time": "2018-11-26T22:45:43.231940Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlesmartin14/anaconda3/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/charlesmartin14/anaconda3/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Users/charlesmartin14/anaconda3/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/charlesmartin14/anaconda3/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/charlesmartin14/anaconda3/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/charlesmartin14/anaconda3/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_vgg11 = df[(df['model']=='VGG11')| (df['model']=='VGG11_BN')]\n",
    "df_vgg11['legend']='VGG11'\n",
    "\n",
    "df_vgg13 = df[(df['model']=='VGG13')| (df['model']=='VGG13_BN')]\n",
    "df_vgg13['legend']='VGG13'\n",
    "\n",
    "df_vgg16 = df[(df['model']=='VGG16')| (df['model']=='VGG16_BN')]\n",
    "df_vgg16['legend']='VGG16'\n",
    "\n",
    "df_vgg19 = df[(df['model']=='VGG19')| (df['model']=='VGG19_BN')]\n",
    "df_vgg19['legend']='VGG19'\n",
    "\n",
    "df_squeezenet = df[(df['model']=='SqueezeNet1_0')| (df['model']=='SqueezeNet1_1')]\n",
    "df_squeezenet['legend']='SqueezeNet'\n",
    "\n",
    "df_resnxt = df[(df['model']=='ResNeXt101_32x4d')| (df['model']=='ResNeXt101_64x4d')]\n",
    "df_resnxt['legend']='ResNeXT101'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:45:47.952954Z",
     "start_time": "2018-11-26T22:45:45.944361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alpha Weighted using WeightWatcher\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "\n",
    "\n",
    "for mf in [df_vgg11, df_vgg13, df_vgg16, df_vgg19]:\n",
    "#for mf in [df_vgg11, df_vgg13]:\n",
    "    x = mf['acc5'].values\n",
    "    y = mf['avg_w_alphas'].values\n",
    "    label = mf['legend'].values[0]\n",
    "    plt.scatter(x,y,label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r\"Test Accuracy vs Average Alpha Log Max Eigenvalue $\\hat{\\alpha}$\"+\"\\nPretrained VGG and VGG_BN Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\hat{\\alpha}$\")\n",
    "#plt.savefig(\"img/vgg-w_alphas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T21:34:58.599857Z",
     "start_time": "2018-10-22T21:34:57.583864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alpha Weighted (original notebook)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "\n",
    "\n",
    "for mf in [df_vgg11, df_vgg13, df_vgg16, df_vgg19]:\n",
    "#for mf in [df_vgg11, df_vgg13]:\n",
    "    x = mf['acc5'].values\n",
    "    y = mf['avg_w_alphas'].values\n",
    "    label = mf['legend'].values[0]\n",
    "    plt.scatter(x,y,label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r\"Test Accuracy vs Average Alpha Log Max Eigenvalue $\\hat{\\alpha}$\"+\"\\nPretrained VGG and VGG_BN Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\hat{\\alpha}$\")\n",
    "#plt.savefig(\"img/vgg-w_alphas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:46:07.449712Z",
     "start_time": "2018-11-26T22:46:06.215762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alpha Weighted compound (WeightWatcher)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "\n",
    "\n",
    "for mf in [df_vgg11, df_vgg13, df_vgg16, df_vgg19]:\n",
    "#for mf in [df_vgg11, df_vgg13]:\n",
    "    x = mf['acc5'].values\n",
    "    y = mf['alpha_weighted_compound'].values\n",
    "    label = mf['legend'].values[0]\n",
    "    plt.scatter(x,y,label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r\"Test Accuracy vs Average Alpha Log Max Eigenvalue $\\hat{\\alpha}$\"+\"\\nPretrained VGG and VGG_BN Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\hat{\\alpha}$\")\n",
    "#plt.savefig(\"img/vgg-w_alphas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:46:28.163856Z",
     "start_time": "2018-11-26T22:46:26.654593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alpha (WeightWatcher)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "\n",
    "\n",
    "for mf in [df_vgg11, df_vgg13, df_vgg16, df_vgg19]:\n",
    "#for mf in [df_vgg11, df_vgg13]:\n",
    "    x = mf['acc5'].values\n",
    "    y = mf['alpha'].values\n",
    "    label = mf['legend'].values[0]\n",
    "    plt.scatter(x,y,label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r\"Test Accuracy vs Average Alpha Log Max Eigenvalue $\\hat{\\alpha}$\"+\"\\nPretrained VGG and VGG_BN Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\hat{\\alpha}$\")\n",
    "#plt.savefig(\"img/vgg-w_alphas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:46:28.163856Z",
     "start_time": "2018-11-26T22:46:26.654593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alpha compound (WeightWatcher)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "\n",
    "\n",
    "for mf in [df_vgg11, df_vgg13, df_vgg16, df_vgg19]:\n",
    "#for mf in [df_vgg11, df_vgg13]:\n",
    "    x = mf['acc5'].values\n",
    "    y = mf['alpha_compound'].values\n",
    "    label = mf['legend'].values[0]\n",
    "    plt.scatter(x,y,label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r\"Test Accuracy vs Average Alpha Log Max Eigenvalue $\\hat{\\alpha}$\"+\"\\nPretrained VGG and VGG_BN Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\hat{\\alpha}$\")\n",
    "#plt.savefig(\"img/vgg-w_alphas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:46:45.696797Z",
     "start_time": "2018-11-26T22:46:44.483163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAIdCAYAAADBH1z+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzs3Xl8VNX9//HXB5IQBIJAQGQTQVxAXJOq1SqLiLUtqFTFhSTqF2urrfbbIvhTkCqt8G0ttWpbaRVFUFCgilDcWKIoFnApRUWwCpQ9QUQQQljO749zJ0wmM8lMSDIwvJ+PxzwmOffce8/dP3PuOfeacw4RERGRVFEv2QUQERERqUkKbkRERCSlKLgRERGRlKLgRkRERFKKghsRERFJKQpuREREJKUouBEREZGUouBGREREUoqCGxERETkkmdkAMxtuZg0TGS+ttgokIiIiUl1m1g14FigBsoAhcY+r1y+IiIjIocTM6gPvAB8DTwBvABc65xbFM75uS4nIYcXMepiZM7ORh8J05PCk7X/Ir4Of42trbnfOLQAeAJ40s4x4Rj4kgptg5cb7WVWL5aipk+asYDrLaqhocojRNq4dR8J6NbOOwTK+mOyyxBJWRmdmn5uZxcj3g7B8SV2eiDLH+sxPZhklfs653znnTnHOfRP8/2vn3KnOudJ4xj9U2tz8KkrafcA24A8R6V/VfnGqz8yOBfoCDuhmZrnOucVJLpbUIG3j2qH1ekjaCxwPXATMjzK8IMhzqFxLAD4FJscYtirs70XAKUBxbRdI6t4hsUM650ZGppnZfcBX0YYd4vKB+sBDwC+AmwCdoFOLtnHt0Ho99LwJnAvcSERwY2bZwPeB2cAP6rxksS2P57rhnNsJLK/94kgyHBK3paor6CI238y2mdkuM/vAzG6JkfdqM1tgZsVB3tVm9qKZXRAMHwnMC7LfF16VmWCxCvA1TvcCK4CBZpZZxTLMMbOtQbk+M7NxZtYh0XxmVhCUuSDKfCoMC78NZ2YXmtlcM/vazL4IhmeY2c/M7HUzW2dmpWa2wcyeNbMu1VmmYD7OzCJr5ELj9gqGPxxr+kG+i4J8j8YY/u1g+ONhaZXuAwkooIptXJ3yhQ2rcr+ujW1nZo3NbKyZrQ/m+76ZXVXFfhX3MRiHAhI4dqKUJXyd9DSzt83sGzMrMrMnzF+MY42ba2ZvmNkOM/vSzCaZWcuIPNU6Hg6GmaWb2S/N7N/B+t1qZq+Y2Xdi5E94G1ZhOzANGGBmjSOGXQ9kAE9FKUfc68q814PyfS9iWINg2UvN7KwEy14pq6QZQm0eCxH7aaX7nSV4HqmJfbSKZaz1c4GZNTWz35jZf4LpfGxmVwbDbjGzvWbWucoJOecOyQ++anpVJcN/G8oDjMPfvvooSBsbkfe2IP0z4FFgNDABWA3cG+TpgT9IHf4XysjQJ4Eynx+M/7fg/+HB/9fFyP9wMHxTsAyjgSnAVuDyauQrCPIVRJlXhWHBMjvgdaAUmAmMAf4UDG+Nr3KeC/wlGPZikPYlcHx1lgn4BF8VnBFl/InB+KdVsa4t2H6bgbQowx8NpnNhvPtATW7jRMuX6H5d09sOX2PyZjDNxcCD+ONhVzDtCvtVvGWt6WMnbNlHxkh/FdgNvAD8Bv+jxQVlaxQl/yxgJzAD+B2wMEhfSNCjtLrHQ4xl7RhM/8U49vGXwsr+f8Bfga+DeV51sNswnjICPYO/b4rI8yHwr2jLU439ry2wBX/eaBXlfDK0ptZrHPtRrR4Liex3JH6eS3S9V1gHJHgdqclzQbANP8N3/R4fbP9twbpvD/wHeCquaSVyAqrLT2hFxRgWui//IpAZlp4epDkgNyz9fWAtcFTEdAxoXtXOnkCZ/xaMf1Hw//HAfuD1KHn7BXkXAVkRwxqGyhVvvurslGHLG+si0gBoEyX9ouBg+Vs1l+kXQb6rI/I0xR/si+Nc36OD6VwWkZ6GPxms5sBJIq59oIa3cdzlS3S/roVtNziY1vMRZfpOsHyR+05Cx2ANr9fQso+Mke6AvIhhfwzS74+Rf0BYej1gTpB+XnXXaSXL2jG07qrIl8+BYC0tLP0U4Bt8+8Mm1d2G8ZYRf4x8DrwZNvzMYPjPoy1PddYVMCCYzsywfWw//sdmvQTKvJywH6cRn3Pj2I9q9Vioxn6XyHku0eO+wjog8etIjZwL8EHl+8A+gvNAxHEwJViGE+Lah+PJlIwPlQc3M4KdrFWUYacG4/4uLO19/MFZoaagqg2dQHkb4X9RRV6wFgQbq0NE/tnBvM6tYrpx5avmThla3riCiYjpLY3cPgksUzb+l/UrEek/Dsa/Nc4yhLb1xIj0y4L0BxPdB2p4G8ddvkT361rYdvOD6Z0YJf8/ouw7CR2DNbxeox6nYemfhE8nGNYCHzh/HiX//ChlCp1Qf1rddVpJ3o7EF9zMJUYtJv6XsQMGVXcbJlJGfAcPB3QO/v8jvsawZbzLE8+6Ap4MpjUCWI+v8W2fYJkr+9wZx35Uq8dCovsdCZ5HElnv0dYBiV9HauRcAFwV5B0Xkd4tbPs9Fc+yOucOjQbF1XAO/mT4E6vYQzE9+D45LG0KPvpdZmZTgEJgoQu6mNWQHwJNgEddsEUCz+Cr3AuA+8PSc4Htzrl3q5huvPkOxpJYA8zsbOAu/DK04sD6BX9yCxdXWZ1zxea7jf7QzDo459YEg27GVz8+F0+hnXPLzGwpcLmZHeV8A0HwbQHA3+IKqYl9IKFtnGD5IPH9Gmpu250ObHHOrYgyqYXAd2ugrLEkeuxU5e2I6eCc22Jmy4EzzayJc2572OAPokxjXfB9dHhiguv0YJ0BbHXOLY0ybD5wR5DnmSAt0W2YiKfwAU6BmT0AXAfMcs4VmVmjaCNUc139DLiQAz1oBzrn/ptgWV9yzl2e4Djh6upYiGu/S/Q8Usf7KNTcueDa4DuyfdHu4Hsf8Ot4C3W4BjfN8WW/r5I84Qfc/+F/AfwY31jxXqDEzCYD/+uc21oDZbox+I68YD2P/5VTYGYPhJ10m+LvH1Yl3nwHY3O0RPMNbefgo/JX8fdCvyGI3IHjIkZJpKx/Ba4OpnO/mZ0GnA1McM5tS6Dsk/D3lfsDzwUn2v7Ah865j8Ly1cQ+kOg2TqR8kPh+DTW37ZoAK2PMM9o8qlPWWKqzXitTFCN9U/CdhW8oGxJtf9sbfNcPJVRjnR6sLGJvk41heUIS3YZxc86tNrN5+JqFf+Nrwp6Klb+668o5t8PM5gCdgQ3A3w+m3NVUV8dCXPtdIK7zSBL2Uai5c8GFwLoYwTzAJOdcrO1SweEa3HwN7HLOtYsnc3BSHAeMM7Nj8Pcfb8Jv7Ob4naTagpbbFwb/fhQlegXfhqAHB3pkfQW0iWPy8eYDv0NDxQMDyp8EI8W6aNyN7w3xbefcwvABZnZNlPyJlHUO/jZR6JfgzUH6E3GOH/IsvkbmenyNz+X4A2lSeKaD3QequY3jLl8gof06UFPbbjv+FkM0raKkVaesFRzEeq1MrOU4Jvj+Ot7yRUh0nR6srzlQ5kjRliXRbZio8fhaot/jL/L/qCRvtdaVmV2Mb/OyBTgWGIWvhahLSTkWqhDveaQm9tFEryMHvfxm1gIfMM+JMjhUU1bZ/lbB4doVfBHQ1szaJzqic26Tc+55/P3KlcB3zSwU5O0LvqNt1MoU4BvdzcNfnCM/LwX5bgwbZzHQxMzOrWLa8eaDAw84bBtl2JlxjB+pM756NvIgOSYYFinusgbBxhP4C9d38QftSufcm4kU0Dm3Ft+z4ZLgALkef3DGvLVVxT4QSwGJb+NEy1ft/TqKRLfdv4AWZnZilGHnRUmrqbIWUI31WoVvW0SUFKz7k4EvIm5JJSLRdXqwPgSamdmpUYZdFJYnJNFtmKhp+AtZW/yv6D2V5E14XQXb6OlgHrn4Nle/NLNeNVD2RCTrWIgpgfNITeyjiV5HamL5jwq+y/1YM7PmHKgR2k8i4m2cU9cfKm9QHGpI9RrQNMrw44GOYf9fAtSPyNMY32BtB0FLfA40XHoygXLWA9bgqxOPjZEnA9/1+RuCXkT4h145ovcsyuRAz6K48gX/twt2gI+ABmHp38Lfa41sCNaDShpQB+t3P3BKxLK8EIznIvLHXdYgrTWwB3+f2QHDqrmv/A8HGiHuAd6IkieufaAmt3Ei5Ut0v66FbfcjDvRICG/UewHRe4gkdAzW8LETddmpfm+pCusw2rBE12kly92R+BoUFwT5Xg7fd4ETg332q/B9LdFtWJ0yAt/G1xq0rixvddYVMD0Ydl3YdLcB/wWa1dR6rWr7J7oeSfx6lNB+FzYsnvNcosd9tP080etITZwL0vFta7YR9PbCnx/Kyo1/x1SV27VsmolkrssPlQQ3wfDfBHmK8PfqR+N/6b0TbJiBYXm/wncDnoy/b/kI/paIAx4Iy5eGv9jtDPIMo4oLLv6i6Qi6L1aSL/S8hsFhaaET7kbgcfzzFCbhq2QvTzRfkDe0MyzFP+l1Mr6R7t+j7JQxD6RgeKhr95fAn4N18gn+Pu6HkQdKomUN8ofKtYcYF7g49pWj8c9FCB14N0bJE9c+UNPbON7yJbpf1/S2C/b9tzkQnEZ7tkdkwBD3MViT6zXWsoelJ/qcmwrrMNqwRNdpJcvTMZjOmmAdR/tchz+5h9b9Uvx+Ow5/AdgXuX6rsw3jKGOVgUK0vNXY/0IX7mcj0m8I0l9IoByVdQWPp7dUrR4LseYbx7B4znOJrvdY6yDu60hNnAuCaTwVTONzfG/Ad4L/hwbTWA3cE8/+69xhHNwEeb6LfxBScbDB1+F7wfwCyA7L92P8r5/Vwc6xGV/Fd02UaX4beAv/y6hCpBsl/3NBvh9Wke+MIN/CiPSBQVm+xgdVK/EPX2pfzXyNgp16c7Az/hO4lMq7glc4kMLyXI1v1b8TH7A8hb/fPz/Wuom3rEHeK4MyvHSQ+0voV98uImpOEt0Hanobx1O+RPfr2th2+IaUD+Mbcu4Kxr2KA88luqK6x2BNrtdYyx6eDvTCX6C+Ccr2JNAyVv4o84w1j4SPhyjT7siBX6OxPn8I8qbjT+4fBfvtV/jg7aIY0054G1ZRxmoFN4msK+AE/Pl2DXB0lOk/SxU/ChJYr6vi3P61dixUZ79L5DySyD4aa34kcB2piXNB2Dr/M77hfyk+yLkhGDYMH9R/EM/+65wre/CPSFKY2f34p9H2d87NSHZ5pCIzewb/C7qbc+7jZJcnFjPrga+l+ZU7/N5JV6sOl214qNN6PHwcrg2KJQUE3RkH428XzUpycY545t/KHZl2Ab4mbiW+elsOYdqGNUPr8fB3uHYFl8NYcJLogW+I1hr4sXNuX6UjSV34q5m1wbcz+Brfu+h7+PvdP3Oq5j0caBvWDK3Hw5yCG0mGi/Hd+zbjG55VeDO2JMXz+J4iP8Q/kHEb/tkSDzrn3klmwSRu2oY1Q+vxMKc2NyIiIpJS1OZGREREUoqCGxEREUkpCm5EREQkpSi4ERERkZSi4EZERERSioIbSTlmNt/MDplugIdaeVKZmT1lZs7MOia7LHJoMLNVZrYq2dOQuqXg5ghhZh2Dk374Z3dw0D5pZp1ref7OzObX5jwOd2b2brCezqgi3xVBvmejDMs1syfM7FMz2xFs47Vm9rKZ/Y+ZHVXJdPuY2bNm9oWZ7TSzXcHfL5jZtWaWXhPLeSgws8nBOuxfRb4zgnwVnm1iZieb2SNmtszMtplZqZltNLPXzOwOM2teyXSrvZ2qKO/IGMd5aDueG2WcgrC8t8WYbihorHTfDMu/Ksi/38yOj5GnRVA2Z2ZfJbakIpXTQ/yOPJ/i3/AKkIV/UvCNwBVm9i3n3MpkFawG5QHVujgk2ZPAOfiX091ZSb6C4Ht8KMHM6uPfpHs7/g3r8/EPHdsFHAtcCHwf//DE9uETC16D8RT+gWU7gbnANGBvkLdHMOwnwHeqt2iHnCeBa/D7/kuV5Lsx+B4fnmhmdwOjAMO/oHMusB1oiX/57h+AB8zsOOfc1rDxqr2dEjQF/3ZsgEz8E3YvB640sysqeY/bvWb2lHPum4OYd8g+oD6Qj3+ZaaTrgAz8fiZSs+J9w6Y+h/eH2G/uNQ68av6pWpy/A+Ynez0kad3PJ443RuODzZ1AEZAeI08r/BtzVwP1wtIfCtbxu0DHGOP2BhZFSZ8ajPsyEW/ODobXAwYAryR7XcaxDkP7ctR1ELFMa4J1WWGZgzzpwbb4hrA3MAM/DeaxAjgtxri5wXZvHZFe7e0U5/KPDKZ/eZRhA4Jhb0akFwTp/wm+76lkvZ4RZzlW4d9g/hbwBcEDYyPyvA8sDeWtxX1iFWFvA0/WNPSp249uSx3hnD9y/xT8mxNKD7UTMbOGZjY6qGbea2YFYXlam9kfzezzoHp5k5lNDK+GNrMeYe1NLoqoLu8R5AlVpfcIquSXmlmJmT0VDG9jZveb2SIzKwrm9ZmZ/c7MmkQuk0Vp4xIxj+vN7F/BPNaa2ajgF3XkdOqZ2WAz+2dw62CHmb1jZldGW5fBLYxXg3xbzWyqmXWIb0uAc+5rfI1JNv7XezQ34C+6Tzvn9gfzPRlf07MJuMw5tyrG9OfgaxXCy3wJ/qK3DPihc64oynj7nXPTKilTOWbW1MyGmdlbwW2aUjNbY2aPm1nrKPlDtzyON7OfmdmKYBv/x8zuiDGP44P1+5WZfR2s99PiKV9omYCn8evyhhjZfoDfFtOCbUNwq+k3+JqW7zrnlsaY/mKgJz44CpW52tuphrwWfGfHGP5X4L/AEKvkllqCxuN/WPUITzSz04Ez8UFTVGbWODg2Q/tDkZlNM7PuMfL3NLO3zd9S3Wz+tl9ltwazgukvD84FW8zsxaBsVTKzZmb2m2D8ncExv8zM/mRmjeOZhtQeBTcCvvYmlun4N+G+CjyKPzFjZl2A94DbgI+BPwLzgKuBRXagDc8q4FfB36uDv0OfVRHzGgqMBf4NPAz8K0i/EPg5sB6YhA/GNgO/AOZYYm1Bfgr8Gf+L8S/4X+73AL8Oz2RmBjwHjAMa4y+ETwNtgGmRF93gwvoW/lf3y8G02wILgGYJlC90+6MgxvB8glq2sLQ8/LH8uHPuy8om7pyLvAUQms/vnXO7Exw3llPw23cHvlboYfwtkluAhWYWa338Dr8t3sJfaBsDfzCzW8MzmVlb/K2gAcCbwGPBoLeATnGWEQ7URhTEGB5KD78l9cOgXC845/5T2cSdF/5C2IPZTjXh4uD7/RjDS/DbrSlwdw3N83l8zdeNEek34m9HTYw2kpll4m/13QN8CfweeAUfYL9r/uW74fkvwQdvZ+KP2/H4W7xv4G99RU4/G197dg/+vPIY/rjtDbxjZudVtlDB+eFVYBj+PPYo/vzwBX6/Obqy8aUOJLvqSJ+6+RDfbanxYenzg7TFQNMo01sI7AYujEg/D9+WYGZEeszbUhyoSt8GnBxleCugUZT0e4PxbohIn0/EbaCweXwJnBCW3hzYgm8vkRGW/qMg/2NA/bD0RsA/g2VvE5b+ZpD/yoj5Ph2ku2jLHmWZDH+C3AO0ihh2djCteRHp84L0ntXYL74Ixj2+Bve1pkDzKOk3BPO6NyI9tP+tBI4JSz8hWA+fRuSfEOT/34j0+0PrmipuS0XZz8+KSD8mmPfnhN1SwV80HXBjNdZLtbdTAvMI7eeTg79H4l9OOx0fyL8PdIgYpyAY5058G5lP8DVTbaNso4RuS4WN+w3QJPg/dLvvpci8YePfF8zviYj1fxH+zdwrCW7L4gPGL/DBUm5Y3jRgTjCdVRHTfy5IvzYi/QT8eejfUZZnVdj/pwXj/z7KsmcRdi7RJzkfNSg+8pxsZiODv7PwJ4uzgK346vZII51z28ITzOws4FzgMefcm+HDnHMLzewlfAPlppHjVmGcc255ZKJzbnOM/H8CHsD/Io36CzCKPzrnPgub9pdmNgN/gj8JX2sEvkZqK/BzF/br2zn3jZk9gP+VdyXwqJkdh29ou9g5Nz1ifsOB6/EXjSo551xwO24kPhj4fdjgguB7fPmxCN3qWR85PTP7PmG3GwOTw9ZzZePegD/Zh/uLc25j7CWASrb5JPwv3IvxjXEj/do5tylsOp+Z2QKgh5k1cc5tN7MGwFXAOuCRiPHH4BvqJlpTdhF+3YbXaNyAvzg+5YIrVqCy9XUBB2pHQl5xzr0bx7hVbadEXRMlbQs+2P5vrJGcc/vM7F58jdt9+Nq2gzUeX+N4NT5YCd3ui9yPw+Xja5L+X/j6d84VBsdrf+B8fG3dBfgfby84fzswlHevmQ0HeoVPOKi1uRqY5Zx7LnxYsM/9FfiFmZ3qnFtWxbLtikxwwS1MSS4FN0eek/AnLfC/TNfje46Mcs59ESX/kihp5wTf7cICpXDH4n9NdYkxfiwx85rZVfjalDPwF6/wW6rHJjCPD6KkrQu+jw7mdRRwKr7B6f/zNdDltAy+Tw6+Q2093orM6JxbY2ZrgKjdYWN4Cr+NCgiCGzPLAK7F1zBNTWBa38evt3AfcqAnTWVuAPpGpL0IVBrcAJhZb3xNwLeAFpQP7mJtr6q2zXbgRHzvn3865/aEZwwCzw/xbV3iNRUfJF1nZr90zpUG6QVUvP1XlQs4cGyFfIW//VGVg9lO0VzhnHsRyvadzviazj/gzwE/iTWic26amS0GbjSz3znnVlSzDCFv4mvACvDBzY34mptZ0TKbWRb+ePkgPNgNMx8f3JyBP+ZCbWQqHH/4dR95iy8Xf/5oHOP8dUrwfTK+LVo0HwfD7jbfPX5WMP9lEcGwJImCmyPPS865yxPIH63WJNRIr3/wiaVRAvOJNS/MbAjwf8Hw2fgLXkkw+D6gQQLziFarEDr5hS7AzfC3h46j4sUqXGj5mgbfsWqYNpFAcOOcW21mc4HeZna2c+49oB8+SPibc25nlOmfjG8P9GnEtG4FbgXfqJqKy7MJv5xt8FX74eNeGvo7qE3Kj6f8ZnY1/rbIdnw7iVUc+IV7J7G3VzzbJp51HbcgIHoeuBlfozDNzHLwwe0bzrk1MabfJsq0RuNvAWG+4X1kzcTBbKdqCwK2T8wsH//D5Edm9n8uRoPmwN349iqj8LUcBzP/UG3k/Wb2HeBS4NHI4DRMVvAda1tujMgXc59wzu03s+KI5ND566LgE0vM81dQK9QLfyv0SuCyYNB/zWyUc25cJdOVOqAGxVKpGL9CQtWug51zVsmnMNHZRSaYWRr+F+d6oJtzbpBzbphzbiS+YXBtCC3f21UsX6iRZOii3CrG9I6pRhkiGxYXRKSHWxh896jGfA5m3FjuwwczZznnrnHODQ2216+I0rgzQVrX1eR8I+UP8ef9Sh/G53yPrTnAD83s7BqY/dP4tjLP4X9UV3ZLKnT8xdqWx0Tki7lPmFk9KvYOC4336yqO76crKSPOuSLn3I/xNZGnA7/E/yh63MyuqGxcqX0KbqQ6FgXfFZ52Won9xNnuJEI2/hfaQudc5C+w86sxvSo557bjbwecGmeXzlB34AsiB5jvCh53d/Aw0/En7euCNj2X4hvWVnhSLgcuHD+qRhfe0EXmf4P2LDWhM/CJq9ib6Eyg4UFOewW+1u6cyF5y5h9GGNcTdMM5597G16RcGqzra/HrPrL9FMAL+F5gV1viT/U+mO1UU0LtkeI59w/DX6wfPNiZBjVgc/E9CD9wMbrQB3m/xtcinmJmLaNkCdW2fBh8h3pVRnvA5LlUvEOxGP9DKpHzV0zOPyphqXPuIfy+A76mVZJIwY0kzDn3T3yAc6OZ/SByuJmlR3bVxPdSaluN2W0mqAUws7ILo5kdS/QG0DXlEXx195+CbqnlmFk3M2sF/jYS/n77t6ziM3AeoBpBnXNuF/7WTnPg2WAaUX/tBo1O/4D/RfsPi/1epaaRCc651/AX8VOBqdEuJkG316zI9EqsAbqE1k8wjSx8l/CD4nx39Rfw+9JPIwYPJbHGxOGewl8En8Wv8+eccyWRmZzvwv3/8O1+ZlvsZ+tEW9fV3k41IWgb8h38rb4q2wE555bgn7vUhyiBezXcBlyB7xJflQn4dXx/eGJwXrkc/8DBt4Pkt/G3Pq80s9ywvGn446+coEH8VPxt3x9HDjf/fKvKbleFnrN0cpRBoVqlCg2NpW6pzY1U13X4rq0zzOwt/K+ovfj2G9/BBzPhB/884Cozm4Kv6dgHPBulTUM5wT3zv+Cfc/OBmc3CX3y+j2+oeFKNLtUBf8Y/SG0QvrfOXPy9/mPxDYjPwHd7D93n/yn+mTbPm9kL+JNtD/xFeCkHGh0n4kl8I9Nv49fXhEry3oVvy3IbsML8e7yW4Ws5jsH/Su0KbMBfGMKFLjZXAqvMbA6+JmMfvofPRfjeKJ8RX5uWR/GBzPtmNi0o13fxtxYr9BSqhrvxF9yHzD8Ichm+m/y5+CCzOq+IeBrfviT08LwnY2V0zj1i/uGRDwAfBj26PsDX6LTE7xu5+NqfyAapB7OdEjHQDrwHKgP//J/L8d2wRzrn4t0O9wTjHfS754KGyfE2Th6DP8ZvDQLIN/HH0jX4dXWTCx5iGfTwuhWYCRSa2XNAMfA9fPf3DVGm/2P8+elPZvY/+B9rO/C1rOfhb3FV+FET5nTg72b2LvAR/jxwPH5d7cQ/50qSyR0C/dH1qf0PMZ5zU0n++VTxbBZ8A9cH8T0HduHvZX+C7xHROyJvG/yvpS34qnkH9AiGjQz/P8p8MoAR+ItrCf6kPzJId0Q8Pyda2SubRxXDrscHZlvxz7ZZg39414+JePYO/rbLa/hnemzF/+o9Lp51Wck6XhaUbWac+c/BX5hXBuXYjW+APQvfrbdxJeP2xbeJWBVsz13B39MJ3gMUZxmMAw933IXvevww0IQoj7GnklcmxBqGv1hPwwcQXwfr/bTKphVHuWcF4y6LM39XfCD3Eb7xdCk++HsD+F+gRW1spyrKFNqXwz/78T82Xsf3ooocpyDId2eMaf4tbFoJP+emunmD/eU3+OO+FH/umA6cHmM6vYB3gn2uKFi/zaPtc0H+RvhauA+CbbAj2B7PUfF5VeWmAbTDNx7/Jz6wKcH3CHsaOKU6206fmv1YsKFEREQNRBpdAAAgAElEQVREUoLa3IiIiEhKUXAjIiIiKUUNikVEDlFBj6qCOLKucs49VZtlETmcqM2NiMghKugNNi+OrIXOuR61WxqRw4eCGxEREUkpui0Vh+zsbNexY8dkF0NERKROvPfee8XOuWhPiD4sKLiJQ8eOHVmyJJGXW4uIiBy+zGx1sstwMNRbSkRERFKKghsRERFJKQpuREREJKUouBEREZGUouBGREREUoqCGxEREUkp6gouIiIJKSkpoaioiJKSEvbu3Zvs4kgC0tPTadWqFVlZWckuSq1ScCMiInHbtm0bmzZtomXLlrRu3Zq0tDTMLNnFkjg459i1axfr1q0DSOkAR7elREQkbsXFxbRr145mzZqRnp6uwOYwYmYcddRRtG3bls2bNye7OLVKwY2IiMSttLSUhg0bJrsYchAaNmzInj17kl2MWqXgRkREEqLamsPbkbD9FNyIiIhISlFwIyIiR6z+/fvTvHlzdu/eHXX49u3badSoEQUFBWVpCxcuZODAgbRr146MjAyysrLIzc1l+PDhbNiwocI0iouLueeee+jevTuNGzcmMzOTzp07k5eXx/z588vlXbBgAQUFBZx66qmkpaXRsWPHqOVau3YtP/3pTznvvPM46qijMDNWrVpVzbWQehTciIjIESs/P5+tW7cyc+bMqMOnTp3Kzp07yc/PB+Chhx7i/PPPp6ioiFGjRvHGG28wefJk+vbty7hx47jpppvKjb9s2TJOP/10xo8fz7XXXsv06dOZPXs2Q4YM4fPPP6dnz55s2rSpLP+cOXN466236NatG6ecckrMcn/22Wc8//zzNGvWjO985zs1sCZSjHNOnyo+Z599thMREec+/vjjZBehRu3evdu1aNHC9evXL+rwHj16uA4dOrj9+/e7uXPnOjNzd955Z9S8O3bscOPHjy/7v7S01HXp0sV16dLFbd68Oeo4kyZNclu2bCn7f9++fWV/X3/99e64446LOl54vr/+9a8OcF988UWMpayoqu0ILHGHwPW3uh/V3IiIyBErIyODgQMHMnv2bIqLi8sNW7NmDYWFhQwaNAgzY8yYMWRnZzNmzJio04q8fTVt2jRWrlzJmDFjaNmyZdRxrrvuOpo3b172f7168V2W4813pNLaERGRI1p+fj579uxhypQp5dInTpyIc468vDz27t1LYWEhffr0ISMjI67pzpkzh/r163PppZfWRrGlEgpuREQkqV78YB3nj57L8cNmcf7oubz4wbo6nX9ubi5du3ZlwoQJ5dKfeeYZzjvvPE488US2bNlCSUkJHTp0qDD+3r17y31C1q5dS8uWLSs8F2j//v3l8vu7QFKTFNyIiEjSvPjBOu6e/m/WfbULB6z7ahd3T/93nQc4eXl5LFq0iBUrVgCwaNEili9fTl5eHkDMAGTjxo2kp6eX+4QCnFjjXHbZZeXyP/HEE7WwREc2BTciIpI0v331U3bt2Vcubdeeffz21U/rtBw33HAD9erVK6u9mTBhAg0aNOCaa64BIDs7m8zMTNasWVNuvOzsbBYvXszixYsZPHhwuWHt27enqKiIXbt2lUt/5JFHWLx4MTNmzKjFJTqyKbgREZGkWf/VroTSa0vbtm25+OKLmThxIqWlpUyZMoV+/frRrFkzANLS0rjwwgt5/fXXKS0tLRsvLS2NnJwccnJyaNOmTblp9urVi3379vHKK6+US+/SpQs5OTl079699hfsCKXgRkREkqbN0dHfUxUrvTbl5+ezevVq7r77boqLi8tuSYXcddddFBcXM3To0LimN2DAADp37szQoUMpKiqqjSJLDGnJLoCIiBy5hvQ9ibun/7vcramG6fUZ0vekOi/LFVdcQVZWFmPHjqVVq1YVejn17t2b0aNHM2zYMJYuXUpeXh7HH388JSUlrFixgsmTJ9OoUaOydzdlZGQwffp0+vbtyxlnnMFtt91Gbm4uGRkZbNy4kWnTpgHQpEmTsnkUFRVRWFgI+K7oO3fuZOrUqQB07dqVrl27luUNpb/33nsAzJ49m5YtW9KyZUsuuuiiWlpLh4lkP2jncPjoIX4iIl5tPMTv7++vdd9+cI7rOHSm+/aDc9zf319b4/OI18033+yAmA/qc865BQsWuKuuusq1adPGpaenuyZNmricnBw3YsQIt379+gr5N2/e7IYNG+a6devmGjZs6Bo0aOA6derk8vLyXGFhYbm88+bNc0DUz3333Vcub6x8F110UZXLmeoP8TOnLmhVysnJcUuWLKmRab34wTp+++qnrP9qF22ObsiQvidx+Zlta2TaIiK17ZNPPqn0tQByeKhqO5rZe865nDosUo3Sbak6FOryGKp+DXV5BBTgiIiI1BA1KK5Dh0qXRxERkVSW9ODGzNqb2VQz22ZmX5vZdDOr+AjI6ON2MLOnzWyNme00sxVmNsrMGkXkm29mLsrnztpZqugOlS6PIiIiqSypt6XM7ChgLrAbyMc3hhoFzDOz05xz31QybiPgDSAdGA6sAXKBXwFdgGsiRlkK/CgibdXBL0X82hzdkHVRAplkdHkUERFJVcluczMY6ASc5Jz7DMDMlgIr8YHI7ysZ93x8ENPXOfdakDbPzJoDvzSzo5xzO8Pyb3fOvVvjS5CAQ6nLo4iISKpK9m2pfsC7ocAGwDn3BfA20L+KcUOvZf06Iv0r/HJZTRWyplx+ZlsevLI7bY9uiAFtj27Ig1d2V2NiERGRGpTsmptuwEtR0j8Crqpi3DfwNTxjzOzH+NtS3wLuAP4S5ZbWmWa2DTgK+AR42DlX528ru/zMtgpmREREalGyg5vmwNYo6V8CzSob0TlXYmYXANPwwVDI34DbI7K/CUwCVgBHA3nA38zsWOfcqGqWXURERA5ByQ5uwDcijlTlLSUzywSmAK2AQRyouRkB7AV+XDYD50ZEjP6Smf0duMfM/uCc2xFl+rcAtwB06BBX5y0RERE5BCS7zc1WfO1NpGZEr9EJdzPQA7jMOTfROfemc+53wC+AW83s9CrGfw7IBKK+ltU5N845l+Ocy2nZsmUVkxIREZFDRbKDm4/w7W4idQU+rmLc7sBW59x/ItIXBd9VPR88VDuk90+IiByh+vfvT/Pmzdm9e3fU4du3b6dRo0YUFBSUpS1cuJCBAwfSrl07MjIyyMrKIjc3l+HDh7Nhw4YK0yguLuaee+6he/fuNG7cmMzMTDp37kxeXh7z588vl3fBggUUFBRw6qmnkpaWRseOHaOW69VXX6VXr160bt2aBg0a0K5dO66++mo+/riqS+eRIdnBzQzgXDPrFEows474bt4zqhh3I9DMzE6ISD8n+F5XxfjXAbuAf8dbWBERSS35+fls3bqVmTNnRh0+depUdu7cSX5+PgAPPfQQ559/PkVFRYwaNYo33niDyZMn07dvX8aNG8dNN91Ubvxly5Zx+umnM378eK699lqmT5/O7NmzGTJkCJ9//jk9e/Zk06ZNZfnnzJnDW2+9Rbdu3Sp999OXX37J2WefzaOPPsprr73Ggw8+yEcffcS5557L6tWra2DNHOaS+dZOoBHwGT7A6I/vGv4v4HOgcVi+4/DtaEaEpXXEdwNfgX8AYE9gSJC2BKgX5PsOMAt/G6s3cCW+h5YDhsZTTr0VXETEq423gifT7t27XYsWLVy/fv2iDu/Ro4fr0KGD279/v5s7d64zs5hvDN+xY4cbP3582f+lpaWuS5curkuXLm7z5s1Rx5k0aZLbsmVL2f/79u0r+/v66693xx13XNzLsnz5cge43/3ud1XmTfW3gie15sb57tq98AHKM/geTV8AvVz5Rr4G1Cespsk5two4F/gQ/1Tjf+AfCjgO6OOc2x9k3RCMd3+QZwLQErjOOTemtpZNREQOfRkZGQwcOJDZs2dTXFxcbtiaNWsoLCxk0KBBmBljxowhOzubMWOiXzoib19NmzaNlStXMmbMGGK13bzuuuto3vxA09N69ap/WW7RogUA6enp1Z5Gqkh6bynn3BpgQBV5VhGlB5Vz7mPg6irG/Qz47kEUUUREUlh+fj6PPfYYU6ZM4bbbbitLnzhxIs458vLy2Lt3L4WFhVx55ZVkZGRUMrUD5syZQ/369bn00ktrq+js27ePffv2sXr1aoYNG0br1q0ZOHBgrc3vcJHsNjciInKkW/o8jD0VRh7tv5c+X6ezz83NpWvXrkyYMKFc+jPPPMN5553HiSeeyJYtWygpKYn6aJC9e/eW+4SsXbuWli1b0rBh+fcH7t+/v1x+fxeoes455xwaNGjAiSeeyNKlS5k7dy6tWrWq9vRShYIbERFJnqXPw8s/g23/BZz/fvlndR7g5OXlsWjRIlasWAHAokWLWL58OXl5eQAxA5CNGzeSnp5e7hMKcGKNc9lll5XL/8QT1X9Y/jPPPMO7777Ls88+S1ZWFn369GHVqlXVnl6qUHAjIiLJM+d+2LOrfNqeXT69Dt1www3Uq1evrPZmwoQJNGjQgGuuuQaA7OxsMjMzWbNmTbnxsrOzWbx4MYsXL2bw4MHlhrVv356ioiJ27Sq/fI888giLFy9mxoyqOgVX7ZRTTuGcc87h2muvZc6cOezYsYPRo0cf9HQPdwpuREQkebatTSy9lrRt25aLL76YiRMnUlpaypQpU+jXrx/Nmvk3AaWlpXHhhRfy+uuvU1paWjZeWloaOTk55OTk0KZNm3LT7NWrF/v27eOVV14pl96lSxdycnLo3j3qM2Sr7eijj+aEE07gs88+qzpzilNwIyIiydO0XWLptSg/P5/Vq1dz9913U1xcXHZLKuSuu+6iuLiYoUOHxjW9AQMG0LlzZ4YOHUpRUVFtFLmcTZs2sXz5cjp37lzr8zrUJb23lIiIHMF6j/BtbMJvTaU39Ol17IorriArK4uxY8fSqlWrCr2cevfuzejRoxk2bBhLly4lLy+P448/npKSElasWMHkyZNp1KgRZr5zb0ZGBtOnT6dv376cccYZ3HbbbeTm5pKRkcHGjRuZNm0aAE2aNCmbR1FREYWFhYDvir5z506mTp0KQNeuXenatWtZWc866yxOO+00srKyWLFiBWPHjiUtLY1f/OIXtb6uDnnJftDO4fDRQ/xERLxaeYjfv6Y49/tuzt3X1H//a0rNzyNON998swNiPqjPOecWLFjgrrrqKtemTRuXnp7umjRp4nJyctyIESPc+vXrK+TfvHmzGzZsmOvWrZtr2LCha9CggevUqZPLy8tzhYWF5fLOmzfP4R8yW+Fz3333leUbPXq0O+uss1zTpk1dw4YN3YknnuhuueUW98UXX8S1nKn+ED9zB9EF7UiRk5PjlixZkuxiiIgk3SeffFLpawHk8FDVdjSz95xzOXVYpBqlNjciIiKSUhTciIiISEpRcCMiIiIpRcGNiIiIpBQFNyIiIpJSFNyIiIhISlFwIyIiIilFwY2IiIikFAU3IiIiklIU3IiIiEhKUXAjIiJHrP79+9O8eXN2794ddfj27dtp1KgRBQUFZWkLFy5k4MCBtGvXjoyMDLKyssjNzWX48OFs2LChwjSKi4u555576N69O40bNyYzM5POnTuTl5fH/Pnzy+VdsGABBQUFnHrqqaSlpdGxY8dKy/+Pf/yDCy+8kMaNG5OVlUVOTg5z585NdDWkHL0VXEREjlj5+fnMmDGDmTNnMmDAgArDp06dys6dO8nPzwfgoYceYsiQIfTs2ZNRo0bRqVMnduzYwTvvvMO4ceNYsmQJs2fPLht/2bJl9O3bF+cct99+Ozk5OaSnp/Ppp58yceJEevbsycaNGznmmGMAmDNnDm+99RY5OTmYGdu3b49Z9scff5zbb7+d22+/neHDh7N//34+/PBDdu7cWcNr6TCU7Dd3Hg4fvRVcRMSrlbeCJ9Hu3btdixYtXL9+/aIO79Gjh+vQoYPbv3+/mzt3rjOzmG8M37Fjhxs/fnzZ/6Wlpa5Lly6uS5cubvPmzVHHmTRpktuyZUvZ//v27Sv7+/rrr3fHHXdc1PG++OILl5mZ6caOHVvFEkaX6m8F120pERE5YmVkZDBw4EBmz55NcXFxuWFr1qyhsLCQQYMGYWaMGTOG7OxsxowZE3Vakbevpk2bxsqVKxkzZgwtW7aMOs51111H8+bNy/6vVy++y/KTTz5JvXr1uPXWW+PKf6RRcCMiIke0/Px89uzZw5QpU8qlT5w4EecceXl57N27l8LCQvr06UNGRkZc050zZw7169fn0ksvrfEyL1iwgJNPPpnJkyfTuXNn0tLSOOGEE3jsscdqfF6HIwU3IiKSVLM+n8UlUy/htKdP45KplzDr81l1Ov/c3Fy6du3KhAkTyqU/88wznHfeeZx44ols2bKFkpISOnToUGH8vXv3lvuErF27lpYtW9KwYcNy+ffv318uv78LlJj169ezcuVKhgwZwrBhw3jttdfo06cPt99+Ow8//HDC00s1Cm5ERCRpZn0+i5HvjGTDNxtwODZ8s4GR74ys8wAnLy+PRYsWsWLFCgAWLVrE8uXLycvLA4gZgGzcuJH09PRyn1CAE2ucyy67rFz+J554IuHy7t+/n+3bt/P4448zePBgevXqxZ///GcuvfRSHnzwwWoFTKlEwY2IiCTNw+8/TMm+knJpJftKePj9uq19uOGGG6hXr15Z7c2ECRNo0KAB11xzDQDZ2dlkZmayZs2acuNlZ2ezePFiFi9ezODBg8sNa9++PUVFRezatatc+iOPPMLixYuZMWNGtcvbokULAPr06VMu/ZJLLmHTpk1Ru6QfSRTciIhI0mz8ZmNC6bWlbdu2XHzxxUycOJHS0lKmTJlCv379aNasGQBpaWlceOGFvP7665SWlpaNl5aWRk5ODjk5ObRp06bcNHv16sW+fft45ZVXyqV36dKFnJwcunfvXu3yduvWLWp6qMYm3obJqerIXnoREUmq1o1aJ5Rem/Lz81m9ejV33303xcXFZbekQu666y6Ki4sZOnRoXNMbMGAAnTt3ZujQoRQVFdVoWa+44goAXn311XLpr776Ku3ataN167pff4cSPcRPRESS5o6z7mDkOyPL3ZrKrJ/JHWfdUedlueKKK8jKymLs2LG0atWqQi+n3r17M3r0aIYNG8bSpUvJy8vj+OOPp6SkhBUrVjB58mQaNWqEmQG+m/n06dPp27cvZ5xxBrfddhu5ublkZGSwceNGpk2bBkCTJk3K5lFUVERhYSHgu6Lv3LmTqVOnAtC1a1e6du0K+HY7PXv25Ec/+hHFxcV06tSJqVOn8tprrzF+/PhaX1eHvGQ/aOdw+OghfiIiXm08xG/mf2a6Pi/0cd2f6u76vNDHzfzPzBqfR7xuvvlmB8R8UJ9zzi1YsMBdddVVrk2bNi49Pd01adLE5eTkuBEjRrj169dXyL9582Y3bNgw161bN9ewYUPXoEED16lTJ5eXl+cKCwvL5Z03b54Don7uu+++cnm3bdvmfvKTn7hWrVq59PR01717dzdp0qS4ljPVH+Jn7ghvUR2PnJwct2TJkmQXQ0Qk6T755BNOOeWUZBdDDlJV29HM3nPO5dRhkWqU2tyIiIhISlFwIyIiIilFwY2IiIikFAU3IiIiklIU3IiIiEhKUXAjIiIiKUXBjYiIiKQUBTciIiKSUhTciIiISEpRcCMiIiIpRcGNiIgcsfr370/z5s3ZvXt31OHbt2+nUaNGFBQUlKUtXLiQgQMH0q5dOzIyMsjKyiI3N5fhw4ezYcOGCtMoLi7mnnvuoXv37jRu3JjMzEw6d+5MXl4e8+fPL5d3wYIFFBQUcOqpp5KWlkbHjh1jln3evHlccMEFNGzYkObNmzNo0CA2bdpUndWQchTciIjIESs/P5+tW7cyc+bMqMOnTp3Kzp07yc/PB+Chhx7i/PPPp6ioiFGjRvHGG28wefJk+vbty7hx47jpppvKjb9s2TJOP/10xo8fz7XXXsv06dOZPXs2Q4YM4fPPP6dnz57lApI5c+bw1ltv0a1bt0rf/fTWW29xySWXcPTRRzNt2jQefvhh3nzzTXr37h0zUDuiJPvNnYfDR28FFxHxauOt4Mm0e/du16JFC9evX7+ow3v06OE6dOjg9u/f7+bOnevMLOYbw3fs2OHGjx9f9n9paanr0qWL69Kli9u8eXPUcSZNmuS2bNlS9v++ffvK/r7++uvdcccdF3W83r17u86dO7s9e/aUpS1atMgB7rHHHou1uGVS/a3gqrkREZEjVkZGBgMHDmT27NkUFxeXG7ZmzRoKCwsZNGgQZsaYMWPIzs5mzJgxUacVeftq2rRprFy5kjFjxtCyZcuo41x33XU0b9687P969eK7LL/77rv06dOHtLS0srTc3FxatGjB3//+97imkcoU3IiIyBEtPz+fPXv2MGXKlHLpEydOxDlHXl4ee/fupbCwkD59+pCRkRHXdOfMmUP9+vW59NJLa7zM9evXj1qOBg0asGzZshqf3+FGwY2IiCTVtpdfZmWv3nxySldW9urNtpdfrtP55+bm0rVrVyZMmFAu/ZlnnuG8887jxBNPZMuWLZSUlNChQ4cK4+/du7fcJ2Tt2rW0bNmShg0blsu/f//+cvn9XaDEnHTSSbz77rvl0lavXs2GDRv48ssvE55eqlFwIyIiSbPt5ZfZMHwEe9evB+fYu349G4aPqPMAJy8vj0WLFrFixQoAFi1axPLly8nLywOIGYBs3LiR9PT0cp9QgBNrnMsuu6xc/ieeeCLh8t5xxx0sWrSIe++9l82bN7N8+XIGDRpEvXr14r61lcq0BkREJGk2j/0DrqSkXJorKWHz2D/UaTluuOEG6tWrV1Z7M2HCBBo0aMA111wDQHZ2NpmZmaxZs6bceNnZ2SxevJjFixczePDgcsPat29PUVERu3btKpf+yCOPsHjxYmbMmFHt8l5//fXce++9PPTQQxxzzDF07dqVtm3bctlll3HsscdWe7qpQsGNiIgkzd4oz4WpLL22tG3blosvvpiJEydSWlrKlClT6NevH82aNQMgLS2NCy+8kNdff53S0tKy8dLS0sjJySEnJ4c2bdqUm2avXr3Yt28fr7zySrn0Ll26kJOTQ/fu3Q+qzA888ADFxcUsXbqUDRs28Nxzz7Fy5UouuOCCg5puKlBwIyIiSZMWo5YhVnptys/PZ/Xq1dx9990UFxeX3ZIKueuuuyguLmbo0KFxTW/AgAF07tyZoUOHUlRUVBtFplGjRnTv3p1jjjmGV155heXLl3PrrbfWyrwOJ2lVZxEREakdrX5+JxuGjyh3a8oyM2n18zvrvCxXXHEFWVlZjB07llatWlXo5dS7d29Gjx7NsGHDWLp0KXl5eRx//PGUlJSwYsUKJk+eTKNGjTAzwHcznz59On379uWMM87gtttuIzc3l4yMDDZu3Mi0adMAaNKkSdk8ioqKKCwsBHxX9J07dzJ16lQAunbtSteuXQH44IMPmD17NmeddRbgn2z829/+lrvuuotvf/vbtbuiDgfJftDO4fDRQ/xERLzaeIjfVzNmuBU9e7mPTz7FrejZy301Y0aNzyNeN998swNiPqjPOecWLFjgrrrqKtemTRuXnp7umjRp4nJyctyIESPc+vXrK+TfvHmzGzZsmOvWrZtr2LCha9CggevUqZPLy8tzhYWF5fLOmzfPAVE/9913X1m+ZcuWufPPP981bdrUZWZmujPPPNM9+eSTcS9nqj/Ez1w1uqAdaXJyctySJUuSXQwRkaT75JNPKn0tgBweqtqOZvaecy6nDotUo9TmRkRERFKKghsRERFJKQpuREREJKUkPbgxs/ZmNtXMtpnZ12Y23cwqPt86+rgdzOxpM1tjZjvNbIWZjTKzRlHyDjaz5Wa228w+NTP1lRMREUlBSe0KbmZHAXOB3UA+vkX4KGCemZ3mnPumknEbAW8A6cBwYA2QC/wK6AJcE5Z3MPA48GAwTm/gT2Zmzrk/18KiiYiISJIk+zk3g4FOwEnOuc8AzGwpsBL4EfD7SsY9Hx/E9HXOvRakzTOz5sAvzewo59xOM0sDfg0845y7JyxfG+ABM/ubc25PzS+aiIiIJEOyb0v1A94NBTYAzrkvgLeB/lWMG3rX+9cR6V/hl8uC/88DWgITI/I9A7QA9JxqEZEE6BEih7cjYfslO7jpBiyLkv4R0LWKcd/A1/CMMbOuZtbYzHoBdwB/Cbul1S34jpzPR8F3VfMREZFARkZGhRdByuFl165dpKenJ7sYtSrZwU1zYGuU9C+BZpWN6Jwrwde61MMHKtuBOcBM4PaIeRBlPl9GDBcRkSpkZ2ezdu1avvzyS/bs2XNE1AKkCuccO3fuZN26dbRq1SrZxalVyW5zA74RcSSLklY+g1kmMAVoBQzCNyj+FjAC2Av8OGJaCR2BZnYLcAtAhw5xdd4SEUl5TZs2pUGDBhQVFbFlyxb27t2b7CJJAtLT0znmmGPIyspKdlFqVbKDm61ErzlpRvQanXA3Az2AE5xz/wnS3jSzbcA4M/uLc+5flK+h2RA2fmi+XxKFc24cMA786xeqKIuIyBEjMzOT9u3bJ7sYIjEl+7bURxxoExOuK/BxFeN2B7aGBTYhi4Lv0EszQm1rIucTamtT1XxERETkMJLs4GYGcK6ZdQolmFlHfDfvGVWMuxFoZmYnRKSfE3yvC74XAsXA9RH5bsDX2rydcKlFRETkkJXs4OavwCrgJTPrb2b9gJeA/+IfugeAmR1nZnvNbETYuE/hGxH/w8zyzaynmQ0Bfge8RxC0BM+wGQ7kB08v7mFm9wM3ASOcc6W1vpQiIiJSZ5La5sY5903QfXss/rkzhu/xdKdzbkdYVgPqExaMOedWmdm5wEj8U42z8UHROODXzrn9YXn/YmYO+AUwBN/4+Hbn3J9qcfFEREQkCUzd+KqWk5PjlixZkuxiiIiI1Akze885l5PsclRXsm9LiYiIiNQoBd1XyosAACAASURBVDciIiKSUhTciIiISEpRcCMiIiIpRcGNiIiIpBQFNyIiIpJSFNyIiIhISlFwIyIiIilFwY2IiIikFAU3IiIiklIU3IiIiEhKUXAjIiIiKUXBjYiIiKQUBTciIiKSUhTciIiISEpRcCMiIiIpRcGNiIiIpBQFNyIiIpJSFNyIiIhISlFwIyIiIilFwY2IiIikFAU3IiIiklIU3IiIiEhKSUt2AUSORC9+sI7fvvop67/aRZujGzKk70lcfmbbZBdLRCQlKLgRqWMvfrCOu6f/m1179gGw7qtd3D393wAKcEREaoBuS4nUsd+++mlZYBOya88+fvvqp0kqkYhIalFwI1LH1n+1K6F0ERFJjIIbkTrW5uiGCaWLiEhiFNyI1LEhfU+iYXr9cmkN0+szpO9JSSqRiEhqUYNikToWajSs3lIiIrVDwY1IElx+ZlsFMyIitUS3pURERCSlKLgRERGRlKLgRkRERFKKghsRERFJKQpuREREJKUouBEREZGUouBGREREUoqCGxEREUkpCm5EREQkpSi4ERERkZSi4EZERERSioIbERERSSkKbkRERCSlKLgRERGRlKLgRurO0udh7Kkw8mj/vfT5ZJdIRERSUFqyCyBHiKXPw8s/gz27/P/b/uv/Bzjt6uSVS0REUo5qbqRuzLn/QGATsmeXTxcREalBCm6kbmxbm1i6iIhINSm4kbrRtF1i6SIiItWk4EbqRu8RkN6wfFp6Q58uIiJSgxTcSN047Wr4wR+haXvA/PcP/qjGxCIiUuPUW0rqzmlXK5gREZFap5obERERSSkKbkRERCSlKLgRERGRlKLgRkRERFJK0oMbM2tvZlPNbJuZfW1m082sQxzjjTQzF+NTEpF3VYx8l9fekomIiEgyJLW3lJkdBcwFdgP5gANGAfPM7DTn3DeVjP434JWItEZB2owo+V8FRkakfVqNYouIiMghLNldwQcDnYCTnHOfAZjZUmAl8CPg97FGdM6tBco9u9/MBuGX6ekooxQ7596toXKLiIjIISrZt6X6Ae+GAhsA59wXwNtA/2pMLx/YhK+lERERkSNQsoObbsCyKOkfAV0TmZCZtQN6ApOcc3ujZPmBme00s91m9q7a24iIiKSmZAc3zYGtUdK/BJolOK1B+OWJdkvqZeCnQF/geqAE+LuZ3ZDgPEREROQQl+w2N+AbEUeyakwnD/jAObe0wgyc+2m5iZv9HXgXeBCYGG1iZnYLcAtAhw5Vdt4SERGRQ0Sya2624mtvIjUjeo1OVGb2LeBkotfaVOCc2we8ALQzs2Nj5BnnnMtxzuW0bNky3qKIiIhIkiU7uPkI3+4mUlfg4wSmkw/sBZ5NYJxQ7VC0miMRERE5TCU7uJkBnGtmnUIJZtYROJ/oz6qpwMwygIHAP5xzRXGOkwZcBaxxzm1MsMwiIiJyCEt2cPNXYBXwkpn1N7N+wEvAf4HHQ5nM7Dgz22tmI6JM4/v4W1tRb0mZ2bVmNtnM8sysp5kNBOYBZwNDa3ZxREREJNmS2qDYOfeNmfUCxgLP4G8VzQHudM7tCMtqQH2iB2P5+N5VM2PM5gugFfBbfBC0E1gMXOqc0/NwREREUkzSe0s559YAA6rIs4oYPaicc5U+7C94KnGv6pZPREREDi/Jvi0lIiIiUqMU3IiIiEhKUXAjIiIiKUXBjYiIiKQUBTciIiKSUhTciIiISEpRcCMiIiIpRcGNiIiIpBQFNyIiIpJSFNyIiIhISlFwIyIiIilFwY2IJMWsz2dxydRLOO3p07hk6iXM+nxWsoskIiki6S/OFJEjz6zPZzHynZGU7CsBYMM3Gxj5zkgAvtfpe0ksmYikAtXciEide/j9h8sCm5CSfSU8/P7DSSqRiKQSBTciUuc2frMxoXQRkUQouBGROte6UeuE0kVEEqHgRkTq3B1n3UFm/cxyaZn1M7njrDuSVCIRSSVqUCwidS7UaPjh9x9m4zcbad2oNXecdYcaE4tIjVBwIyJJ8b1O31MwIyK1QrelREREJKUouBEREZGUouBGREREUoqCGxEREUkpCm5EREQkpSi4ERERkZSi4EZERERSioIbERERSSkKbkRERCSlKLgREakl217+/+3debxdVX338c+XRAigDwZNBAdUxFcVhMfW2GqdQXGMQ7VYHgXaqmidQKtPpUpK0Sp1ilCf1qkDGkdQihFEFKGDNlWkhQKKjAolEMYwSJDA7/lj72sPJ+dOyc095+77eb9e57Vz115777Xuyb73e9de++zVXLzvfvz4sXty8b77sX716mE3SZoXfPyCJG0F61evZu2RK6gNGwDYePXVrD1yBQA7LV8+zKZJnefIjSRtBetWfuxXwWZMbdjAupUfG1KLpPlj2uEmyS5boyGS1CUb166dVrmkmbM5IzeXJjkmyeL+FUm2TbL9DLRLkua0hbvuOq1ySTNn0nCTZO++omcAewKXJXlPkh171u0L3DKD7ZOkOWnp2w4nixbdqyyLFrH0bYcPqUXS/DHuhOIk2wF/BhwA7NGzaj0wdiH5aOCwJJcCC4DHAedsnaZK0twxNml43cqPsXHtWhbuuitL33a4k4mlWTDR3VLnAecCy/rKjwceDBwL3AxsCxxMM5pzIvCGmW+mJM09Oy1fbpiRhmCicLOgXd7TV/544BVVdepYQZIPA28E/hLYH/jSTDZSkiRpqiaac/M44GdseplpLbC0t6Cq7qmqjwN/AnxoRlsoSZI0DeOGm6raUFXvBF7Rt+rvgWOS/NaAza4Elsxg+yRJkqZl0k8orqr/7Cs6Bngm8L0kpwOnApcDOwMrgJ/OcBslSZKmbNqPX6iqjUmeB7wJeD1wXM/q9Ww60iNJkjRrNuvZUlW1keZuqWOTPIjmVvF7gHOr6hcz2D5JkqRp2eIHZ1bVtcC1M9AWSZKkLeaDMyVJUqcYbiRJUqcYbiRJUqcYbiRJUqcYbiRJUqcYbiRJUqcYbiRJUqcYbiRJUqcYbiRJUqcYbiRJUqcYbiRJUqcYbiRJUqcYbiRJUqcYbiRJUqcMPdwkeViSE5OsT3JLkq8l2W0K2x2VpMZ5beiru02SI5JckWRDknOTvHzr9UqSJA3LwmEePMkOwHeBO4FDgALeB5yZZJ+qun2CzT8DnNZXtmNb9vW+8vcC7wDeDfwI+D3ghCQvqqpTt7gjkiRpZAw13ACvA3YHfq2qLgFIch5wMfB64KPjbVhVVwFX9ZYlOYimT8f3lC2lCTbHVNWH2+Izk+wBHAMYbiRJ6pBhX5Z6MbBmLNgAVNXlwPeAl2zG/g4BrgW+1VP2XGBbYFVf3VXA3kkeuRnHkSRJI2rY4WYv4PwB5RcAe05nR0keCjwL+HxVbew7xp3AJX2bXNAup3UcSZI02oYdbnYGbhpQfiOweJr7OoimP8f3le8M3FxVNeAYY+slSVJHDDvcQDOJuF82Yz8HA/9RVecN2Ne0j5Hk0CRnJzn7uuuu24zmSJKkYRh2uLmJwSMnixk8ojNQkt8EHsOmozbQjgIl6Q8zi3vWb6KqPlVVy6pq2ZIlS6baFEmSNGTDDjcX0MyJ6bcncOE09nMIsBH4wjjH2A541IBjMM3jSJKkETfscPN14ElJdh8rSPII4Cls+lk1AyXZluZza06tqkHXj04Dfgm8qq/81cD57d1ZkiSpI4Ydbj4NXAGcnOQlSV4MnAxcCXxyrFKShyfZmGTFgH28iObS1qBLUlTVOmAlcESStyd5ZpK/AfYF/nRGeyNJkoZuqB/iV1W3J9mXJnx8jmaS7xnA4VV1W0/VAAsYHMYOoZk3840JDvVu4DbgMGAX4CLggKpavcWdkCRJIyWb3iGtfsuWLauzzz572M2QJGlWJPlRVS0bdjs217AvS0mSJM0ow40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw42kueu8r8DKx8FR92+W531l2C2SNAIWDrsBkrRZzvsKrH4r3HVH8/X6K5uvAfY5YHjtkjR0jtxImpvOOPp/gs2Yu+5oyiXNa4YbSXPT+qumVy5p3jDcSJqbdnro9MolzRuGG0lz034r4D7b37vsPts35ZLmNcONpLlpnwNg+XGw08OANMvlxzmZWJJ3S0maw/Y5wDAjaROO3EiSpE4x3EiSpE4x3EiSpE4x3EiSpE4x3EiSpE4x3EiSpE4x3EiSpE4x3EiSpE4x3EiSpE4x3EiSpE4x3EiSpE4x3EiSpE4x3EiSpE4x3EiSpE4x3EiSpE4x3EiSpE4x3EiSpE4ZerhJ8rAkJyZZn+SWJF9Lsts0tn9skhOSXJ/kjiQXJTmsr84VSWrA66Uz3yNJkjRMC4d58CQ7AN8F7gQOAQp4H3Bmkn2q6vZJtl/Wbn8W8FpgPfBo4L4Dqn8LOKqv7KItaL4kSRpBQw03wOuA3YFfq6pLAJKcB1wMvB746HgbJtkGOB44o6pe1rPqzHE2ub6q1sxIqyVJ0sga9mWpFwNrxoINQFVdDnwPeMkk2z4T2JMJApAkSZp/hh1u9gLOH1B+AU1wmchT2+WiJGuS3JVkXZLjkmw/oP7yJL9Icmdb3/k2kiR10LDDzc7ATQPKbwQWT7Ltg9vll4HTgecAH6SZe/OFvrqrgbcAzwVeBWwATkry6s1rtiRJGlXDnnMDzSTifpnCdmPBbFVVrWj/fVaSBcAxSfasqgsBquot99p5chKwBvgAsGrQzpMcChwKsNtuU755S5IkDdmwR25uohm96beYwSM6vW5ol9/uKz+9XT5+vA2r6m7gBOChSXYdp86nqmpZVS1bsmTJJE2RJEmjYtjh5gKaeTf99gQunMK2sOnIz9iozz2TbD9Wb9DIkSRJmqOGHW6+Djwpye5jBUkeATylXTeRb9J8Ps7z+sqf2y7PHm/DJAuB3wV+XlXXTK/JkiRplA17zs2ngTcDJyd5D80oynuBK4FPjlVK8nDgUuDoqjoaoKpuSPIB4Mgkt9B8mN8yYAVwfM/n5hxIc1v5qe1+HwS8CXgCcOBsdFKSJM2eoYabqro9yb7ASuBzNJeKzgAOr6rbeqoGWMCmI01HA7cCbwTeAawFPkQTkMZcDixty3cGfgH8EHheVX1rpvskSZKGK1VOOZnMsmXL6uyzx73KJUlSpyT5UVUtG3Y7Ntew59xIkiTNKMONJEnqFMONJEnqFMONJEnqFMONJEnqFMONJEnqFMONJEnqFMONJEnqFMONJEnqFMONJEnqFMONJEnqFMONJEnqFMONJEnqFMONJEnqFMONJKlzTrnsFPY/cX/2OX4f9j9xf0657JRhN0mzaOGwGyBJ0kw65bJTOOr7R7Hh7g0ArL19LUd9/ygAXrj7C4fYMs0WR24kSZ1y7DnH/irYjNlw9waOPefYIbVIs81wI0nqlGtuv2Za5eoew40kqVN22XGXaZWreww3kqROOew3DmPRgkX3Klu0YBGH/cZhQ2qRZpsTiiVJnTI2afjYc47lmtuvYZcdd+Gw3zjMycTziOFGktQ5L9z9hYaZeczLUpIkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVOGHm6SPCzJiUnWJ7klydeS7DaN7R+b5IQk1ye5I8lFSQ7rq7NNkiOSXJFkQ5Jzk7x85nsjSZKGbajhJskOwHeBxwCHAAcBjwbOTLLjFLZfBvw7sB3wWuAFwEeABX1V3wscBXwceD6wBjghyQtmpCOSJGlkLBzy8V8H7A78WlVdApDkPOBi4PXAR8fbMMk2wPHAGVX1sp5VZ/bVWwq8Azimqj48VifJHsAxwKkz1BdJkjQChn1Z6sXAmrFgA1BVlwPfA14yybbPBPZkggDUei6wLbCqr3wVsHeSR06nwZIkabQNO9zsBZw/oPwCmuAykae2y0VJ1iS5K8m6JMcl2b7vGHcCl/Rtf0G7nOw4kiRpDhl2uNkZuGlA+Y3A4km2fXC7/DJwOvAc4IM0c2++0HeMm6uqBhxjbL0kSeqIYc+5AegPHQCZwnZjwWxVVa1o/31WkgXAMUn2rKoL231N+xhJDgUOBdhttynfvCVJkoZs2CM3NzF45GQxg0d0et3QLr/dV356u3x8u7wRWJykP8ws7lm/iar6VFUtq6plS5YsmaQpkiRpVAw73FxAMyem357AhVPYFjYdlRkLMff01NsOeNSAYzCF40iSpDlk2OHm68CTkuw+VpDkEcBT2nUT+SbNROHn9ZU/t12e3S5PA34JvKqv3quB89u7syRJUkcMe87Np4E3AycneQ/NKMx7gSuBT45VSvJw4FLg6Ko6GqCqbkjyAeDIJLfQfBjgMmAFcPzY7eVVtS7JSuCIJLcC5wCvBPZl8tvNJUnSHDPUcFNVtyfZF1gJfI7mktIZwOFVdVtP1dB86nD/SNPRwK3AG2k+qG8t8CGagNTr3cBtwGHALsBFwAFVtXpGOyRJkoYum94hrX7Lli2rs88+e/KKkiR1QJIfVdWyYbdjcw17zo0kSdKMMtxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkqROMdxIkjSHrF+9mov33Y8fP3ZPLt53P9avXj3sJo2chcNugCRJmpr1q1ez9sgV1IYNAGy8+mrWHrkCgJ2WLx9m00aKIzeSJM0R61Z+7FfBZkxt2MC6lR8bUotGk+FGkqQ5YuPatdMqn68MN5IkzRELd911WuXzleFGkqQ5YunbDieLFt2rLIsWsfRthw+pRaPJCcWSJM0RY5OG1638GBvXrmXhrruy9G2HO5m4j+FGkqQ5ZKflyw0zk/CylCRJ6hTDjSRJ6hTDjSRJ6hTDjSRJ6hTDjSRJ6hTDjSRJ6hTDjSRJ6hTDjSRJ6hTDjSRJ6hTDjSRJ6hTDjSRJ6hTDjSRJ6hTDjSRJ6hTDjSRJ6hTDjSRJ6hTDjSRJ6hTDjSRJ6pRU1bDbMPKSXAf8bNjtmEEPBK4fdiNm0XzrL9jn+WC+9RfmX5+H2d+HV9WSIR17ixlu5qEkZ1fVsmG3Y7bMt/6CfZ4P5lt/Yf71eb71dyZ5WUqSJHWK4UaSJHWK4WZ++tSwGzDL5lt/wT7PB/OtvzD/+jzf+jtjnHMjSZI6xZEbSZLUKYabOSjJU5KcnmRdkluSnJPkD/vqPDLJiUluTnJ7kjOTTHnWfZLXJflJkjuTXJTkDTPfk6nb2n1OclaSGvA6fOv0aNL2PCvJvya5I8mNST6X5EED6i1O8pkk17d9/k6Svad4jG2SHJHkiiQbkpyb5OUz35upmaU+XzHO+/zSme/RpG2ZtL9J7pfkw+3/z1vatj5zmscZmXN5Nvo8F8/lJPslWZXk0rbepUn+JsnSKR5jpM7lkVBVvubQC9gHuAM4E3gJ8Bzgk0ABf9TWeQDw38BPgFcCy9v6twKPncIxXgfcA/wF8Czgfe3Xf9ThPp8FnAs8qe+1yxD6+zTgLuAbwAuAg2g+Z+l8YLueegH+BbgKOBB4HvBPNJ+L8dApHOcvgDuBd7Tv8yfb9/kFHe7zFcBpA97nxSPa30cANwLfAb7a/p9/5jSOMzLn8iz2eS6eyycA3wT+AHgG8Fqan2eXAfedwnFG5lweldfQG+Brmm8YvB/4Zf9/eGAN8G/tv98DbAT26Fm/I3At8JVJ9r8QWAcc31f+d+0vkPt0rc9t3bOAfx32+9u25TvAJcDCnrIntj/k39hT9pK27Fk9ZTu1vxiOm+QYS9sfhn/eV34GcF4X+9zWvQJYNYfe4/T8+9lM4xf9qJ3Ls9Hndpu5eC4vGbDt09t6fzjJMUbqXB6Vl5el5p5taf4SuKOv/Gb+5zLjk4CLq+qSsZVVdTvNX7wvSrJwgv0/GVgCrOor/xzN6MhTN7/pm21r93nUPAn4dlVtHCuoqh8CNwAv66n3YuDqqjqzp956YDVNCJjIc2m+r/3v8ypg7ySP3Pzmb5bZ6PMomVJ/q/0ttZlG7VyejT6Pmqn2+boB2/6wXT5kkmOM2rk8Egw3c88/tMvjkjw4yf2TvA7YD1jZrrubZqSj353A9sCjJtj/Xu3y/L7yC9rlntNu8Zb7h3a5tfo85teTrE9yV5LzkrxmSxu+mSbqy+N6vt6LTd8naN6r3ZLcd4Jj7NXu75K+8mG9z7PR5zHLk/yinYOyZhjzbZh6f7fEqJ3Ls9HnMXPtXB7kGe3yx5PUG7VzeSTMpb9mBVTV+e3kupOAN7bFdwFvqKovtV9fBDwnyQOq6gZoJpwBv9mu33mCQ4ytu6mv/MYpbLtVzEKfAf4Z+DzwU+D+wMHAZ5LsWlXvm7HOTM1FNH/x/UqShwO70vR7zM40l1n6jb1Xi4HbxjnGzsDNA/5KHtb7PBt9hmaE54fA5cCDgDcDJyU5qKr6//Ldmqba3y0xaufybPQZ5ua5TF+d+wEfowk2/zjJMUbtXB4JjtzMMUkeTTPJ7gKaSbPPBj4BfCLJq9pqn6B5bz+b5FFJdgWOA8aGJ++Z6BDtcmSGhmehz1TViqr6dFX9U1WdXFUvp/mh8u4pjgbMpGOB30zyviRLkzyG5lLCPdy7H2Hw+5QBZYPqbO62W8Ns9JmqektVfbaq/qWqTqQZ/Tsb+MCWNX/aptrfLTFq5/Js9Hmunsu/0l5C/yLN5ajf672kNY5RO5dHguFm7nk/TeJ/UVV9o6rOqKq3Al8Bjk2yTVVdBrwKeALNUOXVNNffxy7hrJ1g/+Ol/Z371s+mrd3n8XwRWARM6TbjmVJVn6e5q+WPaSZEX0hz58Sp3LsfNzL4r7LF7bL/L/ZeNwKLk/T/AFzcs37WzFKfBx33bpo7VR7aBuJZMY3+bomROpdnqc/jGfVzGfjVaPPxNH/AvbSqzpvCYUbqXB4Vhpu5Z2/g3KrqH9L8Ac0kwaUAVfVVmuS/J80dRE8A7gtcWVU/n2D/Y9dp9+orH7tue+EWtH1zbe0+j2dof/lW1ZHAA2lug9+1qg4EHg38a0+1C9j0fYKm/z+vqokuz1wAbMemc5GG9j7PQp/HM5T3eYr93RIjdy7PQp/HM+rn8phP0HyUxe9V1RlTPMTIncsjYdi3a/ma3ovmNsfLgG37yr9AczfRtuNs92CaBH/EJPu/D3Ad8Pd95Z+hmeE/cP9zuc8THPdk4BfAjiPwvj+P5gfzb/eUvbQte0ZP2f9q36e/mmR/Y7eP/llf+XeA/xp2f7dGn8c5xkKay1I/G8X+9q2f7q3gI3cub+0+T3CckT6X2/KP0FyqOmia+xv5c3kYLycUzz0fpxlGX53kr2l+ub+Y5gPNVlbVL5PcB/ggzYeb3ULzl9sRNAn/I707S3IJzQ/2/QCq6q4kRwJ/neS/aU6QfYE/BN5SVYNm/m9tW7XPSZ4GvAv4Gs1k1Z2AQ9pjvKuaW8pnTZJfB54PnNMWPRV4J/DBqvp+T9WvA/8GrEryTppLMkfQ/JX6wb59bqT5vJPXAFTVuiQrgSOS3Noe65U07/Ws31I9G31OciBN304FrqSZUPwmmkuZB26dng02jf6S5Pk0n9k0dknlGUkeCNxeVd/sqTfS5/Js9HmunstJ/gR4O81nEF2cpHcS8nVVdWlP3ZE+l0fGsNOVr+m/aE6Ws2j+KrsV+E+au4gWtOsX0nwi5rU0if5Smuu+OwzY1xXAWQPKX09zt8GdwMX0fOBU1/oM7EHz6aD/3W57G/B94MAh9XUvmiHrm2mC3DnAH4xTd2eaH4g30vxlegbwvwfUK+Af+soW0Hz44c/afp8HvKKrfaa5a+W77f+Ru4D1NL/wnzvi/b2i7Uv/64qJ/l/3lI/EuTwbfZ6r5zLNz7ZB/R103o70uTwqL58KLkmSOsUJxZIkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN5IkqVMMN9IclqSm8Lpiho/5iiRv3Yztnt2256r2GTqStFX4CcXS3Pbkvq9PAs4Fjuopu3OGj/kKYBnNU9en45B2+RCap3F/eyYbJUljDDfSHFZVa3q/TnIncH1/+bAluS/wOzSfJvw0mqAzcuEmyXZVNdNhUNIsc2hYmkfaS0NnJbmtfZ2S5LF9dV6UZE2SW5LcmuTHSd7VrvsSzXNrHtVz2esnUzj07wI7AMcCq4GXJbnfgPbdL8mHk1yW5M4ka5OckOQBPXX2SPKFJOuSbEhyaZIP9axfk+S0Afu+Jskner5+Q9v+Jyc5Kcl6mmeT0VN2VZI7kvwkyZ8n2W7Afg9oj3l7+z1bk+T5afw0yRcHbPO89tjPmML3TtI0OXIjzRNJfofmAaQnAf+H5nk0RwD/nGSfqlqb5DE0Dx38AvBnwEbg0cDD2t28B3gA8BiawALNM3MmcwjNc8G+SfOQy5fTXN76+572LQLObPf9fuAHwGKa54r9L+CGJI8G/p3mWT1/SvO0+IcDz5zWN+PevgysonlA64K27BHAD4G/pXk+0d7AivZYv9/T5ncAH6L5fgyRVAAABGVJREFUvv4lzffiCcDDq6raMPWBJEuq6rqeY74e+ElV/dMWtFvSeIb9cCtfvnzN3IvmQYKrBpRvQ/Mk7FP7ynemCQrHtF+/GrgH2G6CY3wJuGQabXpEu89j268XAuvoe8gjzYNQiwkeZAl8pW3vkgnqrAFOG1B+DfCJnq/f0B7vA5O0P22bX0sT9u7Xlj+AJsx8YYJtF9M83POdPWUPpnlw5+HD/v/iy1dXX16WkuaHvYCHAquSLBx7AbfQjFA8va13Dk0QOSHJ7yR54Awc+2CagPBZgKraSDMy9PQkj+iptz/ws6r61gT72h/4x7r3KMiWOqm/IMniJB9JchnNhOy7gE/TjOw8qq32NGAR8KnxdlxVN9GEwUOTpC1+DU1I+uyM9UDSvRhupPlhabv8PM0v6t7Xs2lGIaiqC2kuAy2iCSDXJvlekqdswbEPBi4GLk1y/yT3B06mCTwH9dR7AHDVeDtJsgDYaaI6m2ntgLJVwB8AK2m+P08E3t6uW9Qux+YBTdae/wfsAezX3gL/WuArVXXjljRa0viccyPNDze0yz8G/nnA+g1j/6iqbwPfbufAPBX4C+DUJLtV1frpHDTJU/mfkY6bBlQ5GHhv++/rgcePt6+qujvJzTS3kk9kA7BtXzu2Ae4/3q776t6PJuD936r6q57yJ/Ztd327fAhwyQTt/lGSH9LMs1kE7AZ8cpI+SNoChhtpfvgv4GrgsVX10alsUFUbgO8k2Zlm0u1u7X7uBLaf4nEPobnM9VLg1r51y4G3J/ntqvo+cDrw0iTPaQPWIKfT3Gn1zqq6fpw6PwOek2RBVd3dlj0b2OROp3HsQDOqdNdYQXtJ6ZC+ev9CM+fmUNq7rCbw1zSXrx4C/FfbX0lbieFGmgfaUY8308yl2QH4Ks1ozi7AU4CfVtXH208efiJwGs3lliU0dyX9HBi75ftC4OAkrwHOA35RVRf0HzPJ9jR3VJ1eVasHrL8QeAtNaPg+zZ1TrwG+muT9NHOBdqIZRXl/VV1Oc7fW/sCaJB+guVvqYcC+VfX77a6/RDMi9Jkkn6e5JPRW4PYpfq+uTfKfwLuSXE8zgflQ4IF99W5MsgL4UDsy9GWaycO/Dqyvqk/0VP8S8BGaD11801TaIWnzOedGmieq6iTgWTR3SP0t8C3gGJpf2j9oq/0HzeWbv6QZJTkO+DGwX1WNjWT8DXAizS/rH9AEpUFeShNO/m6c9qyj+cybVyZZ1I4U7du27Y00t41/nOY28PXtNhcDv0Uz8fmDbZ0VwLU9+/0mTZh5erv/VwEH0tzSPVW/SzNK9cm2/ZcD7xzQhw/T3Fa/B/BFmlvCX9LW7623AfgGTcBaNY12SNoMqarJa0mSNluSbWlu0z+lql435OZInedlKUnaSpLsBDyO5tLbUpq7ryRtZYYbSdp6nkxz6ewa4I3trfaStjIvS0mSpE5xQrEkSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeoUw40kSeqU/w89WOYTYNk/MwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lognorm (WeightWatcher)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "\n",
    "\n",
    "for mf in [df_vgg11, df_vgg13, df_vgg16, df_vgg19]:\n",
    "#for mf in [df_vgg11, df_vgg13]:\n",
    "    x = mf['acc5'].values\n",
    "    y = mf['lognorm'].values\n",
    "    label = mf['legend'].values[0]\n",
    "    plt.scatter(x,y,label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r\"Test Accuracy vs Average Alpha Log Max Eigenvalue $\\hat{\\alpha}$\"+\"\\nPretrained VGG and VGG_BN Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\hat{\\alpha}$\")\n",
    "#plt.savefig(\"img/vgg-w_alphas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:46:45.696797Z",
     "start_time": "2018-11-26T22:46:44.483163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lognorm compound (WeightWatcher)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "\n",
    "\n",
    "for mf in [df_vgg11, df_vgg13, df_vgg16, df_vgg19]:\n",
    "#for mf in [df_vgg11, df_vgg13]:\n",
    "    x = mf['acc5'].values\n",
    "    y = mf['lognorm_compound'].values\n",
    "    label = mf['legend'].values[0]\n",
    "    plt.scatter(x,y,label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r\"Test Accuracy vs Average Alpha Log Max Eigenvalue $\\hat{\\alpha}$\"+\"\\nPretrained VGG and VGG_BN Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\hat{\\alpha}$\")\n",
    "#plt.savefig(\"img/vgg-w_alphas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:46:53.385503Z",
     "start_time": "2018-11-26T22:46:53.329899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>platform</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc5</th>\n",
       "      <th>modelname</th>\n",
       "      <th>avg_w_alphas</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>alpha_weighted_compound</th>\n",
       "      <th>alpha</th>\n",
       "      <th>alpha_compound</th>\n",
       "      <th>lognorm</th>\n",
       "      <th>lognorm_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ResNet101</td>\n",
       "      <td>Pytorch</td>\n",
       "      <td>77.438</td>\n",
       "      <td>93.672</td>\n",
       "      <td>resnet101</td>\n",
       "      <td>-0.614044</td>\n",
       "      <td>1</td>\n",
       "      <td>0.087516</td>\n",
       "      <td>2.534792</td>\n",
       "      <td>2.943638</td>\n",
       "      <td>0.430459</td>\n",
       "      <td>0.622483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model platform    acc1    acc5  modelname  avg_w_alphas  num_layers  \\\n",
       "35  ResNet101  Pytorch  77.438  93.672  resnet101     -0.614044           1   \n",
       "\n",
       "    alpha_weighted_compound     alpha  alpha_compound   lognorm  \\\n",
       "35                 0.087516  2.534792        2.943638  0.430459   \n",
       "\n",
       "    lognorm_compound  \n",
       "35          0.622483  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['modelname']=='resnet101']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "\n",
    "Only exception is InceptionResNetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:47:14.868799Z",
     "start_time": "2018-11-26T22:47:13.400394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89.274] [0.39066619]\n",
      "[91.456] [-0.42858589]\n",
      "[92.98] [0.03924751]\n",
      "[93.672] [-0.6140441]\n",
      "[94.11] [-0.80216393]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WeightWatcher\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10,10]\n",
    "\n",
    "x, y = [], []\n",
    "\n",
    "modelnames = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']\n",
    "\n",
    "for name in modelnames:\n",
    "    if 'resnet' in name:\n",
    "        mf = df[df.modelname==name]\n",
    "        x = mf['acc5'].values\n",
    "        y = mf['avg_w_alphas'].values\n",
    "        print(x,y)\n",
    "\n",
    "        if np.abs(y) > 0:\n",
    "            plt.scatter(x,y, label=name)\n",
    "        \n",
    "plt.title(r\"Test Accuracy vs Average Alpha X Log Max Eigenvalue $\\hat{\\alpha}$\"+\"\\nPretrained (pyTorch default) ResNet Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\hat{\\alpha}$\")\n",
    "plt.legend()\n",
    "#plt.savefig(\"img/resnet-pytorch-w_alphas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T21:35:06.389243Z",
     "start_time": "2018-10-22T21:35:05.094966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89.274] [0.61067626]\n",
      "[91.456] [-0.39365554]\n",
      "[92.98] [0.1403913]\n",
      "[93.672] [-0.61647061]\n",
      "[94.11] [-0.78980838]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Original notebook\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10,10]\n",
    "\n",
    "x, y = [], []\n",
    "\n",
    "modelnames = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152']\n",
    "\n",
    "for name in modelnames:\n",
    "    if 'resnet' in name:\n",
    "        mf = df[df.modelname==name]\n",
    "        x = mf['acc5'].values\n",
    "        y = mf['avg_w_alphas'].values\n",
    "        print(x,y)\n",
    "\n",
    "        if np.abs(y) > 0:\n",
    "            plt.scatter(x,y, label=name)\n",
    "        \n",
    "plt.title(r\"Test Accuracy vs Average Alpha X Log Max Eigenvalue $\\hat{\\alpha}$\"+\"\\nPretrained (pyTorch default) ResNet Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\hat{\\alpha}$\")\n",
    "plt.legend()\n",
    "#plt.savefig(\"img/resnet-pytorch-w_alphas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:48:54.728369Z",
     "start_time": "2018-11-26T22:48:53.446506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Weightwatcher\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "\n",
    "x, y = [], []\n",
    "\n",
    "for name in df.modelname: \n",
    "    if 'densenet' in name and 'resnet' not in name:\n",
    "        #print(name)\n",
    "        mf = df[df.modelname==name]\n",
    "        x = mf['acc5'].values\n",
    "        y = mf['avg_w_alphas'].values\n",
    "        if np.abs(y) > 0:\n",
    "            plt.scatter(x,y, label=name)\n",
    "        \n",
    "plt.title(r\"Test Accuracy vs Average Alpha X Log Max Eigenvalue $\\hat{\\alpha}$\"+\"\\nPretrained DenseNet  Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\hat{\\alpha}$\")\n",
    "plt.legend()\n",
    "#plt.savefig(\"img/densenet-pytorch-w_alphas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T21:35:25.148462Z",
     "start_time": "2018-10-22T21:35:24.032914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Original notebook\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8,8]\n",
    "\n",
    "x, y = [], []\n",
    "\n",
    "for name in df.modelname: \n",
    "    if 'densenet' in name and 'resnet' not in name:\n",
    "        #print(name)\n",
    "        mf = df[df.modelname==name]\n",
    "        x = mf['acc5'].values\n",
    "        y = mf['avg_w_alphas'].values\n",
    "        if np.abs(y) > 0:\n",
    "            plt.scatter(x,y, label=name)\n",
    "        \n",
    "plt.title(r\"Test Accuracy vs Average Alpha X Log Max Eigenvalue $\\hat{\\alpha}$\"+\"\\nPretrained DenseNet  Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\hat{\\alpha}$\")\n",
    "plt.legend()\n",
    "#plt.savefig(\"img/densenet-pytorch-w_alphas.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNeXt, SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T22:49:40.655947Z",
     "start_time": "2018-11-26T22:49:39.370104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squeezenet1_0\n",
      "squeezenet1_1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Weightwatcher\n",
    "\n",
    "for mf in [df_squeezenet]:\n",
    "    for ix in [1,0]:\n",
    "        x = mf['acc5'].values[ix]\n",
    "        y = mf['avg_w_alphas'].values[ix]\n",
    "        label = mf.modelname.values[ix] # mf['legend'].values[ix]\n",
    "        print(label)\n",
    "        color =  'red' if ix==0  else 'orange' \n",
    "        plt.scatter(x,y,label=label, color=color)\n",
    "        \n",
    "plt.legend()\n",
    "plt.title(r\"Test Accuracy vs Average Alpha X Log Max Eigenvalue $\\hat{\\alpha}$\"+\"\\nPretrained SqueezeNet Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\hat{\\alpha}$\")\n",
    "#plt.savefig(\"img/squeezenet-pytorch-w_alphas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T21:35:31.084991Z",
     "start_time": "2018-10-22T21:35:29.394671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squeezenet1_0\n",
      "squeezenet1_1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Original notebook\n",
    "\n",
    "for mf in [df_squeezenet]:\n",
    "    for ix in [1,0]:\n",
    "        x = mf['acc5'].values[ix]\n",
    "        y = mf['avg_w_alphas'].values[ix]\n",
    "        label = mf.modelname.values[ix] # mf['legend'].values[ix]\n",
    "        print(label)\n",
    "        color =  'red' if ix==0  else 'orange' \n",
    "        plt.scatter(x,y,label=label, color=color)\n",
    "        \n",
    "plt.legend()\n",
    "plt.title(r\"Test Accuracy vs Average Alpha X Log Max Eigenvalue $\\hat{\\alpha}$\"+\"\\nPretrained SqueezeNet Models\")\n",
    "plt.xlabel(r\"Test Accuracy\")\n",
    "plt.ylabel(r\"$\\hat{\\alpha}$\")\n",
    "#plt.savefig(\"img/squeezenet-pytorch-w_alphas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {
    "52ecdae62c394a67868cd3ee83e19861": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "e232317699e24554b5ed09fa6c78c662": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
