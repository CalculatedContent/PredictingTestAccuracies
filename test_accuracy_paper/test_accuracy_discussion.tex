\vspace{-2mm}
\section{Discussion and Conclusion}
\label{sxn:discussion}
\vspace{-1mm}

We have presented an \emph{unsupervised} capacity control metric which predicts trends in test accuracies of a trained DNN---without peeking at the test data. 
In the interests of space, see Appendix~\ref{sxn:appendix-addl-discussion} for additional discussion.
We conclude by observing simply that 
%We expect our result will have applications in the fine-tuning of DNN hyperparameters as well as related challenges.
%Moreover, because we do not need to peek at the test data, our approach may prevent information from leaking from the test set into the model, thereby helping to prevent overtraining and making fined-tuned DNNs more robust.
%Finally, 
our work also leads to a much harder theoretical question: is it possible to characterize properties of realistic DNNs to determine whether a DNN is overtrained---without peeking at the test data?  


