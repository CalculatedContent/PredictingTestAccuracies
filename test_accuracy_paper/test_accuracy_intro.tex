%\vspace{-4mm}

\section{Introduction}
\label{sxn:intro}

Given two or more Deep Neural Networks (DNNs) with the same or similar architectures, and trained on the same dataset, but trained with different solvers, parameters, hyper-parameters, regularization, etc., can we predict which DNN will have the best test accuracy, and can we do so without peeking at the test data?   

Solving this question of generalization would have both theoretical impact and great practical importance. 
With respect to the former, solving this would help to understand why this class of machine learning (ML) models performs as well as it does in certain classes of applications.
With respect to the latter, there are many motivating examples.
% 
Here are several.
\begin{itemize}
\item
\textbf{Automating architecture search.}
Developing DNN models often requires significant architecture engineering, so there is interest in automating the design of DNN models, such as with AutoML \cite{AutoML}.
%Having principles that for the design of good models---in particular metrics that do not require much or any labeled data, thus minimizing the risk of label leakage---is of interest.
\michael{Charles, tweak this and add a sentence or two for context.}
\charlesX{Current methods can produce a series of DNNs across a given general architecture  constraints, however,  the models must be evaluated using cross validation (CV).
 DNNs have so many adjustable parameters  that even using CV it is possible to leak information from the test sets into the training data, thus producing brittle, non-robust models.
It is thus of interest to have design principles and quality metrics that do not depend on the test data and/or the labels.  }
\item
\textbf{Pre-training on smaller data.}
It is often of interest to train a smaller model on a smaller quantity of data before training a full model on a the full set of data.
Current methods to extend these smaller models to full-scale production models are brittle and require extensive cross-validation, and it is of interest to have principles to guide the design of such classes of models.
\michael{Charles, tweak this and add a sentence or two for context.}
\charles{We might scratch this...see below}
\item
\textbf{Fine Tuning Pre-trained Models.}
\item
\textbf{DNN Optimizing Compilers.}
\item
\textbf{Unsupervised Deep Learning}
\end{itemize}

To address our main question, we will build upon and combine two seemingly-unrelated lines of recent work.
The first is that of Martin and Mahoney~\cite{MM17_TR,MM18_TR}, which considered Heavy-Tailed (HT) Universality methods from Statistical Physics to analyze weight matrices constructed from large-scale pre-trained DNNs.
The second is that of Liao et al.~\cite{LMBx18_TR}, which used norm-based capacity control metrics to bound the worst-case generalization error for several small (non production-quality, but still of academic interest) DNN models.

Based on these ideas, we develop a Universal capacity control metric that is a weighted average of the fitted layer Power Law (PL) exponents of various layer weight matrices constructed from the DNN, where the weights depend on the log of the spectral norm of the correlations between layer weight matrices; and we show this metric can be approximated by the average of the log of the Frobenius norm of the weight matrices.
Rather than considering bounds on the worst-case generalization accuracy for small toy NNs, we show that this metric predicts trends in the average case generalization performance for large-scale pre-trained DNNs.

To place these results in context, recall that the work of Martin and Mahoney~\cite{MM18_TR} showed that the empirical spectral density (ESD) of DNN layer matrices for nearly every large-scale pre-trained DNN displays HT behavior, e.g., that it is well-fit by a PL distribtion, and that smaller PL exponents correspond to better implicit Self-Regularization and generalization quality.
Motived by these empirical observations, and using the Universality properties of Heavy-Tailed Random Matrix Theory (HT-RMT), they developed a Theory of Heavy-Tailed Self-Regularization (HT-SR) for DNNs~\cite{MM17_TR,MM18_TR}.
In the Statistical Physics analysis of complicated systems (e.g., many physical systems, but also well-trained NNs~\cite{EB01_BOOK,nishimori01}), Universality of PL exponents is very special and suggests the presence of a deeper, underlying mechanism driving the system~\cite{SornetteBook,BouchaudPotters03}.% 
\footnote{Perhaps the most well-known form of Universality is associated with the Gaussian Universality class, where the sum of many random variables drawn from a wide range of distributions is ``approximately Gaussian,'' e.g., in the sense that the sum approaches a suitably-normalized Gaussian distribution.  As briefly reviewed in Section~\ref{sxn:theory-review}, HT Universality makes analogous (but, admittedly, more complicated) statements for random variables drawn from distributions in which the tails decay more slowly than those in the Gaussian Universality class~\cite{MM18_TR}.}
It is this Universality that originally motivated our study.

This Universality \emph{suggests} that we look for a Universal capacity control metric.%
\footnote{To be clear, this metric is Universal, not in the sense that it will apply ``universally'' to every possible DNN, but in the Statistical Physics sense~\cite{SornetteBook,BouchaudPotters03} that it should apply to matrices within/across HT ``Universality''~classes.}
A natural candidate for this is the weighted sum of PL exponents of various matrices constructed from the DNN, where the weights encode information that ``larger'' matrices are somehow more important.
(See Eqn.~(\ref{eqn:alpha_hat_generic}) below.)
A HT Universality argument then leads to an expression that suggests that the weights should be the log of the spectral norm of the correlations between layer weight matrices.
(See Eqn.~(\ref{eqn:basic_relation}) below.)
Importantly, we show this can be approximated by the average of the log of the Frobenius norm of the layer weight matrices.

Relating the fitted PL exponent to the Frobenius norm provides an interesting connection with the large body of work on norm-based capacity control metrics. 
There is recent work along these lines, e.g.,~\cite{LMBx18_TR, SHNx17_TR,PLMx18_TR} and~\cite{NTS14_TR,NTS15,NBMS17_TR,BFT17_TR,YM17_TR,KKB17_TR,NBS17_TR,AGNZ18_TR,ACH18_TR,ZF18_TR},
but there is also much older work~\cite{Bar97,MN09_TR}.
Much of this work has been motivated by the observation that parameter counting and more traditional VC-based bounds tend to lead to vacuous results for modern state-of-the-art DNNs, e.g., since modern DNNs are heavily over-parameterized and depend so strongly on the training data.
Perhaps the most related example from this line of work is that of Liao et al.~\cite{LMBx18_TR}, who use an appropriately-scaled Product Norm to provide tight bounds on generalization accuracy.
Unlike their result, however, our approach does not require modifying the loss function.
Moreover, their approach and their intent are a bit different: they seek a \emph{worst-case} complexity bound, to reconcile discrepancies with more traditional statistical learning theory, and they apply it to quite small NNs; but we seek an \emph{average-case} complexity metric that can be used in production to guide the development of better DNNs at scale.

In summary, our main results are the following:
\begin{itemize}
\item
We introduce a methodology to analyze the performance of large-scale pre-trained DNNs.
Our approach is based on Statistical Physics (in particular, the concept of Universality underlying HT-SR and related HT-RMT techniques), and it involves constructing a Universal capacity control metric to predict average DNN test performance.
This metric is a weighted linear combination of PL exponents, where the coefficients are the spectral norm of correlation matrices constructed from DNN weight matrices.
\item
We apply our Universal capacity control metric to a wide range of large-scale pre-trained production-level DNNs, including the VGG and ResNet series of models.
This Universal metric predicts well the average test error in large-scale DNNs (without the need for re-training or looking at test data, although one could use the metrics as a training diagnostic).
\item
We demonstrate a connection between our Universal capacity control metric and a norm-based capacity control metric that depends on the average Frobenius norm of layer weight matrices.
We also show that (in addition to providing worst-case bounds on generalization quality for rather small NNs) such norm-based capacity control metrics can also predict well the average test error in large-scale production-level pre-trained DNNs.
\end{itemize}
For both our Universal metric and the Product Norm metric, our empirical results are, to our knowledge, the first time such theoretical capacity metrics have been reported to predict (trends in) the test accuracy for \emph{pre-trained production-level} DNNs.
In particular, this illustrates the usefulness of these norm-based metrics beyond smaller models such as MNIST, CIFAR10, and CIFAR100. 
Our 
results, including for both our Universal metric and the Product Norm metric we consider, can be reproduced with the \texttt{WeightWatcher} package~\cite{weightwatcher_pagkage}; and our
results suggest that our ``practical theory'' approach is fruitful more generally for engineering good algorithms for realistic large-scale DNNs.


